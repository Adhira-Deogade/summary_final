{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from tensorflow.core.example import example_pb2\n",
    "from importlib import reload\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import struct\n",
    "import csv\n",
    "import batch; reload(batch)\n",
    "import data; reload(data)\n",
    "import model; reload(model)\n",
    "\n",
    "from batch import Example,Batch\n",
    "from data import Vocab\n",
    "from model import SummarizationModel\n",
    "from decode import BeamSearchDecoder\n",
    "from batcher import Batcher\n",
    "import util\n",
    "import training_util as tutil\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_params():\n",
    "    hps_dict = {\n",
    "        'mode' : 'train',\n",
    "        'single_pass' : False,\n",
    "        'log_root' : '/home/ubuntu/W266/final_0/W266_Final/model_3/saved/train',\n",
    "        'exp_name' : '',\n",
    "        'hidden_dim' : 200,\n",
    "        'emb_dim' : 128,\n",
    "        'batch_size' : 100,\n",
    "        'max_enc_steps' : 400,\n",
    "        'max_dec_steps' : 100,\n",
    "        'beam_size' : 4,\n",
    "        'min_dec_steps' : 35,\n",
    "        'vocab_size' : 50000,\n",
    "        'lr' : 0.15,\n",
    "        'adagrad_init_acc' : 0.1,\n",
    "        'rand_unif_init_mag' : 0.02,\n",
    "        'trunc_norm_init_std' : 1e-4,\n",
    "        'max_grad_norm' : 2.0,\n",
    "        'pointer_gen' : False,\n",
    "        'coverage' : False,\n",
    "        'cov_loss_wt' : 1.0,\n",
    "        'convert_to_coverage_model' : False,\n",
    "        'vocab_path' : '/home/ubuntu/W266/final_0/W266_Final/data/final_processed/vocab',\n",
    "        'data_path' : '/home/ubuntu/W266/final_0/W266_Final/data/final_chunked/train_*'\n",
    "    }\n",
    "    \n",
    "    hps = namedtuple(\"HParams\", hps_dict.keys())(**hps_dict)\n",
    "    return hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = setup_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hps,epochs,train_step,curr_best,best_loss,avg_loss,restore,epoch_start):\n",
    "    \n",
    "    lm,vocab,batches,train_dir = tutil.training_init(hps)\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        initializer = tf.global_variables_initializer()\n",
    "        \n",
    "    with tf.Session(graph=lm.graph) as session:\n",
    "        \n",
    "        session.run(initializer)\n",
    "        saver = tf.train.Saver(max_to_keep=3) # keep 3 checkpoints at a time\n",
    "        sv = tf.train.Supervisor(logdir=train_dir,\n",
    "                                 is_chief=True,\n",
    "                                 saver=saver,\n",
    "                                 summary_op=None,\n",
    "                                 save_summaries_secs=30, \n",
    "                                 save_model_secs=30, \n",
    "                                 global_step=lm.global_step)    \n",
    "\n",
    "        summary_writer = sv.summary_writer\n",
    "        \n",
    "        if restore:\n",
    "            ckpt_path = util.load_ckpt(saver, session,hps,hps.log_root)\n",
    "\n",
    "        start_time = time.time()\n",
    "        for i in range(epoch_start,epoch_start+epochs):\n",
    "            print(f\"[EPOCH {i+1}] Starting training..\")\n",
    "            random.shuffle(batches)\n",
    "            avg_loss,curr_best,train_step = tutil.run_epoch(lm,\n",
    "                                                            session,\n",
    "                                                            batches,\n",
    "                                                            summary_writer,\n",
    "                                                            train_dir,\n",
    "                                                            train_step,\n",
    "                                                            saver,\n",
    "                                                            hps,\n",
    "                                                            best_loss,\n",
    "                                                            avg_loss)\n",
    "            \n",
    "            if(best_loss is None or curr_best < best_loss):\n",
    "                best_loss = curr_best\n",
    "            print(f\"[EPOCH {i+1}] Complete. Avg Loss: {avg_loss}; Best Loss: {best_loss}\")\n",
    "        sv.stop()\n",
    "        time_total = tutil.pretty_timedelta(since=start_time)\n",
    "        print(f\"[END] Training complete: Best Loss: {best_loss}; Total time: {time_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: incorrectly formatted line in vocabulary file: 0800 555 111 252\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 1800 333 000 110\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 2 1/2 76\n",
      "\n",
      "\n",
      "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
      "Finished constructing vocabulary of 50000 total words. Last word added: 16:03\n",
      "INFO:tensorflow:Fetching data..\n",
      "INFO:tensorflow:Creating batches..\n",
      "INFO:tensorflow:[TOTAL Batches]  : 2808\n",
      "INFO:tensorflow:[TOTAL Examples] : 280778\n",
      "INFO:tensorflow:Creating batches..COMPLETE\n",
      "INFO:tensorflow:Building core graph...\n",
      "INFO:tensorflow:Adding attention_decoder timestep 0 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 1 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 2 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 3 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 4 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 5 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 6 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 7 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 8 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 9 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 10 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 11 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 12 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 13 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 14 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 15 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 16 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 17 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 18 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 19 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 20 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 21 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 22 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 23 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 24 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 25 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 26 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 27 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 28 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 29 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 30 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 31 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 32 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 33 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 34 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 35 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 36 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 37 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 38 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 39 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 40 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 41 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 42 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 43 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 44 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 45 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 46 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 47 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 48 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 49 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 50 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 51 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 52 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 53 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 54 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 55 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 56 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 57 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 58 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 59 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 60 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 61 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 62 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 63 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 64 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 65 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 66 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 67 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 68 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 69 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 70 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 71 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 72 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 73 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 74 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 75 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 76 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 77 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 78 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 79 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 80 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 81 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 82 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 83 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 84 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 85 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 86 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 87 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 88 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 89 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 90 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 91 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 92 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 93 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 94 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 95 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 96 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 97 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 98 of 100\n",
      "INFO:tensorflow:Adding attention_decoder timestep 99 of 100\n",
      "INFO:tensorflow:Building core graph...COMPLETE\n",
      "INFO:tensorflow:Building train graph...\n",
      "INFO:tensorflow:Building train graph...COMPLETE\n",
      "WARNING:tensorflow:From <ipython-input-5-f4099322d632>:18: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "[EPOCH 1] Starting training..\n",
      "    [batch 1]: seen 100 examples : 5.9 eps, Loss: 10.820, Avg loss: 10.820, Best loss: 10.820\n",
      "    [batch 8]: seen 800 examples : 29.0 eps, Loss: 10.790, Avg loss: 10.819, Best loss: 10.819\n",
      "    [batch 15]: seen 1500 examples : 39.5 eps, Loss: 10.762, Avg loss: 10.816, Best loss: 10.816\n",
      "    [batch 22]: seen 2200 examples : 45.5 eps, Loss: 10.734, Avg loss: 10.811, Best loss: 10.811\n",
      "    [batch 29]: seen 2900 examples : 49.3 eps, Loss: 10.708, Avg loss: 10.805, Best loss: 10.805\n",
      "    [batch 36]: seen 3600 examples : 51.9 eps, Loss: 10.684, Avg loss: 10.797, Best loss: 10.797\n",
      "    [batch 43]: seen 4300 examples : 53.9 eps, Loss: 10.658, Avg loss: 10.788, Best loss: 10.788\n",
      "    [batch 50]: seen 5000 examples : 55.3 eps, Loss: 10.633, Avg loss: 10.778, Best loss: 10.778\n",
      "    [batch 57]: seen 5700 examples : 56.5 eps, Loss: 10.607, Avg loss: 10.768, Best loss: 10.768\n",
      "    [batch 64]: seen 6400 examples : 57.4 eps, Loss: 10.591, Avg loss: 10.756, Best loss: 10.756\n",
      "    [batch 71]: seen 7100 examples : 58.2 eps, Loss: 10.571, Avg loss: 10.744, Best loss: 10.744\n",
      "    [batch 78]: seen 7800 examples : 58.9 eps, Loss: 10.542, Avg loss: 10.731, Best loss: 10.731\n",
      "    [batch 85]: seen 8500 examples : 59.5 eps, Loss: 10.498, Avg loss: 10.716, Best loss: 10.716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 92]: seen 9200 examples : 60.0 eps, Loss: 10.440, Avg loss: 10.700, Best loss: 10.700\n",
      "    [batch 99]: seen 9900 examples : 60.5 eps, Loss: 10.208, Avg loss: 10.676, Best loss: 10.676\n",
      "    [batch 106]: seen 10600 examples : 60.8 eps, Loss: 9.626, Avg loss: 10.610, Best loss: 10.610\n",
      "    [batch 113]: seen 11300 examples : 61.0 eps, Loss: 8.960, Avg loss: 10.507, Best loss: 10.507\n",
      "    [batch 120]: seen 12000 examples : 61.4 eps, Loss: 8.526, Avg loss: 10.386, Best loss: 10.386\n",
      "    [batch 127]: seen 12700 examples : 61.7 eps, Loss: 8.517, Avg loss: 10.257, Best loss: 10.257\n",
      "    [batch 134]: seen 13400 examples : 61.9 eps, Loss: 8.111, Avg loss: 10.121, Best loss: 10.121\n",
      "    [batch 141]: seen 14100 examples : 62.1 eps, Loss: 7.961, Avg loss: 9.987, Best loss: 9.987\n",
      "    [batch 148]: seen 14800 examples : 62.4 eps, Loss: 7.914, Avg loss: 9.854, Best loss: 9.854\n",
      "    [batch 155]: seen 15500 examples : 62.6 eps, Loss: 8.096, Avg loss: 9.726, Best loss: 9.726\n",
      "    [batch 162]: seen 16200 examples : 62.7 eps, Loss: 7.856, Avg loss: 9.600, Best loss: 9.600\n",
      "    [batch 169]: seen 16900 examples : 62.9 eps, Loss: 7.907, Avg loss: 9.481, Best loss: 9.481\n",
      "    [batch 176]: seen 17600 examples : 63.1 eps, Loss: 7.833, Avg loss: 9.367, Best loss: 9.367\n",
      "    [batch 183]: seen 18300 examples : 63.2 eps, Loss: 7.734, Avg loss: 9.260, Best loss: 9.260\n",
      "    [batch 190]: seen 19000 examples : 63.3 eps, Loss: 7.715, Avg loss: 9.152, Best loss: 9.152\n",
      "    [batch 197]: seen 19700 examples : 63.5 eps, Loss: 7.611, Avg loss: 9.054, Best loss: 9.054\n",
      "    [batch 204]: seen 20400 examples : 63.6 eps, Loss: 7.472, Avg loss: 8.958, Best loss: 8.958\n",
      "    [batch 211]: seen 21100 examples : 63.7 eps, Loss: 7.620, Avg loss: 8.866, Best loss: 8.866\n",
      "    [batch 218]: seen 21800 examples : 63.8 eps, Loss: 7.596, Avg loss: 8.782, Best loss: 8.782\n",
      "    [batch 225]: seen 22500 examples : 63.9 eps, Loss: 7.694, Avg loss: 8.700, Best loss: 8.700\n",
      "    [batch 232]: seen 23200 examples : 64.0 eps, Loss: 7.507, Avg loss: 8.623, Best loss: 8.623\n",
      "    [batch 239]: seen 23900 examples : 64.1 eps, Loss: 7.507, Avg loss: 8.547, Best loss: 8.547\n",
      "    [batch 246]: seen 24600 examples : 64.1 eps, Loss: 7.517, Avg loss: 8.478, Best loss: 8.478\n",
      "    [batch 253]: seen 25300 examples : 64.2 eps, Loss: 7.578, Avg loss: 8.412, Best loss: 8.412\n",
      "    [batch 260]: seen 26000 examples : 64.2 eps, Loss: 7.574, Avg loss: 8.349, Best loss: 8.349\n",
      "    [batch 267]: seen 26700 examples : 64.3 eps, Loss: 7.434, Avg loss: 8.289, Best loss: 8.289\n",
      "    [batch 274]: seen 27400 examples : 64.4 eps, Loss: 7.453, Avg loss: 8.232, Best loss: 8.232\n",
      "    [batch 281]: seen 28100 examples : 64.4 eps, Loss: 7.377, Avg loss: 8.178, Best loss: 8.178\n",
      "    [batch 288]: seen 28800 examples : 64.5 eps, Loss: 7.382, Avg loss: 8.125, Best loss: 8.125\n",
      "    [batch 295]: seen 29500 examples : 64.5 eps, Loss: 7.500, Avg loss: 8.077, Best loss: 8.077\n",
      "    [batch 302]: seen 30200 examples : 64.6 eps, Loss: 7.409, Avg loss: 8.032, Best loss: 8.032\n",
      "    [batch 309]: seen 30900 examples : 64.6 eps, Loss: 7.470, Avg loss: 7.991, Best loss: 7.991\n",
      "    [batch 316]: seen 31600 examples : 64.7 eps, Loss: 7.388, Avg loss: 7.949, Best loss: 7.949\n",
      "    [batch 323]: seen 32300 examples : 64.8 eps, Loss: 7.398, Avg loss: 7.914, Best loss: 7.914\n",
      "    [batch 330]: seen 33000 examples : 64.8 eps, Loss: 7.374, Avg loss: 7.878, Best loss: 7.878\n",
      "    [batch 337]: seen 33700 examples : 64.9 eps, Loss: 7.338, Avg loss: 7.844, Best loss: 7.844\n",
      "    [batch 344]: seen 34400 examples : 64.9 eps, Loss: 7.378, Avg loss: 7.813, Best loss: 7.813\n",
      "    [batch 351]: seen 35100 examples : 65.0 eps, Loss: 7.340, Avg loss: 7.783, Best loss: 7.783\n",
      "    [batch 358]: seen 35800 examples : 65.0 eps, Loss: 7.333, Avg loss: 7.755, Best loss: 7.755\n",
      "    [batch 365]: seen 36500 examples : 65.1 eps, Loss: 7.388, Avg loss: 7.729, Best loss: 7.729\n",
      "    [batch 372]: seen 37200 examples : 65.1 eps, Loss: 7.323, Avg loss: 7.703, Best loss: 7.703\n",
      "    [batch 379]: seen 37900 examples : 65.1 eps, Loss: 7.370, Avg loss: 7.678, Best loss: 7.678\n",
      "    [batch 386]: seen 38600 examples : 65.2 eps, Loss: 7.303, Avg loss: 7.654, Best loss: 7.654\n",
      "    [batch 393]: seen 39300 examples : 65.2 eps, Loss: 7.360, Avg loss: 7.633, Best loss: 7.633\n",
      "    [batch 400]: seen 40000 examples : 65.2 eps, Loss: 7.393, Avg loss: 7.615, Best loss: 7.615\n",
      "    [batch 407]: seen 40700 examples : 65.3 eps, Loss: 7.351, Avg loss: 7.595, Best loss: 7.595\n",
      "    [batch 414]: seen 41400 examples : 65.3 eps, Loss: 7.365, Avg loss: 7.578, Best loss: 7.578\n",
      "    [batch 421]: seen 42100 examples : 65.4 eps, Loss: 7.283, Avg loss: 7.561, Best loss: 7.561\n",
      "    [batch 428]: seen 42800 examples : 65.4 eps, Loss: 7.363, Avg loss: 7.545, Best loss: 7.545\n",
      "    [batch 435]: seen 43500 examples : 65.4 eps, Loss: 7.259, Avg loss: 7.530, Best loss: 7.530\n",
      "    [batch 442]: seen 44200 examples : 65.5 eps, Loss: 7.415, Avg loss: 7.518, Best loss: 7.518\n",
      "    [batch 449]: seen 44900 examples : 65.5 eps, Loss: 7.294, Avg loss: 7.503, Best loss: 7.503\n",
      "    [batch 456]: seen 45600 examples : 65.5 eps, Loss: 7.271, Avg loss: 7.488, Best loss: 7.488\n",
      "    [batch 463]: seen 46300 examples : 65.6 eps, Loss: 7.268, Avg loss: 7.476, Best loss: 7.476\n",
      "    [batch 470]: seen 47000 examples : 65.6 eps, Loss: 7.335, Avg loss: 7.466, Best loss: 7.466\n",
      "    [batch 477]: seen 47700 examples : 65.6 eps, Loss: 7.325, Avg loss: 7.455, Best loss: 7.455\n",
      "    [batch 484]: seen 48400 examples : 65.6 eps, Loss: 7.308, Avg loss: 7.446, Best loss: 7.446\n",
      "    [batch 491]: seen 49100 examples : 65.7 eps, Loss: 7.250, Avg loss: 7.435, Best loss: 7.435\n",
      "    [batch 498]: seen 49800 examples : 65.7 eps, Loss: 7.303, Avg loss: 7.426, Best loss: 7.426\n",
      "    [batch 505]: seen 50500 examples : 65.7 eps, Loss: 7.278, Avg loss: 7.417, Best loss: 7.417\n",
      "    [batch 512]: seen 51200 examples : 65.7 eps, Loss: 7.368, Avg loss: 7.411, Best loss: 7.411\n",
      "    [batch 519]: seen 51900 examples : 65.7 eps, Loss: 7.273, Avg loss: 7.404, Best loss: 7.404\n",
      "    [batch 526]: seen 52600 examples : 65.8 eps, Loss: 7.287, Avg loss: 7.396, Best loss: 7.396\n",
      "    [batch 533]: seen 53300 examples : 65.8 eps, Loss: 7.253, Avg loss: 7.388, Best loss: 7.388\n",
      "    [batch 540]: seen 54000 examples : 65.8 eps, Loss: 7.321, Avg loss: 7.381, Best loss: 7.381\n",
      "    [batch 547]: seen 54700 examples : 65.8 eps, Loss: 7.305, Avg loss: 7.374, Best loss: 7.374\n",
      "    [batch 554]: seen 55400 examples : 65.9 eps, Loss: 7.231, Avg loss: 7.368, Best loss: 7.368\n",
      "    [batch 561]: seen 56100 examples : 65.9 eps, Loss: 7.309, Avg loss: 7.362, Best loss: 7.362\n",
      "    [batch 568]: seen 56800 examples : 65.9 eps, Loss: 7.248, Avg loss: 7.355, Best loss: 7.355\n",
      "    [batch 575]: seen 57500 examples : 65.9 eps, Loss: 7.366, Avg loss: 7.350, Best loss: 7.350\n",
      "    [batch 582]: seen 58200 examples : 65.9 eps, Loss: 7.229, Avg loss: 7.343, Best loss: 7.343\n",
      "    [batch 589]: seen 58900 examples : 66.0 eps, Loss: 7.215, Avg loss: 7.337, Best loss: 7.337\n",
      "    [batch 596]: seen 59600 examples : 66.0 eps, Loss: 7.228, Avg loss: 7.332, Best loss: 7.332\n",
      "    [batch 603]: seen 60300 examples : 66.0 eps, Loss: 7.316, Avg loss: 7.327, Best loss: 7.327\n",
      "    [batch 610]: seen 61000 examples : 66.0 eps, Loss: 7.237, Avg loss: 7.323, Best loss: 7.323\n",
      "    [batch 617]: seen 61700 examples : 66.0 eps, Loss: 7.224, Avg loss: 7.318, Best loss: 7.318\n",
      "    [batch 624]: seen 62400 examples : 66.1 eps, Loss: 7.273, Avg loss: 7.316, Best loss: 7.316\n",
      "    [batch 631]: seen 63100 examples : 66.0 eps, Loss: 7.253, Avg loss: 7.311, Best loss: 7.311\n",
      "    [batch 638]: seen 63800 examples : 66.1 eps, Loss: 7.280, Avg loss: 7.309, Best loss: 7.309\n",
      "    [batch 645]: seen 64500 examples : 66.1 eps, Loss: 7.318, Avg loss: 7.307, Best loss: 7.307\n",
      "    [batch 652]: seen 65200 examples : 66.1 eps, Loss: 7.208, Avg loss: 7.304, Best loss: 7.304\n",
      "    [batch 659]: seen 65900 examples : 66.1 eps, Loss: 7.242, Avg loss: 7.302, Best loss: 7.302\n",
      "    [batch 666]: seen 66600 examples : 66.1 eps, Loss: 7.254, Avg loss: 7.300, Best loss: 7.300\n",
      "    [batch 673]: seen 67300 examples : 66.2 eps, Loss: 7.260, Avg loss: 7.299, Best loss: 7.299\n",
      "    [batch 680]: seen 68000 examples : 66.2 eps, Loss: 7.305, Avg loss: 7.297, Best loss: 7.297\n",
      "    [batch 687]: seen 68700 examples : 66.2 eps, Loss: 7.254, Avg loss: 7.294, Best loss: 7.294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 694]: seen 69400 examples : 66.2 eps, Loss: 7.268, Avg loss: 7.291, Best loss: 7.291\n",
      "    [batch 701]: seen 70100 examples : 66.2 eps, Loss: 7.319, Avg loss: 7.290, Best loss: 7.289\n",
      "    [batch 708]: seen 70800 examples : 66.2 eps, Loss: 7.261, Avg loss: 7.289, Best loss: 7.289\n",
      "    [batch 715]: seen 71500 examples : 66.2 eps, Loss: 7.146, Avg loss: 7.284, Best loss: 7.284\n",
      "    [batch 722]: seen 72200 examples : 66.3 eps, Loss: 7.284, Avg loss: 7.282, Best loss: 7.282\n",
      "    [batch 729]: seen 72900 examples : 66.3 eps, Loss: 7.222, Avg loss: 7.280, Best loss: 7.280\n",
      "    [batch 736]: seen 73600 examples : 66.3 eps, Loss: 7.246, Avg loss: 7.278, Best loss: 7.278\n",
      "    [batch 743]: seen 74300 examples : 66.3 eps, Loss: 7.319, Avg loss: 7.277, Best loss: 7.277\n",
      "    [batch 750]: seen 75000 examples : 66.3 eps, Loss: 7.181, Avg loss: 7.276, Best loss: 7.276\n",
      "    [batch 757]: seen 75700 examples : 66.3 eps, Loss: 7.310, Avg loss: 7.276, Best loss: 7.275\n",
      "    [batch 764]: seen 76400 examples : 66.3 eps, Loss: 7.174, Avg loss: 7.272, Best loss: 7.272\n",
      "    [batch 771]: seen 77100 examples : 66.3 eps, Loss: 7.242, Avg loss: 7.270, Best loss: 7.270\n",
      "    [batch 778]: seen 77800 examples : 66.4 eps, Loss: 7.248, Avg loss: 7.268, Best loss: 7.268\n",
      "    [batch 785]: seen 78500 examples : 66.4 eps, Loss: 7.238, Avg loss: 7.266, Best loss: 7.266\n",
      "    [batch 792]: seen 79200 examples : 66.4 eps, Loss: 7.240, Avg loss: 7.265, Best loss: 7.265\n",
      "    [batch 799]: seen 79900 examples : 66.4 eps, Loss: 7.233, Avg loss: 7.264, Best loss: 7.264\n",
      "    [batch 806]: seen 80600 examples : 66.4 eps, Loss: 7.276, Avg loss: 7.264, Best loss: 7.263\n",
      "    [batch 813]: seen 81300 examples : 66.4 eps, Loss: 7.239, Avg loss: 7.263, Best loss: 7.263\n",
      "    [batch 820]: seen 82000 examples : 66.4 eps, Loss: 7.276, Avg loss: 7.263, Best loss: 7.263\n",
      "    [batch 827]: seen 82700 examples : 66.5 eps, Loss: 7.229, Avg loss: 7.262, Best loss: 7.262\n",
      "    [batch 834]: seen 83400 examples : 66.5 eps, Loss: 7.198, Avg loss: 7.263, Best loss: 7.262\n",
      "    [batch 841]: seen 84100 examples : 66.5 eps, Loss: 7.274, Avg loss: 7.260, Best loss: 7.260\n",
      "    [batch 848]: seen 84800 examples : 66.5 eps, Loss: 7.227, Avg loss: 7.258, Best loss: 7.258\n",
      "    [batch 855]: seen 85500 examples : 66.5 eps, Loss: 7.167, Avg loss: 7.257, Best loss: 7.257\n",
      "    [batch 862]: seen 86200 examples : 66.5 eps, Loss: 7.235, Avg loss: 7.255, Best loss: 7.255\n",
      "    [batch 869]: seen 86900 examples : 66.5 eps, Loss: 7.304, Avg loss: 7.254, Best loss: 7.254\n",
      "    [batch 876]: seen 87600 examples : 66.5 eps, Loss: 7.296, Avg loss: 7.254, Best loss: 7.253\n",
      "    [batch 883]: seen 88300 examples : 66.5 eps, Loss: 7.195, Avg loss: 7.253, Best loss: 7.253\n",
      "    [batch 890]: seen 89000 examples : 66.6 eps, Loss: 7.265, Avg loss: 7.254, Best loss: 7.253\n",
      "    [batch 897]: seen 89700 examples : 66.5 eps, Loss: 7.236, Avg loss: 7.251, Best loss: 7.251\n",
      "    [batch 904]: seen 90400 examples : 66.6 eps, Loss: 7.203, Avg loss: 7.248, Best loss: 7.248\n",
      "    [batch 911]: seen 91100 examples : 66.6 eps, Loss: 7.261, Avg loss: 7.249, Best loss: 7.248\n",
      "    [batch 918]: seen 91800 examples : 66.6 eps, Loss: 7.225, Avg loss: 7.249, Best loss: 7.248\n",
      "    [batch 925]: seen 92500 examples : 66.6 eps, Loss: 7.222, Avg loss: 7.248, Best loss: 7.248\n",
      "    [batch 932]: seen 93200 examples : 66.6 eps, Loss: 7.181, Avg loss: 7.246, Best loss: 7.246\n",
      "    [batch 939]: seen 93900 examples : 66.6 eps, Loss: 7.326, Avg loss: 7.247, Best loss: 7.246\n",
      "    [batch 946]: seen 94600 examples : 66.6 eps, Loss: 7.186, Avg loss: 7.246, Best loss: 7.246\n",
      "    [batch 953]: seen 95300 examples : 66.6 eps, Loss: 7.208, Avg loss: 7.247, Best loss: 7.246\n",
      "    [batch 960]: seen 96000 examples : 66.6 eps, Loss: 7.218, Avg loss: 7.246, Best loss: 7.246\n",
      "    [batch 967]: seen 96700 examples : 66.7 eps, Loss: 7.185, Avg loss: 7.244, Best loss: 7.244\n",
      "    [batch 974]: seen 97400 examples : 66.7 eps, Loss: 7.303, Avg loss: 7.244, Best loss: 7.243\n",
      "    [batch 981]: seen 98100 examples : 66.7 eps, Loss: 7.153, Avg loss: 7.242, Best loss: 7.242\n",
      "    [batch 988]: seen 98800 examples : 66.7 eps, Loss: 7.246, Avg loss: 7.241, Best loss: 7.241\n",
      "    [batch 995]: seen 99500 examples : 66.7 eps, Loss: 7.299, Avg loss: 7.243, Best loss: 7.241\n",
      "    [batch 1002]: seen 100200 examples : 66.7 eps, Loss: 7.268, Avg loss: 7.244, Best loss: 7.241\n",
      "    [batch 1009]: seen 100900 examples : 66.7 eps, Loss: 7.236, Avg loss: 7.244, Best loss: 7.241\n",
      "    [batch 1016]: seen 101600 examples : 66.7 eps, Loss: 7.337, Avg loss: 7.242, Best loss: 7.241\n",
      "    [batch 1023]: seen 102300 examples : 66.7 eps, Loss: 7.189, Avg loss: 7.241, Best loss: 7.241\n",
      "    [batch 1030]: seen 103000 examples : 66.7 eps, Loss: 7.264, Avg loss: 7.240, Best loss: 7.240\n",
      "    [batch 1037]: seen 103700 examples : 66.7 eps, Loss: 7.163, Avg loss: 7.238, Best loss: 7.238\n",
      "    [batch 1044]: seen 104400 examples : 66.7 eps, Loss: 7.280, Avg loss: 7.237, Best loss: 7.236\n",
      "    [batch 1051]: seen 105100 examples : 66.7 eps, Loss: 7.139, Avg loss: 7.236, Best loss: 7.236\n",
      "    [batch 1058]: seen 105800 examples : 66.7 eps, Loss: 7.138, Avg loss: 7.235, Best loss: 7.235\n",
      "    [batch 1065]: seen 106500 examples : 66.8 eps, Loss: 7.197, Avg loss: 7.236, Best loss: 7.235\n",
      "    [batch 1072]: seen 107200 examples : 66.8 eps, Loss: 7.245, Avg loss: 7.235, Best loss: 7.235\n",
      "    [batch 1079]: seen 107900 examples : 66.8 eps, Loss: 7.173, Avg loss: 7.234, Best loss: 7.234\n",
      "    [batch 1086]: seen 108600 examples : 66.8 eps, Loss: 7.223, Avg loss: 7.235, Best loss: 7.234\n",
      "    [batch 1093]: seen 109300 examples : 66.8 eps, Loss: 7.167, Avg loss: 7.233, Best loss: 7.233\n",
      "    [batch 1100]: seen 110000 examples : 66.8 eps, Loss: 7.245, Avg loss: 7.232, Best loss: 7.232\n",
      "    [batch 1107]: seen 110700 examples : 66.8 eps, Loss: 7.176, Avg loss: 7.231, Best loss: 7.231\n",
      "    [batch 1114]: seen 111400 examples : 66.8 eps, Loss: 7.212, Avg loss: 7.228, Best loss: 7.228\n",
      "    [batch 1121]: seen 112100 examples : 66.8 eps, Loss: 7.288, Avg loss: 7.228, Best loss: 7.227\n",
      "    [batch 1128]: seen 112800 examples : 66.8 eps, Loss: 7.202, Avg loss: 7.228, Best loss: 7.227\n",
      "    [batch 1135]: seen 113500 examples : 66.8 eps, Loss: 7.229, Avg loss: 7.228, Best loss: 7.227\n",
      "    [batch 1142]: seen 114200 examples : 66.8 eps, Loss: 7.230, Avg loss: 7.227, Best loss: 7.227\n",
      "    [batch 1149]: seen 114900 examples : 66.8 eps, Loss: 7.196, Avg loss: 7.225, Best loss: 7.225\n",
      "    [batch 1156]: seen 115600 examples : 66.8 eps, Loss: 7.254, Avg loss: 7.226, Best loss: 7.225\n",
      "    [batch 1163]: seen 116300 examples : 66.8 eps, Loss: 7.197, Avg loss: 7.225, Best loss: 7.225\n",
      "    [batch 1170]: seen 117000 examples : 66.8 eps, Loss: 7.154, Avg loss: 7.225, Best loss: 7.225\n",
      "    [batch 1177]: seen 117700 examples : 66.9 eps, Loss: 7.263, Avg loss: 7.226, Best loss: 7.224\n",
      "    [batch 1184]: seen 118400 examples : 66.9 eps, Loss: 7.231, Avg loss: 7.225, Best loss: 7.223\n",
      "    [batch 1191]: seen 119100 examples : 66.9 eps, Loss: 7.154, Avg loss: 7.222, Best loss: 7.222\n",
      "    [batch 1198]: seen 119800 examples : 66.9 eps, Loss: 7.214, Avg loss: 7.223, Best loss: 7.222\n",
      "    [batch 1205]: seen 120500 examples : 66.9 eps, Loss: 7.256, Avg loss: 7.224, Best loss: 7.222\n",
      "    [batch 1212]: seen 121200 examples : 66.9 eps, Loss: 7.161, Avg loss: 7.221, Best loss: 7.221\n",
      "    [batch 1219]: seen 121900 examples : 66.9 eps, Loss: 7.206, Avg loss: 7.219, Best loss: 7.219\n",
      "    [batch 1226]: seen 122600 examples : 66.9 eps, Loss: 7.231, Avg loss: 7.218, Best loss: 7.218\n",
      "    [batch 1233]: seen 123300 examples : 66.9 eps, Loss: 7.191, Avg loss: 7.218, Best loss: 7.218\n",
      "    [batch 1240]: seen 124000 examples : 66.9 eps, Loss: 7.257, Avg loss: 7.218, Best loss: 7.218\n",
      "    [batch 1247]: seen 124700 examples : 66.9 eps, Loss: 7.227, Avg loss: 7.217, Best loss: 7.216\n",
      "    [batch 1254]: seen 125400 examples : 66.9 eps, Loss: 7.289, Avg loss: 7.217, Best loss: 7.216\n",
      "    [batch 1261]: seen 126100 examples : 66.9 eps, Loss: 7.210, Avg loss: 7.215, Best loss: 7.215\n",
      "    [batch 1268]: seen 126800 examples : 66.9 eps, Loss: 7.224, Avg loss: 7.214, Best loss: 7.214\n",
      "    [batch 1275]: seen 127500 examples : 66.9 eps, Loss: 7.226, Avg loss: 7.214, Best loss: 7.213\n",
      "    [batch 1282]: seen 128200 examples : 66.9 eps, Loss: 7.234, Avg loss: 7.215, Best loss: 7.213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1289]: seen 128900 examples : 66.9 eps, Loss: 7.220, Avg loss: 7.215, Best loss: 7.213\n",
      "    [batch 1296]: seen 129600 examples : 67.0 eps, Loss: 7.261, Avg loss: 7.215, Best loss: 7.213\n",
      "    [batch 1303]: seen 130300 examples : 67.0 eps, Loss: 7.219, Avg loss: 7.215, Best loss: 7.213\n",
      "    [batch 1310]: seen 131000 examples : 67.0 eps, Loss: 7.275, Avg loss: 7.216, Best loss: 7.213\n",
      "    [batch 1317]: seen 131700 examples : 67.0 eps, Loss: 7.156, Avg loss: 7.216, Best loss: 7.213\n",
      "    [batch 1324]: seen 132400 examples : 67.0 eps, Loss: 7.181, Avg loss: 7.216, Best loss: 7.213\n",
      "    [batch 1331]: seen 133100 examples : 67.0 eps, Loss: 7.230, Avg loss: 7.215, Best loss: 7.213\n",
      "    [batch 1338]: seen 133800 examples : 67.0 eps, Loss: 7.181, Avg loss: 7.213, Best loss: 7.213\n",
      "    [batch 1345]: seen 134500 examples : 67.0 eps, Loss: 7.243, Avg loss: 7.212, Best loss: 7.211\n",
      "    [batch 1352]: seen 135200 examples : 67.0 eps, Loss: 7.185, Avg loss: 7.213, Best loss: 7.211\n",
      "    [batch 1359]: seen 135900 examples : 67.0 eps, Loss: 7.238, Avg loss: 7.212, Best loss: 7.211\n",
      "    [batch 1366]: seen 136600 examples : 67.0 eps, Loss: 7.232, Avg loss: 7.214, Best loss: 7.211\n",
      "    [batch 1373]: seen 137300 examples : 67.0 eps, Loss: 7.205, Avg loss: 7.213, Best loss: 7.211\n",
      "    [batch 1380]: seen 138000 examples : 67.0 eps, Loss: 7.181, Avg loss: 7.213, Best loss: 7.211\n",
      "    [batch 1387]: seen 138700 examples : 67.0 eps, Loss: 7.206, Avg loss: 7.213, Best loss: 7.211\n",
      "    [batch 1394]: seen 139400 examples : 67.0 eps, Loss: 7.217, Avg loss: 7.212, Best loss: 7.211\n",
      "    [batch 1401]: seen 140100 examples : 67.0 eps, Loss: 7.233, Avg loss: 7.213, Best loss: 7.211\n",
      "    [batch 1408]: seen 140800 examples : 67.0 eps, Loss: 7.188, Avg loss: 7.211, Best loss: 7.211\n",
      "    [batch 1415]: seen 141500 examples : 67.0 eps, Loss: 7.238, Avg loss: 7.211, Best loss: 7.210\n",
      "    [batch 1422]: seen 142200 examples : 67.0 eps, Loss: 7.213, Avg loss: 7.210, Best loss: 7.210\n",
      "    [batch 1429]: seen 142900 examples : 67.0 eps, Loss: 7.197, Avg loss: 7.211, Best loss: 7.210\n",
      "    [batch 1436]: seen 143600 examples : 67.0 eps, Loss: 7.187, Avg loss: 7.209, Best loss: 7.209\n",
      "    [batch 1443]: seen 144300 examples : 67.0 eps, Loss: 7.258, Avg loss: 7.210, Best loss: 7.208\n",
      "    [batch 1450]: seen 145000 examples : 67.0 eps, Loss: 7.253, Avg loss: 7.209, Best loss: 7.208\n",
      "    [batch 1457]: seen 145700 examples : 67.0 eps, Loss: 7.244, Avg loss: 7.208, Best loss: 7.208\n",
      "    [batch 1464]: seen 146400 examples : 67.0 eps, Loss: 7.216, Avg loss: 7.210, Best loss: 7.208\n",
      "    [batch 1471]: seen 147100 examples : 67.0 eps, Loss: 7.233, Avg loss: 7.208, Best loss: 7.208\n",
      "    [batch 1478]: seen 147800 examples : 67.1 eps, Loss: 7.170, Avg loss: 7.209, Best loss: 7.208\n",
      "    [batch 1485]: seen 148500 examples : 67.1 eps, Loss: 7.205, Avg loss: 7.210, Best loss: 7.208\n",
      "    [batch 1492]: seen 149200 examples : 67.1 eps, Loss: 7.256, Avg loss: 7.210, Best loss: 7.208\n",
      "    [batch 1499]: seen 149900 examples : 67.1 eps, Loss: 7.160, Avg loss: 7.210, Best loss: 7.208\n",
      "    [batch 1506]: seen 150600 examples : 67.1 eps, Loss: 7.180, Avg loss: 7.210, Best loss: 7.208\n",
      "    [batch 1513]: seen 151300 examples : 67.1 eps, Loss: 7.260, Avg loss: 7.209, Best loss: 7.208\n",
      "    [batch 1520]: seen 152000 examples : 67.1 eps, Loss: 7.245, Avg loss: 7.209, Best loss: 7.208\n",
      "    [batch 1527]: seen 152700 examples : 67.1 eps, Loss: 7.207, Avg loss: 7.208, Best loss: 7.208\n",
      "    [batch 1534]: seen 153400 examples : 67.1 eps, Loss: 7.218, Avg loss: 7.208, Best loss: 7.208\n",
      "    [batch 1541]: seen 154100 examples : 67.1 eps, Loss: 7.150, Avg loss: 7.207, Best loss: 7.207\n",
      "    [batch 1548]: seen 154800 examples : 67.1 eps, Loss: 7.194, Avg loss: 7.207, Best loss: 7.207\n",
      "    [batch 1555]: seen 155500 examples : 67.1 eps, Loss: 7.230, Avg loss: 7.208, Best loss: 7.207\n",
      "    [batch 1562]: seen 156200 examples : 67.1 eps, Loss: 7.240, Avg loss: 7.209, Best loss: 7.207\n",
      "    [batch 1569]: seen 156900 examples : 67.1 eps, Loss: 7.157, Avg loss: 7.208, Best loss: 7.207\n",
      "    [batch 1576]: seen 157600 examples : 67.1 eps, Loss: 7.220, Avg loss: 7.208, Best loss: 7.207\n",
      "    [batch 1583]: seen 158300 examples : 67.1 eps, Loss: 7.174, Avg loss: 7.207, Best loss: 7.207\n",
      "    [batch 1590]: seen 159000 examples : 67.1 eps, Loss: 7.133, Avg loss: 7.207, Best loss: 7.207\n",
      "    [batch 1597]: seen 159700 examples : 67.1 eps, Loss: 7.174, Avg loss: 7.205, Best loss: 7.205\n",
      "    [batch 1604]: seen 160400 examples : 67.1 eps, Loss: 7.204, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1611]: seen 161100 examples : 67.1 eps, Loss: 7.223, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1618]: seen 161800 examples : 67.1 eps, Loss: 7.217, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1625]: seen 162500 examples : 67.1 eps, Loss: 7.255, Avg loss: 7.207, Best loss: 7.205\n",
      "    [batch 1632]: seen 163200 examples : 67.1 eps, Loss: 7.190, Avg loss: 7.209, Best loss: 7.205\n",
      "    [batch 1639]: seen 163900 examples : 67.1 eps, Loss: 7.156, Avg loss: 7.209, Best loss: 7.205\n",
      "    [batch 1646]: seen 164600 examples : 67.1 eps, Loss: 7.227, Avg loss: 7.209, Best loss: 7.205\n",
      "    [batch 1653]: seen 165300 examples : 67.1 eps, Loss: 7.200, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1660]: seen 166000 examples : 67.1 eps, Loss: 7.223, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1667]: seen 166700 examples : 67.1 eps, Loss: 7.205, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1674]: seen 167400 examples : 67.1 eps, Loss: 7.152, Avg loss: 7.209, Best loss: 7.205\n",
      "    [batch 1681]: seen 168100 examples : 67.1 eps, Loss: 7.158, Avg loss: 7.208, Best loss: 7.205\n",
      "    [batch 1688]: seen 168800 examples : 67.1 eps, Loss: 7.217, Avg loss: 7.210, Best loss: 7.205\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-1687\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-1687\n",
      "    [batch 1694]: seen 169400 examples : 67.1 eps, Loss: 7.238, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1701]: seen 170100 examples : 67.1 eps, Loss: 7.223, Avg loss: 7.211, Best loss: 7.205\n",
      "    [batch 1708]: seen 170800 examples : 67.1 eps, Loss: 7.177, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1715]: seen 171500 examples : 67.1 eps, Loss: 7.236, Avg loss: 7.211, Best loss: 7.205\n",
      "    [batch 1722]: seen 172200 examples : 67.1 eps, Loss: 7.176, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1729]: seen 172900 examples : 67.1 eps, Loss: 7.183, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1736]: seen 173600 examples : 67.1 eps, Loss: 7.227, Avg loss: 7.210, Best loss: 7.205\n",
      "    [batch 1743]: seen 174300 examples : 67.1 eps, Loss: 7.177, Avg loss: 7.209, Best loss: 7.205\n",
      "    [batch 1750]: seen 175000 examples : 67.1 eps, Loss: 7.246, Avg loss: 7.209, Best loss: 7.205\n",
      "    [batch 1757]: seen 175700 examples : 67.1 eps, Loss: 7.147, Avg loss: 7.208, Best loss: 7.205\n",
      "    [batch 1764]: seen 176400 examples : 67.1 eps, Loss: 7.136, Avg loss: 7.208, Best loss: 7.205\n",
      "    [batch 1771]: seen 177100 examples : 67.1 eps, Loss: 7.150, Avg loss: 7.207, Best loss: 7.205\n",
      "    [batch 1778]: seen 177800 examples : 67.1 eps, Loss: 7.197, Avg loss: 7.205, Best loss: 7.205\n",
      "    [batch 1785]: seen 178500 examples : 67.2 eps, Loss: 7.188, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1792]: seen 179200 examples : 67.2 eps, Loss: 7.176, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1799]: seen 179900 examples : 67.2 eps, Loss: 7.251, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1806]: seen 180600 examples : 67.1 eps, Loss: 7.249, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1813]: seen 181300 examples : 67.2 eps, Loss: 7.217, Avg loss: 7.207, Best loss: 7.205\n",
      "    [batch 1820]: seen 182000 examples : 67.2 eps, Loss: 7.170, Avg loss: 7.206, Best loss: 7.205\n",
      "    [batch 1827]: seen 182700 examples : 67.2 eps, Loss: 7.244, Avg loss: 7.205, Best loss: 7.204\n",
      "    [batch 1834]: seen 183400 examples : 67.2 eps, Loss: 7.154, Avg loss: 7.204, Best loss: 7.204\n",
      "    [batch 1841]: seen 184100 examples : 67.2 eps, Loss: 7.151, Avg loss: 7.203, Best loss: 7.203\n",
      "    [batch 1848]: seen 184800 examples : 67.2 eps, Loss: 7.177, Avg loss: 7.202, Best loss: 7.202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1855]: seen 185500 examples : 67.2 eps, Loss: 7.204, Avg loss: 7.200, Best loss: 7.200\n",
      "    [batch 1862]: seen 186200 examples : 67.2 eps, Loss: 7.282, Avg loss: 7.202, Best loss: 7.200\n",
      "    [batch 1869]: seen 186900 examples : 67.2 eps, Loss: 7.186, Avg loss: 7.202, Best loss: 7.200\n",
      "    [batch 1876]: seen 187600 examples : 67.2 eps, Loss: 7.165, Avg loss: 7.203, Best loss: 7.200\n",
      "    [batch 1883]: seen 188300 examples : 67.2 eps, Loss: 7.167, Avg loss: 7.201, Best loss: 7.200\n",
      "    [batch 1890]: seen 189000 examples : 67.2 eps, Loss: 7.195, Avg loss: 7.201, Best loss: 7.200\n",
      "    [batch 1897]: seen 189700 examples : 67.2 eps, Loss: 7.182, Avg loss: 7.201, Best loss: 7.200\n",
      "    [batch 1904]: seen 190400 examples : 67.2 eps, Loss: 7.189, Avg loss: 7.199, Best loss: 7.199\n",
      "    [batch 1911]: seen 191100 examples : 67.2 eps, Loss: 7.224, Avg loss: 7.199, Best loss: 7.199\n",
      "    [batch 1918]: seen 191800 examples : 67.2 eps, Loss: 7.253, Avg loss: 7.199, Best loss: 7.198\n",
      "    [batch 1925]: seen 192500 examples : 67.2 eps, Loss: 7.152, Avg loss: 7.198, Best loss: 7.198\n",
      "    [batch 1932]: seen 193200 examples : 67.2 eps, Loss: 7.209, Avg loss: 7.197, Best loss: 7.197\n",
      "    [batch 1939]: seen 193900 examples : 67.2 eps, Loss: 7.146, Avg loss: 7.195, Best loss: 7.195\n",
      "    [batch 1946]: seen 194600 examples : 67.2 eps, Loss: 7.189, Avg loss: 7.194, Best loss: 7.194\n",
      "    [batch 1953]: seen 195300 examples : 67.2 eps, Loss: 7.183, Avg loss: 7.195, Best loss: 7.194\n",
      "    [batch 1960]: seen 196000 examples : 67.2 eps, Loss: 7.197, Avg loss: 7.195, Best loss: 7.194\n",
      "    [batch 1967]: seen 196700 examples : 67.2 eps, Loss: 7.146, Avg loss: 7.195, Best loss: 7.194\n",
      "    [batch 1974]: seen 197400 examples : 67.2 eps, Loss: 7.129, Avg loss: 7.196, Best loss: 7.194\n",
      "    [batch 1981]: seen 198100 examples : 67.2 eps, Loss: 7.306, Avg loss: 7.196, Best loss: 7.194\n",
      "    [batch 1988]: seen 198800 examples : 67.2 eps, Loss: 7.207, Avg loss: 7.197, Best loss: 7.194\n",
      "    [batch 1995]: seen 199500 examples : 67.2 eps, Loss: 7.240, Avg loss: 7.197, Best loss: 7.194\n",
      "    [batch 2002]: seen 200200 examples : 67.2 eps, Loss: 7.116, Avg loss: 7.198, Best loss: 7.194\n",
      "    [batch 2009]: seen 200900 examples : 67.2 eps, Loss: 7.214, Avg loss: 7.196, Best loss: 7.194\n",
      "    [batch 2016]: seen 201600 examples : 67.2 eps, Loss: 7.200, Avg loss: 7.195, Best loss: 7.194\n",
      "    [batch 2023]: seen 202300 examples : 67.2 eps, Loss: 7.121, Avg loss: 7.194, Best loss: 7.194\n",
      "    [batch 2030]: seen 203000 examples : 67.2 eps, Loss: 7.277, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2037]: seen 203700 examples : 67.2 eps, Loss: 7.198, Avg loss: 7.194, Best loss: 7.192\n",
      "    [batch 2044]: seen 204400 examples : 67.2 eps, Loss: 7.183, Avg loss: 7.194, Best loss: 7.192\n",
      "    [batch 2051]: seen 205100 examples : 67.2 eps, Loss: 7.258, Avg loss: 7.195, Best loss: 7.192\n",
      "    [batch 2058]: seen 205800 examples : 67.2 eps, Loss: 7.199, Avg loss: 7.196, Best loss: 7.192\n",
      "    [batch 2065]: seen 206500 examples : 67.2 eps, Loss: 7.204, Avg loss: 7.196, Best loss: 7.192\n",
      "    [batch 2072]: seen 207200 examples : 67.2 eps, Loss: 7.245, Avg loss: 7.197, Best loss: 7.192\n",
      "    [batch 2079]: seen 207900 examples : 67.3 eps, Loss: 7.220, Avg loss: 7.199, Best loss: 7.192\n",
      "    [batch 2086]: seen 208600 examples : 67.3 eps, Loss: 7.180, Avg loss: 7.198, Best loss: 7.192\n",
      "    [batch 2093]: seen 209300 examples : 67.3 eps, Loss: 7.173, Avg loss: 7.196, Best loss: 7.192\n",
      "    [batch 2100]: seen 210000 examples : 67.3 eps, Loss: 7.270, Avg loss: 7.197, Best loss: 7.192\n",
      "    [batch 2107]: seen 210700 examples : 67.3 eps, Loss: 7.145, Avg loss: 7.197, Best loss: 7.192\n",
      "    [batch 2114]: seen 211400 examples : 67.3 eps, Loss: 7.094, Avg loss: 7.194, Best loss: 7.192\n",
      "    [batch 2121]: seen 212100 examples : 67.3 eps, Loss: 7.203, Avg loss: 7.197, Best loss: 7.192\n",
      "    [batch 2128]: seen 212800 examples : 67.3 eps, Loss: 7.212, Avg loss: 7.199, Best loss: 7.192\n",
      "    [batch 2135]: seen 213500 examples : 67.3 eps, Loss: 7.173, Avg loss: 7.200, Best loss: 7.192\n",
      "    [batch 2142]: seen 214200 examples : 67.3 eps, Loss: 7.186, Avg loss: 7.199, Best loss: 7.192\n",
      "    [batch 2149]: seen 214900 examples : 67.3 eps, Loss: 7.236, Avg loss: 7.198, Best loss: 7.192\n",
      "    [batch 2156]: seen 215600 examples : 67.3 eps, Loss: 7.226, Avg loss: 7.199, Best loss: 7.192\n",
      "    [batch 2163]: seen 216300 examples : 67.3 eps, Loss: 7.191, Avg loss: 7.198, Best loss: 7.192\n",
      "    [batch 2170]: seen 217000 examples : 67.3 eps, Loss: 7.115, Avg loss: 7.198, Best loss: 7.192\n",
      "    [batch 2177]: seen 217700 examples : 67.3 eps, Loss: 7.172, Avg loss: 7.197, Best loss: 7.192\n",
      "    [batch 2184]: seen 218400 examples : 67.3 eps, Loss: 7.179, Avg loss: 7.196, Best loss: 7.192\n",
      "    [batch 2191]: seen 219100 examples : 67.3 eps, Loss: 7.144, Avg loss: 7.195, Best loss: 7.192\n",
      "    [batch 2198]: seen 219800 examples : 67.3 eps, Loss: 7.161, Avg loss: 7.195, Best loss: 7.192\n",
      "    [batch 2205]: seen 220500 examples : 67.3 eps, Loss: 7.193, Avg loss: 7.194, Best loss: 7.192\n",
      "    [batch 2212]: seen 221200 examples : 67.3 eps, Loss: 7.134, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2219]: seen 221900 examples : 67.3 eps, Loss: 7.180, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2226]: seen 222600 examples : 67.3 eps, Loss: 7.217, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2233]: seen 223300 examples : 67.3 eps, Loss: 7.225, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2240]: seen 224000 examples : 67.3 eps, Loss: 7.268, Avg loss: 7.194, Best loss: 7.192\n",
      "    [batch 2247]: seen 224700 examples : 67.3 eps, Loss: 7.234, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2254]: seen 225400 examples : 67.3 eps, Loss: 7.247, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2261]: seen 226100 examples : 67.3 eps, Loss: 7.204, Avg loss: 7.192, Best loss: 7.192\n",
      "    [batch 2268]: seen 226800 examples : 67.3 eps, Loss: 7.232, Avg loss: 7.194, Best loss: 7.192\n",
      "    [batch 2275]: seen 227500 examples : 67.3 eps, Loss: 7.196, Avg loss: 7.193, Best loss: 7.192\n",
      "    [batch 2282]: seen 228200 examples : 67.3 eps, Loss: 7.149, Avg loss: 7.192, Best loss: 7.192\n",
      "    [batch 2289]: seen 228900 examples : 67.3 eps, Loss: 7.152, Avg loss: 7.191, Best loss: 7.191\n",
      "    [batch 2296]: seen 229600 examples : 67.3 eps, Loss: 7.155, Avg loss: 7.191, Best loss: 7.191\n",
      "    [batch 2303]: seen 230300 examples : 67.3 eps, Loss: 7.216, Avg loss: 7.191, Best loss: 7.191\n",
      "    [batch 2310]: seen 231000 examples : 67.3 eps, Loss: 7.190, Avg loss: 7.192, Best loss: 7.191\n",
      "    [batch 2317]: seen 231700 examples : 67.3 eps, Loss: 7.175, Avg loss: 7.192, Best loss: 7.190\n",
      "    [batch 2324]: seen 232400 examples : 67.3 eps, Loss: 7.174, Avg loss: 7.189, Best loss: 7.189\n",
      "    [batch 2331]: seen 233100 examples : 67.3 eps, Loss: 7.153, Avg loss: 7.189, Best loss: 7.189\n",
      "    [batch 2338]: seen 233800 examples : 67.3 eps, Loss: 7.233, Avg loss: 7.191, Best loss: 7.189\n",
      "    [batch 2345]: seen 234500 examples : 67.3 eps, Loss: 7.138, Avg loss: 7.192, Best loss: 7.189\n",
      "    [batch 2352]: seen 235200 examples : 67.3 eps, Loss: 7.149, Avg loss: 7.193, Best loss: 7.189\n",
      "    [batch 2359]: seen 235900 examples : 67.3 eps, Loss: 7.198, Avg loss: 7.192, Best loss: 7.189\n",
      "    [batch 2366]: seen 236600 examples : 67.3 eps, Loss: 7.137, Avg loss: 7.192, Best loss: 7.189\n",
      "    [batch 2373]: seen 237300 examples : 67.3 eps, Loss: 7.250, Avg loss: 7.192, Best loss: 7.189\n",
      "    [batch 2380]: seen 238000 examples : 67.3 eps, Loss: 7.214, Avg loss: 7.190, Best loss: 7.189\n",
      "    [batch 2387]: seen 238700 examples : 67.3 eps, Loss: 7.215, Avg loss: 7.189, Best loss: 7.188\n",
      "    [batch 2394]: seen 239400 examples : 67.3 eps, Loss: 7.234, Avg loss: 7.188, Best loss: 7.188\n",
      "    [batch 2401]: seen 240100 examples : 67.3 eps, Loss: 7.230, Avg loss: 7.188, Best loss: 7.188\n",
      "    [batch 2408]: seen 240800 examples : 67.3 eps, Loss: 7.261, Avg loss: 7.189, Best loss: 7.188\n",
      "    [batch 2415]: seen 241500 examples : 67.3 eps, Loss: 7.176, Avg loss: 7.188, Best loss: 7.188\n",
      "    [batch 2422]: seen 242200 examples : 67.3 eps, Loss: 7.204, Avg loss: 7.189, Best loss: 7.188\n",
      "    [batch 2429]: seen 242900 examples : 67.3 eps, Loss: 7.151, Avg loss: 7.189, Best loss: 7.188\n",
      "    [batch 2436]: seen 243600 examples : 67.3 eps, Loss: 7.155, Avg loss: 7.189, Best loss: 7.188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2443]: seen 244300 examples : 67.3 eps, Loss: 7.275, Avg loss: 7.190, Best loss: 7.188\n",
      "    [batch 2450]: seen 245000 examples : 67.3 eps, Loss: 7.146, Avg loss: 7.187, Best loss: 7.187\n",
      "    [batch 2457]: seen 245700 examples : 67.3 eps, Loss: 7.157, Avg loss: 7.187, Best loss: 7.187\n",
      "    [batch 2464]: seen 246400 examples : 67.3 eps, Loss: 7.153, Avg loss: 7.185, Best loss: 7.185\n",
      "    [batch 2471]: seen 247100 examples : 67.3 eps, Loss: 7.215, Avg loss: 7.187, Best loss: 7.185\n",
      "    [batch 2478]: seen 247800 examples : 67.3 eps, Loss: 7.172, Avg loss: 7.186, Best loss: 7.185\n",
      "    [batch 2485]: seen 248500 examples : 67.3 eps, Loss: 7.115, Avg loss: 7.185, Best loss: 7.185\n",
      "    [batch 2492]: seen 249200 examples : 67.3 eps, Loss: 7.218, Avg loss: 7.186, Best loss: 7.185\n",
      "    [batch 2499]: seen 249900 examples : 67.3 eps, Loss: 7.119, Avg loss: 7.185, Best loss: 7.185\n",
      "    [batch 2506]: seen 250600 examples : 67.3 eps, Loss: 7.168, Avg loss: 7.183, Best loss: 7.183\n",
      "    [batch 2513]: seen 251300 examples : 67.3 eps, Loss: 7.189, Avg loss: 7.183, Best loss: 7.183\n",
      "    [batch 2520]: seen 252000 examples : 67.3 eps, Loss: 7.198, Avg loss: 7.184, Best loss: 7.183\n",
      "    [batch 2527]: seen 252700 examples : 67.3 eps, Loss: 7.145, Avg loss: 7.183, Best loss: 7.183\n",
      "    [batch 2534]: seen 253400 examples : 67.3 eps, Loss: 7.144, Avg loss: 7.184, Best loss: 7.183\n",
      "    [batch 2541]: seen 254100 examples : 67.3 eps, Loss: 7.150, Avg loss: 7.182, Best loss: 7.182\n",
      "    [batch 2548]: seen 254800 examples : 67.3 eps, Loss: 7.180, Avg loss: 7.184, Best loss: 7.182\n",
      "    [batch 2555]: seen 255500 examples : 67.3 eps, Loss: 7.205, Avg loss: 7.185, Best loss: 7.182\n",
      "    [batch 2562]: seen 256200 examples : 67.3 eps, Loss: 7.174, Avg loss: 7.185, Best loss: 7.182\n",
      "    [batch 2569]: seen 256900 examples : 67.4 eps, Loss: 7.164, Avg loss: 7.185, Best loss: 7.182\n",
      "    [batch 2576]: seen 257600 examples : 67.4 eps, Loss: 7.167, Avg loss: 7.185, Best loss: 7.182\n",
      "    [batch 2583]: seen 258300 examples : 67.3 eps, Loss: 7.138, Avg loss: 7.185, Best loss: 7.182\n",
      "    [batch 2590]: seen 259000 examples : 67.3 eps, Loss: 7.158, Avg loss: 7.184, Best loss: 7.182\n",
      "    [batch 2597]: seen 259700 examples : 67.4 eps, Loss: 7.203, Avg loss: 7.183, Best loss: 7.182\n",
      "    [batch 2604]: seen 260400 examples : 67.4 eps, Loss: 7.178, Avg loss: 7.183, Best loss: 7.182\n",
      "    [batch 2611]: seen 261100 examples : 67.4 eps, Loss: 7.254, Avg loss: 7.184, Best loss: 7.182\n",
      "    [batch 2618]: seen 261800 examples : 67.4 eps, Loss: 7.131, Avg loss: 7.182, Best loss: 7.182\n",
      "    [batch 2625]: seen 262500 examples : 67.4 eps, Loss: 7.160, Avg loss: 7.180, Best loss: 7.180\n",
      "    [batch 2632]: seen 263200 examples : 67.3 eps, Loss: 7.126, Avg loss: 7.179, Best loss: 7.179\n",
      "    [batch 2639]: seen 263900 examples : 67.3 eps, Loss: 7.150, Avg loss: 7.178, Best loss: 7.178\n",
      "    [batch 2646]: seen 264600 examples : 67.3 eps, Loss: 7.182, Avg loss: 7.176, Best loss: 7.176\n",
      "    [batch 2653]: seen 265300 examples : 67.4 eps, Loss: 7.192, Avg loss: 7.176, Best loss: 7.175\n",
      "    [batch 2660]: seen 266000 examples : 67.3 eps, Loss: 7.145, Avg loss: 7.176, Best loss: 7.175\n",
      "    [batch 2667]: seen 266700 examples : 67.4 eps, Loss: 7.124, Avg loss: 7.174, Best loss: 7.174\n",
      "    [batch 2674]: seen 267400 examples : 67.4 eps, Loss: 7.194, Avg loss: 7.174, Best loss: 7.173\n",
      "    [batch 2681]: seen 268100 examples : 67.4 eps, Loss: 7.197, Avg loss: 7.174, Best loss: 7.173\n",
      "    [batch 2688]: seen 268800 examples : 67.4 eps, Loss: 7.116, Avg loss: 7.172, Best loss: 7.172\n",
      "    [batch 2695]: seen 269500 examples : 67.4 eps, Loss: 7.137, Avg loss: 7.172, Best loss: 7.172\n",
      "    [batch 2702]: seen 270200 examples : 67.4 eps, Loss: 7.194, Avg loss: 7.173, Best loss: 7.172\n",
      "    [batch 2709]: seen 270900 examples : 67.4 eps, Loss: 7.149, Avg loss: 7.172, Best loss: 7.172\n",
      "    [batch 2716]: seen 271600 examples : 67.4 eps, Loss: 7.153, Avg loss: 7.170, Best loss: 7.170\n",
      "    [batch 2723]: seen 272300 examples : 67.4 eps, Loss: 7.125, Avg loss: 7.168, Best loss: 7.168\n",
      "    [batch 2730]: seen 273000 examples : 67.4 eps, Loss: 7.125, Avg loss: 7.166, Best loss: 7.166\n",
      "    [batch 2737]: seen 273700 examples : 67.4 eps, Loss: 7.116, Avg loss: 7.164, Best loss: 7.164\n",
      "    [batch 2744]: seen 274400 examples : 67.4 eps, Loss: 7.174, Avg loss: 7.163, Best loss: 7.163\n",
      "    [batch 2751]: seen 275100 examples : 67.4 eps, Loss: 7.090, Avg loss: 7.161, Best loss: 7.161\n",
      "    [batch 2758]: seen 275800 examples : 67.4 eps, Loss: 7.229, Avg loss: 7.160, Best loss: 7.160\n",
      "    [batch 2765]: seen 276500 examples : 67.4 eps, Loss: 7.116, Avg loss: 7.160, Best loss: 7.160\n",
      "    [batch 2772]: seen 277200 examples : 67.4 eps, Loss: 7.224, Avg loss: 7.159, Best loss: 7.159\n",
      "    [batch 2779]: seen 277900 examples : 67.4 eps, Loss: 7.164, Avg loss: 7.159, Best loss: 7.159\n",
      "    [batch 2786]: seen 278600 examples : 67.4 eps, Loss: 7.184, Avg loss: 7.158, Best loss: 7.158\n",
      "    [batch 2793]: seen 279300 examples : 67.4 eps, Loss: 7.124, Avg loss: 7.158, Best loss: 7.158\n",
      "    [batch 2800]: seen 280000 examples : 67.4 eps, Loss: 7.090, Avg loss: 7.155, Best loss: 7.155\n",
      "    [batch 2807]: seen 280700 examples : 67.4 eps, Loss: 7.075, Avg loss: 7.155, Best loss: 7.155\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:28\n",
      "[EPOCH 1] Complete. Avg Loss: 7.154538733965714; Best Loss: 7.154538733965714\n",
      "[EPOCH 2] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.2 eps, Loss: 7.141, Avg loss: 7.153, Best loss: 7.153\n",
      "    [batch 16]: seen 1600 examples : 77.9 eps, Loss: 7.176, Avg loss: 7.152, Best loss: 7.152\n",
      "    [batch 23]: seen 2300 examples : 74.9 eps, Loss: 7.154, Avg loss: 7.152, Best loss: 7.152\n",
      "    [batch 30]: seen 3000 examples : 73.3 eps, Loss: 7.143, Avg loss: 7.151, Best loss: 7.151\n",
      "    [batch 37]: seen 3700 examples : 71.7 eps, Loss: 7.152, Avg loss: 7.151, Best loss: 7.151\n",
      "    [batch 44]: seen 4400 examples : 71.2 eps, Loss: 7.097, Avg loss: 7.150, Best loss: 7.150\n",
      "    [batch 51]: seen 5100 examples : 70.9 eps, Loss: 7.115, Avg loss: 7.150, Best loss: 7.150\n",
      "    [batch 58]: seen 5800 examples : 70.6 eps, Loss: 7.106, Avg loss: 7.149, Best loss: 7.149\n",
      "    [batch 65]: seen 6500 examples : 70.4 eps, Loss: 7.092, Avg loss: 7.148, Best loss: 7.148\n",
      "    [batch 72]: seen 7200 examples : 70.2 eps, Loss: 7.206, Avg loss: 7.147, Best loss: 7.146\n",
      "    [batch 79]: seen 7900 examples : 70.1 eps, Loss: 7.190, Avg loss: 7.147, Best loss: 7.146\n",
      "    [batch 86]: seen 8600 examples : 70.0 eps, Loss: 7.150, Avg loss: 7.146, Best loss: 7.146\n",
      "    [batch 93]: seen 9300 examples : 69.9 eps, Loss: 7.142, Avg loss: 7.147, Best loss: 7.146\n",
      "    [batch 100]: seen 10000 examples : 69.7 eps, Loss: 7.152, Avg loss: 7.145, Best loss: 7.145\n",
      "    [batch 107]: seen 10700 examples : 69.6 eps, Loss: 7.084, Avg loss: 7.143, Best loss: 7.143\n",
      "    [batch 114]: seen 11400 examples : 69.5 eps, Loss: 7.129, Avg loss: 7.143, Best loss: 7.143\n",
      "    [batch 121]: seen 12100 examples : 69.5 eps, Loss: 7.186, Avg loss: 7.142, Best loss: 7.142\n",
      "    [batch 128]: seen 12800 examples : 69.3 eps, Loss: 7.125, Avg loss: 7.142, Best loss: 7.142\n",
      "    [batch 135]: seen 13500 examples : 69.3 eps, Loss: 7.131, Avg loss: 7.141, Best loss: 7.141\n",
      "    [batch 142]: seen 14200 examples : 69.2 eps, Loss: 7.189, Avg loss: 7.141, Best loss: 7.140\n",
      "    [batch 149]: seen 14900 examples : 69.1 eps, Loss: 7.112, Avg loss: 7.140, Best loss: 7.140\n",
      "    [batch 156]: seen 15600 examples : 69.1 eps, Loss: 7.113, Avg loss: 7.140, Best loss: 7.140\n",
      "    [batch 163]: seen 16300 examples : 69.0 eps, Loss: 7.190, Avg loss: 7.140, Best loss: 7.139\n",
      "    [batch 170]: seen 17000 examples : 68.9 eps, Loss: 7.072, Avg loss: 7.137, Best loss: 7.137\n",
      "    [batch 177]: seen 17700 examples : 68.9 eps, Loss: 7.127, Avg loss: 7.139, Best loss: 7.137\n",
      "    [batch 184]: seen 18400 examples : 68.9 eps, Loss: 7.097, Avg loss: 7.138, Best loss: 7.137\n",
      "    [batch 191]: seen 19100 examples : 68.9 eps, Loss: 7.073, Avg loss: 7.137, Best loss: 7.137\n",
      "    [batch 198]: seen 19800 examples : 68.8 eps, Loss: 7.050, Avg loss: 7.137, Best loss: 7.137\n",
      "    [batch 205]: seen 20500 examples : 68.8 eps, Loss: 7.105, Avg loss: 7.136, Best loss: 7.136\n",
      "    [batch 212]: seen 21200 examples : 68.8 eps, Loss: 7.099, Avg loss: 7.134, Best loss: 7.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 219]: seen 21900 examples : 68.7 eps, Loss: 7.141, Avg loss: 7.135, Best loss: 7.134\n",
      "    [batch 226]: seen 22600 examples : 68.7 eps, Loss: 7.131, Avg loss: 7.136, Best loss: 7.134\n",
      "    [batch 233]: seen 23300 examples : 68.7 eps, Loss: 7.137, Avg loss: 7.137, Best loss: 7.134\n",
      "    [batch 240]: seen 24000 examples : 68.7 eps, Loss: 7.100, Avg loss: 7.136, Best loss: 7.134\n",
      "    [batch 247]: seen 24700 examples : 68.6 eps, Loss: 7.083, Avg loss: 7.135, Best loss: 7.134\n",
      "    [batch 254]: seen 25400 examples : 68.6 eps, Loss: 7.052, Avg loss: 7.135, Best loss: 7.134\n",
      "    [batch 261]: seen 26100 examples : 68.6 eps, Loss: 7.123, Avg loss: 7.135, Best loss: 7.134\n",
      "    [batch 268]: seen 26800 examples : 68.6 eps, Loss: 7.122, Avg loss: 7.135, Best loss: 7.134\n",
      "    [batch 275]: seen 27500 examples : 68.6 eps, Loss: 7.058, Avg loss: 7.134, Best loss: 7.134\n",
      "    [batch 282]: seen 28200 examples : 68.5 eps, Loss: 7.187, Avg loss: 7.133, Best loss: 7.132\n",
      "    [batch 289]: seen 28900 examples : 68.5 eps, Loss: 7.114, Avg loss: 7.131, Best loss: 7.131\n",
      "    [batch 296]: seen 29600 examples : 68.5 eps, Loss: 7.128, Avg loss: 7.131, Best loss: 7.131\n",
      "    [batch 303]: seen 30300 examples : 68.5 eps, Loss: 7.179, Avg loss: 7.132, Best loss: 7.131\n",
      "    [batch 310]: seen 31000 examples : 68.5 eps, Loss: 7.072, Avg loss: 7.132, Best loss: 7.131\n",
      "    [batch 317]: seen 31700 examples : 68.5 eps, Loss: 7.177, Avg loss: 7.131, Best loss: 7.130\n",
      "    [batch 324]: seen 32400 examples : 68.4 eps, Loss: 7.129, Avg loss: 7.131, Best loss: 7.130\n",
      "    [batch 331]: seen 33100 examples : 68.4 eps, Loss: 7.120, Avg loss: 7.131, Best loss: 7.130\n",
      "    [batch 338]: seen 33800 examples : 68.3 eps, Loss: 7.139, Avg loss: 7.130, Best loss: 7.130\n",
      "    [batch 345]: seen 34500 examples : 68.3 eps, Loss: 7.091, Avg loss: 7.129, Best loss: 7.128\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-3150\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-3150\n",
      "    [batch 351]: seen 35100 examples : 68.1 eps, Loss: 7.102, Avg loss: 7.129, Best loss: 7.128\n",
      "    [batch 358]: seen 35800 examples : 68.1 eps, Loss: 7.109, Avg loss: 7.130, Best loss: 7.128\n",
      "    [batch 365]: seen 36500 examples : 68.1 eps, Loss: 7.100, Avg loss: 7.129, Best loss: 7.128\n",
      "    [batch 372]: seen 37200 examples : 68.1 eps, Loss: 7.132, Avg loss: 7.128, Best loss: 7.128\n",
      "    [batch 379]: seen 37900 examples : 68.1 eps, Loss: 7.093, Avg loss: 7.126, Best loss: 7.126\n",
      "    [batch 386]: seen 38600 examples : 68.1 eps, Loss: 7.095, Avg loss: 7.126, Best loss: 7.125\n",
      "    [batch 393]: seen 39300 examples : 68.1 eps, Loss: 7.140, Avg loss: 7.124, Best loss: 7.124\n",
      "    [batch 400]: seen 40000 examples : 68.1 eps, Loss: 7.113, Avg loss: 7.123, Best loss: 7.123\n",
      "    [batch 407]: seen 40700 examples : 68.1 eps, Loss: 7.165, Avg loss: 7.124, Best loss: 7.123\n",
      "    [batch 414]: seen 41400 examples : 68.1 eps, Loss: 7.080, Avg loss: 7.121, Best loss: 7.121\n",
      "    [batch 421]: seen 42100 examples : 68.1 eps, Loss: 7.160, Avg loss: 7.120, Best loss: 7.120\n",
      "    [batch 428]: seen 42800 examples : 68.0 eps, Loss: 7.191, Avg loss: 7.121, Best loss: 7.120\n",
      "    [batch 435]: seen 43500 examples : 68.0 eps, Loss: 7.143, Avg loss: 7.120, Best loss: 7.120\n",
      "    [batch 442]: seen 44200 examples : 68.0 eps, Loss: 7.127, Avg loss: 7.122, Best loss: 7.120\n",
      "    [batch 449]: seen 44900 examples : 68.0 eps, Loss: 7.111, Avg loss: 7.121, Best loss: 7.120\n",
      "    [batch 456]: seen 45600 examples : 68.0 eps, Loss: 7.156, Avg loss: 7.121, Best loss: 7.120\n",
      "    [batch 463]: seen 46300 examples : 68.0 eps, Loss: 7.139, Avg loss: 7.117, Best loss: 7.116\n",
      "    [batch 470]: seen 47000 examples : 68.0 eps, Loss: 7.038, Avg loss: 7.115, Best loss: 7.115\n",
      "    [batch 477]: seen 47700 examples : 68.0 eps, Loss: 7.117, Avg loss: 7.114, Best loss: 7.114\n",
      "    [batch 484]: seen 48400 examples : 68.0 eps, Loss: 7.106, Avg loss: 7.112, Best loss: 7.112\n",
      "    [batch 491]: seen 49100 examples : 68.0 eps, Loss: 7.081, Avg loss: 7.111, Best loss: 7.111\n",
      "    [batch 498]: seen 49800 examples : 68.0 eps, Loss: 7.082, Avg loss: 7.108, Best loss: 7.108\n",
      "    [batch 505]: seen 50500 examples : 68.0 eps, Loss: 7.055, Avg loss: 7.108, Best loss: 7.108\n",
      "    [batch 512]: seen 51200 examples : 68.0 eps, Loss: 7.081, Avg loss: 7.106, Best loss: 7.106\n",
      "    [batch 519]: seen 51900 examples : 68.0 eps, Loss: 7.141, Avg loss: 7.106, Best loss: 7.105\n",
      "    [batch 526]: seen 52600 examples : 68.0 eps, Loss: 7.084, Avg loss: 7.102, Best loss: 7.102\n",
      "    [batch 533]: seen 53300 examples : 68.0 eps, Loss: 7.084, Avg loss: 7.099, Best loss: 7.099\n",
      "    [batch 540]: seen 54000 examples : 68.0 eps, Loss: 7.126, Avg loss: 7.099, Best loss: 7.098\n",
      "    [batch 547]: seen 54700 examples : 68.0 eps, Loss: 7.141, Avg loss: 7.097, Best loss: 7.096\n",
      "    [batch 554]: seen 55400 examples : 68.0 eps, Loss: 7.115, Avg loss: 7.093, Best loss: 7.093\n",
      "    [batch 561]: seen 56100 examples : 68.0 eps, Loss: 7.143, Avg loss: 7.093, Best loss: 7.092\n",
      "    [batch 568]: seen 56800 examples : 68.0 eps, Loss: 7.107, Avg loss: 7.090, Best loss: 7.090\n",
      "    [batch 575]: seen 57500 examples : 68.0 eps, Loss: 7.053, Avg loss: 7.086, Best loss: 7.086\n",
      "    [batch 582]: seen 58200 examples : 68.0 eps, Loss: 7.035, Avg loss: 7.084, Best loss: 7.084\n",
      "    [batch 589]: seen 58900 examples : 68.0 eps, Loss: 7.046, Avg loss: 7.082, Best loss: 7.082\n",
      "    [batch 596]: seen 59600 examples : 68.0 eps, Loss: 7.108, Avg loss: 7.082, Best loss: 7.081\n",
      "    [batch 603]: seen 60300 examples : 68.0 eps, Loss: 7.059, Avg loss: 7.079, Best loss: 7.079\n",
      "    [batch 610]: seen 61000 examples : 68.0 eps, Loss: 7.018, Avg loss: 7.074, Best loss: 7.074\n",
      "    [batch 617]: seen 61700 examples : 68.0 eps, Loss: 7.026, Avg loss: 7.072, Best loss: 7.072\n",
      "    [batch 624]: seen 62400 examples : 68.0 eps, Loss: 6.947, Avg loss: 7.070, Best loss: 7.070\n",
      "    [batch 631]: seen 63100 examples : 68.0 eps, Loss: 6.991, Avg loss: 7.066, Best loss: 7.066\n",
      "    [batch 638]: seen 63800 examples : 68.0 eps, Loss: 7.076, Avg loss: 7.066, Best loss: 7.065\n",
      "    [batch 645]: seen 64500 examples : 68.0 eps, Loss: 7.043, Avg loss: 7.062, Best loss: 7.062\n",
      "    [batch 652]: seen 65200 examples : 68.0 eps, Loss: 7.021, Avg loss: 7.058, Best loss: 7.058\n",
      "    [batch 659]: seen 65900 examples : 68.0 eps, Loss: 7.069, Avg loss: 7.055, Best loss: 7.055\n",
      "    [batch 666]: seen 66600 examples : 68.0 eps, Loss: 6.934, Avg loss: 7.050, Best loss: 7.050\n",
      "    [batch 673]: seen 67300 examples : 68.0 eps, Loss: 6.994, Avg loss: 7.047, Best loss: 7.047\n",
      "    [batch 680]: seen 68000 examples : 68.0 eps, Loss: 6.999, Avg loss: 7.045, Best loss: 7.045\n",
      "    [batch 687]: seen 68700 examples : 67.9 eps, Loss: 6.961, Avg loss: 7.041, Best loss: 7.041\n",
      "    [batch 694]: seen 69400 examples : 67.9 eps, Loss: 6.919, Avg loss: 7.036, Best loss: 7.036\n",
      "    [batch 701]: seen 70100 examples : 67.9 eps, Loss: 7.035, Avg loss: 7.036, Best loss: 7.035\n",
      "    [batch 708]: seen 70800 examples : 67.9 eps, Loss: 7.015, Avg loss: 7.033, Best loss: 7.033\n",
      "    [batch 715]: seen 71500 examples : 68.0 eps, Loss: 6.930, Avg loss: 7.029, Best loss: 7.029\n",
      "    [batch 722]: seen 72200 examples : 67.9 eps, Loss: 7.026, Avg loss: 7.026, Best loss: 7.026\n",
      "    [batch 729]: seen 72900 examples : 68.0 eps, Loss: 6.925, Avg loss: 7.023, Best loss: 7.023\n",
      "    [batch 736]: seen 73600 examples : 68.0 eps, Loss: 6.913, Avg loss: 7.020, Best loss: 7.020\n",
      "    [batch 743]: seen 74300 examples : 68.0 eps, Loss: 7.016, Avg loss: 7.016, Best loss: 7.016\n",
      "    [batch 750]: seen 75000 examples : 67.9 eps, Loss: 6.967, Avg loss: 7.013, Best loss: 7.013\n",
      "    [batch 757]: seen 75700 examples : 68.0 eps, Loss: 7.049, Avg loss: 7.012, Best loss: 7.011\n",
      "    [batch 764]: seen 76400 examples : 68.0 eps, Loss: 7.045, Avg loss: 7.011, Best loss: 7.010\n",
      "    [batch 771]: seen 77100 examples : 68.0 eps, Loss: 6.987, Avg loss: 7.006, Best loss: 7.006\n",
      "    [batch 778]: seen 77800 examples : 68.0 eps, Loss: 6.917, Avg loss: 7.003, Best loss: 7.003\n",
      "    [batch 785]: seen 78500 examples : 68.0 eps, Loss: 7.099, Avg loss: 7.003, Best loss: 7.002\n",
      "    [batch 792]: seen 79200 examples : 67.9 eps, Loss: 6.899, Avg loss: 7.002, Best loss: 7.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 799]: seen 79900 examples : 67.9 eps, Loss: 6.893, Avg loss: 6.998, Best loss: 6.998\n",
      "    [batch 806]: seen 80600 examples : 68.0 eps, Loss: 6.943, Avg loss: 6.997, Best loss: 6.996\n",
      "    [batch 813]: seen 81300 examples : 67.9 eps, Loss: 6.961, Avg loss: 6.995, Best loss: 6.995\n",
      "    [batch 820]: seen 82000 examples : 67.9 eps, Loss: 6.990, Avg loss: 6.992, Best loss: 6.992\n",
      "    [batch 827]: seen 82700 examples : 67.9 eps, Loss: 6.925, Avg loss: 6.992, Best loss: 6.992\n",
      "    [batch 834]: seen 83400 examples : 67.9 eps, Loss: 6.919, Avg loss: 6.988, Best loss: 6.988\n",
      "    [batch 841]: seen 84100 examples : 67.9 eps, Loss: 6.982, Avg loss: 6.986, Best loss: 6.986\n",
      "    [batch 848]: seen 84800 examples : 67.9 eps, Loss: 6.984, Avg loss: 6.983, Best loss: 6.983\n",
      "    [batch 855]: seen 85500 examples : 67.9 eps, Loss: 6.925, Avg loss: 6.980, Best loss: 6.980\n",
      "    [batch 862]: seen 86200 examples : 67.9 eps, Loss: 6.867, Avg loss: 6.974, Best loss: 6.974\n",
      "    [batch 869]: seen 86900 examples : 67.9 eps, Loss: 6.940, Avg loss: 6.971, Best loss: 6.971\n",
      "    [batch 876]: seen 87600 examples : 67.9 eps, Loss: 6.983, Avg loss: 6.970, Best loss: 6.969\n",
      "    [batch 883]: seen 88300 examples : 67.9 eps, Loss: 6.829, Avg loss: 6.966, Best loss: 6.966\n",
      "    [batch 890]: seen 89000 examples : 67.9 eps, Loss: 6.942, Avg loss: 6.964, Best loss: 6.964\n",
      "    [batch 897]: seen 89700 examples : 67.9 eps, Loss: 6.947, Avg loss: 6.963, Best loss: 6.963\n",
      "    [batch 904]: seen 90400 examples : 67.9 eps, Loss: 7.022, Avg loss: 6.963, Best loss: 6.962\n",
      "    [batch 911]: seen 91100 examples : 67.9 eps, Loss: 6.913, Avg loss: 6.960, Best loss: 6.960\n",
      "    [batch 918]: seen 91800 examples : 67.9 eps, Loss: 6.890, Avg loss: 6.958, Best loss: 6.958\n",
      "    [batch 925]: seen 92500 examples : 67.9 eps, Loss: 6.956, Avg loss: 6.957, Best loss: 6.956\n",
      "    [batch 932]: seen 93200 examples : 67.9 eps, Loss: 6.943, Avg loss: 6.956, Best loss: 6.956\n",
      "    [batch 939]: seen 93900 examples : 67.9 eps, Loss: 6.899, Avg loss: 6.953, Best loss: 6.953\n",
      "    [batch 946]: seen 94600 examples : 67.9 eps, Loss: 6.965, Avg loss: 6.951, Best loss: 6.951\n",
      "    [batch 953]: seen 95300 examples : 67.9 eps, Loss: 6.913, Avg loss: 6.948, Best loss: 6.948\n",
      "    [batch 960]: seen 96000 examples : 67.9 eps, Loss: 6.872, Avg loss: 6.946, Best loss: 6.946\n",
      "    [batch 967]: seen 96700 examples : 67.9 eps, Loss: 6.932, Avg loss: 6.943, Best loss: 6.943\n",
      "    [batch 974]: seen 97400 examples : 67.9 eps, Loss: 6.922, Avg loss: 6.941, Best loss: 6.941\n",
      "    [batch 981]: seen 98100 examples : 67.9 eps, Loss: 6.891, Avg loss: 6.936, Best loss: 6.936\n",
      "    [batch 988]: seen 98800 examples : 67.9 eps, Loss: 6.927, Avg loss: 6.936, Best loss: 6.936\n",
      "    [batch 995]: seen 99500 examples : 67.9 eps, Loss: 6.967, Avg loss: 6.934, Best loss: 6.933\n",
      "    [batch 1002]: seen 100200 examples : 67.9 eps, Loss: 6.854, Avg loss: 6.929, Best loss: 6.929\n",
      "    [batch 1009]: seen 100900 examples : 67.9 eps, Loss: 6.935, Avg loss: 6.927, Best loss: 6.927\n",
      "    [batch 1016]: seen 101600 examples : 67.9 eps, Loss: 6.867, Avg loss: 6.927, Best loss: 6.927\n",
      "    [batch 1023]: seen 102300 examples : 67.9 eps, Loss: 6.886, Avg loss: 6.923, Best loss: 6.923\n",
      "    [batch 1030]: seen 103000 examples : 67.9 eps, Loss: 6.870, Avg loss: 6.922, Best loss: 6.922\n",
      "    [batch 1037]: seen 103700 examples : 67.9 eps, Loss: 6.889, Avg loss: 6.920, Best loss: 6.920\n",
      "    [batch 1044]: seen 104400 examples : 67.9 eps, Loss: 6.893, Avg loss: 6.917, Best loss: 6.917\n",
      "    [batch 1051]: seen 105100 examples : 67.9 eps, Loss: 6.949, Avg loss: 6.916, Best loss: 6.914\n",
      "    [batch 1058]: seen 105800 examples : 67.9 eps, Loss: 6.874, Avg loss: 6.914, Best loss: 6.914\n",
      "    [batch 1065]: seen 106500 examples : 67.9 eps, Loss: 6.874, Avg loss: 6.912, Best loss: 6.912\n",
      "    [batch 1072]: seen 107200 examples : 67.9 eps, Loss: 6.889, Avg loss: 6.909, Best loss: 6.909\n",
      "    [batch 1079]: seen 107900 examples : 67.9 eps, Loss: 6.884, Avg loss: 6.907, Best loss: 6.907\n",
      "    [batch 1086]: seen 108600 examples : 67.9 eps, Loss: 6.896, Avg loss: 6.904, Best loss: 6.904\n",
      "    [batch 1093]: seen 109300 examples : 67.9 eps, Loss: 6.916, Avg loss: 6.901, Best loss: 6.901\n",
      "    [batch 1100]: seen 110000 examples : 67.9 eps, Loss: 6.839, Avg loss: 6.901, Best loss: 6.901\n",
      "    [batch 1107]: seen 110700 examples : 67.9 eps, Loss: 6.873, Avg loss: 6.898, Best loss: 6.898\n",
      "    [batch 1114]: seen 111400 examples : 67.9 eps, Loss: 6.892, Avg loss: 6.896, Best loss: 6.896\n",
      "    [batch 1121]: seen 112100 examples : 67.9 eps, Loss: 6.858, Avg loss: 6.896, Best loss: 6.895\n",
      "    [batch 1128]: seen 112800 examples : 67.9 eps, Loss: 6.855, Avg loss: 6.893, Best loss: 6.893\n",
      "    [batch 1135]: seen 113500 examples : 67.9 eps, Loss: 6.875, Avg loss: 6.890, Best loss: 6.890\n",
      "    [batch 1142]: seen 114200 examples : 67.9 eps, Loss: 6.745, Avg loss: 6.889, Best loss: 6.889\n",
      "    [batch 1149]: seen 114900 examples : 67.9 eps, Loss: 6.877, Avg loss: 6.887, Best loss: 6.887\n",
      "    [batch 1156]: seen 115600 examples : 67.9 eps, Loss: 6.826, Avg loss: 6.887, Best loss: 6.887\n",
      "    [batch 1163]: seen 116300 examples : 67.9 eps, Loss: 6.917, Avg loss: 6.886, Best loss: 6.885\n",
      "    [batch 1170]: seen 117000 examples : 67.9 eps, Loss: 6.872, Avg loss: 6.884, Best loss: 6.884\n",
      "    [batch 1177]: seen 117700 examples : 67.9 eps, Loss: 6.969, Avg loss: 6.883, Best loss: 6.882\n",
      "    [batch 1184]: seen 118400 examples : 67.9 eps, Loss: 6.785, Avg loss: 6.880, Best loss: 6.880\n",
      "    [batch 1191]: seen 119100 examples : 67.9 eps, Loss: 6.862, Avg loss: 6.879, Best loss: 6.879\n",
      "    [batch 1198]: seen 119800 examples : 67.9 eps, Loss: 6.786, Avg loss: 6.877, Best loss: 6.877\n",
      "    [batch 1205]: seen 120500 examples : 67.9 eps, Loss: 6.801, Avg loss: 6.873, Best loss: 6.873\n",
      "    [batch 1212]: seen 121200 examples : 67.9 eps, Loss: 6.862, Avg loss: 6.871, Best loss: 6.871\n",
      "    [batch 1219]: seen 121900 examples : 67.9 eps, Loss: 6.791, Avg loss: 6.868, Best loss: 6.868\n",
      "    [batch 1226]: seen 122600 examples : 67.9 eps, Loss: 6.852, Avg loss: 6.868, Best loss: 6.868\n",
      "    [batch 1233]: seen 123300 examples : 67.9 eps, Loss: 6.843, Avg loss: 6.867, Best loss: 6.867\n",
      "    [batch 1240]: seen 124000 examples : 67.9 eps, Loss: 6.890, Avg loss: 6.866, Best loss: 6.866\n",
      "    [batch 1247]: seen 124700 examples : 67.9 eps, Loss: 6.893, Avg loss: 6.866, Best loss: 6.866\n",
      "    [batch 1254]: seen 125400 examples : 67.9 eps, Loss: 6.787, Avg loss: 6.864, Best loss: 6.864\n",
      "    [batch 1261]: seen 126100 examples : 67.9 eps, Loss: 6.891, Avg loss: 6.863, Best loss: 6.862\n",
      "    [batch 1268]: seen 126800 examples : 67.9 eps, Loss: 6.791, Avg loss: 6.861, Best loss: 6.861\n",
      "    [batch 1275]: seen 127500 examples : 67.9 eps, Loss: 6.859, Avg loss: 6.860, Best loss: 6.860\n",
      "    [batch 1282]: seen 128200 examples : 67.9 eps, Loss: 6.764, Avg loss: 6.858, Best loss: 6.858\n",
      "    [batch 1289]: seen 128900 examples : 67.9 eps, Loss: 6.792, Avg loss: 6.856, Best loss: 6.856\n",
      "    [batch 1296]: seen 129600 examples : 67.9 eps, Loss: 6.885, Avg loss: 6.853, Best loss: 6.853\n",
      "    [batch 1303]: seen 130300 examples : 67.9 eps, Loss: 6.829, Avg loss: 6.853, Best loss: 6.852\n",
      "    [batch 1310]: seen 131000 examples : 67.9 eps, Loss: 6.830, Avg loss: 6.851, Best loss: 6.851\n",
      "    [batch 1317]: seen 131700 examples : 67.9 eps, Loss: 6.854, Avg loss: 6.851, Best loss: 6.851\n",
      "    [batch 1324]: seen 132400 examples : 67.9 eps, Loss: 6.751, Avg loss: 6.850, Best loss: 6.850\n",
      "    [batch 1331]: seen 133100 examples : 67.9 eps, Loss: 6.809, Avg loss: 6.849, Best loss: 6.849\n",
      "    [batch 1338]: seen 133800 examples : 67.9 eps, Loss: 6.812, Avg loss: 6.847, Best loss: 6.847\n",
      "    [batch 1345]: seen 134500 examples : 67.9 eps, Loss: 6.846, Avg loss: 6.844, Best loss: 6.844\n",
      "    [batch 1352]: seen 135200 examples : 67.9 eps, Loss: 6.853, Avg loss: 6.842, Best loss: 6.842\n",
      "    [batch 1359]: seen 135900 examples : 67.9 eps, Loss: 6.825, Avg loss: 6.843, Best loss: 6.842\n",
      "    [batch 1366]: seen 136600 examples : 67.9 eps, Loss: 6.796, Avg loss: 6.840, Best loss: 6.840\n",
      "    [batch 1373]: seen 137300 examples : 67.9 eps, Loss: 6.757, Avg loss: 6.838, Best loss: 6.838\n",
      "    [batch 1380]: seen 138000 examples : 67.9 eps, Loss: 6.869, Avg loss: 6.837, Best loss: 6.837\n",
      "    [batch 1387]: seen 138700 examples : 67.9 eps, Loss: 6.812, Avg loss: 6.837, Best loss: 6.836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1394]: seen 139400 examples : 67.9 eps, Loss: 6.791, Avg loss: 6.836, Best loss: 6.836\n",
      "    [batch 1401]: seen 140100 examples : 67.9 eps, Loss: 6.850, Avg loss: 6.835, Best loss: 6.835\n",
      "    [batch 1408]: seen 140800 examples : 67.9 eps, Loss: 6.868, Avg loss: 6.833, Best loss: 6.833\n",
      "    [batch 1415]: seen 141500 examples : 67.9 eps, Loss: 6.796, Avg loss: 6.834, Best loss: 6.833\n",
      "    [batch 1422]: seen 142200 examples : 67.9 eps, Loss: 6.744, Avg loss: 6.833, Best loss: 6.833\n",
      "    [batch 1429]: seen 142900 examples : 67.9 eps, Loss: 6.818, Avg loss: 6.833, Best loss: 6.832\n",
      "    [batch 1436]: seen 143600 examples : 67.9 eps, Loss: 6.779, Avg loss: 6.831, Best loss: 6.831\n",
      "    [batch 1443]: seen 144300 examples : 67.9 eps, Loss: 6.862, Avg loss: 6.832, Best loss: 6.831\n",
      "    [batch 1450]: seen 145000 examples : 67.9 eps, Loss: 6.812, Avg loss: 6.831, Best loss: 6.831\n",
      "    [batch 1457]: seen 145700 examples : 67.9 eps, Loss: 6.821, Avg loss: 6.831, Best loss: 6.830\n",
      "    [batch 1464]: seen 146400 examples : 67.9 eps, Loss: 6.894, Avg loss: 6.831, Best loss: 6.830\n",
      "    [batch 1471]: seen 147100 examples : 67.9 eps, Loss: 6.814, Avg loss: 6.832, Best loss: 6.830\n",
      "    [batch 1478]: seen 147800 examples : 67.9 eps, Loss: 6.813, Avg loss: 6.829, Best loss: 6.829\n",
      "    [batch 1485]: seen 148500 examples : 67.9 eps, Loss: 6.764, Avg loss: 6.826, Best loss: 6.826\n",
      "    [batch 1492]: seen 149200 examples : 67.9 eps, Loss: 6.699, Avg loss: 6.823, Best loss: 6.823\n",
      "    [batch 1499]: seen 149900 examples : 67.9 eps, Loss: 6.802, Avg loss: 6.824, Best loss: 6.823\n",
      "    [batch 1506]: seen 150600 examples : 67.9 eps, Loss: 6.751, Avg loss: 6.823, Best loss: 6.823\n",
      "    [batch 1513]: seen 151300 examples : 67.9 eps, Loss: 6.784, Avg loss: 6.820, Best loss: 6.820\n",
      "    [batch 1520]: seen 152000 examples : 67.9 eps, Loss: 6.794, Avg loss: 6.818, Best loss: 6.818\n",
      "    [batch 1527]: seen 152700 examples : 67.9 eps, Loss: 6.822, Avg loss: 6.818, Best loss: 6.818\n",
      "    [batch 1534]: seen 153400 examples : 67.9 eps, Loss: 6.846, Avg loss: 6.816, Best loss: 6.815\n",
      "    [batch 1541]: seen 154100 examples : 67.9 eps, Loss: 6.821, Avg loss: 6.815, Best loss: 6.814\n",
      "    [batch 1548]: seen 154800 examples : 67.9 eps, Loss: 6.781, Avg loss: 6.812, Best loss: 6.812\n",
      "    [batch 1555]: seen 155500 examples : 67.9 eps, Loss: 6.816, Avg loss: 6.809, Best loss: 6.808\n",
      "    [batch 1562]: seen 156200 examples : 67.9 eps, Loss: 6.732, Avg loss: 6.807, Best loss: 6.807\n",
      "    [batch 1569]: seen 156900 examples : 67.9 eps, Loss: 6.780, Avg loss: 6.802, Best loss: 6.802\n",
      "    [batch 1576]: seen 157600 examples : 67.9 eps, Loss: 6.740, Avg loss: 6.803, Best loss: 6.802\n",
      "    [batch 1583]: seen 158300 examples : 67.9 eps, Loss: 6.767, Avg loss: 6.802, Best loss: 6.802\n",
      "    [batch 1590]: seen 159000 examples : 67.9 eps, Loss: 6.771, Avg loss: 6.802, Best loss: 6.801\n",
      "    [batch 1597]: seen 159700 examples : 67.9 eps, Loss: 6.701, Avg loss: 6.799, Best loss: 6.799\n",
      "    [batch 1604]: seen 160400 examples : 67.9 eps, Loss: 6.856, Avg loss: 6.801, Best loss: 6.799\n",
      "    [batch 1611]: seen 161100 examples : 67.9 eps, Loss: 6.716, Avg loss: 6.800, Best loss: 6.799\n",
      "    [batch 1618]: seen 161800 examples : 67.9 eps, Loss: 6.750, Avg loss: 6.797, Best loss: 6.797\n",
      "    [batch 1625]: seen 162500 examples : 67.9 eps, Loss: 6.829, Avg loss: 6.800, Best loss: 6.797\n",
      "    [batch 1632]: seen 163200 examples : 67.9 eps, Loss: 6.840, Avg loss: 6.800, Best loss: 6.797\n",
      "    [batch 1639]: seen 163900 examples : 67.9 eps, Loss: 6.719, Avg loss: 6.799, Best loss: 6.797\n",
      "    [batch 1646]: seen 164600 examples : 67.9 eps, Loss: 6.801, Avg loss: 6.797, Best loss: 6.797\n",
      "    [batch 1653]: seen 165300 examples : 67.9 eps, Loss: 6.794, Avg loss: 6.795, Best loss: 6.795\n",
      "    [batch 1660]: seen 166000 examples : 67.9 eps, Loss: 6.742, Avg loss: 6.793, Best loss: 6.793\n",
      "    [batch 1667]: seen 166700 examples : 67.9 eps, Loss: 6.749, Avg loss: 6.792, Best loss: 6.792\n",
      "    [batch 1674]: seen 167400 examples : 67.9 eps, Loss: 6.812, Avg loss: 6.788, Best loss: 6.787\n",
      "    [batch 1681]: seen 168100 examples : 67.9 eps, Loss: 6.819, Avg loss: 6.787, Best loss: 6.786\n",
      "    [batch 1688]: seen 168800 examples : 67.9 eps, Loss: 6.764, Avg loss: 6.787, Best loss: 6.786\n",
      "    [batch 1695]: seen 169500 examples : 67.9 eps, Loss: 6.780, Avg loss: 6.787, Best loss: 6.786\n",
      "    [batch 1702]: seen 170200 examples : 67.9 eps, Loss: 6.834, Avg loss: 6.788, Best loss: 6.786\n",
      "    [batch 1709]: seen 170900 examples : 67.9 eps, Loss: 6.743, Avg loss: 6.786, Best loss: 6.786\n",
      "    [batch 1716]: seen 171600 examples : 67.9 eps, Loss: 6.744, Avg loss: 6.785, Best loss: 6.785\n",
      "    [batch 1723]: seen 172300 examples : 67.8 eps, Loss: 6.808, Avg loss: 6.787, Best loss: 6.784\n",
      "    [batch 1730]: seen 173000 examples : 67.8 eps, Loss: 6.813, Avg loss: 6.786, Best loss: 6.784\n",
      "    [batch 1737]: seen 173700 examples : 67.8 eps, Loss: 6.728, Avg loss: 6.784, Best loss: 6.784\n",
      "    [batch 1744]: seen 174400 examples : 67.8 eps, Loss: 6.760, Avg loss: 6.784, Best loss: 6.784\n",
      "    [batch 1751]: seen 175100 examples : 67.8 eps, Loss: 6.764, Avg loss: 6.782, Best loss: 6.782\n",
      "    [batch 1758]: seen 175800 examples : 67.8 eps, Loss: 6.854, Avg loss: 6.783, Best loss: 6.781\n",
      "    [batch 1765]: seen 176500 examples : 67.8 eps, Loss: 6.649, Avg loss: 6.780, Best loss: 6.780\n",
      "    [batch 1772]: seen 177200 examples : 67.8 eps, Loss: 6.875, Avg loss: 6.779, Best loss: 6.778\n",
      "    [batch 1779]: seen 177900 examples : 67.8 eps, Loss: 6.823, Avg loss: 6.778, Best loss: 6.778\n",
      "    [batch 1786]: seen 178600 examples : 67.8 eps, Loss: 6.676, Avg loss: 6.775, Best loss: 6.775\n",
      "    [batch 1793]: seen 179300 examples : 67.8 eps, Loss: 6.785, Avg loss: 6.774, Best loss: 6.774\n",
      "    [batch 1800]: seen 180000 examples : 67.8 eps, Loss: 6.684, Avg loss: 6.770, Best loss: 6.770\n",
      "    [batch 1807]: seen 180700 examples : 67.8 eps, Loss: 6.757, Avg loss: 6.768, Best loss: 6.768\n",
      "    [batch 1814]: seen 181400 examples : 67.8 eps, Loss: 6.758, Avg loss: 6.768, Best loss: 6.767\n",
      "    [batch 1821]: seen 182100 examples : 67.8 eps, Loss: 6.781, Avg loss: 6.767, Best loss: 6.766\n",
      "    [batch 1828]: seen 182800 examples : 67.8 eps, Loss: 6.716, Avg loss: 6.766, Best loss: 6.766\n",
      "    [batch 1835]: seen 183500 examples : 67.8 eps, Loss: 6.758, Avg loss: 6.767, Best loss: 6.766\n",
      "    [batch 1842]: seen 184200 examples : 67.8 eps, Loss: 6.779, Avg loss: 6.764, Best loss: 6.764\n",
      "    [batch 1849]: seen 184900 examples : 67.8 eps, Loss: 6.687, Avg loss: 6.763, Best loss: 6.763\n",
      "    [batch 1856]: seen 185600 examples : 67.8 eps, Loss: 6.772, Avg loss: 6.762, Best loss: 6.762\n",
      "    [batch 1863]: seen 186300 examples : 67.8 eps, Loss: 6.743, Avg loss: 6.761, Best loss: 6.761\n",
      "    [batch 1870]: seen 187000 examples : 67.8 eps, Loss: 6.725, Avg loss: 6.758, Best loss: 6.758\n",
      "    [batch 1877]: seen 187700 examples : 67.8 eps, Loss: 6.742, Avg loss: 6.756, Best loss: 6.756\n",
      "    [batch 1884]: seen 188400 examples : 67.8 eps, Loss: 6.666, Avg loss: 6.754, Best loss: 6.754\n",
      "    [batch 1891]: seen 189100 examples : 67.8 eps, Loss: 6.807, Avg loss: 6.755, Best loss: 6.754\n",
      "    [batch 1898]: seen 189800 examples : 67.8 eps, Loss: 6.624, Avg loss: 6.752, Best loss: 6.752\n",
      "    [batch 1905]: seen 190500 examples : 67.8 eps, Loss: 6.802, Avg loss: 6.751, Best loss: 6.751\n",
      "    [batch 1912]: seen 191200 examples : 67.8 eps, Loss: 6.782, Avg loss: 6.750, Best loss: 6.750\n",
      "    [batch 1919]: seen 191900 examples : 67.8 eps, Loss: 6.730, Avg loss: 6.749, Best loss: 6.749\n",
      "    [batch 1926]: seen 192600 examples : 67.8 eps, Loss: 6.768, Avg loss: 6.750, Best loss: 6.747\n",
      "    [batch 1933]: seen 193300 examples : 67.8 eps, Loss: 6.705, Avg loss: 6.747, Best loss: 6.747\n",
      "    [batch 1940]: seen 194000 examples : 67.8 eps, Loss: 6.654, Avg loss: 6.746, Best loss: 6.746\n",
      "    [batch 1947]: seen 194700 examples : 67.8 eps, Loss: 6.658, Avg loss: 6.744, Best loss: 6.744\n",
      "    [batch 1954]: seen 195400 examples : 67.8 eps, Loss: 6.744, Avg loss: 6.744, Best loss: 6.744\n",
      "    [batch 1961]: seen 196100 examples : 67.8 eps, Loss: 6.694, Avg loss: 6.744, Best loss: 6.744\n",
      "    [batch 1968]: seen 196800 examples : 67.8 eps, Loss: 6.708, Avg loss: 6.743, Best loss: 6.743\n",
      "    [batch 1975]: seen 197500 examples : 67.8 eps, Loss: 6.698, Avg loss: 6.740, Best loss: 6.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1982]: seen 198200 examples : 67.8 eps, Loss: 6.794, Avg loss: 6.740, Best loss: 6.739\n",
      "    [batch 1989]: seen 198900 examples : 67.8 eps, Loss: 6.807, Avg loss: 6.741, Best loss: 6.739\n",
      "    [batch 1996]: seen 199600 examples : 67.8 eps, Loss: 6.704, Avg loss: 6.740, Best loss: 6.739\n",
      "    [batch 2003]: seen 200300 examples : 67.8 eps, Loss: 6.737, Avg loss: 6.739, Best loss: 6.738\n",
      "    [batch 2010]: seen 201000 examples : 67.8 eps, Loss: 6.739, Avg loss: 6.739, Best loss: 6.738\n",
      "    [batch 2017]: seen 201700 examples : 67.8 eps, Loss: 6.766, Avg loss: 6.738, Best loss: 6.737\n",
      "    [batch 2024]: seen 202400 examples : 67.8 eps, Loss: 6.720, Avg loss: 6.736, Best loss: 6.736\n",
      "    [batch 2031]: seen 203100 examples : 67.8 eps, Loss: 6.702, Avg loss: 6.735, Best loss: 6.735\n",
      "    [batch 2038]: seen 203800 examples : 67.8 eps, Loss: 6.681, Avg loss: 6.733, Best loss: 6.733\n",
      "    [batch 2045]: seen 204500 examples : 67.8 eps, Loss: 6.735, Avg loss: 6.732, Best loss: 6.732\n",
      "    [batch 2052]: seen 205200 examples : 67.8 eps, Loss: 6.690, Avg loss: 6.732, Best loss: 6.731\n",
      "    [batch 2059]: seen 205900 examples : 67.8 eps, Loss: 6.770, Avg loss: 6.730, Best loss: 6.730\n",
      "    [batch 2066]: seen 206600 examples : 67.8 eps, Loss: 6.707, Avg loss: 6.728, Best loss: 6.728\n",
      "    [batch 2073]: seen 207300 examples : 67.8 eps, Loss: 6.700, Avg loss: 6.725, Best loss: 6.725\n",
      "    [batch 2080]: seen 208000 examples : 67.8 eps, Loss: 6.756, Avg loss: 6.724, Best loss: 6.724\n",
      "    [batch 2087]: seen 208700 examples : 67.8 eps, Loss: 6.859, Avg loss: 6.726, Best loss: 6.724\n",
      "    [batch 2094]: seen 209400 examples : 67.8 eps, Loss: 6.709, Avg loss: 6.724, Best loss: 6.724\n",
      "    [batch 2101]: seen 210100 examples : 67.8 eps, Loss: 6.667, Avg loss: 6.723, Best loss: 6.723\n",
      "    [batch 2108]: seen 210800 examples : 67.8 eps, Loss: 6.694, Avg loss: 6.720, Best loss: 6.720\n",
      "    [batch 2115]: seen 211500 examples : 67.8 eps, Loss: 6.602, Avg loss: 6.719, Best loss: 6.719\n",
      "    [batch 2122]: seen 212200 examples : 67.8 eps, Loss: 6.735, Avg loss: 6.717, Best loss: 6.717\n",
      "    [batch 2129]: seen 212900 examples : 67.8 eps, Loss: 6.768, Avg loss: 6.719, Best loss: 6.717\n",
      "    [batch 2136]: seen 213600 examples : 67.8 eps, Loss: 6.807, Avg loss: 6.717, Best loss: 6.716\n",
      "    [batch 2143]: seen 214300 examples : 67.8 eps, Loss: 6.592, Avg loss: 6.716, Best loss: 6.716\n",
      "    [batch 2150]: seen 215000 examples : 67.8 eps, Loss: 6.752, Avg loss: 6.717, Best loss: 6.715\n",
      "    [batch 2157]: seen 215700 examples : 67.8 eps, Loss: 6.636, Avg loss: 6.715, Best loss: 6.715\n",
      "    [batch 2164]: seen 216400 examples : 67.8 eps, Loss: 6.655, Avg loss: 6.714, Best loss: 6.714\n",
      "    [batch 2171]: seen 217100 examples : 67.8 eps, Loss: 6.670, Avg loss: 6.713, Best loss: 6.713\n",
      "    [batch 2178]: seen 217800 examples : 67.8 eps, Loss: 6.707, Avg loss: 6.711, Best loss: 6.711\n",
      "    [batch 2185]: seen 218500 examples : 67.8 eps, Loss: 6.689, Avg loss: 6.711, Best loss: 6.710\n",
      "    [batch 2192]: seen 219200 examples : 67.8 eps, Loss: 6.710, Avg loss: 6.709, Best loss: 6.709\n",
      "    [batch 2199]: seen 219900 examples : 67.8 eps, Loss: 6.625, Avg loss: 6.708, Best loss: 6.708\n",
      "    [batch 2206]: seen 220600 examples : 67.8 eps, Loss: 6.724, Avg loss: 6.707, Best loss: 6.707\n",
      "    [batch 2213]: seen 221300 examples : 67.8 eps, Loss: 6.643, Avg loss: 6.707, Best loss: 6.707\n",
      "    [batch 2220]: seen 222000 examples : 67.8 eps, Loss: 6.719, Avg loss: 6.705, Best loss: 6.704\n",
      "    [batch 2227]: seen 222700 examples : 67.8 eps, Loss: 6.789, Avg loss: 6.705, Best loss: 6.704\n",
      "    [batch 2234]: seen 223400 examples : 67.8 eps, Loss: 6.730, Avg loss: 6.704, Best loss: 6.703\n",
      "    [batch 2241]: seen 224100 examples : 67.8 eps, Loss: 6.661, Avg loss: 6.702, Best loss: 6.702\n",
      "    [batch 2248]: seen 224800 examples : 67.8 eps, Loss: 6.745, Avg loss: 6.700, Best loss: 6.699\n",
      "    [batch 2255]: seen 225500 examples : 67.8 eps, Loss: 6.634, Avg loss: 6.699, Best loss: 6.699\n",
      "    [batch 2262]: seen 226200 examples : 67.8 eps, Loss: 6.677, Avg loss: 6.698, Best loss: 6.698\n",
      "    [batch 2269]: seen 226900 examples : 67.8 eps, Loss: 6.628, Avg loss: 6.697, Best loss: 6.697\n",
      "    [batch 2276]: seen 227600 examples : 67.8 eps, Loss: 6.702, Avg loss: 6.698, Best loss: 6.697\n",
      "    [batch 2283]: seen 228300 examples : 67.8 eps, Loss: 6.616, Avg loss: 6.693, Best loss: 6.693\n",
      "    [batch 2290]: seen 229000 examples : 67.8 eps, Loss: 6.686, Avg loss: 6.692, Best loss: 6.692\n",
      "    [batch 2297]: seen 229700 examples : 67.8 eps, Loss: 6.720, Avg loss: 6.691, Best loss: 6.691\n",
      "    [batch 2304]: seen 230400 examples : 67.8 eps, Loss: 6.762, Avg loss: 6.692, Best loss: 6.691\n",
      "    [batch 2311]: seen 231100 examples : 67.8 eps, Loss: 6.757, Avg loss: 6.692, Best loss: 6.691\n",
      "    [batch 2318]: seen 231800 examples : 67.8 eps, Loss: 6.739, Avg loss: 6.693, Best loss: 6.691\n",
      "    [batch 2325]: seen 232500 examples : 67.8 eps, Loss: 6.699, Avg loss: 6.693, Best loss: 6.691\n",
      "    [batch 2332]: seen 233200 examples : 67.8 eps, Loss: 6.665, Avg loss: 6.692, Best loss: 6.691\n",
      "    [batch 2339]: seen 233900 examples : 67.8 eps, Loss: 6.768, Avg loss: 6.693, Best loss: 6.691\n",
      "    [batch 2346]: seen 234600 examples : 67.8 eps, Loss: 6.647, Avg loss: 6.691, Best loss: 6.691\n",
      "    [batch 2353]: seen 235300 examples : 67.8 eps, Loss: 6.583, Avg loss: 6.690, Best loss: 6.690\n",
      "    [batch 2360]: seen 236000 examples : 67.8 eps, Loss: 6.627, Avg loss: 6.688, Best loss: 6.688\n",
      "    [batch 2367]: seen 236700 examples : 67.8 eps, Loss: 6.629, Avg loss: 6.686, Best loss: 6.686\n",
      "    [batch 2374]: seen 237400 examples : 67.8 eps, Loss: 6.685, Avg loss: 6.685, Best loss: 6.685\n",
      "    [batch 2381]: seen 238100 examples : 67.8 eps, Loss: 6.662, Avg loss: 6.684, Best loss: 6.684\n",
      "    [batch 2388]: seen 238800 examples : 67.8 eps, Loss: 6.635, Avg loss: 6.684, Best loss: 6.683\n",
      "    [batch 2395]: seen 239500 examples : 67.8 eps, Loss: 6.716, Avg loss: 6.685, Best loss: 6.683\n",
      "    [batch 2402]: seen 240200 examples : 67.8 eps, Loss: 6.656, Avg loss: 6.684, Best loss: 6.683\n",
      "    [batch 2409]: seen 240900 examples : 67.8 eps, Loss: 6.785, Avg loss: 6.683, Best loss: 6.682\n",
      "    [batch 2416]: seen 241600 examples : 67.8 eps, Loss: 6.709, Avg loss: 6.681, Best loss: 6.681\n",
      "    [batch 2423]: seen 242300 examples : 67.8 eps, Loss: 6.722, Avg loss: 6.682, Best loss: 6.681\n",
      "    [batch 2430]: seen 243000 examples : 67.8 eps, Loss: 6.595, Avg loss: 6.682, Best loss: 6.681\n",
      "    [batch 2437]: seen 243700 examples : 67.8 eps, Loss: 6.668, Avg loss: 6.680, Best loss: 6.680\n",
      "    [batch 2444]: seen 244400 examples : 67.8 eps, Loss: 6.609, Avg loss: 6.678, Best loss: 6.678\n",
      "    [batch 2451]: seen 245100 examples : 67.8 eps, Loss: 6.688, Avg loss: 6.678, Best loss: 6.677\n",
      "    [batch 2458]: seen 245800 examples : 67.8 eps, Loss: 6.655, Avg loss: 6.679, Best loss: 6.677\n",
      "    [batch 2465]: seen 246500 examples : 67.8 eps, Loss: 6.619, Avg loss: 6.677, Best loss: 6.677\n",
      "    [batch 2472]: seen 247200 examples : 67.8 eps, Loss: 6.653, Avg loss: 6.678, Best loss: 6.677\n",
      "    [batch 2479]: seen 247900 examples : 67.8 eps, Loss: 6.616, Avg loss: 6.676, Best loss: 6.676\n",
      "    [batch 2486]: seen 248600 examples : 67.8 eps, Loss: 6.699, Avg loss: 6.676, Best loss: 6.676\n",
      "    [batch 2493]: seen 249300 examples : 67.8 eps, Loss: 6.650, Avg loss: 6.674, Best loss: 6.674\n",
      "    [batch 2500]: seen 250000 examples : 67.8 eps, Loss: 6.647, Avg loss: 6.672, Best loss: 6.672\n",
      "    [batch 2507]: seen 250700 examples : 67.8 eps, Loss: 6.681, Avg loss: 6.670, Best loss: 6.670\n",
      "    [batch 2514]: seen 251400 examples : 67.8 eps, Loss: 6.590, Avg loss: 6.669, Best loss: 6.669\n",
      "    [batch 2521]: seen 252100 examples : 67.8 eps, Loss: 6.691, Avg loss: 6.669, Best loss: 6.668\n",
      "    [batch 2528]: seen 252800 examples : 67.8 eps, Loss: 6.747, Avg loss: 6.670, Best loss: 6.668\n",
      "    [batch 2535]: seen 253500 examples : 67.8 eps, Loss: 6.646, Avg loss: 6.670, Best loss: 6.668\n",
      "    [batch 2542]: seen 254200 examples : 67.8 eps, Loss: 6.718, Avg loss: 6.668, Best loss: 6.667\n",
      "    [batch 2549]: seen 254900 examples : 67.8 eps, Loss: 6.742, Avg loss: 6.671, Best loss: 6.667\n",
      "    [batch 2556]: seen 255600 examples : 67.8 eps, Loss: 6.652, Avg loss: 6.671, Best loss: 6.667\n",
      "    [batch 2563]: seen 256300 examples : 67.8 eps, Loss: 6.621, Avg loss: 6.670, Best loss: 6.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2570]: seen 257000 examples : 67.8 eps, Loss: 6.637, Avg loss: 6.668, Best loss: 6.667\n",
      "    [batch 2577]: seen 257700 examples : 67.8 eps, Loss: 6.638, Avg loss: 6.666, Best loss: 6.666\n",
      "    [batch 2584]: seen 258400 examples : 67.8 eps, Loss: 6.662, Avg loss: 6.665, Best loss: 6.665\n",
      "    [batch 2591]: seen 259100 examples : 67.8 eps, Loss: 6.703, Avg loss: 6.665, Best loss: 6.664\n",
      "    [batch 2598]: seen 259800 examples : 67.8 eps, Loss: 6.698, Avg loss: 6.665, Best loss: 6.664\n",
      "    [batch 2605]: seen 260500 examples : 67.8 eps, Loss: 6.638, Avg loss: 6.665, Best loss: 6.664\n",
      "    [batch 2612]: seen 261200 examples : 67.8 eps, Loss: 6.651, Avg loss: 6.664, Best loss: 6.664\n",
      "    [batch 2619]: seen 261900 examples : 67.8 eps, Loss: 6.608, Avg loss: 6.663, Best loss: 6.663\n",
      "    [batch 2626]: seen 262600 examples : 67.8 eps, Loss: 6.644, Avg loss: 6.664, Best loss: 6.663\n",
      "    [batch 2633]: seen 263300 examples : 67.8 eps, Loss: 6.653, Avg loss: 6.662, Best loss: 6.662\n",
      "    [batch 2640]: seen 264000 examples : 67.8 eps, Loss: 6.680, Avg loss: 6.659, Best loss: 6.659\n",
      "    [batch 2647]: seen 264700 examples : 67.8 eps, Loss: 6.617, Avg loss: 6.659, Best loss: 6.659\n",
      "    [batch 2654]: seen 265400 examples : 67.8 eps, Loss: 6.571, Avg loss: 6.657, Best loss: 6.657\n",
      "    [batch 2661]: seen 266100 examples : 67.8 eps, Loss: 6.652, Avg loss: 6.656, Best loss: 6.656\n",
      "    [batch 2668]: seen 266800 examples : 67.8 eps, Loss: 6.519, Avg loss: 6.655, Best loss: 6.655\n",
      "    [batch 2675]: seen 267500 examples : 67.8 eps, Loss: 6.567, Avg loss: 6.653, Best loss: 6.653\n",
      "    [batch 2682]: seen 268200 examples : 67.8 eps, Loss: 6.595, Avg loss: 6.651, Best loss: 6.651\n",
      "    [batch 2689]: seen 268900 examples : 67.8 eps, Loss: 6.671, Avg loss: 6.652, Best loss: 6.651\n",
      "    [batch 2696]: seen 269600 examples : 67.8 eps, Loss: 6.646, Avg loss: 6.651, Best loss: 6.651\n",
      "    [batch 2703]: seen 270300 examples : 67.8 eps, Loss: 6.692, Avg loss: 6.654, Best loss: 6.651\n",
      "    [batch 2710]: seen 271000 examples : 67.8 eps, Loss: 6.609, Avg loss: 6.653, Best loss: 6.651\n",
      "    [batch 2717]: seen 271700 examples : 67.8 eps, Loss: 6.556, Avg loss: 6.650, Best loss: 6.650\n",
      "    [batch 2724]: seen 272400 examples : 67.8 eps, Loss: 6.666, Avg loss: 6.651, Best loss: 6.650\n",
      "    [batch 2731]: seen 273100 examples : 67.8 eps, Loss: 6.657, Avg loss: 6.651, Best loss: 6.650\n",
      "    [batch 2738]: seen 273800 examples : 67.8 eps, Loss: 6.595, Avg loss: 6.650, Best loss: 6.650\n",
      "    [batch 2745]: seen 274500 examples : 67.8 eps, Loss: 6.609, Avg loss: 6.650, Best loss: 6.650\n",
      "    [batch 2752]: seen 275200 examples : 67.8 eps, Loss: 6.636, Avg loss: 6.649, Best loss: 6.649\n",
      "    [batch 2759]: seen 275900 examples : 67.8 eps, Loss: 6.573, Avg loss: 6.649, Best loss: 6.648\n",
      "    [batch 2766]: seen 276600 examples : 67.8 eps, Loss: 6.662, Avg loss: 6.648, Best loss: 6.647\n",
      "    [batch 2773]: seen 277300 examples : 67.8 eps, Loss: 6.648, Avg loss: 6.646, Best loss: 6.646\n",
      "    [batch 2780]: seen 278000 examples : 67.8 eps, Loss: 6.595, Avg loss: 6.646, Best loss: 6.646\n",
      "    [batch 2787]: seen 278700 examples : 67.8 eps, Loss: 6.642, Avg loss: 6.642, Best loss: 6.642\n",
      "    [batch 2794]: seen 279400 examples : 67.8 eps, Loss: 6.623, Avg loss: 6.643, Best loss: 6.642\n",
      "    [batch 2801]: seen 280100 examples : 67.8 eps, Loss: 6.705, Avg loss: 6.643, Best loss: 6.642\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:02\n",
      "[EPOCH 2] Complete. Avg Loss: 6.6413542658411036; Best Loss: 6.6413542658411036\n",
      "[EPOCH 3] Starting training..\n",
      "    [batch 9]: seen 900 examples : 86.9 eps, Loss: 6.692, Avg loss: 6.641, Best loss: 6.640\n",
      "    [batch 16]: seen 1600 examples : 77.9 eps, Loss: 6.621, Avg loss: 6.641, Best loss: 6.640\n",
      "    [batch 23]: seen 2300 examples : 74.8 eps, Loss: 6.655, Avg loss: 6.641, Best loss: 6.640\n",
      "    [batch 30]: seen 3000 examples : 73.3 eps, Loss: 6.611, Avg loss: 6.640, Best loss: 6.640\n",
      "    [batch 37]: seen 3700 examples : 72.4 eps, Loss: 6.663, Avg loss: 6.642, Best loss: 6.640\n",
      "    [batch 44]: seen 4400 examples : 71.8 eps, Loss: 6.629, Avg loss: 6.639, Best loss: 6.639\n",
      "    [batch 51]: seen 5100 examples : 71.4 eps, Loss: 6.635, Avg loss: 6.638, Best loss: 6.638\n",
      "    [batch 58]: seen 5800 examples : 71.0 eps, Loss: 6.605, Avg loss: 6.636, Best loss: 6.636\n",
      "    [batch 65]: seen 6500 examples : 70.8 eps, Loss: 6.572, Avg loss: 6.635, Best loss: 6.634\n",
      "    [batch 72]: seen 7200 examples : 70.6 eps, Loss: 6.679, Avg loss: 6.636, Best loss: 6.634\n",
      "    [batch 79]: seen 7900 examples : 70.4 eps, Loss: 6.642, Avg loss: 6.634, Best loss: 6.634\n",
      "    [batch 86]: seen 8600 examples : 70.2 eps, Loss: 6.643, Avg loss: 6.633, Best loss: 6.633\n",
      "    [batch 93]: seen 9300 examples : 70.0 eps, Loss: 6.614, Avg loss: 6.631, Best loss: 6.631\n",
      "    [batch 100]: seen 10000 examples : 69.7 eps, Loss: 6.600, Avg loss: 6.631, Best loss: 6.631\n",
      "    [batch 107]: seen 10700 examples : 69.6 eps, Loss: 6.583, Avg loss: 6.630, Best loss: 6.630\n",
      "    [batch 114]: seen 11400 examples : 69.5 eps, Loss: 6.617, Avg loss: 6.630, Best loss: 6.630\n",
      "    [batch 121]: seen 12100 examples : 69.4 eps, Loss: 6.616, Avg loss: 6.629, Best loss: 6.629\n",
      "    [batch 128]: seen 12800 examples : 69.4 eps, Loss: 6.660, Avg loss: 6.626, Best loss: 6.626\n",
      "    [batch 135]: seen 13500 examples : 69.3 eps, Loss: 6.603, Avg loss: 6.627, Best loss: 6.626\n",
      "    [batch 142]: seen 14200 examples : 69.2 eps, Loss: 6.627, Avg loss: 6.626, Best loss: 6.626\n",
      "    [batch 149]: seen 14900 examples : 69.2 eps, Loss: 6.573, Avg loss: 6.626, Best loss: 6.626\n",
      "    [batch 156]: seen 15600 examples : 69.1 eps, Loss: 6.630, Avg loss: 6.626, Best loss: 6.626\n",
      "    [batch 163]: seen 16300 examples : 69.0 eps, Loss: 6.601, Avg loss: 6.625, Best loss: 6.625\n",
      "    [batch 170]: seen 17000 examples : 69.0 eps, Loss: 6.619, Avg loss: 6.626, Best loss: 6.625\n",
      "    [batch 177]: seen 17700 examples : 69.0 eps, Loss: 6.503, Avg loss: 6.624, Best loss: 6.624\n",
      "    [batch 184]: seen 18400 examples : 68.9 eps, Loss: 6.552, Avg loss: 6.623, Best loss: 6.623\n",
      "    [batch 191]: seen 19100 examples : 68.9 eps, Loss: 6.647, Avg loss: 6.624, Best loss: 6.623\n",
      "    [batch 198]: seen 19800 examples : 68.8 eps, Loss: 6.659, Avg loss: 6.624, Best loss: 6.623\n",
      "    [batch 205]: seen 20500 examples : 68.8 eps, Loss: 6.635, Avg loss: 6.625, Best loss: 6.623\n",
      "    [batch 212]: seen 21200 examples : 68.8 eps, Loss: 6.650, Avg loss: 6.626, Best loss: 6.623\n",
      "    [batch 219]: seen 21900 examples : 68.8 eps, Loss: 6.585, Avg loss: 6.625, Best loss: 6.623\n",
      "    [batch 226]: seen 22600 examples : 68.7 eps, Loss: 6.590, Avg loss: 6.625, Best loss: 6.623\n",
      "    [batch 233]: seen 23300 examples : 68.7 eps, Loss: 6.624, Avg loss: 6.624, Best loss: 6.623\n",
      "    [batch 240]: seen 24000 examples : 68.7 eps, Loss: 6.596, Avg loss: 6.621, Best loss: 6.621\n",
      "    [batch 247]: seen 24700 examples : 68.7 eps, Loss: 6.638, Avg loss: 6.619, Best loss: 6.619\n",
      "    [batch 254]: seen 25400 examples : 68.6 eps, Loss: 6.590, Avg loss: 6.616, Best loss: 6.616\n",
      "    [batch 261]: seen 26100 examples : 68.6 eps, Loss: 6.629, Avg loss: 6.613, Best loss: 6.613\n",
      "    [batch 268]: seen 26800 examples : 68.6 eps, Loss: 6.519, Avg loss: 6.613, Best loss: 6.612\n",
      "    [batch 275]: seen 27500 examples : 68.6 eps, Loss: 6.526, Avg loss: 6.612, Best loss: 6.612\n",
      "    [batch 282]: seen 28200 examples : 68.6 eps, Loss: 6.659, Avg loss: 6.612, Best loss: 6.611\n",
      "    [batch 289]: seen 28900 examples : 68.6 eps, Loss: 6.598, Avg loss: 6.612, Best loss: 6.611\n",
      "    [batch 296]: seen 29600 examples : 68.5 eps, Loss: 6.582, Avg loss: 6.613, Best loss: 6.611\n",
      "    [batch 303]: seen 30300 examples : 68.5 eps, Loss: 6.544, Avg loss: 6.611, Best loss: 6.611\n",
      "    [batch 310]: seen 31000 examples : 68.5 eps, Loss: 6.616, Avg loss: 6.612, Best loss: 6.611\n",
      "    [batch 317]: seen 31700 examples : 68.5 eps, Loss: 6.588, Avg loss: 6.613, Best loss: 6.611\n",
      "    [batch 324]: seen 32400 examples : 68.5 eps, Loss: 6.558, Avg loss: 6.613, Best loss: 6.611\n",
      "    [batch 331]: seen 33100 examples : 68.5 eps, Loss: 6.661, Avg loss: 6.613, Best loss: 6.611\n",
      "    [batch 338]: seen 33800 examples : 68.5 eps, Loss: 6.601, Avg loss: 6.612, Best loss: 6.611\n",
      "    [batch 345]: seen 34500 examples : 68.5 eps, Loss: 6.638, Avg loss: 6.611, Best loss: 6.610\n",
      "    [batch 352]: seen 35200 examples : 68.5 eps, Loss: 6.603, Avg loss: 6.611, Best loss: 6.610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 359]: seen 35900 examples : 68.4 eps, Loss: 6.563, Avg loss: 6.611, Best loss: 6.610\n",
      "    [batch 366]: seen 36600 examples : 68.4 eps, Loss: 6.601, Avg loss: 6.610, Best loss: 6.610\n",
      "    [batch 373]: seen 37300 examples : 68.4 eps, Loss: 6.618, Avg loss: 6.612, Best loss: 6.610\n",
      "    [batch 380]: seen 38000 examples : 68.4 eps, Loss: 6.571, Avg loss: 6.612, Best loss: 6.610\n",
      "    [batch 387]: seen 38700 examples : 68.4 eps, Loss: 6.633, Avg loss: 6.612, Best loss: 6.610\n",
      "    [batch 394]: seen 39400 examples : 68.4 eps, Loss: 6.614, Avg loss: 6.611, Best loss: 6.610\n",
      "    [batch 401]: seen 40100 examples : 68.4 eps, Loss: 6.587, Avg loss: 6.609, Best loss: 6.609\n",
      "    [batch 408]: seen 40800 examples : 68.4 eps, Loss: 6.641, Avg loss: 6.608, Best loss: 6.607\n",
      "    [batch 415]: seen 41500 examples : 68.4 eps, Loss: 6.636, Avg loss: 6.610, Best loss: 6.607\n",
      "    [batch 422]: seen 42200 examples : 68.4 eps, Loss: 6.691, Avg loss: 6.610, Best loss: 6.607\n",
      "    [batch 429]: seen 42900 examples : 68.3 eps, Loss: 6.631, Avg loss: 6.610, Best loss: 6.607\n",
      "    [batch 436]: seen 43600 examples : 68.3 eps, Loss: 6.561, Avg loss: 6.609, Best loss: 6.607\n",
      "    [batch 443]: seen 44300 examples : 68.3 eps, Loss: 6.583, Avg loss: 6.609, Best loss: 6.607\n",
      "    [batch 450]: seen 45000 examples : 68.3 eps, Loss: 6.561, Avg loss: 6.609, Best loss: 6.607\n",
      "    [batch 457]: seen 45700 examples : 68.3 eps, Loss: 6.693, Avg loss: 6.610, Best loss: 6.607\n",
      "    [batch 464]: seen 46400 examples : 68.3 eps, Loss: 6.662, Avg loss: 6.610, Best loss: 6.607\n",
      "    [batch 471]: seen 47100 examples : 68.3 eps, Loss: 6.641, Avg loss: 6.611, Best loss: 6.607\n",
      "    [batch 478]: seen 47800 examples : 68.3 eps, Loss: 6.698, Avg loss: 6.609, Best loss: 6.607\n",
      "    [batch 485]: seen 48500 examples : 68.3 eps, Loss: 6.624, Avg loss: 6.609, Best loss: 6.607\n",
      "    [batch 492]: seen 49200 examples : 68.3 eps, Loss: 6.675, Avg loss: 6.608, Best loss: 6.607\n",
      "    [batch 499]: seen 49900 examples : 68.3 eps, Loss: 6.522, Avg loss: 6.606, Best loss: 6.606\n",
      "    [batch 506]: seen 50600 examples : 68.3 eps, Loss: 6.610, Avg loss: 6.607, Best loss: 6.606\n",
      "    [batch 513]: seen 51300 examples : 68.3 eps, Loss: 6.487, Avg loss: 6.604, Best loss: 6.604\n",
      "    [batch 520]: seen 52000 examples : 68.3 eps, Loss: 6.524, Avg loss: 6.603, Best loss: 6.603\n",
      "    [batch 527]: seen 52700 examples : 68.3 eps, Loss: 6.588, Avg loss: 6.602, Best loss: 6.602\n",
      "    [batch 534]: seen 53400 examples : 68.3 eps, Loss: 6.524, Avg loss: 6.601, Best loss: 6.600\n",
      "    [batch 541]: seen 54100 examples : 68.3 eps, Loss: 6.596, Avg loss: 6.598, Best loss: 6.598\n",
      "    [batch 548]: seen 54800 examples : 68.3 eps, Loss: 6.622, Avg loss: 6.597, Best loss: 6.596\n",
      "    [batch 555]: seen 55500 examples : 68.3 eps, Loss: 6.584, Avg loss: 6.596, Best loss: 6.596\n",
      "    [batch 562]: seen 56200 examples : 68.2 eps, Loss: 6.546, Avg loss: 6.595, Best loss: 6.595\n",
      "    [batch 569]: seen 56900 examples : 68.2 eps, Loss: 6.592, Avg loss: 6.594, Best loss: 6.594\n",
      "    [batch 576]: seen 57600 examples : 68.2 eps, Loss: 6.662, Avg loss: 6.593, Best loss: 6.592\n",
      "    [batch 583]: seen 58300 examples : 68.2 eps, Loss: 6.663, Avg loss: 6.595, Best loss: 6.592\n",
      "    [batch 590]: seen 59000 examples : 68.2 eps, Loss: 6.661, Avg loss: 6.597, Best loss: 6.592\n",
      "    [batch 597]: seen 59700 examples : 68.2 eps, Loss: 6.554, Avg loss: 6.597, Best loss: 6.592\n",
      "    [batch 604]: seen 60400 examples : 68.2 eps, Loss: 6.511, Avg loss: 6.594, Best loss: 6.592\n",
      "    [batch 611]: seen 61100 examples : 68.2 eps, Loss: 6.503, Avg loss: 6.592, Best loss: 6.592\n",
      "    [batch 618]: seen 61800 examples : 68.2 eps, Loss: 6.626, Avg loss: 6.591, Best loss: 6.591\n",
      "    [batch 625]: seen 62500 examples : 68.2 eps, Loss: 6.612, Avg loss: 6.591, Best loss: 6.590\n",
      "    [batch 632]: seen 63200 examples : 68.2 eps, Loss: 6.539, Avg loss: 6.589, Best loss: 6.589\n",
      "    [batch 639]: seen 63900 examples : 68.2 eps, Loss: 6.639, Avg loss: 6.591, Best loss: 6.589\n",
      "    [batch 646]: seen 64600 examples : 68.2 eps, Loss: 6.540, Avg loss: 6.589, Best loss: 6.589\n",
      "    [batch 653]: seen 65300 examples : 68.2 eps, Loss: 6.589, Avg loss: 6.588, Best loss: 6.588\n",
      "    [batch 660]: seen 66000 examples : 68.2 eps, Loss: 6.637, Avg loss: 6.588, Best loss: 6.587\n",
      "    [batch 667]: seen 66700 examples : 68.2 eps, Loss: 6.484, Avg loss: 6.588, Best loss: 6.587\n",
      "    [batch 674]: seen 67400 examples : 68.2 eps, Loss: 6.600, Avg loss: 6.587, Best loss: 6.587\n",
      "    [batch 681]: seen 68100 examples : 68.2 eps, Loss: 6.529, Avg loss: 6.586, Best loss: 6.586\n",
      "    [batch 688]: seen 68800 examples : 68.2 eps, Loss: 6.643, Avg loss: 6.586, Best loss: 6.585\n",
      "    [batch 695]: seen 69500 examples : 68.2 eps, Loss: 6.588, Avg loss: 6.587, Best loss: 6.585\n",
      "    [batch 702]: seen 70200 examples : 68.2 eps, Loss: 6.602, Avg loss: 6.588, Best loss: 6.585\n",
      "    [batch 709]: seen 70900 examples : 68.2 eps, Loss: 6.591, Avg loss: 6.588, Best loss: 6.585\n",
      "    [batch 716]: seen 71600 examples : 68.2 eps, Loss: 6.435, Avg loss: 6.584, Best loss: 6.584\n",
      "    [batch 723]: seen 72300 examples : 68.2 eps, Loss: 6.518, Avg loss: 6.581, Best loss: 6.581\n",
      "    [batch 730]: seen 73000 examples : 68.2 eps, Loss: 6.520, Avg loss: 6.579, Best loss: 6.579\n",
      "    [batch 737]: seen 73700 examples : 68.2 eps, Loss: 6.612, Avg loss: 6.578, Best loss: 6.578\n",
      "    [batch 744]: seen 74400 examples : 68.2 eps, Loss: 6.454, Avg loss: 6.576, Best loss: 6.576\n",
      "    [batch 751]: seen 75100 examples : 68.1 eps, Loss: 6.462, Avg loss: 6.576, Best loss: 6.576\n",
      "    [batch 758]: seen 75800 examples : 68.1 eps, Loss: 6.517, Avg loss: 6.575, Best loss: 6.575\n",
      "    [batch 765]: seen 76500 examples : 68.2 eps, Loss: 6.598, Avg loss: 6.576, Best loss: 6.575\n",
      "    [batch 772]: seen 77200 examples : 68.2 eps, Loss: 6.556, Avg loss: 6.576, Best loss: 6.575\n",
      "    [batch 779]: seen 77900 examples : 68.1 eps, Loss: 6.549, Avg loss: 6.577, Best loss: 6.575\n",
      "    [batch 786]: seen 78600 examples : 68.1 eps, Loss: 6.552, Avg loss: 6.576, Best loss: 6.575\n",
      "    [batch 793]: seen 79300 examples : 68.1 eps, Loss: 6.596, Avg loss: 6.577, Best loss: 6.575\n",
      "    [batch 800]: seen 80000 examples : 68.1 eps, Loss: 6.555, Avg loss: 6.575, Best loss: 6.575\n",
      "    [batch 807]: seen 80700 examples : 68.1 eps, Loss: 6.529, Avg loss: 6.575, Best loss: 6.574\n",
      "    [batch 814]: seen 81400 examples : 68.1 eps, Loss: 6.548, Avg loss: 6.573, Best loss: 6.573\n",
      "    [batch 821]: seen 82100 examples : 68.1 eps, Loss: 6.508, Avg loss: 6.572, Best loss: 6.572\n",
      "    [batch 828]: seen 82800 examples : 68.1 eps, Loss: 6.599, Avg loss: 6.574, Best loss: 6.572\n",
      "    [batch 835]: seen 83500 examples : 68.1 eps, Loss: 6.508, Avg loss: 6.572, Best loss: 6.572\n",
      "    [batch 842]: seen 84200 examples : 68.1 eps, Loss: 6.547, Avg loss: 6.572, Best loss: 6.571\n",
      "    [batch 849]: seen 84900 examples : 68.1 eps, Loss: 6.539, Avg loss: 6.570, Best loss: 6.570\n",
      "    [batch 856]: seen 85600 examples : 68.1 eps, Loss: 6.559, Avg loss: 6.569, Best loss: 6.569\n",
      "    [batch 863]: seen 86300 examples : 68.1 eps, Loss: 6.631, Avg loss: 6.567, Best loss: 6.567\n",
      "    [batch 870]: seen 87000 examples : 68.1 eps, Loss: 6.526, Avg loss: 6.568, Best loss: 6.567\n",
      "    [batch 877]: seen 87700 examples : 68.1 eps, Loss: 6.577, Avg loss: 6.569, Best loss: 6.567\n",
      "    [batch 884]: seen 88400 examples : 68.1 eps, Loss: 6.621, Avg loss: 6.569, Best loss: 6.567\n",
      "    [batch 891]: seen 89100 examples : 68.1 eps, Loss: 6.559, Avg loss: 6.567, Best loss: 6.567\n",
      "    [batch 898]: seen 89800 examples : 68.1 eps, Loss: 6.509, Avg loss: 6.564, Best loss: 6.564\n",
      "    [batch 905]: seen 90500 examples : 68.1 eps, Loss: 6.559, Avg loss: 6.565, Best loss: 6.564\n",
      "    [batch 912]: seen 91200 examples : 68.1 eps, Loss: 6.586, Avg loss: 6.566, Best loss: 6.564\n",
      "    [batch 919]: seen 91900 examples : 68.1 eps, Loss: 6.589, Avg loss: 6.566, Best loss: 6.564\n",
      "    [batch 926]: seen 92600 examples : 68.1 eps, Loss: 6.564, Avg loss: 6.566, Best loss: 6.564\n",
      "    [batch 933]: seen 93300 examples : 68.1 eps, Loss: 6.595, Avg loss: 6.566, Best loss: 6.564\n",
      "    [batch 940]: seen 94000 examples : 68.1 eps, Loss: 6.597, Avg loss: 6.566, Best loss: 6.564\n",
      "    [batch 947]: seen 94700 examples : 68.1 eps, Loss: 6.528, Avg loss: 6.568, Best loss: 6.564\n",
      "    [batch 954]: seen 95400 examples : 68.1 eps, Loss: 6.630, Avg loss: 6.569, Best loss: 6.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 961]: seen 96100 examples : 68.1 eps, Loss: 6.527, Avg loss: 6.568, Best loss: 6.564\n",
      "    [batch 968]: seen 96800 examples : 68.1 eps, Loss: 6.570, Avg loss: 6.569, Best loss: 6.564\n",
      "    [batch 975]: seen 97500 examples : 68.1 eps, Loss: 6.618, Avg loss: 6.569, Best loss: 6.564\n",
      "    [batch 982]: seen 98200 examples : 68.1 eps, Loss: 6.537, Avg loss: 6.567, Best loss: 6.564\n",
      "    [batch 989]: seen 98900 examples : 68.1 eps, Loss: 6.682, Avg loss: 6.568, Best loss: 6.564\n",
      "    [batch 996]: seen 99600 examples : 68.1 eps, Loss: 6.526, Avg loss: 6.566, Best loss: 6.564\n",
      "    [batch 1003]: seen 100300 examples : 68.1 eps, Loss: 6.571, Avg loss: 6.564, Best loss: 6.564\n",
      "    [batch 1010]: seen 101000 examples : 68.1 eps, Loss: 6.533, Avg loss: 6.561, Best loss: 6.561\n",
      "    [batch 1017]: seen 101700 examples : 68.1 eps, Loss: 6.577, Avg loss: 6.562, Best loss: 6.561\n",
      "    [batch 1024]: seen 102400 examples : 68.1 eps, Loss: 6.618, Avg loss: 6.563, Best loss: 6.561\n",
      "    [batch 1031]: seen 103100 examples : 68.1 eps, Loss: 6.554, Avg loss: 6.563, Best loss: 6.561\n",
      "    [batch 1038]: seen 103800 examples : 68.1 eps, Loss: 6.628, Avg loss: 6.563, Best loss: 6.561\n",
      "    [batch 1045]: seen 104500 examples : 68.1 eps, Loss: 6.599, Avg loss: 6.563, Best loss: 6.561\n",
      "    [batch 1052]: seen 105200 examples : 68.1 eps, Loss: 6.567, Avg loss: 6.563, Best loss: 6.561\n",
      "    [batch 1059]: seen 105900 examples : 68.1 eps, Loss: 6.517, Avg loss: 6.564, Best loss: 6.561\n",
      "    [batch 1066]: seen 106600 examples : 68.1 eps, Loss: 6.489, Avg loss: 6.561, Best loss: 6.561\n",
      "    [batch 1073]: seen 107300 examples : 68.1 eps, Loss: 6.653, Avg loss: 6.561, Best loss: 6.560\n",
      "    [batch 1080]: seen 108000 examples : 68.1 eps, Loss: 6.559, Avg loss: 6.560, Best loss: 6.560\n",
      "    [batch 1087]: seen 108700 examples : 68.1 eps, Loss: 6.545, Avg loss: 6.558, Best loss: 6.558\n",
      "    [batch 1094]: seen 109400 examples : 68.1 eps, Loss: 6.594, Avg loss: 6.558, Best loss: 6.557\n",
      "    [batch 1101]: seen 110100 examples : 68.1 eps, Loss: 6.513, Avg loss: 6.554, Best loss: 6.554\n",
      "    [batch 1108]: seen 110800 examples : 68.1 eps, Loss: 6.552, Avg loss: 6.553, Best loss: 6.553\n",
      "    [batch 1115]: seen 111500 examples : 68.1 eps, Loss: 6.569, Avg loss: 6.553, Best loss: 6.553\n",
      "    [batch 1122]: seen 112200 examples : 68.1 eps, Loss: 6.492, Avg loss: 6.553, Best loss: 6.552\n",
      "    [batch 1129]: seen 112900 examples : 68.1 eps, Loss: 6.499, Avg loss: 6.551, Best loss: 6.551\n",
      "    [batch 1136]: seen 113600 examples : 68.0 eps, Loss: 6.564, Avg loss: 6.550, Best loss: 6.550\n",
      "    [batch 1143]: seen 114300 examples : 68.0 eps, Loss: 6.585, Avg loss: 6.549, Best loss: 6.549\n",
      "    [batch 1150]: seen 115000 examples : 68.1 eps, Loss: 6.489, Avg loss: 6.550, Best loss: 6.549\n",
      "    [batch 1157]: seen 115700 examples : 68.1 eps, Loss: 6.567, Avg loss: 6.551, Best loss: 6.549\n",
      "    [batch 1164]: seen 116400 examples : 68.1 eps, Loss: 6.480, Avg loss: 6.549, Best loss: 6.549\n",
      "    [batch 1171]: seen 117100 examples : 68.1 eps, Loss: 6.547, Avg loss: 6.549, Best loss: 6.548\n",
      "    [batch 1178]: seen 117800 examples : 68.1 eps, Loss: 6.500, Avg loss: 6.548, Best loss: 6.548\n",
      "    [batch 1185]: seen 118500 examples : 68.1 eps, Loss: 6.619, Avg loss: 6.548, Best loss: 6.547\n",
      "    [batch 1192]: seen 119200 examples : 68.1 eps, Loss: 6.562, Avg loss: 6.548, Best loss: 6.547\n",
      "    [batch 1199]: seen 119900 examples : 68.1 eps, Loss: 6.587, Avg loss: 6.548, Best loss: 6.546\n",
      "    [batch 1206]: seen 120600 examples : 68.1 eps, Loss: 6.455, Avg loss: 6.547, Best loss: 6.546\n",
      "    [batch 1213]: seen 121300 examples : 68.1 eps, Loss: 6.609, Avg loss: 6.549, Best loss: 6.546\n",
      "    [batch 1220]: seen 122000 examples : 68.1 eps, Loss: 6.503, Avg loss: 6.548, Best loss: 6.546\n",
      "    [batch 1227]: seen 122700 examples : 68.1 eps, Loss: 6.583, Avg loss: 6.545, Best loss: 6.545\n",
      "    [batch 1234]: seen 123400 examples : 68.1 eps, Loss: 6.466, Avg loss: 6.544, Best loss: 6.544\n",
      "    [batch 1241]: seen 124100 examples : 68.1 eps, Loss: 6.475, Avg loss: 6.544, Best loss: 6.544\n",
      "    [batch 1248]: seen 124800 examples : 68.1 eps, Loss: 6.472, Avg loss: 6.539, Best loss: 6.539\n",
      "    [batch 1255]: seen 125500 examples : 68.1 eps, Loss: 6.556, Avg loss: 6.536, Best loss: 6.536\n",
      "    [batch 1262]: seen 126200 examples : 68.1 eps, Loss: 6.549, Avg loss: 6.535, Best loss: 6.535\n",
      "    [batch 1269]: seen 126900 examples : 68.0 eps, Loss: 6.455, Avg loss: 6.536, Best loss: 6.535\n",
      "    [batch 1276]: seen 127600 examples : 68.0 eps, Loss: 6.555, Avg loss: 6.534, Best loss: 6.534\n",
      "    [batch 1283]: seen 128300 examples : 68.0 eps, Loss: 6.517, Avg loss: 6.533, Best loss: 6.533\n",
      "    [batch 1290]: seen 129000 examples : 68.0 eps, Loss: 6.507, Avg loss: 6.531, Best loss: 6.531\n",
      "    [batch 1297]: seen 129700 examples : 68.0 eps, Loss: 6.532, Avg loss: 6.529, Best loss: 6.529\n",
      "    [batch 1304]: seen 130400 examples : 68.0 eps, Loss: 6.483, Avg loss: 6.529, Best loss: 6.529\n",
      "    [batch 1311]: seen 131100 examples : 68.0 eps, Loss: 6.558, Avg loss: 6.531, Best loss: 6.529\n",
      "    [batch 1318]: seen 131800 examples : 68.0 eps, Loss: 6.424, Avg loss: 6.529, Best loss: 6.529\n",
      "    [batch 1325]: seen 132500 examples : 68.0 eps, Loss: 6.545, Avg loss: 6.530, Best loss: 6.529\n",
      "    [batch 1332]: seen 133200 examples : 68.0 eps, Loss: 6.501, Avg loss: 6.528, Best loss: 6.528\n",
      "    [batch 1339]: seen 133900 examples : 68.0 eps, Loss: 6.542, Avg loss: 6.529, Best loss: 6.527\n",
      "    [batch 1346]: seen 134600 examples : 68.0 eps, Loss: 6.530, Avg loss: 6.528, Best loss: 6.527\n",
      "    [batch 1353]: seen 135300 examples : 68.0 eps, Loss: 6.582, Avg loss: 6.531, Best loss: 6.527\n",
      "    [batch 1360]: seen 136000 examples : 68.0 eps, Loss: 6.498, Avg loss: 6.530, Best loss: 6.527\n",
      "    [batch 1367]: seen 136700 examples : 68.0 eps, Loss: 6.506, Avg loss: 6.530, Best loss: 6.527\n",
      "    [batch 1374]: seen 137400 examples : 68.0 eps, Loss: 6.508, Avg loss: 6.530, Best loss: 6.527\n",
      "    [batch 1381]: seen 138100 examples : 68.0 eps, Loss: 6.466, Avg loss: 6.527, Best loss: 6.527\n",
      "    [batch 1388]: seen 138800 examples : 68.0 eps, Loss: 6.500, Avg loss: 6.524, Best loss: 6.524\n",
      "    [batch 1395]: seen 139500 examples : 68.0 eps, Loss: 6.597, Avg loss: 6.523, Best loss: 6.522\n",
      "    [batch 1402]: seen 140200 examples : 68.0 eps, Loss: 6.555, Avg loss: 6.524, Best loss: 6.522\n",
      "    [batch 1409]: seen 140900 examples : 68.0 eps, Loss: 6.536, Avg loss: 6.525, Best loss: 6.522\n",
      "    [batch 1416]: seen 141600 examples : 68.0 eps, Loss: 6.596, Avg loss: 6.525, Best loss: 6.522\n",
      "    [batch 1423]: seen 142300 examples : 68.0 eps, Loss: 6.578, Avg loss: 6.525, Best loss: 6.522\n",
      "    [batch 1430]: seen 143000 examples : 68.0 eps, Loss: 6.578, Avg loss: 6.525, Best loss: 6.522\n",
      "    [batch 1437]: seen 143700 examples : 68.0 eps, Loss: 6.431, Avg loss: 6.524, Best loss: 6.522\n",
      "    [batch 1444]: seen 144400 examples : 68.0 eps, Loss: 6.535, Avg loss: 6.524, Best loss: 6.522\n",
      "    [batch 1451]: seen 145100 examples : 68.0 eps, Loss: 6.487, Avg loss: 6.522, Best loss: 6.522\n",
      "    [batch 1458]: seen 145800 examples : 68.0 eps, Loss: 6.528, Avg loss: 6.522, Best loss: 6.522\n",
      "    [batch 1465]: seen 146500 examples : 68.0 eps, Loss: 6.532, Avg loss: 6.521, Best loss: 6.521\n",
      "    [batch 1472]: seen 147200 examples : 68.0 eps, Loss: 6.470, Avg loss: 6.517, Best loss: 6.517\n",
      "    [batch 1479]: seen 147900 examples : 68.0 eps, Loss: 6.481, Avg loss: 6.517, Best loss: 6.517\n",
      "    [batch 1486]: seen 148600 examples : 68.0 eps, Loss: 6.507, Avg loss: 6.515, Best loss: 6.515\n",
      "    [batch 1493]: seen 149300 examples : 68.0 eps, Loss: 6.491, Avg loss: 6.516, Best loss: 6.515\n",
      "    [batch 1500]: seen 150000 examples : 68.0 eps, Loss: 6.562, Avg loss: 6.516, Best loss: 6.515\n",
      "    [batch 1507]: seen 150700 examples : 68.0 eps, Loss: 6.568, Avg loss: 6.517, Best loss: 6.515\n",
      "    [batch 1514]: seen 151400 examples : 68.0 eps, Loss: 6.507, Avg loss: 6.517, Best loss: 6.515\n",
      "    [batch 1521]: seen 152100 examples : 68.0 eps, Loss: 6.577, Avg loss: 6.518, Best loss: 6.515\n",
      "    [batch 1528]: seen 152800 examples : 68.0 eps, Loss: 6.448, Avg loss: 6.516, Best loss: 6.515\n",
      "    [batch 1535]: seen 153500 examples : 68.0 eps, Loss: 6.522, Avg loss: 6.516, Best loss: 6.515\n",
      "    [batch 1542]: seen 154200 examples : 68.0 eps, Loss: 6.503, Avg loss: 6.516, Best loss: 6.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1549]: seen 154900 examples : 68.0 eps, Loss: 6.529, Avg loss: 6.515, Best loss: 6.515\n",
      "    [batch 1556]: seen 155600 examples : 68.0 eps, Loss: 6.428, Avg loss: 6.512, Best loss: 6.512\n",
      "    [batch 1563]: seen 156300 examples : 68.0 eps, Loss: 6.564, Avg loss: 6.512, Best loss: 6.512\n",
      "    [batch 1570]: seen 157000 examples : 68.0 eps, Loss: 6.458, Avg loss: 6.510, Best loss: 6.510\n",
      "    [batch 1577]: seen 157700 examples : 68.0 eps, Loss: 6.514, Avg loss: 6.508, Best loss: 6.508\n",
      "    [batch 1584]: seen 158400 examples : 68.0 eps, Loss: 6.487, Avg loss: 6.508, Best loss: 6.507\n",
      "    [batch 1591]: seen 159100 examples : 68.0 eps, Loss: 6.460, Avg loss: 6.508, Best loss: 6.507\n",
      "    [batch 1598]: seen 159800 examples : 68.0 eps, Loss: 6.472, Avg loss: 6.506, Best loss: 6.506\n",
      "    [batch 1605]: seen 160500 examples : 68.0 eps, Loss: 6.496, Avg loss: 6.505, Best loss: 6.504\n",
      "    [batch 1612]: seen 161200 examples : 68.0 eps, Loss: 6.582, Avg loss: 6.505, Best loss: 6.504\n",
      "    [batch 1619]: seen 161900 examples : 68.0 eps, Loss: 6.539, Avg loss: 6.505, Best loss: 6.504\n",
      "    [batch 1626]: seen 162600 examples : 68.0 eps, Loss: 6.542, Avg loss: 6.503, Best loss: 6.502\n",
      "    [batch 1633]: seen 163300 examples : 68.0 eps, Loss: 6.570, Avg loss: 6.503, Best loss: 6.502\n",
      "    [batch 1640]: seen 164000 examples : 68.0 eps, Loss: 6.468, Avg loss: 6.503, Best loss: 6.502\n",
      "    [batch 1647]: seen 164700 examples : 68.0 eps, Loss: 6.464, Avg loss: 6.503, Best loss: 6.502\n",
      "    [batch 1654]: seen 165400 examples : 68.0 eps, Loss: 6.450, Avg loss: 6.500, Best loss: 6.500\n",
      "    [batch 1661]: seen 166100 examples : 68.0 eps, Loss: 6.540, Avg loss: 6.502, Best loss: 6.500\n",
      "    [batch 1668]: seen 166800 examples : 68.0 eps, Loss: 6.493, Avg loss: 6.501, Best loss: 6.500\n",
      "    [batch 1675]: seen 167500 examples : 68.0 eps, Loss: 6.396, Avg loss: 6.498, Best loss: 6.498\n",
      "    [batch 1682]: seen 168200 examples : 68.0 eps, Loss: 6.442, Avg loss: 6.496, Best loss: 6.496\n",
      "    [batch 1689]: seen 168900 examples : 68.0 eps, Loss: 6.446, Avg loss: 6.495, Best loss: 6.495\n",
      "    [batch 1696]: seen 169600 examples : 68.0 eps, Loss: 6.602, Avg loss: 6.495, Best loss: 6.494\n",
      "    [batch 1703]: seen 170300 examples : 68.0 eps, Loss: 6.523, Avg loss: 6.495, Best loss: 6.494\n",
      "    [batch 1710]: seen 171000 examples : 68.0 eps, Loss: 6.467, Avg loss: 6.495, Best loss: 6.494\n",
      "    [batch 1717]: seen 171700 examples : 68.0 eps, Loss: 6.496, Avg loss: 6.493, Best loss: 6.493\n",
      "    [batch 1724]: seen 172400 examples : 68.0 eps, Loss: 6.486, Avg loss: 6.493, Best loss: 6.492\n",
      "    [batch 1731]: seen 173100 examples : 68.0 eps, Loss: 6.527, Avg loss: 6.491, Best loss: 6.491\n",
      "    [batch 1738]: seen 173800 examples : 68.0 eps, Loss: 6.529, Avg loss: 6.490, Best loss: 6.489\n",
      "    [batch 1745]: seen 174500 examples : 68.0 eps, Loss: 6.412, Avg loss: 6.489, Best loss: 6.489\n",
      "    [batch 1752]: seen 175200 examples : 68.0 eps, Loss: 6.456, Avg loss: 6.487, Best loss: 6.487\n",
      "    [batch 1759]: seen 175900 examples : 68.0 eps, Loss: 6.564, Avg loss: 6.486, Best loss: 6.485\n",
      "    [batch 1766]: seen 176600 examples : 68.0 eps, Loss: 6.499, Avg loss: 6.487, Best loss: 6.485\n",
      "    [batch 1773]: seen 177300 examples : 68.0 eps, Loss: 6.484, Avg loss: 6.487, Best loss: 6.485\n",
      "    [batch 1780]: seen 178000 examples : 68.0 eps, Loss: 6.531, Avg loss: 6.487, Best loss: 6.485\n",
      "    [batch 1787]: seen 178700 examples : 68.0 eps, Loss: 6.460, Avg loss: 6.484, Best loss: 6.484\n",
      "    [batch 1794]: seen 179400 examples : 68.0 eps, Loss: 6.483, Avg loss: 6.483, Best loss: 6.483\n",
      "    [batch 1801]: seen 180100 examples : 68.0 eps, Loss: 6.367, Avg loss: 6.481, Best loss: 6.481\n",
      "    [batch 1808]: seen 180800 examples : 68.0 eps, Loss: 6.383, Avg loss: 6.481, Best loss: 6.481\n",
      "    [batch 1815]: seen 181500 examples : 68.0 eps, Loss: 6.543, Avg loss: 6.480, Best loss: 6.480\n",
      "    [batch 1822]: seen 182200 examples : 68.0 eps, Loss: 6.426, Avg loss: 6.479, Best loss: 6.479\n",
      "    [batch 1829]: seen 182900 examples : 68.0 eps, Loss: 6.373, Avg loss: 6.478, Best loss: 6.478\n",
      "    [batch 1836]: seen 183600 examples : 68.0 eps, Loss: 6.390, Avg loss: 6.478, Best loss: 6.478\n",
      "    [batch 1843]: seen 184300 examples : 68.0 eps, Loss: 6.443, Avg loss: 6.476, Best loss: 6.476\n",
      "    [batch 1850]: seen 185000 examples : 68.0 eps, Loss: 6.470, Avg loss: 6.474, Best loss: 6.474\n",
      "    [batch 1857]: seen 185700 examples : 68.0 eps, Loss: 6.410, Avg loss: 6.474, Best loss: 6.472\n",
      "    [batch 1864]: seen 186400 examples : 68.0 eps, Loss: 6.424, Avg loss: 6.472, Best loss: 6.472\n",
      "    [batch 1871]: seen 187100 examples : 68.0 eps, Loss: 6.452, Avg loss: 6.475, Best loss: 6.471\n",
      "    [batch 1878]: seen 187800 examples : 68.0 eps, Loss: 6.408, Avg loss: 6.474, Best loss: 6.471\n",
      "    [batch 1885]: seen 188500 examples : 68.0 eps, Loss: 6.455, Avg loss: 6.474, Best loss: 6.471\n",
      "    [batch 1892]: seen 189200 examples : 68.0 eps, Loss: 6.448, Avg loss: 6.472, Best loss: 6.471\n",
      "    [batch 1899]: seen 189900 examples : 68.0 eps, Loss: 6.435, Avg loss: 6.471, Best loss: 6.471\n",
      "    [batch 1906]: seen 190600 examples : 68.0 eps, Loss: 6.433, Avg loss: 6.470, Best loss: 6.470\n",
      "    [batch 1913]: seen 191300 examples : 68.0 eps, Loss: 6.435, Avg loss: 6.471, Best loss: 6.470\n",
      "    [batch 1920]: seen 192000 examples : 68.0 eps, Loss: 6.518, Avg loss: 6.472, Best loss: 6.470\n",
      "    [batch 1927]: seen 192700 examples : 68.0 eps, Loss: 6.433, Avg loss: 6.473, Best loss: 6.470\n",
      "    [batch 1934]: seen 193400 examples : 68.0 eps, Loss: 6.419, Avg loss: 6.471, Best loss: 6.470\n",
      "    [batch 1941]: seen 194100 examples : 68.0 eps, Loss: 6.377, Avg loss: 6.468, Best loss: 6.468\n",
      "    [batch 1948]: seen 194800 examples : 68.0 eps, Loss: 6.420, Avg loss: 6.465, Best loss: 6.465\n",
      "    [batch 1955]: seen 195500 examples : 68.0 eps, Loss: 6.396, Avg loss: 6.465, Best loss: 6.465\n",
      "    [batch 1962]: seen 196200 examples : 68.0 eps, Loss: 6.462, Avg loss: 6.464, Best loss: 6.464\n",
      "    [batch 1969]: seen 196900 examples : 68.0 eps, Loss: 6.526, Avg loss: 6.464, Best loss: 6.463\n",
      "    [batch 1976]: seen 197600 examples : 68.0 eps, Loss: 6.626, Avg loss: 6.465, Best loss: 6.463\n",
      "    [batch 1983]: seen 198300 examples : 68.0 eps, Loss: 6.467, Avg loss: 6.465, Best loss: 6.463\n",
      "    [batch 1990]: seen 199000 examples : 68.0 eps, Loss: 6.546, Avg loss: 6.465, Best loss: 6.463\n",
      "    [batch 1997]: seen 199700 examples : 68.0 eps, Loss: 6.531, Avg loss: 6.466, Best loss: 6.463\n",
      "    [batch 2004]: seen 200400 examples : 68.0 eps, Loss: 6.378, Avg loss: 6.465, Best loss: 6.463\n",
      "    [batch 2011]: seen 201100 examples : 68.0 eps, Loss: 6.483, Avg loss: 6.465, Best loss: 6.463\n",
      "    [batch 2018]: seen 201800 examples : 68.0 eps, Loss: 6.336, Avg loss: 6.462, Best loss: 6.462\n",
      "    [batch 2025]: seen 202500 examples : 68.0 eps, Loss: 6.436, Avg loss: 6.459, Best loss: 6.459\n",
      "    [batch 2032]: seen 203200 examples : 68.0 eps, Loss: 6.453, Avg loss: 6.458, Best loss: 6.457\n",
      "    [batch 2039]: seen 203900 examples : 68.0 eps, Loss: 6.479, Avg loss: 6.458, Best loss: 6.457\n",
      "    [batch 2046]: seen 204600 examples : 68.0 eps, Loss: 6.422, Avg loss: 6.456, Best loss: 6.456\n",
      "    [batch 2053]: seen 205300 examples : 68.0 eps, Loss: 6.423, Avg loss: 6.455, Best loss: 6.455\n",
      "    [batch 2060]: seen 206000 examples : 68.0 eps, Loss: 6.443, Avg loss: 6.456, Best loss: 6.455\n",
      "    [batch 2067]: seen 206700 examples : 68.0 eps, Loss: 6.490, Avg loss: 6.456, Best loss: 6.455\n",
      "    [batch 2074]: seen 207400 examples : 68.0 eps, Loss: 6.418, Avg loss: 6.455, Best loss: 6.455\n",
      "    [batch 2081]: seen 208100 examples : 68.0 eps, Loss: 6.350, Avg loss: 6.452, Best loss: 6.452\n",
      "    [batch 2088]: seen 208800 examples : 68.0 eps, Loss: 6.491, Avg loss: 6.451, Best loss: 6.451\n",
      "    [batch 2095]: seen 209500 examples : 68.0 eps, Loss: 6.443, Avg loss: 6.451, Best loss: 6.451\n",
      "    [batch 2102]: seen 210200 examples : 68.0 eps, Loss: 6.441, Avg loss: 6.450, Best loss: 6.450\n",
      "    [batch 2109]: seen 210900 examples : 68.0 eps, Loss: 6.406, Avg loss: 6.452, Best loss: 6.450\n",
      "    [batch 2116]: seen 211600 examples : 68.0 eps, Loss: 6.470, Avg loss: 6.451, Best loss: 6.450\n",
      "    [batch 2123]: seen 212300 examples : 68.0 eps, Loss: 6.417, Avg loss: 6.452, Best loss: 6.450\n",
      "    [batch 2130]: seen 213000 examples : 68.0 eps, Loss: 6.443, Avg loss: 6.450, Best loss: 6.450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2137]: seen 213700 examples : 68.0 eps, Loss: 6.358, Avg loss: 6.446, Best loss: 6.446\n",
      "    [batch 2144]: seen 214400 examples : 68.0 eps, Loss: 6.407, Avg loss: 6.444, Best loss: 6.444\n",
      "    [batch 2151]: seen 215100 examples : 68.0 eps, Loss: 6.460, Avg loss: 6.445, Best loss: 6.444\n",
      "    [batch 2158]: seen 215800 examples : 68.0 eps, Loss: 6.467, Avg loss: 6.447, Best loss: 6.444\n",
      "    [batch 2165]: seen 216500 examples : 68.0 eps, Loss: 6.444, Avg loss: 6.445, Best loss: 6.444\n",
      "    [batch 2172]: seen 217200 examples : 68.0 eps, Loss: 6.477, Avg loss: 6.443, Best loss: 6.443\n",
      "    [batch 2179]: seen 217900 examples : 68.0 eps, Loss: 6.393, Avg loss: 6.443, Best loss: 6.443\n",
      "    [batch 2186]: seen 218600 examples : 68.0 eps, Loss: 6.442, Avg loss: 6.441, Best loss: 6.441\n",
      "    [batch 2193]: seen 219300 examples : 68.0 eps, Loss: 6.378, Avg loss: 6.438, Best loss: 6.438\n",
      "    [batch 2200]: seen 220000 examples : 68.0 eps, Loss: 6.397, Avg loss: 6.434, Best loss: 6.434\n",
      "    [batch 2207]: seen 220700 examples : 68.0 eps, Loss: 6.469, Avg loss: 6.435, Best loss: 6.434\n",
      "    [batch 2214]: seen 221400 examples : 68.0 eps, Loss: 6.386, Avg loss: 6.434, Best loss: 6.433\n",
      "    [batch 2221]: seen 222100 examples : 68.0 eps, Loss: 6.482, Avg loss: 6.434, Best loss: 6.433\n",
      "    [batch 2228]: seen 222800 examples : 68.0 eps, Loss: 6.452, Avg loss: 6.434, Best loss: 6.433\n",
      "    [batch 2235]: seen 223500 examples : 68.0 eps, Loss: 6.487, Avg loss: 6.436, Best loss: 6.433\n",
      "    [batch 2242]: seen 224200 examples : 68.0 eps, Loss: 6.427, Avg loss: 6.436, Best loss: 6.433\n",
      "    [batch 2249]: seen 224900 examples : 68.0 eps, Loss: 6.455, Avg loss: 6.436, Best loss: 6.433\n",
      "    [batch 2256]: seen 225600 examples : 68.0 eps, Loss: 6.300, Avg loss: 6.432, Best loss: 6.432\n",
      "    [batch 2263]: seen 226300 examples : 68.0 eps, Loss: 6.433, Avg loss: 6.430, Best loss: 6.430\n",
      "    [batch 2270]: seen 227000 examples : 68.0 eps, Loss: 6.431, Avg loss: 6.430, Best loss: 6.430\n",
      "    [batch 2277]: seen 227700 examples : 68.0 eps, Loss: 6.467, Avg loss: 6.427, Best loss: 6.427\n",
      "    [batch 2284]: seen 228400 examples : 68.0 eps, Loss: 6.436, Avg loss: 6.425, Best loss: 6.425\n",
      "    [batch 2291]: seen 229100 examples : 68.0 eps, Loss: 6.345, Avg loss: 6.425, Best loss: 6.425\n",
      "    [batch 2298]: seen 229800 examples : 68.0 eps, Loss: 6.437, Avg loss: 6.425, Best loss: 6.425\n",
      "    [batch 2305]: seen 230500 examples : 67.9 eps, Loss: 6.430, Avg loss: 6.424, Best loss: 6.424\n",
      "    [batch 2312]: seen 231200 examples : 67.9 eps, Loss: 6.378, Avg loss: 6.424, Best loss: 6.423\n",
      "    [batch 2319]: seen 231900 examples : 68.0 eps, Loss: 6.445, Avg loss: 6.423, Best loss: 6.423\n",
      "    [batch 2326]: seen 232600 examples : 68.0 eps, Loss: 6.349, Avg loss: 6.421, Best loss: 6.421\n",
      "    [batch 2333]: seen 233300 examples : 68.0 eps, Loss: 6.416, Avg loss: 6.422, Best loss: 6.421\n",
      "    [batch 2340]: seen 234000 examples : 68.0 eps, Loss: 6.358, Avg loss: 6.419, Best loss: 6.419\n",
      "    [batch 2347]: seen 234700 examples : 68.0 eps, Loss: 6.408, Avg loss: 6.418, Best loss: 6.417\n",
      "    [batch 2354]: seen 235400 examples : 68.0 eps, Loss: 6.372, Avg loss: 6.414, Best loss: 6.414\n",
      "    [batch 2361]: seen 236100 examples : 68.0 eps, Loss: 6.535, Avg loss: 6.416, Best loss: 6.414\n",
      "    [batch 2368]: seen 236800 examples : 68.0 eps, Loss: 6.445, Avg loss: 6.416, Best loss: 6.414\n",
      "    [batch 2375]: seen 237500 examples : 68.0 eps, Loss: 6.404, Avg loss: 6.416, Best loss: 6.414\n",
      "    [batch 2382]: seen 238200 examples : 68.0 eps, Loss: 6.424, Avg loss: 6.417, Best loss: 6.414\n",
      "    [batch 2389]: seen 238900 examples : 68.0 eps, Loss: 6.460, Avg loss: 6.416, Best loss: 6.414\n",
      "    [batch 2396]: seen 239600 examples : 68.0 eps, Loss: 6.473, Avg loss: 6.415, Best loss: 6.414\n",
      "    [batch 2403]: seen 240300 examples : 68.0 eps, Loss: 6.326, Avg loss: 6.414, Best loss: 6.414\n",
      "    [batch 2410]: seen 241000 examples : 68.0 eps, Loss: 6.384, Avg loss: 6.415, Best loss: 6.414\n",
      "    [batch 2417]: seen 241700 examples : 68.0 eps, Loss: 6.393, Avg loss: 6.413, Best loss: 6.413\n",
      "    [batch 2424]: seen 242400 examples : 68.0 eps, Loss: 6.417, Avg loss: 6.412, Best loss: 6.412\n",
      "    [batch 2431]: seen 243100 examples : 68.0 eps, Loss: 6.480, Avg loss: 6.414, Best loss: 6.412\n",
      "    [batch 2438]: seen 243800 examples : 67.9 eps, Loss: 6.429, Avg loss: 6.412, Best loss: 6.411\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-8048\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-8048\n",
      "    [batch 2444]: seen 244400 examples : 67.9 eps, Loss: 6.458, Avg loss: 6.410, Best loss: 6.409\n",
      "    [batch 2451]: seen 245100 examples : 67.9 eps, Loss: 6.403, Avg loss: 6.409, Best loss: 6.408\n",
      "    [batch 2458]: seen 245800 examples : 67.9 eps, Loss: 6.400, Avg loss: 6.407, Best loss: 6.407\n",
      "    [batch 2465]: seen 246500 examples : 67.9 eps, Loss: 6.444, Avg loss: 6.408, Best loss: 6.406\n",
      "    [batch 2472]: seen 247200 examples : 67.9 eps, Loss: 6.294, Avg loss: 6.406, Best loss: 6.406\n",
      "    [batch 2479]: seen 247900 examples : 67.9 eps, Loss: 6.325, Avg loss: 6.405, Best loss: 6.405\n",
      "    [batch 2486]: seen 248600 examples : 67.9 eps, Loss: 6.432, Avg loss: 6.404, Best loss: 6.404\n",
      "    [batch 2493]: seen 249300 examples : 67.9 eps, Loss: 6.435, Avg loss: 6.404, Best loss: 6.403\n",
      "    [batch 2500]: seen 250000 examples : 67.9 eps, Loss: 6.474, Avg loss: 6.406, Best loss: 6.403\n",
      "    [batch 2507]: seen 250700 examples : 67.9 eps, Loss: 6.416, Avg loss: 6.403, Best loss: 6.403\n",
      "    [batch 2514]: seen 251400 examples : 67.9 eps, Loss: 6.351, Avg loss: 6.403, Best loss: 6.403\n",
      "    [batch 2521]: seen 252100 examples : 67.9 eps, Loss: 6.389, Avg loss: 6.402, Best loss: 6.402\n",
      "    [batch 2528]: seen 252800 examples : 67.9 eps, Loss: 6.406, Avg loss: 6.403, Best loss: 6.402\n",
      "    [batch 2535]: seen 253500 examples : 67.9 eps, Loss: 6.406, Avg loss: 6.404, Best loss: 6.402\n",
      "    [batch 2542]: seen 254200 examples : 67.9 eps, Loss: 6.338, Avg loss: 6.403, Best loss: 6.402\n",
      "    [batch 2549]: seen 254900 examples : 67.9 eps, Loss: 6.367, Avg loss: 6.404, Best loss: 6.402\n",
      "    [batch 2556]: seen 255600 examples : 67.9 eps, Loss: 6.357, Avg loss: 6.403, Best loss: 6.402\n",
      "    [batch 2563]: seen 256300 examples : 67.9 eps, Loss: 6.374, Avg loss: 6.402, Best loss: 6.402\n",
      "    [batch 2570]: seen 257000 examples : 67.9 eps, Loss: 6.379, Avg loss: 6.402, Best loss: 6.401\n",
      "    [batch 2577]: seen 257700 examples : 67.9 eps, Loss: 6.428, Avg loss: 6.403, Best loss: 6.401\n",
      "    [batch 2584]: seen 258400 examples : 67.9 eps, Loss: 6.416, Avg loss: 6.401, Best loss: 6.401\n",
      "    [batch 2591]: seen 259100 examples : 67.9 eps, Loss: 6.384, Avg loss: 6.399, Best loss: 6.399\n",
      "    [batch 2598]: seen 259800 examples : 67.9 eps, Loss: 6.404, Avg loss: 6.397, Best loss: 6.397\n",
      "    [batch 2605]: seen 260500 examples : 67.9 eps, Loss: 6.435, Avg loss: 6.396, Best loss: 6.396\n",
      "    [batch 2612]: seen 261200 examples : 67.9 eps, Loss: 6.396, Avg loss: 6.397, Best loss: 6.396\n",
      "    [batch 2619]: seen 261900 examples : 67.9 eps, Loss: 6.326, Avg loss: 6.399, Best loss: 6.396\n",
      "    [batch 2626]: seen 262600 examples : 67.9 eps, Loss: 6.383, Avg loss: 6.395, Best loss: 6.395\n",
      "    [batch 2633]: seen 263300 examples : 67.9 eps, Loss: 6.407, Avg loss: 6.393, Best loss: 6.393\n",
      "    [batch 2640]: seen 264000 examples : 67.9 eps, Loss: 6.442, Avg loss: 6.391, Best loss: 6.390\n",
      "    [batch 2647]: seen 264700 examples : 67.9 eps, Loss: 6.380, Avg loss: 6.391, Best loss: 6.390\n",
      "    [batch 2654]: seen 265400 examples : 67.9 eps, Loss: 6.382, Avg loss: 6.392, Best loss: 6.390\n",
      "    [batch 2661]: seen 266100 examples : 67.9 eps, Loss: 6.333, Avg loss: 6.391, Best loss: 6.390\n",
      "    [batch 2668]: seen 266800 examples : 67.9 eps, Loss: 6.361, Avg loss: 6.391, Best loss: 6.390\n",
      "    [batch 2675]: seen 267500 examples : 67.9 eps, Loss: 6.419, Avg loss: 6.391, Best loss: 6.390\n",
      "    [batch 2682]: seen 268200 examples : 67.9 eps, Loss: 6.424, Avg loss: 6.393, Best loss: 6.390\n",
      "    [batch 2689]: seen 268900 examples : 67.9 eps, Loss: 6.383, Avg loss: 6.391, Best loss: 6.390\n",
      "    [batch 2696]: seen 269600 examples : 67.9 eps, Loss: 6.274, Avg loss: 6.388, Best loss: 6.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2703]: seen 270300 examples : 67.9 eps, Loss: 6.428, Avg loss: 6.388, Best loss: 6.385\n",
      "    [batch 2710]: seen 271000 examples : 67.9 eps, Loss: 6.329, Avg loss: 6.388, Best loss: 6.385\n",
      "    [batch 2717]: seen 271700 examples : 67.9 eps, Loss: 6.344, Avg loss: 6.387, Best loss: 6.385\n",
      "    [batch 2724]: seen 272400 examples : 67.9 eps, Loss: 6.392, Avg loss: 6.386, Best loss: 6.385\n",
      "    [batch 2731]: seen 273100 examples : 67.9 eps, Loss: 6.389, Avg loss: 6.385, Best loss: 6.384\n",
      "    [batch 2738]: seen 273800 examples : 67.9 eps, Loss: 6.358, Avg loss: 6.383, Best loss: 6.383\n",
      "    [batch 2745]: seen 274500 examples : 67.9 eps, Loss: 6.485, Avg loss: 6.382, Best loss: 6.381\n",
      "    [batch 2752]: seen 275200 examples : 67.9 eps, Loss: 6.460, Avg loss: 6.381, Best loss: 6.380\n",
      "    [batch 2759]: seen 275900 examples : 67.9 eps, Loss: 6.359, Avg loss: 6.380, Best loss: 6.380\n",
      "    [batch 2766]: seen 276600 examples : 67.9 eps, Loss: 6.375, Avg loss: 6.380, Best loss: 6.379\n",
      "    [batch 2773]: seen 277300 examples : 67.9 eps, Loss: 6.358, Avg loss: 6.380, Best loss: 6.379\n",
      "    [batch 2780]: seen 278000 examples : 67.9 eps, Loss: 6.405, Avg loss: 6.379, Best loss: 6.379\n",
      "    [batch 2787]: seen 278700 examples : 67.9 eps, Loss: 6.377, Avg loss: 6.378, Best loss: 6.378\n",
      "    [batch 2794]: seen 279400 examples : 67.9 eps, Loss: 6.331, Avg loss: 6.377, Best loss: 6.376\n",
      "    [batch 2801]: seen 280100 examples : 67.9 eps, Loss: 6.347, Avg loss: 6.376, Best loss: 6.376\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:08:54\n",
      "[EPOCH 3] Complete. Avg Loss: 6.37377303343098; Best Loss: 6.37377303343098\n",
      "[EPOCH 4] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.2 eps, Loss: 6.323, Avg loss: 6.373, Best loss: 6.373\n",
      "    [batch 16]: seen 1600 examples : 78.2 eps, Loss: 6.371, Avg loss: 6.373, Best loss: 6.373\n",
      "    [batch 23]: seen 2300 examples : 74.0 eps, Loss: 6.306, Avg loss: 6.371, Best loss: 6.371\n",
      "    [batch 30]: seen 3000 examples : 72.8 eps, Loss: 6.356, Avg loss: 6.369, Best loss: 6.369\n",
      "    [batch 37]: seen 3700 examples : 72.0 eps, Loss: 6.353, Avg loss: 6.367, Best loss: 6.367\n",
      "    [batch 44]: seen 4400 examples : 71.4 eps, Loss: 6.362, Avg loss: 6.365, Best loss: 6.365\n",
      "    [batch 51]: seen 5100 examples : 71.1 eps, Loss: 6.356, Avg loss: 6.364, Best loss: 6.364\n",
      "    [batch 58]: seen 5800 examples : 70.8 eps, Loss: 6.318, Avg loss: 6.364, Best loss: 6.364\n",
      "    [batch 65]: seen 6500 examples : 70.6 eps, Loss: 6.429, Avg loss: 6.363, Best loss: 6.362\n",
      "    [batch 72]: seen 7200 examples : 70.4 eps, Loss: 6.327, Avg loss: 6.362, Best loss: 6.362\n",
      "    [batch 79]: seen 7900 examples : 70.2 eps, Loss: 6.346, Avg loss: 6.359, Best loss: 6.359\n",
      "    [batch 86]: seen 8600 examples : 70.1 eps, Loss: 6.440, Avg loss: 6.360, Best loss: 6.359\n",
      "    [batch 93]: seen 9300 examples : 70.0 eps, Loss: 6.365, Avg loss: 6.359, Best loss: 6.359\n",
      "    [batch 100]: seen 10000 examples : 69.9 eps, Loss: 6.399, Avg loss: 6.359, Best loss: 6.357\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-8513\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-8513\n",
      "    [batch 106]: seen 10600 examples : 69.2 eps, Loss: 6.358, Avg loss: 6.360, Best loss: 6.357\n",
      "    [batch 113]: seen 11300 examples : 69.1 eps, Loss: 6.444, Avg loss: 6.361, Best loss: 6.357\n",
      "    [batch 120]: seen 12000 examples : 69.1 eps, Loss: 6.230, Avg loss: 6.360, Best loss: 6.357\n",
      "    [batch 127]: seen 12700 examples : 69.1 eps, Loss: 6.311, Avg loss: 6.359, Best loss: 6.357\n",
      "    [batch 134]: seen 13400 examples : 69.1 eps, Loss: 6.333, Avg loss: 6.357, Best loss: 6.357\n",
      "    [batch 141]: seen 14100 examples : 69.1 eps, Loss: 6.340, Avg loss: 6.356, Best loss: 6.355\n",
      "    [batch 148]: seen 14800 examples : 69.1 eps, Loss: 6.411, Avg loss: 6.356, Best loss: 6.355\n",
      "    [batch 155]: seen 15500 examples : 68.9 eps, Loss: 6.426, Avg loss: 6.356, Best loss: 6.355\n",
      "    [batch 162]: seen 16200 examples : 68.9 eps, Loss: 6.267, Avg loss: 6.356, Best loss: 6.354\n",
      "    [batch 169]: seen 16900 examples : 68.9 eps, Loss: 6.363, Avg loss: 6.356, Best loss: 6.354\n",
      "    [batch 176]: seen 17600 examples : 68.9 eps, Loss: 6.380, Avg loss: 6.355, Best loss: 6.354\n",
      "    [batch 183]: seen 18300 examples : 68.9 eps, Loss: 6.408, Avg loss: 6.354, Best loss: 6.353\n",
      "    [batch 190]: seen 19000 examples : 68.9 eps, Loss: 6.302, Avg loss: 6.353, Best loss: 6.353\n",
      "    [batch 197]: seen 19700 examples : 68.9 eps, Loss: 6.380, Avg loss: 6.352, Best loss: 6.351\n",
      "    [batch 204]: seen 20400 examples : 68.8 eps, Loss: 6.408, Avg loss: 6.355, Best loss: 6.351\n",
      "    [batch 211]: seen 21100 examples : 68.8 eps, Loss: 6.329, Avg loss: 6.355, Best loss: 6.351\n",
      "    [batch 218]: seen 21800 examples : 68.8 eps, Loss: 6.374, Avg loss: 6.355, Best loss: 6.351\n",
      "    [batch 225]: seen 22500 examples : 68.7 eps, Loss: 6.337, Avg loss: 6.353, Best loss: 6.351\n",
      "    [batch 232]: seen 23200 examples : 68.7 eps, Loss: 6.297, Avg loss: 6.351, Best loss: 6.351\n",
      "    [batch 239]: seen 23900 examples : 68.7 eps, Loss: 6.383, Avg loss: 6.349, Best loss: 6.349\n",
      "    [batch 246]: seen 24600 examples : 68.7 eps, Loss: 6.275, Avg loss: 6.348, Best loss: 6.348\n",
      "    [batch 253]: seen 25300 examples : 68.6 eps, Loss: 6.381, Avg loss: 6.347, Best loss: 6.347\n",
      "    [batch 260]: seen 26000 examples : 68.6 eps, Loss: 6.352, Avg loss: 6.347, Best loss: 6.347\n",
      "    [batch 267]: seen 26700 examples : 68.6 eps, Loss: 6.278, Avg loss: 6.346, Best loss: 6.346\n",
      "    [batch 274]: seen 27400 examples : 68.6 eps, Loss: 6.240, Avg loss: 6.344, Best loss: 6.344\n",
      "    [batch 281]: seen 28100 examples : 68.5 eps, Loss: 6.291, Avg loss: 6.343, Best loss: 6.343\n",
      "    [batch 288]: seen 28800 examples : 68.4 eps, Loss: 6.311, Avg loss: 6.340, Best loss: 6.340\n",
      "    [batch 295]: seen 29500 examples : 68.5 eps, Loss: 6.302, Avg loss: 6.340, Best loss: 6.339\n",
      "    [batch 302]: seen 30200 examples : 68.4 eps, Loss: 6.260, Avg loss: 6.339, Best loss: 6.339\n",
      "    [batch 309]: seen 30900 examples : 68.4 eps, Loss: 6.424, Avg loss: 6.340, Best loss: 6.338\n",
      "    [batch 316]: seen 31600 examples : 68.4 eps, Loss: 6.261, Avg loss: 6.339, Best loss: 6.338\n",
      "    [batch 323]: seen 32300 examples : 68.4 eps, Loss: 6.361, Avg loss: 6.339, Best loss: 6.338\n",
      "    [batch 330]: seen 33000 examples : 68.4 eps, Loss: 6.389, Avg loss: 6.340, Best loss: 6.338\n",
      "    [batch 337]: seen 33700 examples : 68.4 eps, Loss: 6.332, Avg loss: 6.339, Best loss: 6.338\n",
      "    [batch 344]: seen 34400 examples : 68.4 eps, Loss: 6.259, Avg loss: 6.337, Best loss: 6.337\n",
      "    [batch 351]: seen 35100 examples : 68.3 eps, Loss: 6.342, Avg loss: 6.336, Best loss: 6.336\n",
      "    [batch 358]: seen 35800 examples : 68.3 eps, Loss: 6.371, Avg loss: 6.335, Best loss: 6.334\n",
      "    [batch 365]: seen 36500 examples : 68.3 eps, Loss: 6.305, Avg loss: 6.336, Best loss: 6.334\n",
      "    [batch 372]: seen 37200 examples : 68.3 eps, Loss: 6.362, Avg loss: 6.335, Best loss: 6.334\n",
      "    [batch 379]: seen 37900 examples : 68.3 eps, Loss: 6.243, Avg loss: 6.334, Best loss: 6.334\n",
      "    [batch 386]: seen 38600 examples : 68.3 eps, Loss: 6.324, Avg loss: 6.333, Best loss: 6.332\n",
      "    [batch 393]: seen 39300 examples : 68.3 eps, Loss: 6.351, Avg loss: 6.332, Best loss: 6.332\n",
      "    [batch 400]: seen 40000 examples : 68.3 eps, Loss: 6.390, Avg loss: 6.330, Best loss: 6.330\n",
      "    [batch 407]: seen 40700 examples : 68.3 eps, Loss: 6.387, Avg loss: 6.334, Best loss: 6.330\n",
      "    [batch 414]: seen 41400 examples : 68.2 eps, Loss: 6.355, Avg loss: 6.330, Best loss: 6.330\n",
      "    [batch 421]: seen 42100 examples : 68.2 eps, Loss: 6.256, Avg loss: 6.330, Best loss: 6.330\n",
      "    [batch 428]: seen 42800 examples : 68.2 eps, Loss: 6.271, Avg loss: 6.329, Best loss: 6.329\n",
      "    [batch 435]: seen 43500 examples : 68.2 eps, Loss: 6.203, Avg loss: 6.329, Best loss: 6.329\n",
      "    [batch 442]: seen 44200 examples : 68.2 eps, Loss: 6.402, Avg loss: 6.329, Best loss: 6.328\n",
      "    [batch 449]: seen 44900 examples : 68.2 eps, Loss: 6.353, Avg loss: 6.329, Best loss: 6.328\n",
      "    [batch 456]: seen 45600 examples : 68.2 eps, Loss: 6.327, Avg loss: 6.327, Best loss: 6.327\n",
      "    [batch 463]: seen 46300 examples : 68.2 eps, Loss: 6.332, Avg loss: 6.328, Best loss: 6.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 470]: seen 47000 examples : 68.2 eps, Loss: 6.433, Avg loss: 6.330, Best loss: 6.327\n",
      "    [batch 477]: seen 47700 examples : 68.1 eps, Loss: 6.253, Avg loss: 6.329, Best loss: 6.327\n",
      "    [batch 484]: seen 48400 examples : 68.1 eps, Loss: 6.237, Avg loss: 6.326, Best loss: 6.326\n",
      "    [batch 491]: seen 49100 examples : 68.1 eps, Loss: 6.307, Avg loss: 6.324, Best loss: 6.324\n",
      "    [batch 498]: seen 49800 examples : 68.1 eps, Loss: 6.258, Avg loss: 6.321, Best loss: 6.321\n",
      "    [batch 505]: seen 50500 examples : 68.1 eps, Loss: 6.350, Avg loss: 6.323, Best loss: 6.321\n",
      "    [batch 512]: seen 51200 examples : 68.1 eps, Loss: 6.365, Avg loss: 6.324, Best loss: 6.321\n",
      "    [batch 519]: seen 51900 examples : 68.1 eps, Loss: 6.292, Avg loss: 6.324, Best loss: 6.321\n",
      "    [batch 526]: seen 52600 examples : 68.1 eps, Loss: 6.260, Avg loss: 6.325, Best loss: 6.321\n",
      "    [batch 533]: seen 53300 examples : 68.1 eps, Loss: 6.277, Avg loss: 6.324, Best loss: 6.321\n",
      "    [batch 540]: seen 54000 examples : 68.1 eps, Loss: 6.378, Avg loss: 6.325, Best loss: 6.321\n",
      "    [batch 547]: seen 54700 examples : 68.1 eps, Loss: 6.207, Avg loss: 6.325, Best loss: 6.321\n",
      "    [batch 554]: seen 55400 examples : 68.1 eps, Loss: 6.331, Avg loss: 6.323, Best loss: 6.321\n",
      "    [batch 561]: seen 56100 examples : 68.1 eps, Loss: 6.259, Avg loss: 6.321, Best loss: 6.321\n",
      "    [batch 568]: seen 56800 examples : 68.1 eps, Loss: 6.324, Avg loss: 6.320, Best loss: 6.320\n",
      "    [batch 575]: seen 57500 examples : 68.1 eps, Loss: 6.282, Avg loss: 6.319, Best loss: 6.319\n",
      "    [batch 582]: seen 58200 examples : 68.1 eps, Loss: 6.310, Avg loss: 6.318, Best loss: 6.318\n",
      "    [batch 589]: seen 58900 examples : 68.1 eps, Loss: 6.256, Avg loss: 6.317, Best loss: 6.317\n",
      "    [batch 596]: seen 59600 examples : 68.1 eps, Loss: 6.335, Avg loss: 6.318, Best loss: 6.317\n",
      "    [batch 603]: seen 60300 examples : 68.1 eps, Loss: 6.277, Avg loss: 6.316, Best loss: 6.316\n",
      "    [batch 610]: seen 61000 examples : 68.1 eps, Loss: 6.335, Avg loss: 6.317, Best loss: 6.315\n",
      "    [batch 617]: seen 61700 examples : 68.1 eps, Loss: 6.286, Avg loss: 6.317, Best loss: 6.315\n",
      "    [batch 624]: seen 62400 examples : 68.1 eps, Loss: 6.320, Avg loss: 6.318, Best loss: 6.315\n",
      "    [batch 631]: seen 63100 examples : 68.1 eps, Loss: 6.367, Avg loss: 6.318, Best loss: 6.315\n",
      "    [batch 638]: seen 63800 examples : 68.1 eps, Loss: 6.301, Avg loss: 6.318, Best loss: 6.315\n",
      "    [batch 645]: seen 64500 examples : 68.0 eps, Loss: 6.276, Avg loss: 6.317, Best loss: 6.315\n",
      "    [batch 652]: seen 65200 examples : 68.0 eps, Loss: 6.294, Avg loss: 6.316, Best loss: 6.315\n",
      "    [batch 659]: seen 65900 examples : 68.0 eps, Loss: 6.253, Avg loss: 6.315, Best loss: 6.315\n",
      "    [batch 666]: seen 66600 examples : 68.0 eps, Loss: 6.266, Avg loss: 6.315, Best loss: 6.315\n",
      "    [batch 673]: seen 67300 examples : 68.0 eps, Loss: 6.228, Avg loss: 6.312, Best loss: 6.312\n",
      "    [batch 680]: seen 68000 examples : 68.0 eps, Loss: 6.262, Avg loss: 6.310, Best loss: 6.310\n",
      "    [batch 687]: seen 68700 examples : 68.0 eps, Loss: 6.259, Avg loss: 6.306, Best loss: 6.306\n",
      "    [batch 694]: seen 69400 examples : 68.0 eps, Loss: 6.272, Avg loss: 6.302, Best loss: 6.302\n",
      "    [batch 701]: seen 70100 examples : 68.0 eps, Loss: 6.287, Avg loss: 6.299, Best loss: 6.299\n",
      "    [batch 708]: seen 70800 examples : 68.0 eps, Loss: 6.243, Avg loss: 6.297, Best loss: 6.297\n",
      "    [batch 715]: seen 71500 examples : 68.0 eps, Loss: 6.307, Avg loss: 6.297, Best loss: 6.296\n",
      "    [batch 722]: seen 72200 examples : 68.0 eps, Loss: 6.225, Avg loss: 6.296, Best loss: 6.296\n",
      "    [batch 729]: seen 72900 examples : 68.0 eps, Loss: 6.387, Avg loss: 6.296, Best loss: 6.295\n",
      "    [batch 736]: seen 73600 examples : 68.0 eps, Loss: 6.322, Avg loss: 6.296, Best loss: 6.295\n",
      "    [batch 743]: seen 74300 examples : 68.0 eps, Loss: 6.304, Avg loss: 6.296, Best loss: 6.295\n",
      "    [batch 750]: seen 75000 examples : 68.0 eps, Loss: 6.302, Avg loss: 6.297, Best loss: 6.295\n",
      "    [batch 757]: seen 75700 examples : 68.0 eps, Loss: 6.335, Avg loss: 6.297, Best loss: 6.295\n",
      "    [batch 764]: seen 76400 examples : 68.0 eps, Loss: 6.198, Avg loss: 6.293, Best loss: 6.293\n",
      "    [batch 771]: seen 77100 examples : 68.0 eps, Loss: 6.290, Avg loss: 6.293, Best loss: 6.293\n",
      "    [batch 778]: seen 77800 examples : 68.0 eps, Loss: 6.261, Avg loss: 6.294, Best loss: 6.292\n",
      "    [batch 785]: seen 78500 examples : 68.0 eps, Loss: 6.253, Avg loss: 6.294, Best loss: 6.292\n",
      "    [batch 792]: seen 79200 examples : 68.0 eps, Loss: 6.317, Avg loss: 6.294, Best loss: 6.292\n",
      "    [batch 799]: seen 79900 examples : 68.0 eps, Loss: 6.357, Avg loss: 6.295, Best loss: 6.292\n",
      "    [batch 806]: seen 80600 examples : 68.0 eps, Loss: 6.243, Avg loss: 6.294, Best loss: 6.292\n",
      "    [batch 813]: seen 81300 examples : 68.0 eps, Loss: 6.195, Avg loss: 6.293, Best loss: 6.292\n",
      "    [batch 820]: seen 82000 examples : 68.0 eps, Loss: 6.291, Avg loss: 6.292, Best loss: 6.291\n",
      "    [batch 827]: seen 82700 examples : 68.0 eps, Loss: 6.182, Avg loss: 6.288, Best loss: 6.288\n",
      "    [batch 834]: seen 83400 examples : 68.0 eps, Loss: 6.243, Avg loss: 6.286, Best loss: 6.286\n",
      "    [batch 841]: seen 84100 examples : 68.0 eps, Loss: 6.312, Avg loss: 6.286, Best loss: 6.285\n",
      "    [batch 848]: seen 84800 examples : 68.0 eps, Loss: 6.254, Avg loss: 6.284, Best loss: 6.284\n",
      "    [batch 855]: seen 85500 examples : 68.0 eps, Loss: 6.181, Avg loss: 6.285, Best loss: 6.284\n",
      "    [batch 862]: seen 86200 examples : 68.0 eps, Loss: 6.240, Avg loss: 6.286, Best loss: 6.284\n",
      "    [batch 869]: seen 86900 examples : 68.0 eps, Loss: 6.371, Avg loss: 6.285, Best loss: 6.284\n",
      "    [batch 876]: seen 87600 examples : 67.9 eps, Loss: 6.302, Avg loss: 6.285, Best loss: 6.284\n",
      "    [batch 883]: seen 88300 examples : 67.9 eps, Loss: 6.250, Avg loss: 6.285, Best loss: 6.284\n",
      "    [batch 890]: seen 89000 examples : 67.9 eps, Loss: 6.234, Avg loss: 6.282, Best loss: 6.282\n",
      "    [batch 897]: seen 89700 examples : 67.9 eps, Loss: 6.234, Avg loss: 6.282, Best loss: 6.282\n",
      "    [batch 904]: seen 90400 examples : 67.9 eps, Loss: 6.329, Avg loss: 6.282, Best loss: 6.281\n",
      "    [batch 911]: seen 91100 examples : 67.9 eps, Loss: 6.258, Avg loss: 6.281, Best loss: 6.281\n",
      "    [batch 918]: seen 91800 examples : 67.9 eps, Loss: 6.291, Avg loss: 6.281, Best loss: 6.280\n",
      "    [batch 925]: seen 92500 examples : 67.9 eps, Loss: 6.267, Avg loss: 6.281, Best loss: 6.280\n",
      "    [batch 932]: seen 93200 examples : 67.9 eps, Loss: 6.233, Avg loss: 6.279, Best loss: 6.279\n",
      "    [batch 939]: seen 93900 examples : 67.9 eps, Loss: 6.303, Avg loss: 6.280, Best loss: 6.279\n",
      "    [batch 946]: seen 94600 examples : 67.9 eps, Loss: 6.239, Avg loss: 6.280, Best loss: 6.279\n",
      "    [batch 953]: seen 95300 examples : 67.9 eps, Loss: 6.311, Avg loss: 6.280, Best loss: 6.279\n",
      "    [batch 960]: seen 96000 examples : 67.9 eps, Loss: 6.350, Avg loss: 6.289, Best loss: 6.279\n",
      "    [batch 967]: seen 96700 examples : 67.9 eps, Loss: 6.303, Avg loss: 6.288, Best loss: 6.279\n",
      "    [batch 974]: seen 97400 examples : 67.9 eps, Loss: 6.278, Avg loss: 6.285, Best loss: 6.279\n",
      "    [batch 981]: seen 98100 examples : 67.9 eps, Loss: 6.225, Avg loss: 6.284, Best loss: 6.279\n",
      "    [batch 988]: seen 98800 examples : 67.9 eps, Loss: 6.289, Avg loss: 6.281, Best loss: 6.279\n",
      "    [batch 995]: seen 99500 examples : 67.9 eps, Loss: 6.291, Avg loss: 6.280, Best loss: 6.279\n",
      "    [batch 1002]: seen 100200 examples : 67.9 eps, Loss: 6.321, Avg loss: 6.278, Best loss: 6.278\n",
      "    [batch 1009]: seen 100900 examples : 67.9 eps, Loss: 6.136, Avg loss: 6.277, Best loss: 6.277\n",
      "    [batch 1016]: seen 101600 examples : 67.9 eps, Loss: 6.285, Avg loss: 6.276, Best loss: 6.276\n",
      "    [batch 1023]: seen 102300 examples : 67.9 eps, Loss: 6.315, Avg loss: 6.276, Best loss: 6.275\n",
      "    [batch 1030]: seen 103000 examples : 67.9 eps, Loss: 6.212, Avg loss: 6.274, Best loss: 6.274\n",
      "    [batch 1037]: seen 103700 examples : 67.9 eps, Loss: 6.256, Avg loss: 6.273, Best loss: 6.273\n",
      "    [batch 1044]: seen 104400 examples : 67.9 eps, Loss: 6.254, Avg loss: 6.272, Best loss: 6.271\n",
      "    [batch 1051]: seen 105100 examples : 67.9 eps, Loss: 6.164, Avg loss: 6.273, Best loss: 6.271\n",
      "    [batch 1058]: seen 105800 examples : 67.9 eps, Loss: 6.150, Avg loss: 6.270, Best loss: 6.270\n",
      "    [batch 1065]: seen 106500 examples : 67.9 eps, Loss: 6.135, Avg loss: 6.267, Best loss: 6.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1072]: seen 107200 examples : 67.9 eps, Loss: 6.257, Avg loss: 6.265, Best loss: 6.265\n",
      "    [batch 1079]: seen 107900 examples : 67.9 eps, Loss: 6.159, Avg loss: 6.263, Best loss: 6.263\n",
      "    [batch 1086]: seen 108600 examples : 67.9 eps, Loss: 6.293, Avg loss: 6.262, Best loss: 6.262\n",
      "    [batch 1093]: seen 109300 examples : 67.9 eps, Loss: 6.302, Avg loss: 6.262, Best loss: 6.261\n",
      "    [batch 1100]: seen 110000 examples : 67.9 eps, Loss: 6.306, Avg loss: 6.263, Best loss: 6.261\n",
      "    [batch 1107]: seen 110700 examples : 67.9 eps, Loss: 6.271, Avg loss: 6.264, Best loss: 6.261\n",
      "    [batch 1114]: seen 111400 examples : 67.9 eps, Loss: 6.225, Avg loss: 6.261, Best loss: 6.261\n",
      "    [batch 1121]: seen 112100 examples : 67.9 eps, Loss: 6.331, Avg loss: 6.262, Best loss: 6.260\n",
      "    [batch 1128]: seen 112800 examples : 67.9 eps, Loss: 6.232, Avg loss: 6.259, Best loss: 6.259\n",
      "    [batch 1135]: seen 113500 examples : 67.9 eps, Loss: 6.267, Avg loss: 6.258, Best loss: 6.258\n",
      "    [batch 1142]: seen 114200 examples : 67.9 eps, Loss: 6.251, Avg loss: 6.258, Best loss: 6.258\n",
      "    [batch 1149]: seen 114900 examples : 67.9 eps, Loss: 6.184, Avg loss: 6.257, Best loss: 6.257\n",
      "    [batch 1156]: seen 115600 examples : 67.9 eps, Loss: 6.289, Avg loss: 6.255, Best loss: 6.255\n",
      "    [batch 1163]: seen 116300 examples : 67.9 eps, Loss: 6.244, Avg loss: 6.252, Best loss: 6.252\n",
      "    [batch 1170]: seen 117000 examples : 67.9 eps, Loss: 6.212, Avg loss: 6.253, Best loss: 6.252\n",
      "    [batch 1177]: seen 117700 examples : 67.9 eps, Loss: 6.225, Avg loss: 6.250, Best loss: 6.250\n",
      "    [batch 1184]: seen 118400 examples : 67.9 eps, Loss: 6.287, Avg loss: 6.249, Best loss: 6.249\n",
      "    [batch 1191]: seen 119100 examples : 67.9 eps, Loss: 6.220, Avg loss: 6.248, Best loss: 6.248\n",
      "    [batch 1198]: seen 119800 examples : 67.9 eps, Loss: 6.300, Avg loss: 6.246, Best loss: 6.245\n",
      "    [batch 1205]: seen 120500 examples : 67.9 eps, Loss: 6.181, Avg loss: 6.246, Best loss: 6.245\n",
      "    [batch 1212]: seen 121200 examples : 67.9 eps, Loss: 6.136, Avg loss: 6.243, Best loss: 6.243\n",
      "    [batch 1219]: seen 121900 examples : 67.9 eps, Loss: 6.274, Avg loss: 6.244, Best loss: 6.243\n",
      "    [batch 1226]: seen 122600 examples : 67.9 eps, Loss: 6.269, Avg loss: 6.244, Best loss: 6.243\n",
      "    [batch 1233]: seen 123300 examples : 67.9 eps, Loss: 6.185, Avg loss: 6.242, Best loss: 6.242\n",
      "    [batch 1240]: seen 124000 examples : 67.9 eps, Loss: 6.237, Avg loss: 6.240, Best loss: 6.240\n",
      "    [batch 1247]: seen 124700 examples : 67.9 eps, Loss: 6.171, Avg loss: 6.237, Best loss: 6.237\n",
      "    [batch 1254]: seen 125400 examples : 67.9 eps, Loss: 6.185, Avg loss: 6.236, Best loss: 6.236\n",
      "    [batch 1261]: seen 126100 examples : 67.9 eps, Loss: 6.303, Avg loss: 6.236, Best loss: 6.236\n",
      "    [batch 1268]: seen 126800 examples : 67.9 eps, Loss: 6.251, Avg loss: 6.236, Best loss: 6.235\n",
      "    [batch 1275]: seen 127500 examples : 67.9 eps, Loss: 6.251, Avg loss: 6.235, Best loss: 6.235\n",
      "    [batch 1282]: seen 128200 examples : 67.9 eps, Loss: 6.184, Avg loss: 6.236, Best loss: 6.234\n",
      "    [batch 1289]: seen 128900 examples : 67.9 eps, Loss: 6.249, Avg loss: 6.237, Best loss: 6.234\n",
      "    [batch 1296]: seen 129600 examples : 67.9 eps, Loss: 6.208, Avg loss: 6.237, Best loss: 6.234\n",
      "    [batch 1303]: seen 130300 examples : 67.9 eps, Loss: 6.206, Avg loss: 6.238, Best loss: 6.234\n",
      "    [batch 1310]: seen 131000 examples : 67.9 eps, Loss: 6.308, Avg loss: 6.237, Best loss: 6.234\n",
      "    [batch 1317]: seen 131700 examples : 67.9 eps, Loss: 6.241, Avg loss: 6.237, Best loss: 6.234\n",
      "    [batch 1324]: seen 132400 examples : 67.8 eps, Loss: 6.269, Avg loss: 6.236, Best loss: 6.234\n",
      "    [batch 1331]: seen 133100 examples : 67.8 eps, Loss: 6.198, Avg loss: 6.234, Best loss: 6.234\n",
      "    [batch 1338]: seen 133800 examples : 67.9 eps, Loss: 6.129, Avg loss: 6.230, Best loss: 6.230\n",
      "    [batch 1345]: seen 134500 examples : 67.9 eps, Loss: 6.089, Avg loss: 6.228, Best loss: 6.228\n",
      "    [batch 1352]: seen 135200 examples : 67.9 eps, Loss: 6.184, Avg loss: 6.226, Best loss: 6.226\n",
      "    [batch 1359]: seen 135900 examples : 67.9 eps, Loss: 6.180, Avg loss: 6.227, Best loss: 6.226\n",
      "    [batch 1366]: seen 136600 examples : 67.9 eps, Loss: 6.198, Avg loss: 6.227, Best loss: 6.226\n",
      "    [batch 1373]: seen 137300 examples : 67.9 eps, Loss: 6.209, Avg loss: 6.226, Best loss: 6.225\n",
      "    [batch 1380]: seen 138000 examples : 67.9 eps, Loss: 6.212, Avg loss: 6.225, Best loss: 6.225\n",
      "    [batch 1387]: seen 138700 examples : 67.9 eps, Loss: 6.289, Avg loss: 6.224, Best loss: 6.223\n",
      "    [batch 1394]: seen 139400 examples : 67.9 eps, Loss: 6.311, Avg loss: 6.226, Best loss: 6.223\n",
      "    [batch 1401]: seen 140100 examples : 67.9 eps, Loss: 6.264, Avg loss: 6.224, Best loss: 6.223\n",
      "    [batch 1408]: seen 140800 examples : 67.9 eps, Loss: 6.313, Avg loss: 6.243, Best loss: 6.223\n",
      "    [batch 1415]: seen 141500 examples : 67.9 eps, Loss: 6.310, Avg loss: 6.242, Best loss: 6.223\n",
      "    [batch 1422]: seen 142200 examples : 67.9 eps, Loss: 6.263, Avg loss: 6.242, Best loss: 6.223\n",
      "    [batch 1429]: seen 142900 examples : 67.9 eps, Loss: 6.281, Avg loss: 6.242, Best loss: 6.223\n",
      "    [batch 1436]: seen 143600 examples : 67.9 eps, Loss: 6.164, Avg loss: 6.240, Best loss: 6.223\n",
      "    [batch 1443]: seen 144300 examples : 67.9 eps, Loss: 6.246, Avg loss: 6.240, Best loss: 6.223\n",
      "    [batch 1450]: seen 145000 examples : 67.9 eps, Loss: 6.720, Avg loss: 6.242, Best loss: 6.223\n",
      "    [batch 1457]: seen 145700 examples : 67.8 eps, Loss: 6.184, Avg loss: 6.248, Best loss: 6.223\n",
      "    [batch 1464]: seen 146400 examples : 67.8 eps, Loss: 6.275, Avg loss: 6.248, Best loss: 6.223\n",
      "    [batch 1471]: seen 147100 examples : 67.8 eps, Loss: 6.265, Avg loss: 6.247, Best loss: 6.223\n",
      "    [batch 1478]: seen 147800 examples : 67.8 eps, Loss: 6.221, Avg loss: 6.244, Best loss: 6.223\n",
      "    [batch 1485]: seen 148500 examples : 67.8 eps, Loss: 6.201, Avg loss: 6.240, Best loss: 6.223\n",
      "    [batch 1492]: seen 149200 examples : 67.8 eps, Loss: 6.185, Avg loss: 6.235, Best loss: 6.223\n",
      "    [batch 1499]: seen 149900 examples : 67.8 eps, Loss: 6.255, Avg loss: 6.235, Best loss: 6.223\n",
      "    [batch 1506]: seen 150600 examples : 67.8 eps, Loss: 6.183, Avg loss: 6.232, Best loss: 6.223\n",
      "    [batch 1513]: seen 151300 examples : 67.8 eps, Loss: 6.192, Avg loss: 6.228, Best loss: 6.223\n",
      "    [batch 1520]: seen 152000 examples : 67.8 eps, Loss: 6.177, Avg loss: 6.224, Best loss: 6.223\n",
      "    [batch 1527]: seen 152700 examples : 67.8 eps, Loss: 6.153, Avg loss: 6.221, Best loss: 6.221\n",
      "    [batch 1534]: seen 153400 examples : 67.8 eps, Loss: 6.126, Avg loss: 6.218, Best loss: 6.218\n",
      "    [batch 1541]: seen 154100 examples : 67.8 eps, Loss: 6.240, Avg loss: 6.217, Best loss: 6.217\n",
      "    [batch 1548]: seen 154800 examples : 67.8 eps, Loss: 6.180, Avg loss: 6.215, Best loss: 6.215\n",
      "    [batch 1555]: seen 155500 examples : 67.8 eps, Loss: 6.129, Avg loss: 6.212, Best loss: 6.212\n",
      "    [batch 1562]: seen 156200 examples : 67.8 eps, Loss: 6.291, Avg loss: 6.215, Best loss: 6.212\n",
      "    [batch 1569]: seen 156900 examples : 67.8 eps, Loss: 6.204, Avg loss: 6.216, Best loss: 6.212\n",
      "    [batch 1576]: seen 157600 examples : 67.8 eps, Loss: 6.205, Avg loss: 6.215, Best loss: 6.212\n",
      "    [batch 1583]: seen 158300 examples : 67.8 eps, Loss: 6.133, Avg loss: 6.214, Best loss: 6.212\n",
      "    [batch 1590]: seen 159000 examples : 67.8 eps, Loss: 6.215, Avg loss: 6.213, Best loss: 6.212\n",
      "    [batch 1597]: seen 159700 examples : 67.8 eps, Loss: 6.203, Avg loss: 6.211, Best loss: 6.211\n",
      "    [batch 1604]: seen 160400 examples : 67.8 eps, Loss: 6.165, Avg loss: 6.209, Best loss: 6.209\n",
      "    [batch 1611]: seen 161100 examples : 67.8 eps, Loss: 6.257, Avg loss: 6.209, Best loss: 6.208\n",
      "    [batch 1618]: seen 161800 examples : 67.8 eps, Loss: 6.283, Avg loss: 6.210, Best loss: 6.208\n",
      "    [batch 1625]: seen 162500 examples : 67.8 eps, Loss: 6.154, Avg loss: 6.207, Best loss: 6.207\n",
      "    [batch 1632]: seen 163200 examples : 67.8 eps, Loss: 6.137, Avg loss: 6.207, Best loss: 6.207\n",
      "    [batch 1639]: seen 163900 examples : 67.8 eps, Loss: 6.231, Avg loss: 6.210, Best loss: 6.207\n",
      "    [batch 1646]: seen 164600 examples : 67.8 eps, Loss: 6.272, Avg loss: 6.208, Best loss: 6.207\n",
      "    [batch 1653]: seen 165300 examples : 67.8 eps, Loss: 6.148, Avg loss: 6.206, Best loss: 6.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1660]: seen 166000 examples : 67.8 eps, Loss: 6.170, Avg loss: 6.205, Best loss: 6.204\n",
      "    [batch 1667]: seen 166700 examples : 67.8 eps, Loss: 6.230, Avg loss: 6.204, Best loss: 6.204\n",
      "    [batch 1674]: seen 167400 examples : 67.8 eps, Loss: 6.250, Avg loss: 6.204, Best loss: 6.204\n",
      "    [batch 1681]: seen 168100 examples : 67.8 eps, Loss: 6.251, Avg loss: 6.203, Best loss: 6.202\n",
      "    [batch 1688]: seen 168800 examples : 67.8 eps, Loss: 6.257, Avg loss: 6.203, Best loss: 6.202\n",
      "    [batch 1695]: seen 169500 examples : 67.8 eps, Loss: 6.262, Avg loss: 6.204, Best loss: 6.202\n",
      "    [batch 1702]: seen 170200 examples : 67.8 eps, Loss: 6.231, Avg loss: 6.204, Best loss: 6.202\n",
      "    [batch 1709]: seen 170900 examples : 67.8 eps, Loss: 6.202, Avg loss: 6.203, Best loss: 6.202\n",
      "    [batch 1716]: seen 171600 examples : 67.8 eps, Loss: 6.162, Avg loss: 6.202, Best loss: 6.202\n",
      "    [batch 1723]: seen 172300 examples : 67.8 eps, Loss: 6.246, Avg loss: 6.202, Best loss: 6.201\n",
      "    [batch 1730]: seen 173000 examples : 67.8 eps, Loss: 6.199, Avg loss: 6.201, Best loss: 6.201\n",
      "    [batch 1737]: seen 173700 examples : 67.8 eps, Loss: 6.194, Avg loss: 6.201, Best loss: 6.201\n",
      "    [batch 1744]: seen 174400 examples : 67.8 eps, Loss: 6.163, Avg loss: 6.198, Best loss: 6.198\n",
      "    [batch 1751]: seen 175100 examples : 67.8 eps, Loss: 6.157, Avg loss: 6.195, Best loss: 6.195\n",
      "    [batch 1758]: seen 175800 examples : 67.8 eps, Loss: 6.260, Avg loss: 6.194, Best loss: 6.193\n",
      "    [batch 1765]: seen 176500 examples : 67.8 eps, Loss: 6.193, Avg loss: 6.194, Best loss: 6.193\n",
      "    [batch 1772]: seen 177200 examples : 67.8 eps, Loss: 6.188, Avg loss: 6.191, Best loss: 6.191\n",
      "    [batch 1779]: seen 177900 examples : 67.8 eps, Loss: 6.195, Avg loss: 6.190, Best loss: 6.190\n",
      "    [batch 1786]: seen 178600 examples : 67.8 eps, Loss: 6.181, Avg loss: 6.189, Best loss: 6.187\n",
      "    [batch 1793]: seen 179300 examples : 67.8 eps, Loss: 6.174, Avg loss: 6.186, Best loss: 6.186\n",
      "    [batch 1800]: seen 180000 examples : 67.8 eps, Loss: 6.252, Avg loss: 6.185, Best loss: 6.184\n",
      "    [batch 1807]: seen 180700 examples : 67.8 eps, Loss: 6.206, Avg loss: 6.185, Best loss: 6.184\n",
      "    [batch 1814]: seen 181400 examples : 67.8 eps, Loss: 6.167, Avg loss: 6.182, Best loss: 6.182\n",
      "    [batch 1821]: seen 182100 examples : 67.8 eps, Loss: 6.116, Avg loss: 6.182, Best loss: 6.181\n",
      "    [batch 1828]: seen 182800 examples : 67.8 eps, Loss: 6.292, Avg loss: 6.182, Best loss: 6.180\n",
      "    [batch 1835]: seen 183500 examples : 67.8 eps, Loss: 6.087, Avg loss: 6.182, Best loss: 6.180\n",
      "    [batch 1842]: seen 184200 examples : 67.8 eps, Loss: 6.112, Avg loss: 6.179, Best loss: 6.179\n",
      "    [batch 1849]: seen 184900 examples : 67.8 eps, Loss: 6.160, Avg loss: 6.178, Best loss: 6.178\n",
      "    [batch 1856]: seen 185600 examples : 67.8 eps, Loss: 6.122, Avg loss: 6.175, Best loss: 6.175\n",
      "    [batch 1863]: seen 186300 examples : 67.8 eps, Loss: 6.172, Avg loss: 6.172, Best loss: 6.172\n",
      "    [batch 1870]: seen 187000 examples : 67.8 eps, Loss: 6.254, Avg loss: 6.175, Best loss: 6.172\n",
      "    [batch 1877]: seen 187700 examples : 67.8 eps, Loss: 6.143, Avg loss: 6.176, Best loss: 6.172\n",
      "    [batch 1884]: seen 188400 examples : 67.8 eps, Loss: 6.219, Avg loss: 6.177, Best loss: 6.172\n",
      "    [batch 1891]: seen 189100 examples : 67.8 eps, Loss: 6.253, Avg loss: 6.179, Best loss: 6.172\n",
      "    [batch 1898]: seen 189800 examples : 67.8 eps, Loss: 6.178, Avg loss: 6.181, Best loss: 6.172\n",
      "    [batch 1905]: seen 190500 examples : 67.8 eps, Loss: 6.182, Avg loss: 6.181, Best loss: 6.172\n",
      "    [batch 1912]: seen 191200 examples : 67.8 eps, Loss: 6.140, Avg loss: 6.178, Best loss: 6.172\n",
      "    [batch 1919]: seen 191900 examples : 67.8 eps, Loss: 6.162, Avg loss: 6.180, Best loss: 6.172\n",
      "    [batch 1926]: seen 192600 examples : 67.8 eps, Loss: 6.107, Avg loss: 6.179, Best loss: 6.172\n",
      "    [batch 1933]: seen 193300 examples : 67.8 eps, Loss: 6.222, Avg loss: 6.179, Best loss: 6.172\n",
      "    [batch 1940]: seen 194000 examples : 67.8 eps, Loss: 6.130, Avg loss: 6.177, Best loss: 6.172\n",
      "    [batch 1947]: seen 194700 examples : 67.8 eps, Loss: 6.235, Avg loss: 6.179, Best loss: 6.172\n",
      "    [batch 1954]: seen 195400 examples : 67.8 eps, Loss: 6.137, Avg loss: 6.176, Best loss: 6.172\n",
      "    [batch 1961]: seen 196100 examples : 67.8 eps, Loss: 6.096, Avg loss: 6.174, Best loss: 6.172\n",
      "    [batch 1968]: seen 196800 examples : 67.8 eps, Loss: 6.249, Avg loss: 6.172, Best loss: 6.171\n",
      "    [batch 1975]: seen 197500 examples : 67.7 eps, Loss: 6.218, Avg loss: 6.169, Best loss: 6.169\n",
      "    [batch 1982]: seen 198200 examples : 67.8 eps, Loss: 6.284, Avg loss: 6.170, Best loss: 6.168\n",
      "    [batch 1989]: seen 198900 examples : 67.8 eps, Loss: 6.276, Avg loss: 6.171, Best loss: 6.168\n",
      "    [batch 1996]: seen 199600 examples : 67.8 eps, Loss: 6.195, Avg loss: 6.173, Best loss: 6.168\n",
      "    [batch 2003]: seen 200300 examples : 67.8 eps, Loss: 6.167, Avg loss: 6.172, Best loss: 6.168\n",
      "    [batch 2010]: seen 201000 examples : 67.8 eps, Loss: 6.152, Avg loss: 6.172, Best loss: 6.168\n",
      "    [batch 2017]: seen 201700 examples : 67.8 eps, Loss: 6.122, Avg loss: 6.171, Best loss: 6.168\n",
      "    [batch 2024]: seen 202400 examples : 67.8 eps, Loss: 6.065, Avg loss: 6.168, Best loss: 6.168\n",
      "    [batch 2031]: seen 203100 examples : 67.8 eps, Loss: 6.099, Avg loss: 6.164, Best loss: 6.164\n",
      "    [batch 2038]: seen 203800 examples : 67.8 eps, Loss: 6.153, Avg loss: 6.165, Best loss: 6.164\n",
      "    [batch 2045]: seen 204500 examples : 67.8 eps, Loss: 6.184, Avg loss: 6.165, Best loss: 6.164\n",
      "    [batch 2052]: seen 205200 examples : 67.8 eps, Loss: 6.212, Avg loss: 6.163, Best loss: 6.162\n",
      "    [batch 2059]: seen 205900 examples : 67.8 eps, Loss: 6.112, Avg loss: 6.163, Best loss: 6.162\n",
      "    [batch 2066]: seen 206600 examples : 67.7 eps, Loss: 6.098, Avg loss: 6.159, Best loss: 6.159\n",
      "    [batch 2073]: seen 207300 examples : 67.7 eps, Loss: 6.214, Avg loss: 6.161, Best loss: 6.159\n",
      "    [batch 2080]: seen 208000 examples : 67.7 eps, Loss: 6.171, Avg loss: 6.160, Best loss: 6.159\n",
      "    [batch 2087]: seen 208700 examples : 67.7 eps, Loss: 6.101, Avg loss: 6.158, Best loss: 6.158\n",
      "    [batch 2094]: seen 209400 examples : 67.7 eps, Loss: 6.135, Avg loss: 6.156, Best loss: 6.156\n",
      "    [batch 2101]: seen 210100 examples : 67.7 eps, Loss: 6.100, Avg loss: 6.155, Best loss: 6.155\n",
      "    [batch 2108]: seen 210800 examples : 67.7 eps, Loss: 6.130, Avg loss: 6.156, Best loss: 6.155\n",
      "    [batch 2115]: seen 211500 examples : 67.7 eps, Loss: 6.101, Avg loss: 6.156, Best loss: 6.155\n",
      "    [batch 2122]: seen 212200 examples : 67.7 eps, Loss: 6.191, Avg loss: 6.153, Best loss: 6.153\n",
      "    [batch 2129]: seen 212900 examples : 67.7 eps, Loss: 6.165, Avg loss: 6.152, Best loss: 6.152\n",
      "    [batch 2136]: seen 213600 examples : 67.7 eps, Loss: 6.175, Avg loss: 6.153, Best loss: 6.152\n",
      "    [batch 2143]: seen 214300 examples : 67.7 eps, Loss: 6.111, Avg loss: 6.153, Best loss: 6.152\n",
      "    [batch 2150]: seen 215000 examples : 67.7 eps, Loss: 6.050, Avg loss: 6.152, Best loss: 6.152\n",
      "    [batch 2157]: seen 215700 examples : 67.7 eps, Loss: 6.290, Avg loss: 6.153, Best loss: 6.151\n",
      "    [batch 2164]: seen 216400 examples : 67.7 eps, Loss: 6.136, Avg loss: 6.155, Best loss: 6.151\n",
      "    [batch 2171]: seen 217100 examples : 67.7 eps, Loss: 6.165, Avg loss: 6.154, Best loss: 6.151\n",
      "    [batch 2178]: seen 217800 examples : 67.7 eps, Loss: 6.132, Avg loss: 6.156, Best loss: 6.151\n",
      "    [batch 2185]: seen 218500 examples : 67.7 eps, Loss: 6.106, Avg loss: 6.156, Best loss: 6.151\n",
      "    [batch 2192]: seen 219200 examples : 67.7 eps, Loss: 6.130, Avg loss: 6.154, Best loss: 6.151\n",
      "    [batch 2199]: seen 219900 examples : 67.7 eps, Loss: 6.119, Avg loss: 6.154, Best loss: 6.151\n",
      "    [batch 2206]: seen 220600 examples : 67.7 eps, Loss: 6.180, Avg loss: 6.152, Best loss: 6.151\n",
      "    [batch 2213]: seen 221300 examples : 67.7 eps, Loss: 6.188, Avg loss: 6.154, Best loss: 6.151\n",
      "    [batch 2220]: seen 222000 examples : 67.7 eps, Loss: 6.148, Avg loss: 6.155, Best loss: 6.151\n",
      "    [batch 2227]: seen 222700 examples : 67.7 eps, Loss: 6.107, Avg loss: 6.151, Best loss: 6.151\n",
      "    [batch 2234]: seen 223400 examples : 67.7 eps, Loss: 6.123, Avg loss: 6.149, Best loss: 6.149\n",
      "    [batch 2241]: seen 224100 examples : 67.7 eps, Loss: 6.090, Avg loss: 6.148, Best loss: 6.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2248]: seen 224800 examples : 67.7 eps, Loss: 6.144, Avg loss: 6.147, Best loss: 6.147\n",
      "    [batch 2255]: seen 225500 examples : 67.7 eps, Loss: 6.083, Avg loss: 6.146, Best loss: 6.146\n",
      "    [batch 2262]: seen 226200 examples : 67.7 eps, Loss: 6.106, Avg loss: 6.145, Best loss: 6.145\n",
      "    [batch 2269]: seen 226900 examples : 67.7 eps, Loss: 6.049, Avg loss: 6.143, Best loss: 6.143\n",
      "    [batch 2276]: seen 227600 examples : 67.7 eps, Loss: 6.067, Avg loss: 6.142, Best loss: 6.142\n",
      "    [batch 2283]: seen 228300 examples : 67.7 eps, Loss: 6.196, Avg loss: 6.139, Best loss: 6.138\n",
      "    [batch 2290]: seen 229000 examples : 67.7 eps, Loss: 6.128, Avg loss: 6.136, Best loss: 6.135\n",
      "    [batch 2297]: seen 229700 examples : 67.7 eps, Loss: 6.112, Avg loss: 6.135, Best loss: 6.134\n",
      "    [batch 2304]: seen 230400 examples : 67.7 eps, Loss: 6.179, Avg loss: 6.135, Best loss: 6.134\n",
      "    [batch 2311]: seen 231100 examples : 67.7 eps, Loss: 6.172, Avg loss: 6.135, Best loss: 6.134\n",
      "    [batch 2318]: seen 231800 examples : 67.7 eps, Loss: 6.117, Avg loss: 6.133, Best loss: 6.133\n",
      "    [batch 2325]: seen 232500 examples : 67.7 eps, Loss: 6.118, Avg loss: 6.134, Best loss: 6.133\n",
      "    [batch 2332]: seen 233200 examples : 67.7 eps, Loss: 6.191, Avg loss: 6.133, Best loss: 6.132\n",
      "    [batch 2339]: seen 233900 examples : 67.7 eps, Loss: 6.038, Avg loss: 6.130, Best loss: 6.130\n",
      "    [batch 2346]: seen 234600 examples : 67.7 eps, Loss: 6.112, Avg loss: 6.132, Best loss: 6.130\n",
      "    [batch 2353]: seen 235300 examples : 67.7 eps, Loss: 6.123, Avg loss: 6.132, Best loss: 6.130\n",
      "    [batch 2360]: seen 236000 examples : 67.7 eps, Loss: 6.102, Avg loss: 6.129, Best loss: 6.129\n",
      "    [batch 2367]: seen 236700 examples : 67.7 eps, Loss: 6.141, Avg loss: 6.128, Best loss: 6.128\n",
      "    [batch 2374]: seen 237400 examples : 67.7 eps, Loss: 6.208, Avg loss: 6.130, Best loss: 6.128\n",
      "    [batch 2381]: seen 238100 examples : 67.7 eps, Loss: 6.206, Avg loss: 6.130, Best loss: 6.128\n",
      "    [batch 2388]: seen 238800 examples : 67.7 eps, Loss: 6.125, Avg loss: 6.130, Best loss: 6.128\n",
      "    [batch 2395]: seen 239500 examples : 67.7 eps, Loss: 6.067, Avg loss: 6.130, Best loss: 6.128\n",
      "    [batch 2402]: seen 240200 examples : 67.7 eps, Loss: 6.163, Avg loss: 6.128, Best loss: 6.127\n",
      "    [batch 2409]: seen 240900 examples : 67.7 eps, Loss: 6.153, Avg loss: 6.129, Best loss: 6.127\n",
      "    [batch 2416]: seen 241600 examples : 67.7 eps, Loss: 6.246, Avg loss: 6.130, Best loss: 6.127\n",
      "    [batch 2423]: seen 242300 examples : 67.7 eps, Loss: 6.153, Avg loss: 6.132, Best loss: 6.127\n",
      "    [batch 2430]: seen 243000 examples : 67.7 eps, Loss: 6.216, Avg loss: 6.133, Best loss: 6.127\n",
      "    [batch 2437]: seen 243700 examples : 67.7 eps, Loss: 6.231, Avg loss: 6.131, Best loss: 6.127\n",
      "    [batch 2444]: seen 244400 examples : 67.7 eps, Loss: 6.134, Avg loss: 6.129, Best loss: 6.127\n",
      "    [batch 2451]: seen 245100 examples : 67.7 eps, Loss: 6.190, Avg loss: 6.128, Best loss: 6.127\n",
      "    [batch 2458]: seen 245800 examples : 67.7 eps, Loss: 5.998, Avg loss: 6.128, Best loss: 6.127\n",
      "    [batch 2465]: seen 246500 examples : 67.7 eps, Loss: 6.127, Avg loss: 6.129, Best loss: 6.127\n",
      "    [batch 2472]: seen 247200 examples : 67.7 eps, Loss: 6.029, Avg loss: 6.127, Best loss: 6.127\n",
      "    [batch 2478]: seen 247800 examples : 67.7 eps, Loss: 6.132, Avg loss: 6.127, Best loss: 6.126\n",
      "    [batch 2485]: seen 248500 examples : 67.7 eps, Loss: 6.093, Avg loss: 6.128, Best loss: 6.126\n",
      "    [batch 2492]: seen 249200 examples : 67.7 eps, Loss: 6.038, Avg loss: 6.128, Best loss: 6.126\n",
      "    [batch 2499]: seen 249900 examples : 67.7 eps, Loss: 6.075, Avg loss: 6.125, Best loss: 6.125\n",
      "    [batch 2506]: seen 250600 examples : 67.7 eps, Loss: 6.100, Avg loss: 6.126, Best loss: 6.125\n",
      "    [batch 2513]: seen 251300 examples : 67.7 eps, Loss: 6.099, Avg loss: 6.125, Best loss: 6.125\n",
      "    [batch 2519]: seen 251900 examples : 67.7 eps, Loss: 5.987, Avg loss: 6.124, Best loss: 6.124\n",
      "    [batch 2526]: seen 252600 examples : 67.7 eps, Loss: 6.118, Avg loss: 6.125, Best loss: 6.124\n",
      "    [batch 2533]: seen 253300 examples : 67.7 eps, Loss: 6.153, Avg loss: 6.125, Best loss: 6.124\n",
      "    [batch 2540]: seen 254000 examples : 67.7 eps, Loss: 6.207, Avg loss: 6.125, Best loss: 6.124\n",
      "    [batch 2547]: seen 254700 examples : 67.7 eps, Loss: 6.093, Avg loss: 6.124, Best loss: 6.124\n",
      "    [batch 2554]: seen 255400 examples : 67.7 eps, Loss: 5.999, Avg loss: 6.123, Best loss: 6.123\n",
      "    [batch 2561]: seen 256100 examples : 67.7 eps, Loss: 6.160, Avg loss: 6.122, Best loss: 6.122\n",
      "    [batch 2568]: seen 256800 examples : 67.7 eps, Loss: 6.114, Avg loss: 6.122, Best loss: 6.121\n",
      "    [batch 2575]: seen 257500 examples : 67.7 eps, Loss: 6.069, Avg loss: 6.120, Best loss: 6.120\n",
      "    [batch 2582]: seen 258200 examples : 67.7 eps, Loss: 6.113, Avg loss: 6.121, Best loss: 6.120\n",
      "    [batch 2589]: seen 258900 examples : 67.7 eps, Loss: 5.986, Avg loss: 6.121, Best loss: 6.120\n",
      "    [batch 2596]: seen 259600 examples : 67.7 eps, Loss: 5.985, Avg loss: 6.117, Best loss: 6.117\n",
      "    [batch 2603]: seen 260300 examples : 67.7 eps, Loss: 6.037, Avg loss: 6.116, Best loss: 6.116\n",
      "    [batch 2610]: seen 261000 examples : 67.7 eps, Loss: 6.171, Avg loss: 6.118, Best loss: 6.115\n",
      "    [batch 2617]: seen 261700 examples : 67.7 eps, Loss: 6.126, Avg loss: 6.119, Best loss: 6.115\n",
      "    [batch 2624]: seen 262400 examples : 67.7 eps, Loss: 6.158, Avg loss: 6.118, Best loss: 6.115\n",
      "    [batch 2631]: seen 263100 examples : 67.7 eps, Loss: 5.990, Avg loss: 6.115, Best loss: 6.115\n",
      "    [batch 2638]: seen 263800 examples : 67.7 eps, Loss: 6.067, Avg loss: 6.116, Best loss: 6.115\n",
      "    [batch 2645]: seen 264500 examples : 67.7 eps, Loss: 6.147, Avg loss: 6.113, Best loss: 6.112\n",
      "    [batch 2652]: seen 265200 examples : 67.7 eps, Loss: 6.169, Avg loss: 6.112, Best loss: 6.112\n",
      "    [batch 2659]: seen 265900 examples : 67.7 eps, Loss: 6.082, Avg loss: 6.112, Best loss: 6.112\n",
      "    [batch 2666]: seen 266600 examples : 67.7 eps, Loss: 6.174, Avg loss: 6.111, Best loss: 6.111\n",
      "    [batch 2673]: seen 267300 examples : 67.7 eps, Loss: 6.022, Avg loss: 6.109, Best loss: 6.109\n",
      "    [batch 2680]: seen 268000 examples : 67.7 eps, Loss: 6.120, Avg loss: 6.109, Best loss: 6.109\n",
      "    [batch 2687]: seen 268700 examples : 67.7 eps, Loss: 6.119, Avg loss: 6.106, Best loss: 6.106\n",
      "    [batch 2694]: seen 269400 examples : 67.7 eps, Loss: 6.170, Avg loss: 6.105, Best loss: 6.105\n",
      "    [batch 2701]: seen 270100 examples : 67.7 eps, Loss: 6.075, Avg loss: 6.105, Best loss: 6.105\n",
      "    [batch 2708]: seen 270800 examples : 67.7 eps, Loss: 6.048, Avg loss: 6.101, Best loss: 6.101\n",
      "    [batch 2715]: seen 271500 examples : 67.7 eps, Loss: 6.099, Avg loss: 6.099, Best loss: 6.099\n",
      "    [batch 2722]: seen 272200 examples : 67.7 eps, Loss: 6.044, Avg loss: 6.097, Best loss: 6.097\n",
      "    [batch 2729]: seen 272900 examples : 67.7 eps, Loss: 6.009, Avg loss: 6.096, Best loss: 6.096\n",
      "    [batch 2736]: seen 273600 examples : 67.7 eps, Loss: 5.949, Avg loss: 6.095, Best loss: 6.095\n",
      "    [batch 2743]: seen 274300 examples : 67.7 eps, Loss: 6.045, Avg loss: 6.095, Best loss: 6.095\n",
      "    [batch 2750]: seen 275000 examples : 67.6 eps, Loss: 5.976, Avg loss: 6.094, Best loss: 6.094\n",
      "    [batch 2757]: seen 275700 examples : 67.6 eps, Loss: 6.208, Avg loss: 6.095, Best loss: 6.094\n",
      "    [batch 2764]: seen 276400 examples : 67.6 eps, Loss: 6.049, Avg loss: 6.095, Best loss: 6.094\n",
      "    [batch 2771]: seen 277100 examples : 67.7 eps, Loss: 6.097, Avg loss: 6.097, Best loss: 6.094\n",
      "    [batch 2778]: seen 277800 examples : 67.7 eps, Loss: 6.081, Avg loss: 6.096, Best loss: 6.094\n",
      "    [batch 2785]: seen 278500 examples : 67.6 eps, Loss: 6.023, Avg loss: 6.095, Best loss: 6.094\n",
      "    [batch 2792]: seen 279200 examples : 67.6 eps, Loss: 6.128, Avg loss: 6.094, Best loss: 6.094\n",
      "    [batch 2799]: seen 279900 examples : 67.6 eps, Loss: 6.139, Avg loss: 6.096, Best loss: 6.094\n",
      "    [batch 2806]: seen 280600 examples : 67.6 eps, Loss: 6.096, Avg loss: 6.096, Best loss: 6.094\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:11\n",
      "[EPOCH 4] Complete. Avg Loss: 6.09541640592061; Best Loss: 6.09367306261951\n",
      "[EPOCH 5] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.1 eps, Loss: 6.081, Avg loss: 6.096, Best loss: 6.094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 16]: seen 1600 examples : 78.1 eps, Loss: 6.091, Avg loss: 6.093, Best loss: 6.093\n",
      "    [batch 23]: seen 2300 examples : 75.1 eps, Loss: 6.093, Avg loss: 6.093, Best loss: 6.092\n",
      "    [batch 30]: seen 3000 examples : 73.5 eps, Loss: 5.963, Avg loss: 6.092, Best loss: 6.092\n",
      "    [batch 37]: seen 3700 examples : 72.6 eps, Loss: 6.069, Avg loss: 6.090, Best loss: 6.089\n",
      "    [batch 44]: seen 4400 examples : 71.9 eps, Loss: 5.940, Avg loss: 6.087, Best loss: 6.087\n",
      "    [batch 51]: seen 5100 examples : 71.5 eps, Loss: 6.056, Avg loss: 6.087, Best loss: 6.087\n",
      "    [batch 58]: seen 5800 examples : 71.1 eps, Loss: 6.088, Avg loss: 6.086, Best loss: 6.086\n",
      "    [batch 65]: seen 6500 examples : 70.9 eps, Loss: 5.991, Avg loss: 6.082, Best loss: 6.082\n",
      "    [batch 72]: seen 7200 examples : 70.7 eps, Loss: 6.030, Avg loss: 6.083, Best loss: 6.082\n",
      "    [batch 79]: seen 7900 examples : 70.2 eps, Loss: 6.128, Avg loss: 6.083, Best loss: 6.082\n",
      "    [batch 86]: seen 8600 examples : 70.1 eps, Loss: 5.957, Avg loss: 6.079, Best loss: 6.079\n",
      "    [batch 93]: seen 9300 examples : 70.0 eps, Loss: 6.080, Avg loss: 6.076, Best loss: 6.076\n",
      "    [batch 100]: seen 10000 examples : 69.9 eps, Loss: 6.186, Avg loss: 6.076, Best loss: 6.074\n",
      "    [batch 107]: seen 10700 examples : 69.9 eps, Loss: 6.025, Avg loss: 6.077, Best loss: 6.074\n",
      "    [batch 114]: seen 11400 examples : 69.6 eps, Loss: 6.050, Avg loss: 6.076, Best loss: 6.074\n",
      "    [batch 121]: seen 12100 examples : 69.5 eps, Loss: 6.119, Avg loss: 6.078, Best loss: 6.074\n",
      "    [batch 128]: seen 12800 examples : 69.4 eps, Loss: 6.091, Avg loss: 6.078, Best loss: 6.074\n",
      "    [batch 135]: seen 13500 examples : 69.3 eps, Loss: 6.164, Avg loss: 6.080, Best loss: 6.074\n",
      "    [batch 142]: seen 14200 examples : 69.2 eps, Loss: 6.107, Avg loss: 6.081, Best loss: 6.074\n",
      "    [batch 149]: seen 14900 examples : 69.1 eps, Loss: 6.067, Avg loss: 6.083, Best loss: 6.074\n",
      "    [batch 156]: seen 15600 examples : 69.1 eps, Loss: 6.092, Avg loss: 6.082, Best loss: 6.074\n",
      "    [batch 163]: seen 16300 examples : 69.0 eps, Loss: 6.067, Avg loss: 6.081, Best loss: 6.074\n",
      "    [batch 170]: seen 17000 examples : 69.0 eps, Loss: 6.116, Avg loss: 6.080, Best loss: 6.074\n",
      "    [batch 177]: seen 17700 examples : 68.9 eps, Loss: 6.090, Avg loss: 6.082, Best loss: 6.074\n",
      "    [batch 184]: seen 18400 examples : 68.9 eps, Loss: 6.046, Avg loss: 6.079, Best loss: 6.074\n",
      "    [batch 191]: seen 19100 examples : 68.8 eps, Loss: 6.129, Avg loss: 6.077, Best loss: 6.074\n",
      "    [batch 198]: seen 19800 examples : 68.8 eps, Loss: 6.026, Avg loss: 6.075, Best loss: 6.074\n",
      "    [batch 205]: seen 20500 examples : 68.7 eps, Loss: 6.175, Avg loss: 6.075, Best loss: 6.073\n",
      "    [batch 212]: seen 21200 examples : 68.6 eps, Loss: 6.140, Avg loss: 6.074, Best loss: 6.073\n",
      "    [batch 219]: seen 21900 examples : 68.7 eps, Loss: 5.981, Avg loss: 6.072, Best loss: 6.072\n",
      "    [batch 226]: seen 22600 examples : 68.7 eps, Loss: 6.006, Avg loss: 6.071, Best loss: 6.071\n",
      "    [batch 233]: seen 23300 examples : 68.6 eps, Loss: 6.011, Avg loss: 6.069, Best loss: 6.069\n",
      "    [batch 240]: seen 24000 examples : 68.5 eps, Loss: 6.036, Avg loss: 6.068, Best loss: 6.068\n",
      "    [batch 247]: seen 24700 examples : 68.5 eps, Loss: 6.092, Avg loss: 6.075, Best loss: 6.068\n",
      "    [batch 254]: seen 25400 examples : 68.4 eps, Loss: 6.019, Avg loss: 6.074, Best loss: 6.068\n",
      "    [batch 261]: seen 26100 examples : 68.4 eps, Loss: 5.984, Avg loss: 6.072, Best loss: 6.068\n",
      "    [batch 268]: seen 26800 examples : 68.4 eps, Loss: 6.039, Avg loss: 6.070, Best loss: 6.068\n",
      "    [batch 275]: seen 27500 examples : 68.4 eps, Loss: 6.018, Avg loss: 6.069, Best loss: 6.068\n",
      "    [batch 282]: seen 28200 examples : 68.3 eps, Loss: 6.037, Avg loss: 6.066, Best loss: 6.066\n",
      "    [batch 289]: seen 28900 examples : 68.3 eps, Loss: 6.001, Avg loss: 6.065, Best loss: 6.065\n",
      "    [batch 296]: seen 29600 examples : 68.3 eps, Loss: 5.983, Avg loss: 6.064, Best loss: 6.064\n",
      "    [batch 303]: seen 30300 examples : 68.3 eps, Loss: 6.069, Avg loss: 6.063, Best loss: 6.062\n",
      "    [batch 310]: seen 31000 examples : 68.2 eps, Loss: 6.087, Avg loss: 6.063, Best loss: 6.061\n",
      "    [batch 317]: seen 31700 examples : 68.2 eps, Loss: 6.009, Avg loss: 6.062, Best loss: 6.061\n",
      "    [batch 324]: seen 32400 examples : 68.2 eps, Loss: 6.082, Avg loss: 6.061, Best loss: 6.061\n",
      "    [batch 331]: seen 33100 examples : 68.2 eps, Loss: 6.030, Avg loss: 6.061, Best loss: 6.061\n",
      "    [batch 338]: seen 33800 examples : 68.2 eps, Loss: 5.889, Avg loss: 6.061, Best loss: 6.061\n",
      "    [batch 345]: seen 34500 examples : 68.2 eps, Loss: 6.065, Avg loss: 6.060, Best loss: 6.060\n",
      "    [batch 352]: seen 35200 examples : 68.2 eps, Loss: 6.057, Avg loss: 6.061, Best loss: 6.060\n",
      "    [batch 359]: seen 35900 examples : 68.1 eps, Loss: 6.124, Avg loss: 6.062, Best loss: 6.060\n",
      "    [batch 366]: seen 36600 examples : 68.1 eps, Loss: 6.092, Avg loss: 6.062, Best loss: 6.060\n",
      "    [batch 373]: seen 37300 examples : 68.1 eps, Loss: 6.054, Avg loss: 6.060, Best loss: 6.060\n",
      "    [batch 380]: seen 38000 examples : 68.1 eps, Loss: 6.027, Avg loss: 6.059, Best loss: 6.058\n",
      "    [batch 387]: seen 38700 examples : 68.1 eps, Loss: 6.012, Avg loss: 6.058, Best loss: 6.058\n",
      "    [batch 394]: seen 39400 examples : 68.1 eps, Loss: 6.069, Avg loss: 6.059, Best loss: 6.057\n",
      "    [batch 401]: seen 40100 examples : 68.0 eps, Loss: 6.118, Avg loss: 6.058, Best loss: 6.057\n",
      "    [batch 408]: seen 40800 examples : 68.0 eps, Loss: 6.056, Avg loss: 6.060, Best loss: 6.057\n",
      "    [batch 415]: seen 41500 examples : 68.0 eps, Loss: 6.032, Avg loss: 6.058, Best loss: 6.057\n",
      "    [batch 422]: seen 42200 examples : 68.0 eps, Loss: 6.014, Avg loss: 6.058, Best loss: 6.057\n",
      "    [batch 429]: seen 42900 examples : 68.0 eps, Loss: 6.109, Avg loss: 6.059, Best loss: 6.057\n",
      "    [batch 436]: seen 43600 examples : 68.0 eps, Loss: 6.055, Avg loss: 6.058, Best loss: 6.057\n",
      "    [batch 443]: seen 44300 examples : 68.0 eps, Loss: 6.064, Avg loss: 6.055, Best loss: 6.055\n",
      "    [batch 450]: seen 45000 examples : 68.0 eps, Loss: 6.038, Avg loss: 6.054, Best loss: 6.054\n",
      "    [batch 457]: seen 45700 examples : 68.0 eps, Loss: 6.051, Avg loss: 6.056, Best loss: 6.054\n",
      "    [batch 464]: seen 46400 examples : 68.0 eps, Loss: 6.059, Avg loss: 6.056, Best loss: 6.054\n",
      "    [batch 471]: seen 47100 examples : 67.9 eps, Loss: 5.964, Avg loss: 6.053, Best loss: 6.053\n",
      "    [batch 478]: seen 47800 examples : 67.9 eps, Loss: 5.993, Avg loss: 6.051, Best loss: 6.051\n",
      "    [batch 485]: seen 48500 examples : 67.9 eps, Loss: 6.024, Avg loss: 6.050, Best loss: 6.049\n",
      "    [batch 492]: seen 49200 examples : 67.9 eps, Loss: 6.105, Avg loss: 6.049, Best loss: 6.048\n",
      "    [batch 499]: seen 49900 examples : 67.9 eps, Loss: 6.096, Avg loss: 6.048, Best loss: 6.047\n",
      "    [batch 506]: seen 50600 examples : 67.9 eps, Loss: 6.094, Avg loss: 6.048, Best loss: 6.047\n",
      "    [batch 513]: seen 51300 examples : 67.9 eps, Loss: 5.964, Avg loss: 6.046, Best loss: 6.046\n",
      "    [batch 520]: seen 52000 examples : 67.9 eps, Loss: 6.048, Avg loss: 6.045, Best loss: 6.045\n",
      "    [batch 527]: seen 52700 examples : 67.9 eps, Loss: 5.962, Avg loss: 6.044, Best loss: 6.044\n",
      "    [batch 534]: seen 53400 examples : 67.9 eps, Loss: 6.095, Avg loss: 6.043, Best loss: 6.043\n",
      "    [batch 541]: seen 54100 examples : 67.9 eps, Loss: 5.971, Avg loss: 6.041, Best loss: 6.041\n",
      "    [batch 547]: seen 54700 examples : 67.8 eps, Loss: 6.029, Avg loss: 6.040, Best loss: 6.040\n",
      "    [batch 554]: seen 55400 examples : 67.8 eps, Loss: 6.004, Avg loss: 6.042, Best loss: 6.040\n",
      "    [batch 561]: seen 56100 examples : 67.8 eps, Loss: 5.980, Avg loss: 6.043, Best loss: 6.040\n",
      "    [batch 568]: seen 56800 examples : 67.8 eps, Loss: 6.068, Avg loss: 6.044, Best loss: 6.040\n",
      "    [batch 575]: seen 57500 examples : 67.8 eps, Loss: 5.992, Avg loss: 6.043, Best loss: 6.040\n",
      "    [batch 582]: seen 58200 examples : 67.9 eps, Loss: 6.020, Avg loss: 6.041, Best loss: 6.040\n",
      "    [batch 589]: seen 58900 examples : 67.9 eps, Loss: 6.079, Avg loss: 6.042, Best loss: 6.040\n",
      "    [batch 596]: seen 59600 examples : 67.8 eps, Loss: 6.066, Avg loss: 6.044, Best loss: 6.040\n",
      "    [batch 603]: seen 60300 examples : 67.8 eps, Loss: 5.964, Avg loss: 6.040, Best loss: 6.040\n",
      "    [batch 610]: seen 61000 examples : 67.8 eps, Loss: 6.036, Avg loss: 6.041, Best loss: 6.040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 617]: seen 61700 examples : 67.8 eps, Loss: 6.114, Avg loss: 6.041, Best loss: 6.039\n",
      "    [batch 624]: seen 62400 examples : 67.8 eps, Loss: 5.979, Avg loss: 6.039, Best loss: 6.039\n",
      "    [batch 631]: seen 63100 examples : 67.8 eps, Loss: 6.062, Avg loss: 6.038, Best loss: 6.037\n",
      "    [batch 638]: seen 63800 examples : 67.8 eps, Loss: 5.942, Avg loss: 6.036, Best loss: 6.036\n",
      "    [batch 645]: seen 64500 examples : 67.8 eps, Loss: 5.993, Avg loss: 6.037, Best loss: 6.035\n",
      "    [batch 652]: seen 65200 examples : 67.8 eps, Loss: 5.915, Avg loss: 6.034, Best loss: 6.034\n",
      "    [batch 659]: seen 65900 examples : 67.8 eps, Loss: 6.004, Avg loss: 6.033, Best loss: 6.032\n",
      "    [batch 666]: seen 66600 examples : 67.8 eps, Loss: 5.990, Avg loss: 6.032, Best loss: 6.030\n",
      "    [batch 673]: seen 67300 examples : 67.8 eps, Loss: 6.072, Avg loss: 6.036, Best loss: 6.030\n",
      "    [batch 680]: seen 68000 examples : 67.8 eps, Loss: 5.968, Avg loss: 6.035, Best loss: 6.030\n",
      "    [batch 687]: seen 68700 examples : 67.8 eps, Loss: 6.047, Avg loss: 6.035, Best loss: 6.030\n",
      "    [batch 694]: seen 69400 examples : 67.8 eps, Loss: 6.130, Avg loss: 6.036, Best loss: 6.030\n",
      "    [batch 701]: seen 70100 examples : 67.8 eps, Loss: 5.933, Avg loss: 6.034, Best loss: 6.030\n",
      "    [batch 708]: seen 70800 examples : 67.8 eps, Loss: 6.007, Avg loss: 6.034, Best loss: 6.030\n",
      "    [batch 715]: seen 71500 examples : 67.8 eps, Loss: 6.013, Avg loss: 6.035, Best loss: 6.030\n",
      "    [batch 722]: seen 72200 examples : 67.8 eps, Loss: 6.012, Avg loss: 6.035, Best loss: 6.030\n",
      "    [batch 729]: seen 72900 examples : 67.8 eps, Loss: 6.010, Avg loss: 6.038, Best loss: 6.030\n",
      "    [batch 736]: seen 73600 examples : 67.8 eps, Loss: 6.113, Avg loss: 6.039, Best loss: 6.030\n",
      "    [batch 743]: seen 74300 examples : 67.8 eps, Loss: 6.012, Avg loss: 6.039, Best loss: 6.030\n",
      "    [batch 750]: seen 75000 examples : 67.8 eps, Loss: 5.994, Avg loss: 6.036, Best loss: 6.030\n",
      "    [batch 757]: seen 75700 examples : 67.7 eps, Loss: 5.992, Avg loss: 6.035, Best loss: 6.030\n",
      "    [batch 764]: seen 76400 examples : 67.7 eps, Loss: 5.953, Avg loss: 6.034, Best loss: 6.030\n",
      "    [batch 771]: seen 77100 examples : 67.7 eps, Loss: 5.940, Avg loss: 6.030, Best loss: 6.030\n",
      "    [batch 778]: seen 77800 examples : 67.7 eps, Loss: 6.041, Avg loss: 6.029, Best loss: 6.028\n",
      "    [batch 785]: seen 78500 examples : 67.7 eps, Loss: 6.023, Avg loss: 6.027, Best loss: 6.027\n",
      "    [batch 792]: seen 79200 examples : 67.7 eps, Loss: 6.012, Avg loss: 6.026, Best loss: 6.026\n",
      "    [batch 799]: seen 79900 examples : 67.7 eps, Loss: 6.049, Avg loss: 6.028, Best loss: 6.026\n",
      "    [batch 806]: seen 80600 examples : 67.7 eps, Loss: 6.072, Avg loss: 6.026, Best loss: 6.026\n",
      "    [batch 813]: seen 81300 examples : 67.7 eps, Loss: 6.023, Avg loss: 6.025, Best loss: 6.025\n",
      "    [batch 820]: seen 82000 examples : 67.7 eps, Loss: 6.073, Avg loss: 6.022, Best loss: 6.022\n",
      "    [batch 827]: seen 82700 examples : 67.7 eps, Loss: 5.990, Avg loss: 6.022, Best loss: 6.022\n",
      "    [batch 834]: seen 83400 examples : 67.7 eps, Loss: 5.968, Avg loss: 6.018, Best loss: 6.018\n",
      "    [batch 841]: seen 84100 examples : 67.7 eps, Loss: 6.053, Avg loss: 6.020, Best loss: 6.018\n",
      "    [batch 848]: seen 84800 examples : 67.7 eps, Loss: 5.952, Avg loss: 6.019, Best loss: 6.018\n",
      "    [batch 855]: seen 85500 examples : 67.7 eps, Loss: 5.967, Avg loss: 6.019, Best loss: 6.018\n",
      "    [batch 862]: seen 86200 examples : 67.7 eps, Loss: 6.015, Avg loss: 6.020, Best loss: 6.018\n",
      "    [batch 869]: seen 86900 examples : 67.7 eps, Loss: 6.043, Avg loss: 6.020, Best loss: 6.018\n",
      "    [batch 876]: seen 87600 examples : 67.7 eps, Loss: 6.033, Avg loss: 6.020, Best loss: 6.018\n",
      "    [batch 883]: seen 88300 examples : 67.7 eps, Loss: 6.142, Avg loss: 6.021, Best loss: 6.018\n",
      "    [batch 890]: seen 89000 examples : 67.7 eps, Loss: 5.942, Avg loss: 6.020, Best loss: 6.018\n",
      "    [batch 897]: seen 89700 examples : 67.7 eps, Loss: 6.074, Avg loss: 6.019, Best loss: 6.018\n",
      "    [batch 904]: seen 90400 examples : 67.7 eps, Loss: 6.054, Avg loss: 6.019, Best loss: 6.017\n",
      "    [batch 911]: seen 91100 examples : 67.7 eps, Loss: 6.101, Avg loss: 6.021, Best loss: 6.017\n",
      "    [batch 918]: seen 91800 examples : 67.7 eps, Loss: 5.957, Avg loss: 6.018, Best loss: 6.017\n",
      "    [batch 925]: seen 92500 examples : 67.7 eps, Loss: 5.978, Avg loss: 6.015, Best loss: 6.015\n",
      "    [batch 932]: seen 93200 examples : 67.7 eps, Loss: 6.007, Avg loss: 6.013, Best loss: 6.013\n",
      "    [batch 939]: seen 93900 examples : 67.7 eps, Loss: 6.029, Avg loss: 6.013, Best loss: 6.012\n",
      "    [batch 946]: seen 94600 examples : 67.7 eps, Loss: 6.035, Avg loss: 6.012, Best loss: 6.011\n",
      "    [batch 953]: seen 95300 examples : 67.7 eps, Loss: 5.974, Avg loss: 6.012, Best loss: 6.011\n",
      "    [batch 960]: seen 96000 examples : 67.7 eps, Loss: 6.041, Avg loss: 6.014, Best loss: 6.011\n",
      "    [batch 967]: seen 96700 examples : 67.7 eps, Loss: 5.945, Avg loss: 6.013, Best loss: 6.011\n",
      "    [batch 974]: seen 97400 examples : 67.7 eps, Loss: 6.052, Avg loss: 6.012, Best loss: 6.011\n",
      "    [batch 981]: seen 98100 examples : 67.7 eps, Loss: 5.890, Avg loss: 6.011, Best loss: 6.011\n",
      "    [batch 988]: seen 98800 examples : 67.7 eps, Loss: 6.051, Avg loss: 6.012, Best loss: 6.011\n",
      "    [batch 995]: seen 99500 examples : 67.7 eps, Loss: 5.996, Avg loss: 6.012, Best loss: 6.011\n",
      "    [batch 1002]: seen 100200 examples : 67.7 eps, Loss: 5.992, Avg loss: 6.014, Best loss: 6.011\n",
      "    [batch 1009]: seen 100900 examples : 67.7 eps, Loss: 6.021, Avg loss: 6.013, Best loss: 6.011\n",
      "    [batch 1016]: seen 101600 examples : 67.7 eps, Loss: 6.089, Avg loss: 6.014, Best loss: 6.011\n",
      "    [batch 1023]: seen 102300 examples : 67.7 eps, Loss: 6.001, Avg loss: 6.013, Best loss: 6.011\n",
      "    [batch 1030]: seen 103000 examples : 67.7 eps, Loss: 6.032, Avg loss: 6.012, Best loss: 6.011\n",
      "    [batch 1037]: seen 103700 examples : 67.7 eps, Loss: 5.960, Avg loss: 6.010, Best loss: 6.010\n",
      "    [batch 1044]: seen 104400 examples : 67.7 eps, Loss: 5.903, Avg loss: 6.010, Best loss: 6.010\n",
      "    [batch 1051]: seen 105100 examples : 67.7 eps, Loss: 5.961, Avg loss: 6.009, Best loss: 6.009\n",
      "    [batch 1058]: seen 105800 examples : 67.7 eps, Loss: 6.138, Avg loss: 6.010, Best loss: 6.008\n",
      "    [batch 1065]: seen 106500 examples : 67.7 eps, Loss: 6.006, Avg loss: 6.010, Best loss: 6.008\n",
      "    [batch 1072]: seen 107200 examples : 67.7 eps, Loss: 6.019, Avg loss: 6.010, Best loss: 6.008\n",
      "    [batch 1079]: seen 107900 examples : 67.7 eps, Loss: 6.021, Avg loss: 6.013, Best loss: 6.008\n",
      "    [batch 1086]: seen 108600 examples : 67.7 eps, Loss: 6.026, Avg loss: 6.014, Best loss: 6.008\n",
      "    [batch 1093]: seen 109300 examples : 67.7 eps, Loss: 5.962, Avg loss: 6.013, Best loss: 6.008\n",
      "    [batch 1100]: seen 110000 examples : 67.7 eps, Loss: 6.001, Avg loss: 6.008, Best loss: 6.008\n",
      "    [batch 1107]: seen 110700 examples : 67.7 eps, Loss: 5.978, Avg loss: 6.007, Best loss: 6.007\n",
      "    [batch 1114]: seen 111400 examples : 67.7 eps, Loss: 6.054, Avg loss: 6.008, Best loss: 6.007\n",
      "    [batch 1121]: seen 112100 examples : 67.7 eps, Loss: 5.957, Avg loss: 6.007, Best loss: 6.007\n",
      "    [batch 1128]: seen 112800 examples : 67.7 eps, Loss: 5.948, Avg loss: 6.004, Best loss: 6.004\n",
      "    [batch 1135]: seen 113500 examples : 67.7 eps, Loss: 5.832, Avg loss: 6.000, Best loss: 6.000\n",
      "    [batch 1142]: seen 114200 examples : 67.7 eps, Loss: 6.018, Avg loss: 6.000, Best loss: 5.999\n",
      "    [batch 1149]: seen 114900 examples : 67.7 eps, Loss: 6.080, Avg loss: 6.001, Best loss: 5.999\n",
      "    [batch 1156]: seen 115600 examples : 67.7 eps, Loss: 5.952, Avg loss: 6.000, Best loss: 5.999\n",
      "    [batch 1163]: seen 116300 examples : 67.7 eps, Loss: 6.025, Avg loss: 5.999, Best loss: 5.999\n",
      "    [batch 1170]: seen 117000 examples : 67.7 eps, Loss: 6.029, Avg loss: 5.996, Best loss: 5.995\n",
      "    [batch 1177]: seen 117700 examples : 67.7 eps, Loss: 5.876, Avg loss: 5.993, Best loss: 5.993\n",
      "    [batch 1184]: seen 118400 examples : 67.7 eps, Loss: 6.007, Avg loss: 5.989, Best loss: 5.989\n",
      "    [batch 1191]: seen 119100 examples : 67.7 eps, Loss: 5.921, Avg loss: 5.989, Best loss: 5.989\n",
      "    [batch 1198]: seen 119800 examples : 67.7 eps, Loss: 5.993, Avg loss: 5.987, Best loss: 5.987\n",
      "    [batch 1205]: seen 120500 examples : 67.7 eps, Loss: 5.952, Avg loss: 5.987, Best loss: 5.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1212]: seen 121200 examples : 67.7 eps, Loss: 5.924, Avg loss: 5.984, Best loss: 5.984\n",
      "    [batch 1219]: seen 121900 examples : 67.7 eps, Loss: 5.921, Avg loss: 5.985, Best loss: 5.983\n",
      "    [batch 1226]: seen 122600 examples : 67.7 eps, Loss: 6.076, Avg loss: 5.985, Best loss: 5.983\n",
      "    [batch 1233]: seen 123300 examples : 67.7 eps, Loss: 5.993, Avg loss: 5.983, Best loss: 5.983\n",
      "    [batch 1240]: seen 124000 examples : 67.7 eps, Loss: 5.993, Avg loss: 5.986, Best loss: 5.983\n",
      "    [batch 1247]: seen 124700 examples : 67.7 eps, Loss: 5.887, Avg loss: 5.983, Best loss: 5.983\n",
      "    [batch 1254]: seen 125400 examples : 67.7 eps, Loss: 5.875, Avg loss: 5.981, Best loss: 5.981\n",
      "    [batch 1261]: seen 126100 examples : 67.7 eps, Loss: 5.969, Avg loss: 5.983, Best loss: 5.981\n",
      "    [batch 1268]: seen 126800 examples : 67.7 eps, Loss: 6.023, Avg loss: 5.983, Best loss: 5.981\n",
      "    [batch 1275]: seen 127500 examples : 67.7 eps, Loss: 5.970, Avg loss: 5.983, Best loss: 5.981\n",
      "    [batch 1282]: seen 128200 examples : 67.7 eps, Loss: 5.878, Avg loss: 5.983, Best loss: 5.981\n",
      "    [batch 1289]: seen 128900 examples : 67.7 eps, Loss: 5.917, Avg loss: 5.980, Best loss: 5.980\n",
      "    [batch 1296]: seen 129600 examples : 67.7 eps, Loss: 5.978, Avg loss: 5.982, Best loss: 5.980\n",
      "    [batch 1303]: seen 130300 examples : 67.7 eps, Loss: 5.924, Avg loss: 5.983, Best loss: 5.980\n",
      "    [batch 1310]: seen 131000 examples : 67.7 eps, Loss: 5.870, Avg loss: 5.981, Best loss: 5.980\n",
      "    [batch 1317]: seen 131700 examples : 67.7 eps, Loss: 6.066, Avg loss: 5.982, Best loss: 5.980\n",
      "    [batch 1324]: seen 132400 examples : 67.7 eps, Loss: 6.002, Avg loss: 5.980, Best loss: 5.979\n",
      "    [batch 1331]: seen 133100 examples : 67.7 eps, Loss: 5.921, Avg loss: 5.977, Best loss: 5.977\n",
      "    [batch 1338]: seen 133800 examples : 67.7 eps, Loss: 5.924, Avg loss: 5.979, Best loss: 5.977\n",
      "    [batch 1345]: seen 134500 examples : 67.7 eps, Loss: 5.990, Avg loss: 5.980, Best loss: 5.977\n",
      "    [batch 1352]: seen 135200 examples : 67.7 eps, Loss: 5.956, Avg loss: 5.980, Best loss: 5.977\n",
      "    [batch 1359]: seen 135900 examples : 67.7 eps, Loss: 5.957, Avg loss: 5.980, Best loss: 5.977\n",
      "    [batch 1366]: seen 136600 examples : 67.7 eps, Loss: 6.072, Avg loss: 5.979, Best loss: 5.977\n",
      "    [batch 1373]: seen 137300 examples : 67.7 eps, Loss: 5.962, Avg loss: 5.979, Best loss: 5.977\n",
      "    [batch 1380]: seen 138000 examples : 67.7 eps, Loss: 5.967, Avg loss: 5.977, Best loss: 5.976\n",
      "    [batch 1387]: seen 138700 examples : 67.7 eps, Loss: 6.002, Avg loss: 5.977, Best loss: 5.976\n",
      "    [batch 1394]: seen 139400 examples : 67.7 eps, Loss: 5.994, Avg loss: 5.975, Best loss: 5.975\n",
      "    [batch 1401]: seen 140100 examples : 67.7 eps, Loss: 5.962, Avg loss: 5.975, Best loss: 5.975\n",
      "    [batch 1408]: seen 140800 examples : 67.7 eps, Loss: 5.986, Avg loss: 5.972, Best loss: 5.972\n",
      "    [batch 1415]: seen 141500 examples : 67.7 eps, Loss: 5.951, Avg loss: 5.972, Best loss: 5.971\n",
      "    [batch 1422]: seen 142200 examples : 67.7 eps, Loss: 6.073, Avg loss: 5.972, Best loss: 5.970\n",
      "    [batch 1429]: seen 142900 examples : 67.7 eps, Loss: 6.073, Avg loss: 5.977, Best loss: 5.970\n",
      "    [batch 1436]: seen 143600 examples : 67.7 eps, Loss: 5.894, Avg loss: 5.976, Best loss: 5.970\n",
      "    [batch 1443]: seen 144300 examples : 67.7 eps, Loss: 5.996, Avg loss: 5.979, Best loss: 5.970\n",
      "    [batch 1450]: seen 145000 examples : 67.7 eps, Loss: 5.835, Avg loss: 5.977, Best loss: 5.970\n",
      "    [batch 1457]: seen 145700 examples : 67.7 eps, Loss: 5.966, Avg loss: 5.978, Best loss: 5.970\n",
      "    [batch 1464]: seen 146400 examples : 67.7 eps, Loss: 5.931, Avg loss: 5.977, Best loss: 5.970\n",
      "    [batch 1471]: seen 147100 examples : 67.7 eps, Loss: 5.902, Avg loss: 5.977, Best loss: 5.970\n",
      "    [batch 1478]: seen 147800 examples : 67.7 eps, Loss: 6.038, Avg loss: 5.976, Best loss: 5.970\n",
      "    [batch 1485]: seen 148500 examples : 67.7 eps, Loss: 5.982, Avg loss: 5.976, Best loss: 5.970\n",
      "    [batch 1492]: seen 149200 examples : 67.7 eps, Loss: 5.831, Avg loss: 5.974, Best loss: 5.970\n",
      "    [batch 1499]: seen 149900 examples : 67.7 eps, Loss: 6.002, Avg loss: 5.975, Best loss: 5.970\n",
      "    [batch 1506]: seen 150600 examples : 67.7 eps, Loss: 5.894, Avg loss: 5.974, Best loss: 5.970\n",
      "    [batch 1513]: seen 151300 examples : 67.7 eps, Loss: 5.916, Avg loss: 5.973, Best loss: 5.970\n",
      "    [batch 1520]: seen 152000 examples : 67.7 eps, Loss: 6.012, Avg loss: 5.972, Best loss: 5.970\n",
      "    [batch 1527]: seen 152700 examples : 67.7 eps, Loss: 5.845, Avg loss: 5.969, Best loss: 5.969\n",
      "    [batch 1534]: seen 153400 examples : 67.7 eps, Loss: 5.896, Avg loss: 5.967, Best loss: 5.967\n",
      "    [batch 1541]: seen 154100 examples : 67.7 eps, Loss: 5.950, Avg loss: 5.968, Best loss: 5.967\n",
      "    [batch 1548]: seen 154800 examples : 67.7 eps, Loss: 5.993, Avg loss: 5.967, Best loss: 5.967\n",
      "    [batch 1555]: seen 155500 examples : 67.7 eps, Loss: 5.881, Avg loss: 5.970, Best loss: 5.967\n",
      "    [batch 1562]: seen 156200 examples : 67.7 eps, Loss: 6.032, Avg loss: 5.966, Best loss: 5.966\n",
      "    [batch 1569]: seen 156900 examples : 67.7 eps, Loss: 6.024, Avg loss: 5.968, Best loss: 5.966\n",
      "    [batch 1576]: seen 157600 examples : 67.7 eps, Loss: 6.021, Avg loss: 5.968, Best loss: 5.966\n",
      "    [batch 1583]: seen 158300 examples : 67.7 eps, Loss: 6.004, Avg loss: 5.970, Best loss: 5.966\n",
      "    [batch 1590]: seen 159000 examples : 67.7 eps, Loss: 6.142, Avg loss: 5.975, Best loss: 5.966\n",
      "    [batch 1597]: seen 159700 examples : 67.7 eps, Loss: 5.912, Avg loss: 5.976, Best loss: 5.966\n",
      "    [batch 1604]: seen 160400 examples : 67.7 eps, Loss: 5.959, Avg loss: 5.977, Best loss: 5.966\n",
      "    [batch 1611]: seen 161100 examples : 67.7 eps, Loss: 6.041, Avg loss: 5.978, Best loss: 5.966\n",
      "    [batch 1618]: seen 161800 examples : 67.7 eps, Loss: 5.993, Avg loss: 5.977, Best loss: 5.966\n",
      "    [batch 1625]: seen 162500 examples : 67.7 eps, Loss: 5.984, Avg loss: 5.977, Best loss: 5.966\n",
      "    [batch 1632]: seen 163200 examples : 67.7 eps, Loss: 6.070, Avg loss: 5.974, Best loss: 5.966\n",
      "    [batch 1639]: seen 163900 examples : 67.7 eps, Loss: 5.922, Avg loss: 5.972, Best loss: 5.966\n",
      "    [batch 1646]: seen 164600 examples : 67.7 eps, Loss: 5.867, Avg loss: 5.970, Best loss: 5.966\n",
      "    [batch 1653]: seen 165300 examples : 67.7 eps, Loss: 5.876, Avg loss: 5.970, Best loss: 5.966\n",
      "    [batch 1660]: seen 166000 examples : 67.7 eps, Loss: 5.959, Avg loss: 5.973, Best loss: 5.966\n",
      "    [batch 1667]: seen 166700 examples : 67.7 eps, Loss: 5.879, Avg loss: 5.971, Best loss: 5.966\n",
      "    [batch 1674]: seen 167400 examples : 67.7 eps, Loss: 5.903, Avg loss: 5.969, Best loss: 5.966\n",
      "    [batch 1681]: seen 168100 examples : 67.7 eps, Loss: 5.961, Avg loss: 5.971, Best loss: 5.966\n",
      "    [batch 1688]: seen 168800 examples : 67.7 eps, Loss: 5.866, Avg loss: 5.970, Best loss: 5.966\n",
      "    [batch 1695]: seen 169500 examples : 67.7 eps, Loss: 5.938, Avg loss: 5.969, Best loss: 5.966\n",
      "    [batch 1702]: seen 170200 examples : 67.7 eps, Loss: 5.926, Avg loss: 5.968, Best loss: 5.966\n",
      "    [batch 1709]: seen 170900 examples : 67.7 eps, Loss: 5.970, Avg loss: 5.967, Best loss: 5.966\n",
      "    [batch 1716]: seen 171600 examples : 67.7 eps, Loss: 5.936, Avg loss: 5.966, Best loss: 5.966\n",
      "    [batch 1723]: seen 172300 examples : 67.7 eps, Loss: 6.013, Avg loss: 5.965, Best loss: 5.964\n",
      "    [batch 1730]: seen 173000 examples : 67.7 eps, Loss: 5.915, Avg loss: 5.965, Best loss: 5.964\n",
      "    [batch 1737]: seen 173700 examples : 67.7 eps, Loss: 5.899, Avg loss: 5.963, Best loss: 5.963\n",
      "    [batch 1744]: seen 174400 examples : 67.7 eps, Loss: 6.090, Avg loss: 5.965, Best loss: 5.963\n",
      "    [batch 1751]: seen 175100 examples : 67.7 eps, Loss: 5.968, Avg loss: 5.962, Best loss: 5.962\n",
      "    [batch 1758]: seen 175800 examples : 67.7 eps, Loss: 5.980, Avg loss: 5.962, Best loss: 5.960\n",
      "    [batch 1765]: seen 176500 examples : 67.7 eps, Loss: 5.944, Avg loss: 5.963, Best loss: 5.960\n",
      "    [batch 1772]: seen 177200 examples : 67.7 eps, Loss: 5.935, Avg loss: 5.965, Best loss: 5.960\n",
      "    [batch 1779]: seen 177900 examples : 67.7 eps, Loss: 5.931, Avg loss: 5.966, Best loss: 5.960\n",
      "    [batch 1786]: seen 178600 examples : 67.7 eps, Loss: 6.056, Avg loss: 5.963, Best loss: 5.960\n",
      "    [batch 1793]: seen 179300 examples : 67.7 eps, Loss: 5.945, Avg loss: 5.963, Best loss: 5.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1800]: seen 180000 examples : 67.7 eps, Loss: 5.938, Avg loss: 5.961, Best loss: 5.960\n",
      "    [batch 1807]: seen 180700 examples : 67.7 eps, Loss: 5.891, Avg loss: 5.961, Best loss: 5.960\n",
      "    [batch 1814]: seen 181400 examples : 67.7 eps, Loss: 5.848, Avg loss: 5.957, Best loss: 5.957\n",
      "    [batch 1821]: seen 182100 examples : 67.7 eps, Loss: 5.983, Avg loss: 5.957, Best loss: 5.957\n",
      "    [batch 1828]: seen 182800 examples : 67.7 eps, Loss: 5.934, Avg loss: 5.957, Best loss: 5.957\n",
      "    [batch 1835]: seen 183500 examples : 67.7 eps, Loss: 6.064, Avg loss: 5.958, Best loss: 5.957\n",
      "    [batch 1842]: seen 184200 examples : 67.7 eps, Loss: 5.908, Avg loss: 5.955, Best loss: 5.955\n",
      "    [batch 1849]: seen 184900 examples : 67.7 eps, Loss: 5.981, Avg loss: 5.953, Best loss: 5.952\n",
      "    [batch 1856]: seen 185600 examples : 67.7 eps, Loss: 5.925, Avg loss: 5.956, Best loss: 5.952\n",
      "    [batch 1863]: seen 186300 examples : 67.7 eps, Loss: 5.947, Avg loss: 5.953, Best loss: 5.952\n",
      "    [batch 1870]: seen 187000 examples : 67.7 eps, Loss: 5.946, Avg loss: 5.953, Best loss: 5.952\n",
      "    [batch 1877]: seen 187700 examples : 67.7 eps, Loss: 5.785, Avg loss: 5.951, Best loss: 5.951\n",
      "    [batch 1884]: seen 188400 examples : 67.7 eps, Loss: 5.912, Avg loss: 5.952, Best loss: 5.951\n",
      "    [batch 1891]: seen 189100 examples : 67.7 eps, Loss: 5.915, Avg loss: 5.951, Best loss: 5.951\n",
      "    [batch 1898]: seen 189800 examples : 67.7 eps, Loss: 6.017, Avg loss: 5.952, Best loss: 5.950\n",
      "    [batch 1905]: seen 190500 examples : 67.7 eps, Loss: 5.937, Avg loss: 5.949, Best loss: 5.949\n",
      "    [batch 1912]: seen 191200 examples : 67.7 eps, Loss: 5.911, Avg loss: 5.948, Best loss: 5.948\n",
      "    [batch 1919]: seen 191900 examples : 67.7 eps, Loss: 5.878, Avg loss: 5.946, Best loss: 5.946\n",
      "    [batch 1926]: seen 192600 examples : 67.7 eps, Loss: 5.896, Avg loss: 5.947, Best loss: 5.946\n",
      "    [batch 1933]: seen 193300 examples : 67.7 eps, Loss: 5.875, Avg loss: 5.947, Best loss: 5.946\n",
      "    [batch 1940]: seen 194000 examples : 67.7 eps, Loss: 5.922, Avg loss: 5.948, Best loss: 5.946\n",
      "    [batch 1947]: seen 194700 examples : 67.7 eps, Loss: 6.006, Avg loss: 5.945, Best loss: 5.945\n",
      "    [batch 1954]: seen 195400 examples : 67.7 eps, Loss: 5.897, Avg loss: 5.949, Best loss: 5.945\n",
      "    [batch 1961]: seen 196100 examples : 67.7 eps, Loss: 6.017, Avg loss: 5.951, Best loss: 5.945\n",
      "    [batch 1968]: seen 196800 examples : 67.7 eps, Loss: 5.970, Avg loss: 5.951, Best loss: 5.945\n",
      "    [batch 1975]: seen 197500 examples : 67.7 eps, Loss: 5.917, Avg loss: 5.948, Best loss: 5.945\n",
      "    [batch 1982]: seen 198200 examples : 67.7 eps, Loss: 5.921, Avg loss: 5.949, Best loss: 5.945\n",
      "    [batch 1989]: seen 198900 examples : 67.7 eps, Loss: 5.892, Avg loss: 5.947, Best loss: 5.945\n",
      "    [batch 1996]: seen 199600 examples : 67.7 eps, Loss: 5.907, Avg loss: 5.945, Best loss: 5.945\n",
      "    [batch 2003]: seen 200300 examples : 67.7 eps, Loss: 5.933, Avg loss: 5.943, Best loss: 5.943\n",
      "    [batch 2010]: seen 201000 examples : 67.7 eps, Loss: 5.875, Avg loss: 5.943, Best loss: 5.943\n",
      "    [batch 2017]: seen 201700 examples : 67.7 eps, Loss: 5.878, Avg loss: 5.943, Best loss: 5.943\n",
      "    [batch 2024]: seen 202400 examples : 67.7 eps, Loss: 5.946, Avg loss: 5.944, Best loss: 5.943\n",
      "    [batch 2031]: seen 203100 examples : 67.7 eps, Loss: 5.785, Avg loss: 5.944, Best loss: 5.943\n",
      "    [batch 2038]: seen 203800 examples : 67.7 eps, Loss: 5.883, Avg loss: 5.942, Best loss: 5.942\n",
      "    [batch 2045]: seen 204500 examples : 67.7 eps, Loss: 6.016, Avg loss: 5.941, Best loss: 5.941\n",
      "    [batch 2052]: seen 205200 examples : 67.7 eps, Loss: 5.896, Avg loss: 5.939, Best loss: 5.939\n",
      "    [batch 2059]: seen 205900 examples : 67.7 eps, Loss: 5.967, Avg loss: 5.938, Best loss: 5.938\n",
      "    [batch 2066]: seen 206600 examples : 67.7 eps, Loss: 5.909, Avg loss: 5.941, Best loss: 5.938\n",
      "    [batch 2073]: seen 207300 examples : 67.7 eps, Loss: 6.052, Avg loss: 5.943, Best loss: 5.938\n",
      "    [batch 2080]: seen 208000 examples : 67.7 eps, Loss: 5.953, Avg loss: 5.945, Best loss: 5.938\n",
      "    [batch 2087]: seen 208700 examples : 67.7 eps, Loss: 6.062, Avg loss: 5.946, Best loss: 5.938\n",
      "    [batch 2094]: seen 209400 examples : 67.7 eps, Loss: 5.953, Avg loss: 5.946, Best loss: 5.938\n",
      "    [batch 2101]: seen 210100 examples : 67.7 eps, Loss: 5.891, Avg loss: 5.943, Best loss: 5.938\n",
      "    [batch 2108]: seen 210800 examples : 67.7 eps, Loss: 5.850, Avg loss: 5.941, Best loss: 5.938\n",
      "    [batch 2115]: seen 211500 examples : 67.7 eps, Loss: 5.939, Avg loss: 5.939, Best loss: 5.938\n",
      "    [batch 2122]: seen 212200 examples : 67.7 eps, Loss: 5.874, Avg loss: 5.939, Best loss: 5.938\n",
      "    [batch 2129]: seen 212900 examples : 67.7 eps, Loss: 5.859, Avg loss: 5.937, Best loss: 5.936\n",
      "    [batch 2136]: seen 213600 examples : 67.7 eps, Loss: 5.922, Avg loss: 5.937, Best loss: 5.936\n",
      "    [batch 2143]: seen 214300 examples : 67.7 eps, Loss: 5.886, Avg loss: 5.936, Best loss: 5.936\n",
      "    [batch 2150]: seen 215000 examples : 67.7 eps, Loss: 5.894, Avg loss: 5.935, Best loss: 5.935\n",
      "    [batch 2157]: seen 215700 examples : 67.7 eps, Loss: 5.972, Avg loss: 5.933, Best loss: 5.932\n",
      "    [batch 2164]: seen 216400 examples : 67.7 eps, Loss: 5.941, Avg loss: 5.933, Best loss: 5.931\n",
      "    [batch 2171]: seen 217100 examples : 67.7 eps, Loss: 5.944, Avg loss: 5.934, Best loss: 5.931\n",
      "    [batch 2178]: seen 217800 examples : 67.7 eps, Loss: 6.011, Avg loss: 5.932, Best loss: 5.931\n",
      "    [batch 2185]: seen 218500 examples : 67.7 eps, Loss: 5.967, Avg loss: 5.932, Best loss: 5.931\n",
      "    [batch 2192]: seen 219200 examples : 67.7 eps, Loss: 5.891, Avg loss: 5.932, Best loss: 5.931\n",
      "    [batch 2199]: seen 219900 examples : 67.7 eps, Loss: 5.900, Avg loss: 5.932, Best loss: 5.931\n",
      "    [batch 2206]: seen 220600 examples : 67.7 eps, Loss: 5.942, Avg loss: 5.934, Best loss: 5.931\n",
      "    [batch 2213]: seen 221300 examples : 67.7 eps, Loss: 5.871, Avg loss: 5.934, Best loss: 5.931\n",
      "    [batch 2220]: seen 222000 examples : 67.7 eps, Loss: 5.932, Avg loss: 5.934, Best loss: 5.931\n",
      "    [batch 2227]: seen 222700 examples : 67.7 eps, Loss: 5.989, Avg loss: 5.936, Best loss: 5.931\n",
      "    [batch 2234]: seen 223400 examples : 67.7 eps, Loss: 5.938, Avg loss: 5.936, Best loss: 5.931\n",
      "    [batch 2241]: seen 224100 examples : 67.7 eps, Loss: 5.778, Avg loss: 5.932, Best loss: 5.931\n",
      "    [batch 2248]: seen 224800 examples : 67.7 eps, Loss: 5.963, Avg loss: 5.931, Best loss: 5.930\n",
      "    [batch 2255]: seen 225500 examples : 67.7 eps, Loss: 5.830, Avg loss: 5.927, Best loss: 5.927\n",
      "    [batch 2262]: seen 226200 examples : 67.7 eps, Loss: 5.905, Avg loss: 5.928, Best loss: 5.927\n",
      "    [batch 2269]: seen 226900 examples : 67.7 eps, Loss: 5.834, Avg loss: 5.925, Best loss: 5.925\n",
      "    [batch 2276]: seen 227600 examples : 67.7 eps, Loss: 5.878, Avg loss: 5.924, Best loss: 5.924\n",
      "    [batch 2283]: seen 228300 examples : 67.7 eps, Loss: 5.838, Avg loss: 5.921, Best loss: 5.921\n",
      "    [batch 2290]: seen 229000 examples : 67.7 eps, Loss: 5.825, Avg loss: 5.919, Best loss: 5.919\n",
      "    [batch 2297]: seen 229700 examples : 67.7 eps, Loss: 5.895, Avg loss: 5.917, Best loss: 5.917\n",
      "    [batch 2304]: seen 230400 examples : 67.7 eps, Loss: 5.957, Avg loss: 5.919, Best loss: 5.917\n",
      "    [batch 2311]: seen 231100 examples : 67.7 eps, Loss: 5.953, Avg loss: 5.919, Best loss: 5.917\n",
      "    [batch 2318]: seen 231800 examples : 67.7 eps, Loss: 5.876, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2325]: seen 232500 examples : 67.7 eps, Loss: 5.900, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2332]: seen 233200 examples : 67.7 eps, Loss: 5.970, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2339]: seen 233900 examples : 67.7 eps, Loss: 5.982, Avg loss: 5.920, Best loss: 5.917\n",
      "    [batch 2346]: seen 234600 examples : 67.7 eps, Loss: 5.860, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2353]: seen 235300 examples : 67.7 eps, Loss: 5.929, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2360]: seen 236000 examples : 67.7 eps, Loss: 5.993, Avg loss: 5.920, Best loss: 5.917\n",
      "    [batch 2366]: seen 236600 examples : 67.6 eps, Loss: 5.848, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2373]: seen 237300 examples : 67.6 eps, Loss: 5.956, Avg loss: 5.921, Best loss: 5.917\n",
      "    [batch 2380]: seen 238000 examples : 67.6 eps, Loss: 5.944, Avg loss: 5.922, Best loss: 5.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2387]: seen 238700 examples : 67.6 eps, Loss: 5.883, Avg loss: 5.919, Best loss: 5.917\n",
      "    [batch 2394]: seen 239400 examples : 67.6 eps, Loss: 5.944, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2401]: seen 240100 examples : 67.7 eps, Loss: 5.880, Avg loss: 5.917, Best loss: 5.917\n",
      "    [batch 2408]: seen 240800 examples : 67.6 eps, Loss: 5.945, Avg loss: 5.919, Best loss: 5.917\n",
      "    [batch 2415]: seen 241500 examples : 67.6 eps, Loss: 5.949, Avg loss: 5.918, Best loss: 5.917\n",
      "    [batch 2422]: seen 242200 examples : 67.6 eps, Loss: 5.862, Avg loss: 5.915, Best loss: 5.915\n",
      "    [batch 2429]: seen 242900 examples : 67.6 eps, Loss: 5.950, Avg loss: 5.914, Best loss: 5.913\n",
      "    [batch 2436]: seen 243600 examples : 67.6 eps, Loss: 5.785, Avg loss: 5.912, Best loss: 5.912\n",
      "    [batch 2443]: seen 244300 examples : 67.6 eps, Loss: 5.929, Avg loss: 5.913, Best loss: 5.912\n",
      "    [batch 2450]: seen 245000 examples : 67.6 eps, Loss: 5.855, Avg loss: 5.912, Best loss: 5.912\n",
      "    [batch 2457]: seen 245700 examples : 67.6 eps, Loss: 5.885, Avg loss: 5.911, Best loss: 5.911\n",
      "    [batch 2464]: seen 246400 examples : 67.6 eps, Loss: 5.900, Avg loss: 5.910, Best loss: 5.910\n",
      "    [batch 2471]: seen 247100 examples : 67.6 eps, Loss: 5.807, Avg loss: 5.910, Best loss: 5.910\n",
      "    [batch 2478]: seen 247800 examples : 67.6 eps, Loss: 5.908, Avg loss: 5.910, Best loss: 5.910\n",
      "    [batch 2485]: seen 248500 examples : 67.6 eps, Loss: 5.931, Avg loss: 5.910, Best loss: 5.910\n",
      "    [batch 2492]: seen 249200 examples : 67.6 eps, Loss: 5.907, Avg loss: 5.907, Best loss: 5.907\n",
      "    [batch 2499]: seen 249900 examples : 67.6 eps, Loss: 5.937, Avg loss: 5.908, Best loss: 5.906\n",
      "    [batch 2506]: seen 250600 examples : 67.6 eps, Loss: 5.867, Avg loss: 5.906, Best loss: 5.906\n",
      "    [batch 2513]: seen 251300 examples : 67.6 eps, Loss: 5.893, Avg loss: 5.906, Best loss: 5.906\n",
      "    [batch 2520]: seen 252000 examples : 67.6 eps, Loss: 5.991, Avg loss: 5.905, Best loss: 5.904\n",
      "    [batch 2527]: seen 252700 examples : 67.6 eps, Loss: 5.918, Avg loss: 5.906, Best loss: 5.904\n",
      "    [batch 2534]: seen 253400 examples : 67.6 eps, Loss: 5.977, Avg loss: 5.910, Best loss: 5.904\n",
      "    [batch 2541]: seen 254100 examples : 67.6 eps, Loss: 6.005, Avg loss: 5.910, Best loss: 5.904\n",
      "    [batch 2548]: seen 254800 examples : 67.6 eps, Loss: 5.918, Avg loss: 5.910, Best loss: 5.904\n",
      "    [batch 2555]: seen 255500 examples : 67.6 eps, Loss: 5.888, Avg loss: 5.908, Best loss: 5.904\n",
      "    [batch 2562]: seen 256200 examples : 67.6 eps, Loss: 5.826, Avg loss: 5.907, Best loss: 5.904\n",
      "    [batch 2569]: seen 256900 examples : 67.6 eps, Loss: 5.891, Avg loss: 5.908, Best loss: 5.904\n",
      "    [batch 2576]: seen 257600 examples : 67.6 eps, Loss: 5.991, Avg loss: 5.906, Best loss: 5.904\n",
      "    [batch 2583]: seen 258300 examples : 67.6 eps, Loss: 5.863, Avg loss: 5.904, Best loss: 5.904\n",
      "    [batch 2590]: seen 259000 examples : 67.6 eps, Loss: 5.959, Avg loss: 5.905, Best loss: 5.904\n",
      "    [batch 2597]: seen 259700 examples : 67.6 eps, Loss: 5.951, Avg loss: 5.905, Best loss: 5.904\n",
      "    [batch 2604]: seen 260400 examples : 67.6 eps, Loss: 5.863, Avg loss: 5.905, Best loss: 5.904\n",
      "    [batch 2611]: seen 261100 examples : 67.6 eps, Loss: 5.900, Avg loss: 5.906, Best loss: 5.904\n",
      "    [batch 2618]: seen 261800 examples : 67.6 eps, Loss: 5.865, Avg loss: 5.905, Best loss: 5.904\n",
      "    [batch 2625]: seen 262500 examples : 67.6 eps, Loss: 5.988, Avg loss: 5.906, Best loss: 5.904\n",
      "    [batch 2632]: seen 263200 examples : 67.6 eps, Loss: 5.878, Avg loss: 5.905, Best loss: 5.904\n",
      "    [batch 2639]: seen 263900 examples : 67.6 eps, Loss: 5.904, Avg loss: 5.903, Best loss: 5.903\n",
      "    [batch 2646]: seen 264600 examples : 67.6 eps, Loss: 6.023, Avg loss: 5.902, Best loss: 5.900\n",
      "    [batch 2653]: seen 265300 examples : 67.6 eps, Loss: 5.892, Avg loss: 5.899, Best loss: 5.899\n",
      "    [batch 2660]: seen 266000 examples : 67.6 eps, Loss: 5.809, Avg loss: 5.898, Best loss: 5.898\n",
      "    [batch 2667]: seen 266700 examples : 67.6 eps, Loss: 5.875, Avg loss: 5.898, Best loss: 5.898\n",
      "    [batch 2674]: seen 267400 examples : 67.6 eps, Loss: 5.787, Avg loss: 5.897, Best loss: 5.897\n",
      "    [batch 2681]: seen 268100 examples : 67.6 eps, Loss: 5.851, Avg loss: 5.897, Best loss: 5.896\n",
      "    [batch 2688]: seen 268800 examples : 67.6 eps, Loss: 5.936, Avg loss: 5.896, Best loss: 5.895\n",
      "    [batch 2695]: seen 269500 examples : 67.6 eps, Loss: 5.891, Avg loss: 5.894, Best loss: 5.893\n",
      "    [batch 2702]: seen 270200 examples : 67.6 eps, Loss: 5.887, Avg loss: 5.894, Best loss: 5.893\n",
      "    [batch 2709]: seen 270900 examples : 67.6 eps, Loss: 5.934, Avg loss: 5.892, Best loss: 5.892\n",
      "    [batch 2716]: seen 271600 examples : 67.6 eps, Loss: 5.825, Avg loss: 5.888, Best loss: 5.888\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-13931\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-13931\n",
      "    [batch 2722]: seen 272200 examples : 67.6 eps, Loss: 5.937, Avg loss: 5.890, Best loss: 5.888\n",
      "    [batch 2729]: seen 272900 examples : 67.6 eps, Loss: 5.840, Avg loss: 5.888, Best loss: 5.888\n",
      "    [batch 2736]: seen 273600 examples : 67.6 eps, Loss: 5.970, Avg loss: 5.887, Best loss: 5.886\n",
      "    [batch 2743]: seen 274300 examples : 67.6 eps, Loss: 5.880, Avg loss: 5.887, Best loss: 5.886\n",
      "    [batch 2750]: seen 275000 examples : 67.6 eps, Loss: 5.880, Avg loss: 5.886, Best loss: 5.886\n",
      "    [batch 2757]: seen 275700 examples : 67.6 eps, Loss: 5.912, Avg loss: 5.886, Best loss: 5.886\n",
      "    [batch 2764]: seen 276400 examples : 67.6 eps, Loss: 5.904, Avg loss: 5.886, Best loss: 5.885\n",
      "    [batch 2771]: seen 277100 examples : 67.6 eps, Loss: 5.851, Avg loss: 5.885, Best loss: 5.884\n",
      "    [batch 2778]: seen 277800 examples : 67.6 eps, Loss: 5.904, Avg loss: 5.887, Best loss: 5.884\n",
      "    [batch 2785]: seen 278500 examples : 67.6 eps, Loss: 5.809, Avg loss: 5.889, Best loss: 5.884\n",
      "    [batch 2792]: seen 279200 examples : 67.6 eps, Loss: 5.795, Avg loss: 5.887, Best loss: 5.884\n",
      "    [batch 2799]: seen 279900 examples : 67.6 eps, Loss: 5.929, Avg loss: 5.887, Best loss: 5.884\n",
      "    [batch 2806]: seen 280600 examples : 67.6 eps, Loss: 5.807, Avg loss: 5.884, Best loss: 5.884\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:16\n",
      "[EPOCH 5] Complete. Avg Loss: 5.8839052736604405; Best Loss: 5.8839052736604405\n",
      "[EPOCH 6] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.2 eps, Loss: 5.949, Avg loss: 5.884, Best loss: 5.883\n",
      "    [batch 16]: seen 1600 examples : 77.9 eps, Loss: 5.846, Avg loss: 5.884, Best loss: 5.883\n",
      "    [batch 23]: seen 2300 examples : 74.8 eps, Loss: 5.846, Avg loss: 5.880, Best loss: 5.880\n",
      "    [batch 30]: seen 3000 examples : 73.3 eps, Loss: 5.813, Avg loss: 5.878, Best loss: 5.878\n",
      "    [batch 37]: seen 3700 examples : 72.4 eps, Loss: 5.819, Avg loss: 5.878, Best loss: 5.878\n",
      "    [batch 44]: seen 4400 examples : 71.7 eps, Loss: 5.898, Avg loss: 5.877, Best loss: 5.876\n",
      "    [batch 51]: seen 5100 examples : 71.2 eps, Loss: 5.829, Avg loss: 5.874, Best loss: 5.874\n",
      "    [batch 58]: seen 5800 examples : 70.9 eps, Loss: 5.797, Avg loss: 5.874, Best loss: 5.874\n",
      "    [batch 65]: seen 6500 examples : 70.6 eps, Loss: 5.869, Avg loss: 5.873, Best loss: 5.873\n",
      "    [batch 72]: seen 7200 examples : 70.4 eps, Loss: 5.953, Avg loss: 5.872, Best loss: 5.871\n",
      "    [batch 79]: seen 7900 examples : 70.2 eps, Loss: 5.850, Avg loss: 5.874, Best loss: 5.871\n",
      "    [batch 86]: seen 8600 examples : 70.1 eps, Loss: 5.963, Avg loss: 5.873, Best loss: 5.871\n",
      "    [batch 93]: seen 9300 examples : 70.0 eps, Loss: 5.829, Avg loss: 5.872, Best loss: 5.871\n",
      "    [batch 100]: seen 10000 examples : 69.9 eps, Loss: 5.970, Avg loss: 5.871, Best loss: 5.870\n",
      "    [batch 107]: seen 10700 examples : 69.9 eps, Loss: 5.937, Avg loss: 5.873, Best loss: 5.870\n",
      "    [batch 114]: seen 11400 examples : 69.8 eps, Loss: 5.827, Avg loss: 5.873, Best loss: 5.870\n",
      "    [batch 121]: seen 12100 examples : 69.7 eps, Loss: 5.832, Avg loss: 5.872, Best loss: 5.870\n",
      "    [batch 128]: seen 12800 examples : 69.7 eps, Loss: 5.832, Avg loss: 5.871, Best loss: 5.870\n",
      "    [batch 135]: seen 13500 examples : 69.5 eps, Loss: 5.801, Avg loss: 5.871, Best loss: 5.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 142]: seen 14200 examples : 69.4 eps, Loss: 5.835, Avg loss: 5.868, Best loss: 5.868\n",
      "    [batch 149]: seen 14900 examples : 69.3 eps, Loss: 5.888, Avg loss: 5.870, Best loss: 5.868\n",
      "    [batch 156]: seen 15600 examples : 69.3 eps, Loss: 5.894, Avg loss: 5.868, Best loss: 5.868\n",
      "    [batch 163]: seen 16300 examples : 69.2 eps, Loss: 5.839, Avg loss: 5.870, Best loss: 5.868\n",
      "    [batch 170]: seen 17000 examples : 69.1 eps, Loss: 5.790, Avg loss: 5.870, Best loss: 5.868\n",
      "    [batch 177]: seen 17700 examples : 69.1 eps, Loss: 5.925, Avg loss: 5.870, Best loss: 5.868\n",
      "    [batch 184]: seen 18400 examples : 69.0 eps, Loss: 5.817, Avg loss: 5.870, Best loss: 5.868\n",
      "    [batch 191]: seen 19100 examples : 69.0 eps, Loss: 5.854, Avg loss: 5.866, Best loss: 5.866\n",
      "    [batch 198]: seen 19800 examples : 68.9 eps, Loss: 5.831, Avg loss: 5.864, Best loss: 5.864\n",
      "    [batch 205]: seen 20500 examples : 68.9 eps, Loss: 5.820, Avg loss: 5.863, Best loss: 5.863\n",
      "    [batch 212]: seen 21200 examples : 68.9 eps, Loss: 5.799, Avg loss: 5.862, Best loss: 5.862\n",
      "    [batch 219]: seen 21900 examples : 68.8 eps, Loss: 5.825, Avg loss: 5.859, Best loss: 5.859\n",
      "    [batch 226]: seen 22600 examples : 68.8 eps, Loss: 5.887, Avg loss: 5.859, Best loss: 5.858\n",
      "    [batch 233]: seen 23300 examples : 68.8 eps, Loss: 5.789, Avg loss: 5.859, Best loss: 5.858\n",
      "    [batch 240]: seen 24000 examples : 68.7 eps, Loss: 5.806, Avg loss: 5.859, Best loss: 5.858\n",
      "    [batch 247]: seen 24700 examples : 68.7 eps, Loss: 5.849, Avg loss: 5.860, Best loss: 5.858\n",
      "    [batch 254]: seen 25400 examples : 68.6 eps, Loss: 5.777, Avg loss: 5.862, Best loss: 5.858\n",
      "    [batch 261]: seen 26100 examples : 68.5 eps, Loss: 5.941, Avg loss: 5.864, Best loss: 5.858\n",
      "    [batch 268]: seen 26800 examples : 68.5 eps, Loss: 5.909, Avg loss: 5.862, Best loss: 5.858\n",
      "    [batch 275]: seen 27500 examples : 68.5 eps, Loss: 5.842, Avg loss: 5.862, Best loss: 5.858\n",
      "    [batch 282]: seen 28200 examples : 68.5 eps, Loss: 5.863, Avg loss: 5.864, Best loss: 5.858\n",
      "    [batch 289]: seen 28900 examples : 68.4 eps, Loss: 5.872, Avg loss: 5.862, Best loss: 5.858\n",
      "    [batch 296]: seen 29600 examples : 68.4 eps, Loss: 5.875, Avg loss: 5.861, Best loss: 5.858\n",
      "    [batch 303]: seen 30300 examples : 68.4 eps, Loss: 5.820, Avg loss: 5.857, Best loss: 5.857\n",
      "    [batch 310]: seen 31000 examples : 68.3 eps, Loss: 5.962, Avg loss: 5.857, Best loss: 5.856\n",
      "    [batch 317]: seen 31700 examples : 68.3 eps, Loss: 5.741, Avg loss: 5.856, Best loss: 5.856\n",
      "    [batch 324]: seen 32400 examples : 68.3 eps, Loss: 5.853, Avg loss: 5.854, Best loss: 5.854\n",
      "    [batch 331]: seen 33100 examples : 68.3 eps, Loss: 5.962, Avg loss: 5.859, Best loss: 5.854\n",
      "    [batch 338]: seen 33800 examples : 68.3 eps, Loss: 5.871, Avg loss: 5.861, Best loss: 5.854\n",
      "    [batch 345]: seen 34500 examples : 68.2 eps, Loss: 5.913, Avg loss: 5.862, Best loss: 5.854\n",
      "    [batch 352]: seen 35200 examples : 68.2 eps, Loss: 5.864, Avg loss: 5.861, Best loss: 5.854\n",
      "    [batch 359]: seen 35900 examples : 68.2 eps, Loss: 5.941, Avg loss: 5.864, Best loss: 5.854\n",
      "    [batch 366]: seen 36600 examples : 68.2 eps, Loss: 5.924, Avg loss: 5.864, Best loss: 5.854\n",
      "    [batch 373]: seen 37300 examples : 68.2 eps, Loss: 5.972, Avg loss: 5.866, Best loss: 5.854\n",
      "    [batch 380]: seen 38000 examples : 68.2 eps, Loss: 5.929, Avg loss: 5.866, Best loss: 5.854\n",
      "    [batch 387]: seen 38700 examples : 68.2 eps, Loss: 5.826, Avg loss: 5.865, Best loss: 5.854\n",
      "    [batch 394]: seen 39400 examples : 68.1 eps, Loss: 5.839, Avg loss: 5.866, Best loss: 5.854\n",
      "    [batch 401]: seen 40100 examples : 68.1 eps, Loss: 5.798, Avg loss: 5.864, Best loss: 5.854\n",
      "    [batch 408]: seen 40800 examples : 68.1 eps, Loss: 5.929, Avg loss: 5.863, Best loss: 5.854\n",
      "    [batch 415]: seen 41500 examples : 68.1 eps, Loss: 5.818, Avg loss: 5.861, Best loss: 5.854\n",
      "    [batch 422]: seen 42200 examples : 68.1 eps, Loss: 5.780, Avg loss: 5.857, Best loss: 5.854\n",
      "    [batch 429]: seen 42900 examples : 68.1 eps, Loss: 5.879, Avg loss: 5.862, Best loss: 5.854\n",
      "    [batch 436]: seen 43600 examples : 68.1 eps, Loss: 5.976, Avg loss: 5.863, Best loss: 5.854\n",
      "    [batch 443]: seen 44300 examples : 68.1 eps, Loss: 5.860, Avg loss: 5.864, Best loss: 5.854\n",
      "    [batch 450]: seen 45000 examples : 68.1 eps, Loss: 5.724, Avg loss: 5.861, Best loss: 5.854\n",
      "    [batch 457]: seen 45700 examples : 68.1 eps, Loss: 5.800, Avg loss: 5.859, Best loss: 5.854\n",
      "    [batch 464]: seen 46400 examples : 68.1 eps, Loss: 5.807, Avg loss: 5.857, Best loss: 5.854\n",
      "    [batch 471]: seen 47100 examples : 68.1 eps, Loss: 5.814, Avg loss: 5.855, Best loss: 5.854\n",
      "    [batch 478]: seen 47800 examples : 68.1 eps, Loss: 5.832, Avg loss: 5.855, Best loss: 5.854\n",
      "    [batch 485]: seen 48500 examples : 68.1 eps, Loss: 5.893, Avg loss: 5.855, Best loss: 5.854\n",
      "    [batch 492]: seen 49200 examples : 68.0 eps, Loss: 5.829, Avg loss: 5.854, Best loss: 5.854\n",
      "    [batch 499]: seen 49900 examples : 68.0 eps, Loss: 5.849, Avg loss: 5.855, Best loss: 5.854\n",
      "    [batch 506]: seen 50600 examples : 68.0 eps, Loss: 5.843, Avg loss: 5.854, Best loss: 5.854\n",
      "    [batch 513]: seen 51300 examples : 68.0 eps, Loss: 5.946, Avg loss: 5.857, Best loss: 5.854\n",
      "    [batch 520]: seen 52000 examples : 68.0 eps, Loss: 5.995, Avg loss: 5.857, Best loss: 5.854\n",
      "    [batch 527]: seen 52700 examples : 68.0 eps, Loss: 5.827, Avg loss: 5.856, Best loss: 5.854\n",
      "    [batch 534]: seen 53400 examples : 68.0 eps, Loss: 5.899, Avg loss: 5.855, Best loss: 5.854\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-14554\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-14554\n",
      "    [batch 540]: seen 54000 examples : 67.9 eps, Loss: 5.803, Avg loss: 5.854, Best loss: 5.854\n",
      "    [batch 547]: seen 54700 examples : 67.9 eps, Loss: 5.804, Avg loss: 5.853, Best loss: 5.852\n",
      "    [batch 554]: seen 55400 examples : 67.9 eps, Loss: 5.837, Avg loss: 5.853, Best loss: 5.852\n",
      "    [batch 561]: seen 56100 examples : 67.8 eps, Loss: 5.850, Avg loss: 5.850, Best loss: 5.850\n",
      "    [batch 568]: seen 56800 examples : 67.8 eps, Loss: 5.839, Avg loss: 5.849, Best loss: 5.849\n",
      "    [batch 575]: seen 57500 examples : 67.8 eps, Loss: 5.879, Avg loss: 5.849, Best loss: 5.848\n",
      "    [batch 582]: seen 58200 examples : 67.8 eps, Loss: 5.800, Avg loss: 5.849, Best loss: 5.848\n",
      "    [batch 589]: seen 58900 examples : 67.8 eps, Loss: 5.820, Avg loss: 5.849, Best loss: 5.848\n",
      "    [batch 596]: seen 59600 examples : 67.8 eps, Loss: 5.735, Avg loss: 5.847, Best loss: 5.847\n",
      "    [batch 603]: seen 60300 examples : 67.8 eps, Loss: 5.947, Avg loss: 5.847, Best loss: 5.846\n",
      "    [batch 610]: seen 61000 examples : 67.8 eps, Loss: 5.825, Avg loss: 5.848, Best loss: 5.846\n",
      "    [batch 617]: seen 61700 examples : 67.8 eps, Loss: 5.832, Avg loss: 5.849, Best loss: 5.846\n",
      "    [batch 624]: seen 62400 examples : 67.8 eps, Loss: 5.812, Avg loss: 5.847, Best loss: 5.846\n",
      "    [batch 631]: seen 63100 examples : 67.8 eps, Loss: 5.967, Avg loss: 5.849, Best loss: 5.846\n",
      "    [batch 638]: seen 63800 examples : 67.8 eps, Loss: 5.709, Avg loss: 5.845, Best loss: 5.845\n",
      "    [batch 645]: seen 64500 examples : 67.8 eps, Loss: 5.856, Avg loss: 5.843, Best loss: 5.843\n",
      "    [batch 652]: seen 65200 examples : 67.8 eps, Loss: 5.837, Avg loss: 5.843, Best loss: 5.843\n",
      "    [batch 659]: seen 65900 examples : 67.8 eps, Loss: 5.776, Avg loss: 5.843, Best loss: 5.842\n",
      "    [batch 666]: seen 66600 examples : 67.8 eps, Loss: 5.873, Avg loss: 5.844, Best loss: 5.842\n",
      "    [batch 673]: seen 67300 examples : 67.8 eps, Loss: 5.934, Avg loss: 5.845, Best loss: 5.842\n",
      "    [batch 680]: seen 68000 examples : 67.8 eps, Loss: 5.871, Avg loss: 5.842, Best loss: 5.842\n",
      "    [batch 687]: seen 68700 examples : 67.8 eps, Loss: 5.900, Avg loss: 5.841, Best loss: 5.840\n",
      "    [batch 694]: seen 69400 examples : 67.8 eps, Loss: 5.884, Avg loss: 5.840, Best loss: 5.840\n",
      "    [batch 701]: seen 70100 examples : 67.8 eps, Loss: 5.750, Avg loss: 5.840, Best loss: 5.840\n",
      "    [batch 708]: seen 70800 examples : 67.8 eps, Loss: 5.839, Avg loss: 5.839, Best loss: 5.839\n",
      "    [batch 715]: seen 71500 examples : 67.8 eps, Loss: 5.810, Avg loss: 5.836, Best loss: 5.836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 722]: seen 72200 examples : 67.8 eps, Loss: 5.845, Avg loss: 5.835, Best loss: 5.833\n",
      "    [batch 729]: seen 72900 examples : 67.8 eps, Loss: 5.880, Avg loss: 5.832, Best loss: 5.831\n",
      "    [batch 736]: seen 73600 examples : 67.8 eps, Loss: 5.862, Avg loss: 5.829, Best loss: 5.829\n",
      "    [batch 743]: seen 74300 examples : 67.8 eps, Loss: 5.931, Avg loss: 5.832, Best loss: 5.829\n",
      "    [batch 750]: seen 75000 examples : 67.8 eps, Loss: 5.816, Avg loss: 5.832, Best loss: 5.829\n",
      "    [batch 757]: seen 75700 examples : 67.8 eps, Loss: 5.813, Avg loss: 5.830, Best loss: 5.829\n",
      "    [batch 764]: seen 76400 examples : 67.8 eps, Loss: 5.804, Avg loss: 5.831, Best loss: 5.829\n",
      "    [batch 771]: seen 77100 examples : 67.8 eps, Loss: 5.816, Avg loss: 5.832, Best loss: 5.829\n",
      "    [batch 778]: seen 77800 examples : 67.8 eps, Loss: 5.964, Avg loss: 5.839, Best loss: 5.829\n",
      "    [batch 785]: seen 78500 examples : 67.8 eps, Loss: 5.886, Avg loss: 5.840, Best loss: 5.829\n",
      "    [batch 792]: seen 79200 examples : 67.8 eps, Loss: 5.829, Avg loss: 5.839, Best loss: 5.829\n",
      "    [batch 799]: seen 79900 examples : 67.8 eps, Loss: 5.860, Avg loss: 5.841, Best loss: 5.829\n",
      "    [batch 806]: seen 80600 examples : 67.8 eps, Loss: 5.780, Avg loss: 5.839, Best loss: 5.829\n",
      "    [batch 813]: seen 81300 examples : 67.8 eps, Loss: 5.795, Avg loss: 5.837, Best loss: 5.829\n",
      "    [batch 820]: seen 82000 examples : 67.8 eps, Loss: 5.836, Avg loss: 5.835, Best loss: 5.829\n",
      "    [batch 827]: seen 82700 examples : 67.8 eps, Loss: 5.763, Avg loss: 5.833, Best loss: 5.829\n",
      "    [batch 834]: seen 83400 examples : 67.8 eps, Loss: 5.813, Avg loss: 5.832, Best loss: 5.829\n",
      "    [batch 841]: seen 84100 examples : 67.8 eps, Loss: 5.798, Avg loss: 5.833, Best loss: 5.829\n",
      "    [batch 848]: seen 84800 examples : 67.8 eps, Loss: 5.737, Avg loss: 5.831, Best loss: 5.829\n",
      "    [batch 855]: seen 85500 examples : 67.8 eps, Loss: 5.891, Avg loss: 5.830, Best loss: 5.829\n",
      "    [batch 862]: seen 86200 examples : 67.8 eps, Loss: 5.916, Avg loss: 5.830, Best loss: 5.829\n",
      "    [batch 869]: seen 86900 examples : 67.8 eps, Loss: 5.880, Avg loss: 5.830, Best loss: 5.829\n",
      "    [batch 876]: seen 87600 examples : 67.8 eps, Loss: 5.905, Avg loss: 5.832, Best loss: 5.829\n",
      "    [batch 883]: seen 88300 examples : 67.8 eps, Loss: 5.760, Avg loss: 5.831, Best loss: 5.829\n",
      "    [batch 890]: seen 89000 examples : 67.8 eps, Loss: 5.809, Avg loss: 5.831, Best loss: 5.829\n",
      "    [batch 897]: seen 89700 examples : 67.8 eps, Loss: 5.791, Avg loss: 5.829, Best loss: 5.829\n",
      "    [batch 904]: seen 90400 examples : 67.8 eps, Loss: 5.835, Avg loss: 5.829, Best loss: 5.828\n",
      "    [batch 911]: seen 91100 examples : 67.8 eps, Loss: 5.710, Avg loss: 5.829, Best loss: 5.828\n",
      "    [batch 918]: seen 91800 examples : 67.8 eps, Loss: 5.826, Avg loss: 5.830, Best loss: 5.828\n",
      "    [batch 925]: seen 92500 examples : 67.8 eps, Loss: 5.900, Avg loss: 5.831, Best loss: 5.828\n",
      "    [batch 932]: seen 93200 examples : 67.8 eps, Loss: 5.858, Avg loss: 5.831, Best loss: 5.828\n",
      "    [batch 939]: seen 93900 examples : 67.8 eps, Loss: 5.915, Avg loss: 5.833, Best loss: 5.828\n",
      "    [batch 946]: seen 94600 examples : 67.8 eps, Loss: 5.728, Avg loss: 5.833, Best loss: 5.828\n",
      "    [batch 953]: seen 95300 examples : 67.8 eps, Loss: 5.781, Avg loss: 5.835, Best loss: 5.828\n",
      "    [batch 960]: seen 96000 examples : 67.8 eps, Loss: 5.785, Avg loss: 5.834, Best loss: 5.828\n",
      "    [batch 967]: seen 96700 examples : 67.8 eps, Loss: 5.893, Avg loss: 5.831, Best loss: 5.828\n",
      "    [batch 974]: seen 97400 examples : 67.8 eps, Loss: 5.781, Avg loss: 5.830, Best loss: 5.828\n",
      "    [batch 981]: seen 98100 examples : 67.8 eps, Loss: 5.757, Avg loss: 5.826, Best loss: 5.826\n",
      "    [batch 988]: seen 98800 examples : 67.8 eps, Loss: 5.805, Avg loss: 5.825, Best loss: 5.825\n",
      "    [batch 995]: seen 99500 examples : 67.8 eps, Loss: 5.894, Avg loss: 5.825, Best loss: 5.824\n",
      "    [batch 1002]: seen 100200 examples : 67.8 eps, Loss: 5.845, Avg loss: 5.824, Best loss: 5.824\n",
      "    [batch 1009]: seen 100900 examples : 67.8 eps, Loss: 5.808, Avg loss: 5.824, Best loss: 5.823\n",
      "    [batch 1016]: seen 101600 examples : 67.8 eps, Loss: 5.929, Avg loss: 5.824, Best loss: 5.822\n",
      "    [batch 1023]: seen 102300 examples : 67.8 eps, Loss: 5.823, Avg loss: 5.824, Best loss: 5.822\n",
      "    [batch 1030]: seen 103000 examples : 67.8 eps, Loss: 5.802, Avg loss: 5.826, Best loss: 5.822\n",
      "    [batch 1037]: seen 103700 examples : 67.8 eps, Loss: 5.797, Avg loss: 5.821, Best loss: 5.821\n",
      "    [batch 1044]: seen 104400 examples : 67.8 eps, Loss: 5.907, Avg loss: 5.822, Best loss: 5.821\n",
      "    [batch 1051]: seen 105100 examples : 67.8 eps, Loss: 5.935, Avg loss: 5.825, Best loss: 5.821\n",
      "    [batch 1058]: seen 105800 examples : 67.8 eps, Loss: 5.803, Avg loss: 5.826, Best loss: 5.821\n",
      "    [batch 1065]: seen 106500 examples : 67.8 eps, Loss: 5.867, Avg loss: 5.826, Best loss: 5.821\n",
      "    [batch 1072]: seen 107200 examples : 67.8 eps, Loss: 5.939, Avg loss: 5.828, Best loss: 5.821\n",
      "    [batch 1079]: seen 107900 examples : 67.8 eps, Loss: 5.794, Avg loss: 5.826, Best loss: 5.821\n",
      "    [batch 1086]: seen 108600 examples : 67.8 eps, Loss: 5.835, Avg loss: 5.825, Best loss: 5.821\n",
      "    [batch 1093]: seen 109300 examples : 67.8 eps, Loss: 5.806, Avg loss: 5.825, Best loss: 5.821\n",
      "    [batch 1100]: seen 110000 examples : 67.8 eps, Loss: 5.800, Avg loss: 5.824, Best loss: 5.821\n",
      "    [batch 1107]: seen 110700 examples : 67.8 eps, Loss: 5.753, Avg loss: 5.821, Best loss: 5.821\n",
      "    [batch 1114]: seen 111400 examples : 67.8 eps, Loss: 5.831, Avg loss: 5.821, Best loss: 5.821\n",
      "    [batch 1121]: seen 112100 examples : 67.8 eps, Loss: 5.771, Avg loss: 5.821, Best loss: 5.821\n",
      "    [batch 1128]: seen 112800 examples : 67.8 eps, Loss: 5.697, Avg loss: 5.818, Best loss: 5.818\n",
      "    [batch 1135]: seen 113500 examples : 67.8 eps, Loss: 5.878, Avg loss: 5.819, Best loss: 5.818\n",
      "    [batch 1142]: seen 114200 examples : 67.8 eps, Loss: 5.805, Avg loss: 5.816, Best loss: 5.816\n",
      "    [batch 1149]: seen 114900 examples : 67.8 eps, Loss: 5.753, Avg loss: 5.815, Best loss: 5.815\n",
      "    [batch 1156]: seen 115600 examples : 67.8 eps, Loss: 5.763, Avg loss: 5.813, Best loss: 5.813\n",
      "    [batch 1163]: seen 116300 examples : 67.8 eps, Loss: 5.843, Avg loss: 5.815, Best loss: 5.813\n",
      "    [batch 1170]: seen 117000 examples : 67.8 eps, Loss: 5.805, Avg loss: 5.814, Best loss: 5.813\n",
      "    [batch 1177]: seen 117700 examples : 67.8 eps, Loss: 5.781, Avg loss: 5.816, Best loss: 5.813\n",
      "    [batch 1184]: seen 118400 examples : 67.8 eps, Loss: 5.750, Avg loss: 5.815, Best loss: 5.813\n",
      "    [batch 1191]: seen 119100 examples : 67.8 eps, Loss: 5.766, Avg loss: 5.811, Best loss: 5.811\n",
      "    [batch 1198]: seen 119800 examples : 67.8 eps, Loss: 5.893, Avg loss: 5.812, Best loss: 5.811\n",
      "    [batch 1205]: seen 120500 examples : 67.8 eps, Loss: 5.861, Avg loss: 5.814, Best loss: 5.811\n",
      "    [batch 1212]: seen 121200 examples : 67.8 eps, Loss: 5.838, Avg loss: 5.814, Best loss: 5.811\n",
      "    [batch 1219]: seen 121900 examples : 67.8 eps, Loss: 5.717, Avg loss: 5.815, Best loss: 5.811\n",
      "    [batch 1226]: seen 122600 examples : 67.8 eps, Loss: 5.856, Avg loss: 5.817, Best loss: 5.811\n",
      "    [batch 1233]: seen 123300 examples : 67.8 eps, Loss: 5.845, Avg loss: 5.818, Best loss: 5.811\n",
      "    [batch 1240]: seen 124000 examples : 67.8 eps, Loss: 5.739, Avg loss: 5.817, Best loss: 5.811\n",
      "    [batch 1247]: seen 124700 examples : 67.8 eps, Loss: 5.839, Avg loss: 5.815, Best loss: 5.811\n",
      "    [batch 1254]: seen 125400 examples : 67.8 eps, Loss: 5.837, Avg loss: 5.811, Best loss: 5.811\n",
      "    [batch 1261]: seen 126100 examples : 67.8 eps, Loss: 5.880, Avg loss: 5.813, Best loss: 5.811\n",
      "    [batch 1268]: seen 126800 examples : 67.8 eps, Loss: 5.816, Avg loss: 5.813, Best loss: 5.811\n",
      "    [batch 1275]: seen 127500 examples : 67.8 eps, Loss: 5.860, Avg loss: 5.814, Best loss: 5.811\n",
      "    [batch 1282]: seen 128200 examples : 67.8 eps, Loss: 5.852, Avg loss: 5.816, Best loss: 5.811\n",
      "    [batch 1289]: seen 128900 examples : 67.8 eps, Loss: 5.787, Avg loss: 5.817, Best loss: 5.811\n",
      "    [batch 1296]: seen 129600 examples : 67.7 eps, Loss: 5.803, Avg loss: 5.817, Best loss: 5.811\n",
      "    [batch 1303]: seen 130300 examples : 67.8 eps, Loss: 5.717, Avg loss: 5.815, Best loss: 5.811\n",
      "    [batch 1310]: seen 131000 examples : 67.8 eps, Loss: 5.773, Avg loss: 5.813, Best loss: 5.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1317]: seen 131700 examples : 67.8 eps, Loss: 5.856, Avg loss: 5.812, Best loss: 5.811\n",
      "    [batch 1324]: seen 132400 examples : 67.8 eps, Loss: 5.834, Avg loss: 5.812, Best loss: 5.811\n",
      "    [batch 1331]: seen 133100 examples : 67.8 eps, Loss: 5.850, Avg loss: 5.812, Best loss: 5.811\n",
      "    [batch 1338]: seen 133800 examples : 67.8 eps, Loss: 5.737, Avg loss: 5.810, Best loss: 5.810\n",
      "    [batch 1345]: seen 134500 examples : 67.8 eps, Loss: 5.780, Avg loss: 5.806, Best loss: 5.806\n",
      "    [batch 1352]: seen 135200 examples : 67.8 eps, Loss: 5.743, Avg loss: 5.805, Best loss: 5.805\n",
      "    [batch 1359]: seen 135900 examples : 67.8 eps, Loss: 5.754, Avg loss: 5.805, Best loss: 5.805\n",
      "    [batch 1366]: seen 136600 examples : 67.8 eps, Loss: 5.861, Avg loss: 5.809, Best loss: 5.805\n",
      "    [batch 1373]: seen 137300 examples : 67.8 eps, Loss: 5.805, Avg loss: 5.811, Best loss: 5.805\n",
      "    [batch 1380]: seen 138000 examples : 67.8 eps, Loss: 5.760, Avg loss: 5.809, Best loss: 5.805\n",
      "    [batch 1387]: seen 138700 examples : 67.8 eps, Loss: 5.858, Avg loss: 5.807, Best loss: 5.805\n",
      "    [batch 1394]: seen 139400 examples : 67.8 eps, Loss: 5.770, Avg loss: 5.805, Best loss: 5.805\n",
      "    [batch 1401]: seen 140100 examples : 67.8 eps, Loss: 5.807, Avg loss: 5.807, Best loss: 5.805\n",
      "    [batch 1408]: seen 140800 examples : 67.8 eps, Loss: 5.830, Avg loss: 5.807, Best loss: 5.805\n",
      "    [batch 1415]: seen 141500 examples : 67.8 eps, Loss: 5.746, Avg loss: 5.806, Best loss: 5.805\n",
      "    [batch 1422]: seen 142200 examples : 67.8 eps, Loss: 5.670, Avg loss: 5.804, Best loss: 5.804\n",
      "    [batch 1429]: seen 142900 examples : 67.8 eps, Loss: 5.790, Avg loss: 5.801, Best loss: 5.801\n",
      "    [batch 1436]: seen 143600 examples : 67.8 eps, Loss: 5.754, Avg loss: 5.800, Best loss: 5.800\n",
      "    [batch 1443]: seen 144300 examples : 67.8 eps, Loss: 5.736, Avg loss: 5.799, Best loss: 5.799\n",
      "    [batch 1450]: seen 145000 examples : 67.8 eps, Loss: 5.817, Avg loss: 5.799, Best loss: 5.798\n",
      "    [batch 1457]: seen 145700 examples : 67.8 eps, Loss: 5.822, Avg loss: 5.796, Best loss: 5.796\n",
      "    [batch 1464]: seen 146400 examples : 67.8 eps, Loss: 5.868, Avg loss: 5.807, Best loss: 5.796\n",
      "    [batch 1471]: seen 147100 examples : 67.8 eps, Loss: 5.746, Avg loss: 5.807, Best loss: 5.796\n",
      "    [batch 1478]: seen 147800 examples : 67.8 eps, Loss: 5.801, Avg loss: 5.806, Best loss: 5.796\n",
      "    [batch 1485]: seen 148500 examples : 67.8 eps, Loss: 5.847, Avg loss: 5.808, Best loss: 5.796\n",
      "    [batch 1492]: seen 149200 examples : 67.8 eps, Loss: 5.778, Avg loss: 5.807, Best loss: 5.796\n",
      "    [batch 1499]: seen 149900 examples : 67.8 eps, Loss: 5.822, Avg loss: 5.805, Best loss: 5.796\n",
      "    [batch 1506]: seen 150600 examples : 67.8 eps, Loss: 5.809, Avg loss: 5.804, Best loss: 5.796\n",
      "    [batch 1513]: seen 151300 examples : 67.8 eps, Loss: 5.769, Avg loss: 5.806, Best loss: 5.796\n",
      "    [batch 1520]: seen 152000 examples : 67.8 eps, Loss: 5.728, Avg loss: 5.805, Best loss: 5.796\n",
      "    [batch 1527]: seen 152700 examples : 67.8 eps, Loss: 5.680, Avg loss: 5.803, Best loss: 5.796\n",
      "    [batch 1534]: seen 153400 examples : 67.8 eps, Loss: 5.814, Avg loss: 5.804, Best loss: 5.796\n",
      "    [batch 1541]: seen 154100 examples : 67.8 eps, Loss: 5.774, Avg loss: 5.799, Best loss: 5.796\n",
      "    [batch 1548]: seen 154800 examples : 67.8 eps, Loss: 5.699, Avg loss: 5.797, Best loss: 5.796\n",
      "    [batch 1555]: seen 155500 examples : 67.7 eps, Loss: 5.794, Avg loss: 5.797, Best loss: 5.796\n",
      "    [batch 1562]: seen 156200 examples : 67.7 eps, Loss: 5.769, Avg loss: 5.795, Best loss: 5.795\n",
      "    [batch 1569]: seen 156900 examples : 67.7 eps, Loss: 5.846, Avg loss: 5.796, Best loss: 5.795\n",
      "    [batch 1576]: seen 157600 examples : 67.7 eps, Loss: 5.802, Avg loss: 5.798, Best loss: 5.795\n",
      "    [batch 1583]: seen 158300 examples : 67.7 eps, Loss: 5.669, Avg loss: 5.796, Best loss: 5.795\n",
      "    [batch 1590]: seen 159000 examples : 67.7 eps, Loss: 5.796, Avg loss: 5.795, Best loss: 5.795\n",
      "    [batch 1597]: seen 159700 examples : 67.7 eps, Loss: 5.827, Avg loss: 5.795, Best loss: 5.794\n",
      "    [batch 1604]: seen 160400 examples : 67.7 eps, Loss: 5.920, Avg loss: 5.795, Best loss: 5.794\n",
      "    [batch 1611]: seen 161100 examples : 67.7 eps, Loss: 5.712, Avg loss: 5.794, Best loss: 5.794\n",
      "    [batch 1618]: seen 161800 examples : 67.7 eps, Loss: 5.752, Avg loss: 5.794, Best loss: 5.793\n",
      "    [batch 1625]: seen 162500 examples : 67.7 eps, Loss: 5.734, Avg loss: 5.791, Best loss: 5.791\n",
      "    [batch 1632]: seen 163200 examples : 67.7 eps, Loss: 5.708, Avg loss: 5.787, Best loss: 5.787\n",
      "    [batch 1639]: seen 163900 examples : 67.7 eps, Loss: 5.869, Avg loss: 5.786, Best loss: 5.785\n",
      "    [batch 1646]: seen 164600 examples : 67.7 eps, Loss: 5.718, Avg loss: 5.787, Best loss: 5.785\n",
      "    [batch 1653]: seen 165300 examples : 67.7 eps, Loss: 5.882, Avg loss: 5.789, Best loss: 5.785\n",
      "    [batch 1660]: seen 166000 examples : 67.7 eps, Loss: 5.751, Avg loss: 5.787, Best loss: 5.785\n",
      "    [batch 1667]: seen 166700 examples : 67.7 eps, Loss: 5.843, Avg loss: 5.787, Best loss: 5.785\n",
      "    [batch 1674]: seen 167400 examples : 67.7 eps, Loss: 5.751, Avg loss: 5.786, Best loss: 5.785\n",
      "    [batch 1681]: seen 168100 examples : 67.7 eps, Loss: 5.780, Avg loss: 5.785, Best loss: 5.785\n",
      "    [batch 1688]: seen 168800 examples : 67.7 eps, Loss: 5.758, Avg loss: 5.786, Best loss: 5.784\n",
      "    [batch 1695]: seen 169500 examples : 67.7 eps, Loss: 5.746, Avg loss: 5.784, Best loss: 5.784\n",
      "    [batch 1702]: seen 170200 examples : 67.7 eps, Loss: 5.703, Avg loss: 5.784, Best loss: 5.784\n",
      "    [batch 1709]: seen 170900 examples : 67.7 eps, Loss: 5.757, Avg loss: 5.784, Best loss: 5.783\n",
      "    [batch 1716]: seen 171600 examples : 67.7 eps, Loss: 5.855, Avg loss: 5.784, Best loss: 5.783\n",
      "    [batch 1723]: seen 172300 examples : 67.7 eps, Loss: 5.749, Avg loss: 5.784, Best loss: 5.783\n",
      "    [batch 1730]: seen 173000 examples : 67.7 eps, Loss: 5.929, Avg loss: 5.782, Best loss: 5.780\n",
      "    [batch 1737]: seen 173700 examples : 67.7 eps, Loss: 5.818, Avg loss: 5.784, Best loss: 5.780\n",
      "    [batch 1744]: seen 174400 examples : 67.7 eps, Loss: 5.807, Avg loss: 5.784, Best loss: 5.780\n",
      "    [batch 1751]: seen 175100 examples : 67.7 eps, Loss: 5.730, Avg loss: 5.785, Best loss: 5.780\n",
      "    [batch 1758]: seen 175800 examples : 67.7 eps, Loss: 5.857, Avg loss: 5.785, Best loss: 5.780\n",
      "    [batch 1765]: seen 176500 examples : 67.7 eps, Loss: 5.833, Avg loss: 5.782, Best loss: 5.780\n",
      "    [batch 1772]: seen 177200 examples : 67.7 eps, Loss: 5.690, Avg loss: 5.781, Best loss: 5.780\n",
      "    [batch 1779]: seen 177900 examples : 67.7 eps, Loss: 5.782, Avg loss: 5.781, Best loss: 5.780\n",
      "    [batch 1786]: seen 178600 examples : 67.7 eps, Loss: 5.793, Avg loss: 5.779, Best loss: 5.779\n",
      "    [batch 1793]: seen 179300 examples : 67.7 eps, Loss: 5.811, Avg loss: 5.781, Best loss: 5.779\n",
      "    [batch 1800]: seen 180000 examples : 67.7 eps, Loss: 5.833, Avg loss: 5.780, Best loss: 5.779\n",
      "    [batch 1807]: seen 180700 examples : 67.7 eps, Loss: 5.802, Avg loss: 5.778, Best loss: 5.777\n",
      "    [batch 1814]: seen 181400 examples : 67.7 eps, Loss: 5.712, Avg loss: 5.777, Best loss: 5.777\n",
      "    [batch 1821]: seen 182100 examples : 67.7 eps, Loss: 5.783, Avg loss: 5.779, Best loss: 5.776\n",
      "    [batch 1828]: seen 182800 examples : 67.7 eps, Loss: 6.667, Avg loss: 5.787, Best loss: 5.776\n",
      "    [batch 1835]: seen 183500 examples : 67.7 eps, Loss: 5.925, Avg loss: 5.800, Best loss: 5.776\n",
      "    [batch 1842]: seen 184200 examples : 67.7 eps, Loss: 5.820, Avg loss: 5.798, Best loss: 5.776\n",
      "    [batch 1849]: seen 184900 examples : 67.7 eps, Loss: 5.747, Avg loss: 5.798, Best loss: 5.776\n",
      "    [batch 1856]: seen 185600 examples : 67.7 eps, Loss: 5.764, Avg loss: 5.798, Best loss: 5.776\n",
      "    [batch 1863]: seen 186300 examples : 67.7 eps, Loss: 5.782, Avg loss: 5.795, Best loss: 5.776\n",
      "    [batch 1870]: seen 187000 examples : 67.7 eps, Loss: 5.709, Avg loss: 5.796, Best loss: 5.776\n",
      "    [batch 1877]: seen 187700 examples : 67.7 eps, Loss: 5.824, Avg loss: 5.795, Best loss: 5.776\n",
      "    [batch 1884]: seen 188400 examples : 67.7 eps, Loss: 5.827, Avg loss: 5.795, Best loss: 5.776\n",
      "    [batch 1891]: seen 189100 examples : 67.7 eps, Loss: 5.736, Avg loss: 5.794, Best loss: 5.776\n",
      "    [batch 1898]: seen 189800 examples : 67.7 eps, Loss: 5.753, Avg loss: 5.795, Best loss: 5.776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1905]: seen 190500 examples : 67.7 eps, Loss: 5.775, Avg loss: 5.796, Best loss: 5.776\n",
      "    [batch 1912]: seen 191200 examples : 67.7 eps, Loss: 5.768, Avg loss: 5.795, Best loss: 5.776\n",
      "    [batch 1919]: seen 191900 examples : 67.7 eps, Loss: 5.785, Avg loss: 5.795, Best loss: 5.776\n",
      "    [batch 1926]: seen 192600 examples : 67.7 eps, Loss: 5.766, Avg loss: 5.792, Best loss: 5.776\n",
      "    [batch 1933]: seen 193300 examples : 67.7 eps, Loss: 5.727, Avg loss: 5.792, Best loss: 5.776\n",
      "    [batch 1940]: seen 194000 examples : 67.7 eps, Loss: 5.796, Avg loss: 5.793, Best loss: 5.776\n",
      "    [batch 1947]: seen 194700 examples : 67.7 eps, Loss: 5.746, Avg loss: 5.789, Best loss: 5.776\n",
      "    [batch 1954]: seen 195400 examples : 67.7 eps, Loss: 5.725, Avg loss: 5.787, Best loss: 5.776\n",
      "    [batch 1961]: seen 196100 examples : 67.7 eps, Loss: 5.785, Avg loss: 5.784, Best loss: 5.776\n",
      "    [batch 1968]: seen 196800 examples : 67.7 eps, Loss: 5.702, Avg loss: 5.784, Best loss: 5.776\n",
      "    [batch 1975]: seen 197500 examples : 67.7 eps, Loss: 5.762, Avg loss: 5.785, Best loss: 5.776\n",
      "    [batch 1982]: seen 198200 examples : 67.7 eps, Loss: 5.797, Avg loss: 5.784, Best loss: 5.776\n",
      "    [batch 1989]: seen 198900 examples : 67.7 eps, Loss: 5.721, Avg loss: 5.780, Best loss: 5.776\n",
      "    [batch 1996]: seen 199600 examples : 67.7 eps, Loss: 5.735, Avg loss: 5.780, Best loss: 5.776\n",
      "    [batch 2003]: seen 200300 examples : 67.7 eps, Loss: 5.810, Avg loss: 5.779, Best loss: 5.776\n",
      "    [batch 2010]: seen 201000 examples : 67.7 eps, Loss: 5.754, Avg loss: 5.779, Best loss: 5.776\n",
      "    [batch 2017]: seen 201700 examples : 67.7 eps, Loss: 5.783, Avg loss: 5.780, Best loss: 5.776\n",
      "    [batch 2024]: seen 202400 examples : 67.7 eps, Loss: 5.777, Avg loss: 5.780, Best loss: 5.776\n",
      "    [batch 2031]: seen 203100 examples : 67.7 eps, Loss: 5.825, Avg loss: 5.782, Best loss: 5.776\n",
      "    [batch 2038]: seen 203800 examples : 67.7 eps, Loss: 5.663, Avg loss: 5.778, Best loss: 5.776\n",
      "    [batch 2045]: seen 204500 examples : 67.7 eps, Loss: 5.773, Avg loss: 5.779, Best loss: 5.776\n",
      "    [batch 2052]: seen 205200 examples : 67.7 eps, Loss: 5.747, Avg loss: 5.779, Best loss: 5.776\n",
      "    [batch 2059]: seen 205900 examples : 67.7 eps, Loss: 5.790, Avg loss: 5.779, Best loss: 5.776\n",
      "    [batch 2066]: seen 206600 examples : 67.7 eps, Loss: 5.704, Avg loss: 5.777, Best loss: 5.776\n",
      "    [batch 2073]: seen 207300 examples : 67.7 eps, Loss: 5.740, Avg loss: 5.774, Best loss: 5.774\n",
      "    [batch 2080]: seen 208000 examples : 67.7 eps, Loss: 5.742, Avg loss: 5.774, Best loss: 5.774\n",
      "    [batch 2087]: seen 208700 examples : 67.7 eps, Loss: 5.744, Avg loss: 5.774, Best loss: 5.774\n",
      "    [batch 2094]: seen 209400 examples : 67.7 eps, Loss: 5.718, Avg loss: 5.771, Best loss: 5.771\n",
      "    [batch 2101]: seen 210100 examples : 67.7 eps, Loss: 5.769, Avg loss: 5.772, Best loss: 5.771\n",
      "    [batch 2108]: seen 210800 examples : 67.7 eps, Loss: 5.734, Avg loss: 5.772, Best loss: 5.771\n",
      "    [batch 2115]: seen 211500 examples : 67.7 eps, Loss: 5.762, Avg loss: 5.772, Best loss: 5.771\n",
      "    [batch 2122]: seen 212200 examples : 67.7 eps, Loss: 5.849, Avg loss: 5.774, Best loss: 5.771\n",
      "    [batch 2129]: seen 212900 examples : 67.7 eps, Loss: 5.811, Avg loss: 5.776, Best loss: 5.771\n",
      "    [batch 2136]: seen 213600 examples : 67.7 eps, Loss: 5.744, Avg loss: 5.774, Best loss: 5.771\n",
      "    [batch 2143]: seen 214300 examples : 67.7 eps, Loss: 5.804, Avg loss: 5.772, Best loss: 5.771\n",
      "    [batch 2150]: seen 215000 examples : 67.7 eps, Loss: 5.705, Avg loss: 5.770, Best loss: 5.770\n",
      "    [batch 2157]: seen 215700 examples : 67.7 eps, Loss: 5.790, Avg loss: 5.772, Best loss: 5.770\n",
      "    [batch 2164]: seen 216400 examples : 67.7 eps, Loss: 5.792, Avg loss: 5.770, Best loss: 5.769\n",
      "    [batch 2171]: seen 217100 examples : 67.7 eps, Loss: 5.741, Avg loss: 5.768, Best loss: 5.768\n",
      "    [batch 2178]: seen 217800 examples : 67.7 eps, Loss: 5.732, Avg loss: 5.769, Best loss: 5.767\n",
      "    [batch 2185]: seen 218500 examples : 67.7 eps, Loss: 5.722, Avg loss: 5.767, Best loss: 5.767\n",
      "    [batch 2192]: seen 219200 examples : 67.7 eps, Loss: 5.660, Avg loss: 5.767, Best loss: 5.766\n",
      "    [batch 2199]: seen 219900 examples : 67.7 eps, Loss: 5.734, Avg loss: 5.766, Best loss: 5.766\n",
      "    [batch 2206]: seen 220600 examples : 67.7 eps, Loss: 5.768, Avg loss: 5.767, Best loss: 5.766\n",
      "    [batch 2213]: seen 221300 examples : 67.7 eps, Loss: 5.718, Avg loss: 5.768, Best loss: 5.766\n",
      "    [batch 2220]: seen 222000 examples : 67.7 eps, Loss: 5.652, Avg loss: 5.765, Best loss: 5.765\n",
      "    [batch 2227]: seen 222700 examples : 67.7 eps, Loss: 5.775, Avg loss: 5.764, Best loss: 5.764\n",
      "    [batch 2234]: seen 223400 examples : 67.7 eps, Loss: 5.799, Avg loss: 5.762, Best loss: 5.762\n",
      "    [batch 2241]: seen 224100 examples : 67.7 eps, Loss: 5.706, Avg loss: 5.760, Best loss: 5.760\n",
      "    [batch 2248]: seen 224800 examples : 67.7 eps, Loss: 5.744, Avg loss: 5.761, Best loss: 5.760\n",
      "    [batch 2255]: seen 225500 examples : 67.7 eps, Loss: 5.661, Avg loss: 5.759, Best loss: 5.759\n",
      "    [batch 2262]: seen 226200 examples : 67.7 eps, Loss: 5.726, Avg loss: 5.759, Best loss: 5.759\n",
      "    [batch 2269]: seen 226900 examples : 67.7 eps, Loss: 5.644, Avg loss: 5.758, Best loss: 5.758\n",
      "    [batch 2276]: seen 227600 examples : 67.7 eps, Loss: 5.760, Avg loss: 5.757, Best loss: 5.757\n",
      "    [batch 2283]: seen 228300 examples : 67.7 eps, Loss: 5.770, Avg loss: 5.758, Best loss: 5.757\n",
      "    [batch 2290]: seen 229000 examples : 67.7 eps, Loss: 5.666, Avg loss: 5.757, Best loss: 5.757\n",
      "    [batch 2297]: seen 229700 examples : 67.7 eps, Loss: 5.715, Avg loss: 5.755, Best loss: 5.755\n",
      "    [batch 2304]: seen 230400 examples : 67.7 eps, Loss: 5.792, Avg loss: 5.755, Best loss: 5.754\n",
      "    [batch 2311]: seen 231100 examples : 67.7 eps, Loss: 5.782, Avg loss: 5.753, Best loss: 5.752\n",
      "    [batch 2318]: seen 231800 examples : 67.7 eps, Loss: 5.707, Avg loss: 5.751, Best loss: 5.751\n",
      "    [batch 2325]: seen 232500 examples : 67.7 eps, Loss: 5.755, Avg loss: 5.751, Best loss: 5.750\n",
      "    [batch 2332]: seen 233200 examples : 67.7 eps, Loss: 5.736, Avg loss: 5.750, Best loss: 5.750\n",
      "    [batch 2339]: seen 233900 examples : 67.7 eps, Loss: 5.740, Avg loss: 5.749, Best loss: 5.749\n",
      "    [batch 2346]: seen 234600 examples : 67.7 eps, Loss: 5.746, Avg loss: 5.748, Best loss: 5.748\n",
      "    [batch 2353]: seen 235300 examples : 67.7 eps, Loss: 5.756, Avg loss: 5.746, Best loss: 5.746\n",
      "    [batch 2360]: seen 236000 examples : 67.7 eps, Loss: 5.843, Avg loss: 5.747, Best loss: 5.746\n",
      "    [batch 2367]: seen 236700 examples : 67.7 eps, Loss: 5.764, Avg loss: 5.748, Best loss: 5.746\n",
      "    [batch 2374]: seen 237400 examples : 67.7 eps, Loss: 5.672, Avg loss: 5.749, Best loss: 5.746\n",
      "    [batch 2381]: seen 238100 examples : 67.7 eps, Loss: 5.708, Avg loss: 5.748, Best loss: 5.746\n",
      "    [batch 2388]: seen 238800 examples : 67.7 eps, Loss: 5.862, Avg loss: 5.750, Best loss: 5.746\n",
      "    [batch 2395]: seen 239500 examples : 67.7 eps, Loss: 5.693, Avg loss: 5.749, Best loss: 5.746\n",
      "    [batch 2402]: seen 240200 examples : 67.7 eps, Loss: 5.820, Avg loss: 5.751, Best loss: 5.746\n",
      "    [batch 2409]: seen 240900 examples : 67.7 eps, Loss: 5.748, Avg loss: 5.752, Best loss: 5.746\n",
      "    [batch 2416]: seen 241600 examples : 67.7 eps, Loss: 5.764, Avg loss: 5.753, Best loss: 5.746\n",
      "    [batch 2423]: seen 242300 examples : 67.7 eps, Loss: 5.783, Avg loss: 5.754, Best loss: 5.746\n",
      "    [batch 2430]: seen 243000 examples : 67.7 eps, Loss: 5.666, Avg loss: 5.752, Best loss: 5.746\n",
      "    [batch 2437]: seen 243700 examples : 67.7 eps, Loss: 5.717, Avg loss: 5.753, Best loss: 5.746\n",
      "    [batch 2444]: seen 244400 examples : 67.7 eps, Loss: 5.788, Avg loss: 5.752, Best loss: 5.746\n",
      "    [batch 2451]: seen 245100 examples : 67.7 eps, Loss: 5.756, Avg loss: 5.751, Best loss: 5.746\n",
      "    [batch 2458]: seen 245800 examples : 67.7 eps, Loss: 5.776, Avg loss: 5.751, Best loss: 5.746\n",
      "    [batch 2465]: seen 246500 examples : 67.7 eps, Loss: 5.889, Avg loss: 5.754, Best loss: 5.746\n",
      "    [batch 2472]: seen 247200 examples : 67.7 eps, Loss: 5.873, Avg loss: 5.762, Best loss: 5.746\n",
      "    [batch 2479]: seen 247900 examples : 67.7 eps, Loss: 5.776, Avg loss: 5.766, Best loss: 5.746\n",
      "    [batch 2486]: seen 248600 examples : 67.7 eps, Loss: 5.681, Avg loss: 5.766, Best loss: 5.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2493]: seen 249300 examples : 67.7 eps, Loss: 5.646, Avg loss: 5.764, Best loss: 5.746\n",
      "    [batch 2500]: seen 250000 examples : 67.7 eps, Loss: 5.747, Avg loss: 5.762, Best loss: 5.746\n",
      "    [batch 2507]: seen 250700 examples : 67.7 eps, Loss: 5.659, Avg loss: 5.760, Best loss: 5.746\n",
      "    [batch 2514]: seen 251400 examples : 67.7 eps, Loss: 5.861, Avg loss: 5.761, Best loss: 5.746\n",
      "    [batch 2521]: seen 252100 examples : 67.7 eps, Loss: 5.727, Avg loss: 5.759, Best loss: 5.746\n",
      "    [batch 2528]: seen 252800 examples : 67.7 eps, Loss: 5.749, Avg loss: 5.760, Best loss: 5.746\n",
      "    [batch 2535]: seen 253500 examples : 67.7 eps, Loss: 5.597, Avg loss: 5.759, Best loss: 5.746\n",
      "    [batch 2542]: seen 254200 examples : 67.7 eps, Loss: 5.775, Avg loss: 5.759, Best loss: 5.746\n",
      "    [batch 2549]: seen 254900 examples : 67.7 eps, Loss: 5.741, Avg loss: 5.760, Best loss: 5.746\n",
      "    [batch 2556]: seen 255600 examples : 67.7 eps, Loss: 5.707, Avg loss: 5.758, Best loss: 5.746\n",
      "    [batch 2563]: seen 256300 examples : 67.7 eps, Loss: 5.757, Avg loss: 5.758, Best loss: 5.746\n",
      "    [batch 2570]: seen 257000 examples : 67.7 eps, Loss: 5.756, Avg loss: 5.756, Best loss: 5.746\n",
      "    [batch 2577]: seen 257700 examples : 67.7 eps, Loss: 5.654, Avg loss: 5.755, Best loss: 5.746\n",
      "    [batch 2584]: seen 258400 examples : 67.7 eps, Loss: 5.758, Avg loss: 5.753, Best loss: 5.746\n",
      "    [batch 2591]: seen 259100 examples : 67.7 eps, Loss: 5.722, Avg loss: 5.750, Best loss: 5.746\n",
      "    [batch 2598]: seen 259800 examples : 67.7 eps, Loss: 5.636, Avg loss: 5.749, Best loss: 5.746\n",
      "    [batch 2605]: seen 260500 examples : 67.7 eps, Loss: 5.729, Avg loss: 5.747, Best loss: 5.746\n",
      "    [batch 2612]: seen 261200 examples : 67.7 eps, Loss: 5.739, Avg loss: 5.749, Best loss: 5.746\n",
      "    [batch 2619]: seen 261900 examples : 67.7 eps, Loss: 5.750, Avg loss: 5.749, Best loss: 5.746\n",
      "    [batch 2626]: seen 262600 examples : 67.7 eps, Loss: 5.729, Avg loss: 5.747, Best loss: 5.746\n",
      "    [batch 2633]: seen 263300 examples : 67.7 eps, Loss: 5.683, Avg loss: 5.746, Best loss: 5.746\n",
      "    [batch 2640]: seen 264000 examples : 67.7 eps, Loss: 5.715, Avg loss: 5.742, Best loss: 5.742\n",
      "    [batch 2647]: seen 264700 examples : 67.7 eps, Loss: 5.700, Avg loss: 5.743, Best loss: 5.742\n",
      "    [batch 2654]: seen 265400 examples : 67.7 eps, Loss: 5.674, Avg loss: 5.742, Best loss: 5.742\n",
      "    [batch 2661]: seen 266100 examples : 67.7 eps, Loss: 5.781, Avg loss: 5.743, Best loss: 5.742\n",
      "    [batch 2668]: seen 266800 examples : 67.7 eps, Loss: 5.692, Avg loss: 5.744, Best loss: 5.742\n",
      "    [batch 2675]: seen 267500 examples : 67.7 eps, Loss: 5.741, Avg loss: 5.742, Best loss: 5.741\n",
      "    [batch 2682]: seen 268200 examples : 67.7 eps, Loss: 5.774, Avg loss: 5.746, Best loss: 5.741\n",
      "    [batch 2689]: seen 268900 examples : 67.7 eps, Loss: 5.731, Avg loss: 5.747, Best loss: 5.741\n",
      "    [batch 2696]: seen 269600 examples : 67.7 eps, Loss: 5.812, Avg loss: 5.748, Best loss: 5.741\n",
      "    [batch 2703]: seen 270300 examples : 67.7 eps, Loss: 5.754, Avg loss: 5.747, Best loss: 5.741\n",
      "    [batch 2710]: seen 271000 examples : 67.7 eps, Loss: 5.702, Avg loss: 5.745, Best loss: 5.741\n",
      "    [batch 2717]: seen 271700 examples : 67.7 eps, Loss: 5.664, Avg loss: 5.745, Best loss: 5.741\n",
      "    [batch 2724]: seen 272400 examples : 67.7 eps, Loss: 5.804, Avg loss: 5.743, Best loss: 5.741\n",
      "    [batch 2731]: seen 273100 examples : 67.7 eps, Loss: 5.776, Avg loss: 5.742, Best loss: 5.741\n",
      "    [batch 2738]: seen 273800 examples : 67.7 eps, Loss: 5.767, Avg loss: 5.741, Best loss: 5.741\n",
      "    [batch 2745]: seen 274500 examples : 67.7 eps, Loss: 5.719, Avg loss: 5.740, Best loss: 5.739\n",
      "    [batch 2752]: seen 275200 examples : 67.7 eps, Loss: 5.719, Avg loss: 5.741, Best loss: 5.739\n",
      "    [batch 2759]: seen 275900 examples : 67.7 eps, Loss: 5.742, Avg loss: 5.740, Best loss: 5.739\n",
      "    [batch 2766]: seen 276600 examples : 67.7 eps, Loss: 5.719, Avg loss: 5.740, Best loss: 5.739\n",
      "    [batch 2773]: seen 277300 examples : 67.6 eps, Loss: 5.793, Avg loss: 5.741, Best loss: 5.739\n",
      "    [batch 2780]: seen 278000 examples : 67.6 eps, Loss: 5.647, Avg loss: 5.739, Best loss: 5.739\n",
      "    [batch 2787]: seen 278700 examples : 67.6 eps, Loss: 5.712, Avg loss: 5.737, Best loss: 5.737\n",
      "    [batch 2794]: seen 279400 examples : 67.6 eps, Loss: 5.778, Avg loss: 5.737, Best loss: 5.736\n",
      "    [batch 2801]: seen 280100 examples : 67.6 eps, Loss: 5.720, Avg loss: 5.737, Best loss: 5.736\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:09\n",
      "[EPOCH 6] Complete. Avg Loss: 5.737026612362635; Best Loss: 5.7355465908464955\n",
      "[EPOCH 7] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.1 eps, Loss: 5.731, Avg loss: 5.732, Best loss: 5.732\n",
      "    [batch 16]: seen 1600 examples : 77.9 eps, Loss: 5.659, Avg loss: 5.731, Best loss: 5.730\n",
      "    [batch 23]: seen 2300 examples : 74.9 eps, Loss: 5.792, Avg loss: 5.730, Best loss: 5.729\n",
      "    [batch 30]: seen 3000 examples : 73.4 eps, Loss: 5.676, Avg loss: 5.729, Best loss: 5.729\n",
      "    [batch 37]: seen 3700 examples : 72.6 eps, Loss: 5.745, Avg loss: 5.726, Best loss: 5.726\n",
      "    [batch 44]: seen 4400 examples : 72.0 eps, Loss: 5.669, Avg loss: 5.725, Best loss: 5.725\n",
      "    [batch 51]: seen 5100 examples : 71.5 eps, Loss: 5.702, Avg loss: 5.725, Best loss: 5.724\n",
      "    [batch 58]: seen 5800 examples : 70.8 eps, Loss: 5.637, Avg loss: 5.721, Best loss: 5.721\n",
      "    [batch 65]: seen 6500 examples : 70.5 eps, Loss: 5.658, Avg loss: 5.720, Best loss: 5.720\n",
      "    [batch 72]: seen 7200 examples : 70.4 eps, Loss: 5.665, Avg loss: 5.720, Best loss: 5.720\n",
      "    [batch 79]: seen 7900 examples : 70.2 eps, Loss: 5.632, Avg loss: 5.718, Best loss: 5.718\n",
      "    [batch 86]: seen 8600 examples : 70.1 eps, Loss: 5.674, Avg loss: 5.715, Best loss: 5.715\n",
      "    [batch 93]: seen 9300 examples : 70.0 eps, Loss: 5.731, Avg loss: 5.715, Best loss: 5.715\n",
      "    [batch 100]: seen 10000 examples : 69.7 eps, Loss: 5.776, Avg loss: 5.716, Best loss: 5.714\n",
      "    [batch 107]: seen 10700 examples : 69.5 eps, Loss: 5.675, Avg loss: 5.716, Best loss: 5.714\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-16929\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-16929\n",
      "    [batch 113]: seen 11300 examples : 68.6 eps, Loss: 5.782, Avg loss: 5.717, Best loss: 5.714\n",
      "    [batch 120]: seen 12000 examples : 68.6 eps, Loss: 5.593, Avg loss: 5.713, Best loss: 5.713\n",
      "    [batch 127]: seen 12700 examples : 68.4 eps, Loss: 5.762, Avg loss: 5.712, Best loss: 5.712\n",
      "    [batch 134]: seen 13400 examples : 68.4 eps, Loss: 5.625, Avg loss: 5.711, Best loss: 5.711\n",
      "    [batch 141]: seen 14100 examples : 68.4 eps, Loss: 5.882, Avg loss: 5.712, Best loss: 5.710\n",
      "    [batch 148]: seen 14800 examples : 68.3 eps, Loss: 5.844, Avg loss: 5.715, Best loss: 5.710\n",
      "    [batch 155]: seen 15500 examples : 68.3 eps, Loss: 5.630, Avg loss: 5.716, Best loss: 5.710\n",
      "    [batch 162]: seen 16200 examples : 68.2 eps, Loss: 5.672, Avg loss: 5.716, Best loss: 5.710\n",
      "    [batch 169]: seen 16900 examples : 68.2 eps, Loss: 5.744, Avg loss: 5.717, Best loss: 5.710\n",
      "    [batch 176]: seen 17600 examples : 68.2 eps, Loss: 5.669, Avg loss: 5.718, Best loss: 5.710\n",
      "    [batch 183]: seen 18300 examples : 68.2 eps, Loss: 5.700, Avg loss: 5.719, Best loss: 5.710\n",
      "    [batch 190]: seen 19000 examples : 68.0 eps, Loss: 5.776, Avg loss: 5.721, Best loss: 5.710\n",
      "    [batch 197]: seen 19700 examples : 68.0 eps, Loss: 5.689, Avg loss: 5.723, Best loss: 5.710\n",
      "    [batch 204]: seen 20400 examples : 68.1 eps, Loss: 5.635, Avg loss: 5.719, Best loss: 5.710\n",
      "    [batch 211]: seen 21100 examples : 68.0 eps, Loss: 5.696, Avg loss: 5.718, Best loss: 5.710\n",
      "    [batch 218]: seen 21800 examples : 68.0 eps, Loss: 5.689, Avg loss: 5.719, Best loss: 5.710\n",
      "    [batch 225]: seen 22500 examples : 68.0 eps, Loss: 5.637, Avg loss: 5.718, Best loss: 5.710\n",
      "    [batch 232]: seen 23200 examples : 68.0 eps, Loss: 5.707, Avg loss: 5.713, Best loss: 5.710\n",
      "    [batch 239]: seen 23900 examples : 68.0 eps, Loss: 5.740, Avg loss: 5.715, Best loss: 5.710\n",
      "    [batch 246]: seen 24600 examples : 68.0 eps, Loss: 5.700, Avg loss: 5.712, Best loss: 5.710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 253]: seen 25300 examples : 68.0 eps, Loss: 5.669, Avg loss: 5.712, Best loss: 5.710\n",
      "    [batch 260]: seen 26000 examples : 68.0 eps, Loss: 5.705, Avg loss: 5.710, Best loss: 5.710\n",
      "    [batch 267]: seen 26700 examples : 68.0 eps, Loss: 5.743, Avg loss: 5.709, Best loss: 5.709\n",
      "    [batch 274]: seen 27400 examples : 67.9 eps, Loss: 5.567, Avg loss: 5.711, Best loss: 5.709\n",
      "    [batch 281]: seen 28100 examples : 67.9 eps, Loss: 5.622, Avg loss: 5.709, Best loss: 5.709\n",
      "    [batch 288]: seen 28800 examples : 67.9 eps, Loss: 5.757, Avg loss: 5.709, Best loss: 5.708\n",
      "    [batch 295]: seen 29500 examples : 67.9 eps, Loss: 5.644, Avg loss: 5.709, Best loss: 5.708\n",
      "    [batch 302]: seen 30200 examples : 67.9 eps, Loss: 5.811, Avg loss: 5.711, Best loss: 5.708\n",
      "    [batch 309]: seen 30900 examples : 67.9 eps, Loss: 5.782, Avg loss: 5.713, Best loss: 5.708\n",
      "    [batch 316]: seen 31600 examples : 67.8 eps, Loss: 5.728, Avg loss: 5.713, Best loss: 5.708\n",
      "    [batch 323]: seen 32300 examples : 67.8 eps, Loss: 5.615, Avg loss: 5.711, Best loss: 5.708\n",
      "    [batch 330]: seen 33000 examples : 67.8 eps, Loss: 5.735, Avg loss: 5.711, Best loss: 5.708\n",
      "    [batch 337]: seen 33700 examples : 67.8 eps, Loss: 5.749, Avg loss: 5.710, Best loss: 5.708\n",
      "    [batch 344]: seen 34400 examples : 67.8 eps, Loss: 5.773, Avg loss: 5.709, Best loss: 5.708\n",
      "    [batch 351]: seen 35100 examples : 67.8 eps, Loss: 5.645, Avg loss: 5.707, Best loss: 5.707\n",
      "    [batch 358]: seen 35800 examples : 67.8 eps, Loss: 5.740, Avg loss: 5.707, Best loss: 5.706\n",
      "    [batch 365]: seen 36500 examples : 67.8 eps, Loss: 5.735, Avg loss: 5.706, Best loss: 5.706\n",
      "    [batch 372]: seen 37200 examples : 67.8 eps, Loss: 5.730, Avg loss: 5.705, Best loss: 5.705\n",
      "    [batch 379]: seen 37900 examples : 67.8 eps, Loss: 5.775, Avg loss: 5.705, Best loss: 5.704\n",
      "    [batch 386]: seen 38600 examples : 67.8 eps, Loss: 5.631, Avg loss: 5.703, Best loss: 5.703\n",
      "    [batch 393]: seen 39300 examples : 67.8 eps, Loss: 6.117, Avg loss: 5.709, Best loss: 5.702\n",
      "    [batch 400]: seen 40000 examples : 67.8 eps, Loss: 5.813, Avg loss: 5.787, Best loss: 5.702\n",
      "    [batch 407]: seen 40700 examples : 67.8 eps, Loss: 5.740, Avg loss: 5.786, Best loss: 5.702\n",
      "    [batch 414]: seen 41400 examples : 67.8 eps, Loss: 5.794, Avg loss: 5.783, Best loss: 5.702\n",
      "    [batch 421]: seen 42100 examples : 67.8 eps, Loss: 5.742, Avg loss: 5.778, Best loss: 5.702\n",
      "    [batch 428]: seen 42800 examples : 67.8 eps, Loss: 5.799, Avg loss: 5.772, Best loss: 5.702\n",
      "    [batch 435]: seen 43500 examples : 67.8 eps, Loss: 5.806, Avg loss: 5.771, Best loss: 5.702\n",
      "    [batch 442]: seen 44200 examples : 67.8 eps, Loss: 5.615, Avg loss: 5.765, Best loss: 5.702\n",
      "    [batch 449]: seen 44900 examples : 67.8 eps, Loss: 5.694, Avg loss: 5.760, Best loss: 5.702\n",
      "    [batch 456]: seen 45600 examples : 67.8 eps, Loss: 5.715, Avg loss: 5.757, Best loss: 5.702\n",
      "    [batch 463]: seen 46300 examples : 67.8 eps, Loss: 5.769, Avg loss: 5.753, Best loss: 5.702\n",
      "    [batch 470]: seen 47000 examples : 67.8 eps, Loss: 5.660, Avg loss: 5.749, Best loss: 5.702\n",
      "    [batch 477]: seen 47700 examples : 67.8 eps, Loss: 5.731, Avg loss: 5.745, Best loss: 5.702\n",
      "    [batch 484]: seen 48400 examples : 67.8 eps, Loss: 5.616, Avg loss: 5.741, Best loss: 5.702\n",
      "    [batch 491]: seen 49100 examples : 67.8 eps, Loss: 5.680, Avg loss: 5.740, Best loss: 5.702\n",
      "    [batch 498]: seen 49800 examples : 67.8 eps, Loss: 5.651, Avg loss: 5.739, Best loss: 5.702\n",
      "    [batch 505]: seen 50500 examples : 67.8 eps, Loss: 5.689, Avg loss: 5.737, Best loss: 5.702\n",
      "    [batch 512]: seen 51200 examples : 67.8 eps, Loss: 5.750, Avg loss: 5.736, Best loss: 5.702\n",
      "    [batch 519]: seen 51900 examples : 67.8 eps, Loss: 5.680, Avg loss: 5.735, Best loss: 5.702\n",
      "    [batch 526]: seen 52600 examples : 67.8 eps, Loss: 5.676, Avg loss: 5.734, Best loss: 5.702\n",
      "    [batch 533]: seen 53300 examples : 67.8 eps, Loss: 5.768, Avg loss: 5.733, Best loss: 5.702\n",
      "    [batch 540]: seen 54000 examples : 67.8 eps, Loss: 5.702, Avg loss: 5.730, Best loss: 5.702\n",
      "    [batch 547]: seen 54700 examples : 67.8 eps, Loss: 5.700, Avg loss: 5.732, Best loss: 5.702\n",
      "    [batch 554]: seen 55400 examples : 67.8 eps, Loss: 5.729, Avg loss: 5.730, Best loss: 5.702\n",
      "    [batch 561]: seen 56100 examples : 67.8 eps, Loss: 5.717, Avg loss: 5.727, Best loss: 5.702\n",
      "    [batch 568]: seen 56800 examples : 67.8 eps, Loss: 5.680, Avg loss: 5.726, Best loss: 5.702\n",
      "    [batch 575]: seen 57500 examples : 67.8 eps, Loss: 5.739, Avg loss: 5.723, Best loss: 5.702\n",
      "    [batch 582]: seen 58200 examples : 67.7 eps, Loss: 5.663, Avg loss: 5.718, Best loss: 5.702\n",
      "    [batch 589]: seen 58900 examples : 67.7 eps, Loss: 5.742, Avg loss: 5.717, Best loss: 5.702\n",
      "    [batch 596]: seen 59600 examples : 67.8 eps, Loss: 5.681, Avg loss: 5.715, Best loss: 5.702\n",
      "    [batch 603]: seen 60300 examples : 67.7 eps, Loss: 5.702, Avg loss: 5.714, Best loss: 5.702\n",
      "    [batch 610]: seen 61000 examples : 67.7 eps, Loss: 5.575, Avg loss: 5.711, Best loss: 5.702\n",
      "    [batch 617]: seen 61700 examples : 67.7 eps, Loss: 5.688, Avg loss: 5.709, Best loss: 5.702\n",
      "    [batch 624]: seen 62400 examples : 67.7 eps, Loss: 5.757, Avg loss: 5.710, Best loss: 5.702\n",
      "    [batch 631]: seen 63100 examples : 67.7 eps, Loss: 5.681, Avg loss: 5.708, Best loss: 5.702\n",
      "    [batch 638]: seen 63800 examples : 67.7 eps, Loss: 5.680, Avg loss: 5.702, Best loss: 5.702\n",
      "    [batch 645]: seen 64500 examples : 67.7 eps, Loss: 5.687, Avg loss: 5.700, Best loss: 5.700\n",
      "    [batch 652]: seen 65200 examples : 67.7 eps, Loss: 5.731, Avg loss: 5.698, Best loss: 5.698\n",
      "    [batch 659]: seen 65900 examples : 67.7 eps, Loss: 5.627, Avg loss: 5.699, Best loss: 5.698\n",
      "    [batch 666]: seen 66600 examples : 67.7 eps, Loss: 5.708, Avg loss: 5.700, Best loss: 5.698\n",
      "    [batch 673]: seen 67300 examples : 67.7 eps, Loss: 5.616, Avg loss: 5.701, Best loss: 5.698\n",
      "    [batch 680]: seen 68000 examples : 67.7 eps, Loss: 5.745, Avg loss: 5.700, Best loss: 5.698\n",
      "    [batch 687]: seen 68700 examples : 67.7 eps, Loss: 5.646, Avg loss: 5.701, Best loss: 5.698\n",
      "    [batch 694]: seen 69400 examples : 67.7 eps, Loss: 5.698, Avg loss: 5.701, Best loss: 5.698\n",
      "    [batch 701]: seen 70100 examples : 67.7 eps, Loss: 5.651, Avg loss: 5.700, Best loss: 5.698\n",
      "    [batch 708]: seen 70800 examples : 67.7 eps, Loss: 5.712, Avg loss: 5.696, Best loss: 5.696\n",
      "    [batch 715]: seen 71500 examples : 67.7 eps, Loss: 5.641, Avg loss: 5.696, Best loss: 5.696\n",
      "    [batch 722]: seen 72200 examples : 67.7 eps, Loss: 5.692, Avg loss: 5.695, Best loss: 5.695\n",
      "    [batch 729]: seen 72900 examples : 67.7 eps, Loss: 5.607, Avg loss: 5.693, Best loss: 5.693\n",
      "    [batch 736]: seen 73600 examples : 67.7 eps, Loss: 5.732, Avg loss: 5.692, Best loss: 5.692\n",
      "    [batch 743]: seen 74300 examples : 67.7 eps, Loss: 5.597, Avg loss: 5.692, Best loss: 5.692\n",
      "    [batch 750]: seen 75000 examples : 67.7 eps, Loss: 5.606, Avg loss: 5.688, Best loss: 5.688\n",
      "    [batch 757]: seen 75700 examples : 67.7 eps, Loss: 5.605, Avg loss: 5.687, Best loss: 5.687\n",
      "    [batch 764]: seen 76400 examples : 67.7 eps, Loss: 5.742, Avg loss: 5.686, Best loss: 5.686\n",
      "    [batch 771]: seen 77100 examples : 67.7 eps, Loss: 5.708, Avg loss: 5.688, Best loss: 5.686\n",
      "    [batch 778]: seen 77800 examples : 67.7 eps, Loss: 5.674, Avg loss: 5.687, Best loss: 5.686\n",
      "    [batch 785]: seen 78500 examples : 67.7 eps, Loss: 5.702, Avg loss: 5.687, Best loss: 5.686\n",
      "    [batch 792]: seen 79200 examples : 67.7 eps, Loss: 5.640, Avg loss: 5.686, Best loss: 5.686\n",
      "    [batch 799]: seen 79900 examples : 67.7 eps, Loss: 5.609, Avg loss: 5.682, Best loss: 5.682\n",
      "    [batch 806]: seen 80600 examples : 67.7 eps, Loss: 5.715, Avg loss: 5.679, Best loss: 5.679\n",
      "    [batch 813]: seen 81300 examples : 67.7 eps, Loss: 5.590, Avg loss: 5.681, Best loss: 5.679\n",
      "    [batch 820]: seen 82000 examples : 67.7 eps, Loss: 5.641, Avg loss: 5.681, Best loss: 5.679\n",
      "    [batch 827]: seen 82700 examples : 67.7 eps, Loss: 5.681, Avg loss: 5.683, Best loss: 5.679\n",
      "    [batch 834]: seen 83400 examples : 67.7 eps, Loss: 5.699, Avg loss: 5.684, Best loss: 5.679\n",
      "    [batch 841]: seen 84100 examples : 67.7 eps, Loss: 5.729, Avg loss: 5.685, Best loss: 5.679\n",
      "    [batch 848]: seen 84800 examples : 67.7 eps, Loss: 5.723, Avg loss: 5.686, Best loss: 5.679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 855]: seen 85500 examples : 67.7 eps, Loss: 5.654, Avg loss: 5.685, Best loss: 5.679\n",
      "    [batch 862]: seen 86200 examples : 67.7 eps, Loss: 5.785, Avg loss: 5.687, Best loss: 5.679\n",
      "    [batch 869]: seen 86900 examples : 67.7 eps, Loss: 5.682, Avg loss: 5.690, Best loss: 5.679\n",
      "    [batch 876]: seen 87600 examples : 67.7 eps, Loss: 5.652, Avg loss: 5.691, Best loss: 5.679\n",
      "    [batch 883]: seen 88300 examples : 67.7 eps, Loss: 5.740, Avg loss: 5.692, Best loss: 5.679\n",
      "    [batch 890]: seen 89000 examples : 67.7 eps, Loss: 5.543, Avg loss: 5.689, Best loss: 5.679\n",
      "    [batch 897]: seen 89700 examples : 67.7 eps, Loss: 5.571, Avg loss: 5.687, Best loss: 5.679\n",
      "    [batch 904]: seen 90400 examples : 67.7 eps, Loss: 5.782, Avg loss: 5.686, Best loss: 5.679\n",
      "    [batch 911]: seen 91100 examples : 67.7 eps, Loss: 5.709, Avg loss: 5.686, Best loss: 5.679\n",
      "    [batch 918]: seen 91800 examples : 67.7 eps, Loss: 5.752, Avg loss: 5.686, Best loss: 5.679\n",
      "    [batch 925]: seen 92500 examples : 67.7 eps, Loss: 5.666, Avg loss: 5.685, Best loss: 5.679\n",
      "    [batch 932]: seen 93200 examples : 67.7 eps, Loss: 5.698, Avg loss: 5.686, Best loss: 5.679\n",
      "    [batch 939]: seen 93900 examples : 67.7 eps, Loss: 5.623, Avg loss: 5.686, Best loss: 5.679\n",
      "    [batch 946]: seen 94600 examples : 67.7 eps, Loss: 5.738, Avg loss: 5.685, Best loss: 5.679\n",
      "    [batch 953]: seen 95300 examples : 67.7 eps, Loss: 5.655, Avg loss: 5.684, Best loss: 5.679\n",
      "    [batch 960]: seen 96000 examples : 67.7 eps, Loss: 5.671, Avg loss: 5.682, Best loss: 5.679\n",
      "    [batch 967]: seen 96700 examples : 67.7 eps, Loss: 5.686, Avg loss: 5.683, Best loss: 5.679\n",
      "    [batch 974]: seen 97400 examples : 67.7 eps, Loss: 5.590, Avg loss: 5.681, Best loss: 5.679\n",
      "    [batch 981]: seen 98100 examples : 67.7 eps, Loss: 5.655, Avg loss: 5.679, Best loss: 5.679\n",
      "    [batch 988]: seen 98800 examples : 67.7 eps, Loss: 5.627, Avg loss: 5.680, Best loss: 5.678\n",
      "    [batch 995]: seen 99500 examples : 67.7 eps, Loss: 5.718, Avg loss: 5.681, Best loss: 5.678\n",
      "    [batch 1002]: seen 100200 examples : 67.7 eps, Loss: 5.688, Avg loss: 5.680, Best loss: 5.678\n",
      "    [batch 1009]: seen 100900 examples : 67.7 eps, Loss: 5.610, Avg loss: 5.679, Best loss: 5.678\n",
      "    [batch 1016]: seen 101600 examples : 67.7 eps, Loss: 5.764, Avg loss: 5.680, Best loss: 5.678\n",
      "    [batch 1023]: seen 102300 examples : 67.7 eps, Loss: 5.655, Avg loss: 5.680, Best loss: 5.678\n",
      "    [batch 1030]: seen 103000 examples : 67.7 eps, Loss: 5.712, Avg loss: 5.682, Best loss: 5.678\n",
      "    [batch 1037]: seen 103700 examples : 67.7 eps, Loss: 5.583, Avg loss: 5.678, Best loss: 5.678\n",
      "    [batch 1044]: seen 104400 examples : 67.7 eps, Loss: 5.578, Avg loss: 5.678, Best loss: 5.678\n",
      "    [batch 1051]: seen 105100 examples : 67.7 eps, Loss: 5.738, Avg loss: 5.679, Best loss: 5.678\n",
      "    [batch 1058]: seen 105800 examples : 67.7 eps, Loss: 5.647, Avg loss: 5.678, Best loss: 5.678\n",
      "    [batch 1065]: seen 106500 examples : 67.7 eps, Loss: 5.696, Avg loss: 5.678, Best loss: 5.678\n",
      "    [batch 1072]: seen 107200 examples : 67.7 eps, Loss: 5.584, Avg loss: 5.677, Best loss: 5.677\n",
      "    [batch 1079]: seen 107900 examples : 67.7 eps, Loss: 5.634, Avg loss: 5.676, Best loss: 5.676\n",
      "    [batch 1086]: seen 108600 examples : 67.7 eps, Loss: 5.707, Avg loss: 5.676, Best loss: 5.674\n",
      "    [batch 1093]: seen 109300 examples : 67.7 eps, Loss: 5.786, Avg loss: 5.678, Best loss: 5.674\n",
      "    [batch 1100]: seen 110000 examples : 67.7 eps, Loss: 5.671, Avg loss: 5.679, Best loss: 5.674\n",
      "    [batch 1107]: seen 110700 examples : 67.7 eps, Loss: 5.811, Avg loss: 5.680, Best loss: 5.674\n",
      "    [batch 1114]: seen 111400 examples : 67.7 eps, Loss: 5.705, Avg loss: 5.680, Best loss: 5.674\n",
      "    [batch 1121]: seen 112100 examples : 67.7 eps, Loss: 5.643, Avg loss: 5.680, Best loss: 5.674\n",
      "    [batch 1128]: seen 112800 examples : 67.7 eps, Loss: 5.685, Avg loss: 5.678, Best loss: 5.674\n",
      "    [batch 1135]: seen 113500 examples : 67.7 eps, Loss: 5.714, Avg loss: 5.681, Best loss: 5.674\n",
      "    [batch 1142]: seen 114200 examples : 67.7 eps, Loss: 5.727, Avg loss: 5.679, Best loss: 5.674\n",
      "    [batch 1149]: seen 114900 examples : 67.7 eps, Loss: 5.740, Avg loss: 5.679, Best loss: 5.674\n",
      "    [batch 1156]: seen 115600 examples : 67.7 eps, Loss: 5.605, Avg loss: 5.675, Best loss: 5.674\n",
      "    [batch 1163]: seen 116300 examples : 67.7 eps, Loss: 5.622, Avg loss: 5.676, Best loss: 5.674\n",
      "    [batch 1170]: seen 117000 examples : 67.7 eps, Loss: 5.694, Avg loss: 5.680, Best loss: 5.674\n",
      "    [batch 1177]: seen 117700 examples : 67.7 eps, Loss: 5.660, Avg loss: 5.678, Best loss: 5.674\n",
      "    [batch 1184]: seen 118400 examples : 67.7 eps, Loss: 5.681, Avg loss: 5.681, Best loss: 5.674\n",
      "    [batch 1191]: seen 119100 examples : 67.7 eps, Loss: 5.707, Avg loss: 5.681, Best loss: 5.674\n",
      "    [batch 1198]: seen 119800 examples : 67.7 eps, Loss: 5.648, Avg loss: 5.679, Best loss: 5.674\n",
      "    [batch 1205]: seen 120500 examples : 67.7 eps, Loss: 5.711, Avg loss: 5.677, Best loss: 5.674\n",
      "    [batch 1212]: seen 121200 examples : 67.7 eps, Loss: 5.586, Avg loss: 5.675, Best loss: 5.674\n",
      "    [batch 1219]: seen 121900 examples : 67.7 eps, Loss: 5.633, Avg loss: 5.674, Best loss: 5.674\n",
      "    [batch 1226]: seen 122600 examples : 67.7 eps, Loss: 5.657, Avg loss: 5.674, Best loss: 5.673\n",
      "    [batch 1233]: seen 123300 examples : 67.7 eps, Loss: 5.726, Avg loss: 5.673, Best loss: 5.673\n",
      "    [batch 1240]: seen 124000 examples : 67.7 eps, Loss: 5.616, Avg loss: 5.673, Best loss: 5.673\n",
      "    [batch 1247]: seen 124700 examples : 67.7 eps, Loss: 5.712, Avg loss: 5.671, Best loss: 5.671\n",
      "    [batch 1254]: seen 125400 examples : 67.7 eps, Loss: 5.718, Avg loss: 5.672, Best loss: 5.671\n",
      "    [batch 1261]: seen 126100 examples : 67.7 eps, Loss: 5.769, Avg loss: 5.673, Best loss: 5.671\n",
      "    [batch 1268]: seen 126800 examples : 67.7 eps, Loss: 5.647, Avg loss: 5.673, Best loss: 5.671\n",
      "    [batch 1275]: seen 127500 examples : 67.7 eps, Loss: 5.589, Avg loss: 5.671, Best loss: 5.671\n",
      "    [batch 1282]: seen 128200 examples : 67.7 eps, Loss: 5.642, Avg loss: 5.669, Best loss: 5.669\n",
      "    [batch 1289]: seen 128900 examples : 67.7 eps, Loss: 5.659, Avg loss: 5.669, Best loss: 5.669\n",
      "    [batch 1296]: seen 129600 examples : 67.7 eps, Loss: 5.614, Avg loss: 5.668, Best loss: 5.668\n",
      "    [batch 1303]: seen 130300 examples : 67.7 eps, Loss: 5.679, Avg loss: 5.670, Best loss: 5.668\n",
      "    [batch 1310]: seen 131000 examples : 67.7 eps, Loss: 5.671, Avg loss: 5.668, Best loss: 5.668\n",
      "    [batch 1317]: seen 131700 examples : 67.7 eps, Loss: 5.726, Avg loss: 5.669, Best loss: 5.668\n",
      "    [batch 1324]: seen 132400 examples : 67.7 eps, Loss: 5.629, Avg loss: 5.667, Best loss: 5.667\n",
      "    [batch 1331]: seen 133100 examples : 67.7 eps, Loss: 5.817, Avg loss: 5.668, Best loss: 5.665\n",
      "    [batch 1338]: seen 133800 examples : 67.7 eps, Loss: 5.647, Avg loss: 5.666, Best loss: 5.665\n",
      "    [batch 1345]: seen 134500 examples : 67.7 eps, Loss: 5.621, Avg loss: 5.664, Best loss: 5.664\n",
      "    [batch 1352]: seen 135200 examples : 67.7 eps, Loss: 5.736, Avg loss: 5.663, Best loss: 5.662\n",
      "    [batch 1359]: seen 135900 examples : 67.7 eps, Loss: 5.880, Avg loss: 5.669, Best loss: 5.662\n",
      "    [batch 1366]: seen 136600 examples : 67.7 eps, Loss: 5.648, Avg loss: 5.673, Best loss: 5.662\n",
      "    [batch 1373]: seen 137300 examples : 67.7 eps, Loss: 5.780, Avg loss: 5.675, Best loss: 5.662\n",
      "    [batch 1380]: seen 138000 examples : 67.7 eps, Loss: 5.715, Avg loss: 5.673, Best loss: 5.662\n",
      "    [batch 1387]: seen 138700 examples : 67.7 eps, Loss: 5.672, Avg loss: 5.673, Best loss: 5.662\n",
      "    [batch 1394]: seen 139400 examples : 67.7 eps, Loss: 5.722, Avg loss: 5.671, Best loss: 5.662\n",
      "    [batch 1401]: seen 140100 examples : 67.7 eps, Loss: 5.748, Avg loss: 5.670, Best loss: 5.662\n",
      "    [batch 1408]: seen 140800 examples : 67.7 eps, Loss: 5.622, Avg loss: 5.670, Best loss: 5.662\n",
      "    [batch 1415]: seen 141500 examples : 67.7 eps, Loss: 5.627, Avg loss: 5.668, Best loss: 5.662\n",
      "    [batch 1422]: seen 142200 examples : 67.7 eps, Loss: 5.751, Avg loss: 5.666, Best loss: 5.662\n",
      "    [batch 1429]: seen 142900 examples : 67.7 eps, Loss: 5.526, Avg loss: 5.667, Best loss: 5.662\n",
      "    [batch 1436]: seen 143600 examples : 67.7 eps, Loss: 5.665, Avg loss: 5.665, Best loss: 5.662\n",
      "    [batch 1443]: seen 144300 examples : 67.7 eps, Loss: 5.699, Avg loss: 5.666, Best loss: 5.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1450]: seen 145000 examples : 67.7 eps, Loss: 5.744, Avg loss: 5.668, Best loss: 5.662\n",
      "    [batch 1457]: seen 145700 examples : 67.6 eps, Loss: 5.657, Avg loss: 5.667, Best loss: 5.662\n",
      "    [batch 1464]: seen 146400 examples : 67.6 eps, Loss: 5.677, Avg loss: 5.665, Best loss: 5.662\n",
      "    [batch 1471]: seen 147100 examples : 67.6 eps, Loss: 5.600, Avg loss: 5.665, Best loss: 5.662\n",
      "    [batch 1478]: seen 147800 examples : 67.6 eps, Loss: 5.709, Avg loss: 5.663, Best loss: 5.662\n",
      "    [batch 1485]: seen 148500 examples : 67.6 eps, Loss: 5.569, Avg loss: 5.661, Best loss: 5.661\n",
      "    [batch 1492]: seen 149200 examples : 67.6 eps, Loss: 5.755, Avg loss: 5.661, Best loss: 5.659\n",
      "    [batch 1499]: seen 149900 examples : 67.6 eps, Loss: 5.653, Avg loss: 5.660, Best loss: 5.659\n",
      "    [batch 1506]: seen 150600 examples : 67.6 eps, Loss: 5.658, Avg loss: 5.660, Best loss: 5.659\n",
      "    [batch 1513]: seen 151300 examples : 67.6 eps, Loss: 5.640, Avg loss: 5.660, Best loss: 5.659\n",
      "    [batch 1520]: seen 152000 examples : 67.6 eps, Loss: 5.683, Avg loss: 5.660, Best loss: 5.659\n",
      "    [batch 1527]: seen 152700 examples : 67.6 eps, Loss: 5.840, Avg loss: 5.664, Best loss: 5.659\n",
      "    [batch 1534]: seen 153400 examples : 67.6 eps, Loss: 5.662, Avg loss: 5.665, Best loss: 5.659\n",
      "    [batch 1541]: seen 154100 examples : 67.6 eps, Loss: 5.727, Avg loss: 5.665, Best loss: 5.659\n",
      "    [batch 1548]: seen 154800 examples : 67.6 eps, Loss: 5.599, Avg loss: 5.663, Best loss: 5.659\n",
      "    [batch 1555]: seen 155500 examples : 67.6 eps, Loss: 5.656, Avg loss: 5.662, Best loss: 5.659\n",
      "    [batch 1562]: seen 156200 examples : 67.6 eps, Loss: 5.639, Avg loss: 5.661, Best loss: 5.659\n",
      "    [batch 1569]: seen 156900 examples : 67.6 eps, Loss: 5.659, Avg loss: 5.661, Best loss: 5.659\n",
      "    [batch 1576]: seen 157600 examples : 67.6 eps, Loss: 5.620, Avg loss: 5.661, Best loss: 5.659\n",
      "    [batch 1583]: seen 158300 examples : 67.6 eps, Loss: 5.786, Avg loss: 5.661, Best loss: 5.659\n",
      "    [batch 1590]: seen 159000 examples : 67.6 eps, Loss: 5.645, Avg loss: 5.658, Best loss: 5.658\n",
      "    [batch 1597]: seen 159700 examples : 67.6 eps, Loss: 5.719, Avg loss: 5.661, Best loss: 5.658\n",
      "    [batch 1604]: seen 160400 examples : 67.6 eps, Loss: 5.635, Avg loss: 5.661, Best loss: 5.658\n",
      "    [batch 1611]: seen 161100 examples : 67.6 eps, Loss: 5.663, Avg loss: 5.659, Best loss: 5.658\n",
      "    [batch 1618]: seen 161800 examples : 67.6 eps, Loss: 5.636, Avg loss: 5.658, Best loss: 5.658\n",
      "    [batch 1625]: seen 162500 examples : 67.6 eps, Loss: 5.650, Avg loss: 5.657, Best loss: 5.657\n",
      "    [batch 1632]: seen 163200 examples : 67.6 eps, Loss: 5.651, Avg loss: 5.657, Best loss: 5.657\n",
      "    [batch 1639]: seen 163900 examples : 67.6 eps, Loss: 5.657, Avg loss: 5.655, Best loss: 5.655\n",
      "    [batch 1646]: seen 164600 examples : 67.6 eps, Loss: 5.629, Avg loss: 5.653, Best loss: 5.653\n",
      "    [batch 1653]: seen 165300 examples : 67.6 eps, Loss: 5.591, Avg loss: 5.653, Best loss: 5.652\n",
      "    [batch 1660]: seen 166000 examples : 67.6 eps, Loss: 5.644, Avg loss: 5.651, Best loss: 5.651\n",
      "    [batch 1667]: seen 166700 examples : 67.6 eps, Loss: 5.685, Avg loss: 5.651, Best loss: 5.650\n",
      "    [batch 1674]: seen 167400 examples : 67.6 eps, Loss: 5.606, Avg loss: 5.653, Best loss: 5.650\n",
      "    [batch 1681]: seen 168100 examples : 67.6 eps, Loss: 5.735, Avg loss: 5.654, Best loss: 5.650\n",
      "    [batch 1688]: seen 168800 examples : 67.6 eps, Loss: 5.725, Avg loss: 5.655, Best loss: 5.650\n",
      "    [batch 1695]: seen 169500 examples : 67.6 eps, Loss: 5.669, Avg loss: 5.655, Best loss: 5.650\n",
      "    [batch 1702]: seen 170200 examples : 67.6 eps, Loss: 5.617, Avg loss: 5.652, Best loss: 5.650\n",
      "    [batch 1709]: seen 170900 examples : 67.6 eps, Loss: 5.643, Avg loss: 5.654, Best loss: 5.650\n",
      "    [batch 1716]: seen 171600 examples : 67.6 eps, Loss: 5.685, Avg loss: 5.652, Best loss: 5.650\n",
      "    [batch 1723]: seen 172300 examples : 67.6 eps, Loss: 5.671, Avg loss: 5.652, Best loss: 5.650\n",
      "    [batch 1730]: seen 173000 examples : 67.6 eps, Loss: 5.666, Avg loss: 5.651, Best loss: 5.650\n",
      "    [batch 1737]: seen 173700 examples : 67.6 eps, Loss: 5.671, Avg loss: 5.650, Best loss: 5.649\n",
      "    [batch 1744]: seen 174400 examples : 67.6 eps, Loss: 5.614, Avg loss: 5.647, Best loss: 5.647\n",
      "    [batch 1751]: seen 175100 examples : 67.6 eps, Loss: 5.650, Avg loss: 5.649, Best loss: 5.647\n",
      "    [batch 1758]: seen 175800 examples : 67.6 eps, Loss: 5.719, Avg loss: 5.654, Best loss: 5.647\n",
      "    [batch 1765]: seen 176500 examples : 67.6 eps, Loss: 5.663, Avg loss: 5.655, Best loss: 5.647\n",
      "    [batch 1772]: seen 177200 examples : 67.6 eps, Loss: 5.565, Avg loss: 5.658, Best loss: 5.647\n",
      "    [batch 1779]: seen 177900 examples : 67.6 eps, Loss: 5.707, Avg loss: 5.657, Best loss: 5.647\n",
      "    [batch 1786]: seen 178600 examples : 67.6 eps, Loss: 5.725, Avg loss: 5.655, Best loss: 5.647\n",
      "    [batch 1793]: seen 179300 examples : 67.6 eps, Loss: 5.637, Avg loss: 5.658, Best loss: 5.647\n",
      "    [batch 1800]: seen 180000 examples : 67.6 eps, Loss: 5.676, Avg loss: 5.659, Best loss: 5.647\n",
      "    [batch 1807]: seen 180700 examples : 67.6 eps, Loss: 5.710, Avg loss: 5.659, Best loss: 5.647\n",
      "    [batch 1814]: seen 181400 examples : 67.6 eps, Loss: 5.561, Avg loss: 5.657, Best loss: 5.647\n",
      "    [batch 1821]: seen 182100 examples : 67.6 eps, Loss: 5.665, Avg loss: 5.657, Best loss: 5.647\n",
      "    [batch 1828]: seen 182800 examples : 67.6 eps, Loss: 5.680, Avg loss: 5.655, Best loss: 5.647\n",
      "    [batch 1835]: seen 183500 examples : 67.6 eps, Loss: 5.611, Avg loss: 5.653, Best loss: 5.647\n",
      "    [batch 1842]: seen 184200 examples : 67.6 eps, Loss: 5.582, Avg loss: 5.650, Best loss: 5.647\n",
      "    [batch 1849]: seen 184900 examples : 67.6 eps, Loss: 5.578, Avg loss: 5.648, Best loss: 5.647\n",
      "    [batch 1856]: seen 185600 examples : 67.6 eps, Loss: 5.562, Avg loss: 5.647, Best loss: 5.647\n",
      "    [batch 1863]: seen 186300 examples : 67.6 eps, Loss: 5.620, Avg loss: 5.647, Best loss: 5.647\n",
      "    [batch 1870]: seen 187000 examples : 67.6 eps, Loss: 5.718, Avg loss: 5.648, Best loss: 5.647\n",
      "    [batch 1877]: seen 187700 examples : 67.6 eps, Loss: 5.679, Avg loss: 5.650, Best loss: 5.647\n",
      "    [batch 1884]: seen 188400 examples : 67.6 eps, Loss: 5.549, Avg loss: 5.648, Best loss: 5.647\n",
      "    [batch 1891]: seen 189100 examples : 67.6 eps, Loss: 5.611, Avg loss: 5.648, Best loss: 5.647\n",
      "    [batch 1898]: seen 189800 examples : 67.6 eps, Loss: 5.665, Avg loss: 5.647, Best loss: 5.647\n",
      "    [batch 1905]: seen 190500 examples : 67.6 eps, Loss: 5.543, Avg loss: 5.647, Best loss: 5.647\n",
      "    [batch 1912]: seen 191200 examples : 67.6 eps, Loss: 5.620, Avg loss: 5.644, Best loss: 5.644\n",
      "    [batch 1919]: seen 191900 examples : 67.6 eps, Loss: 5.654, Avg loss: 5.645, Best loss: 5.644\n",
      "    [batch 1926]: seen 192600 examples : 67.6 eps, Loss: 5.683, Avg loss: 5.642, Best loss: 5.642\n",
      "    [batch 1933]: seen 193300 examples : 67.6 eps, Loss: 5.653, Avg loss: 5.643, Best loss: 5.642\n",
      "    [batch 1940]: seen 194000 examples : 67.6 eps, Loss: 5.671, Avg loss: 5.644, Best loss: 5.642\n",
      "    [batch 1947]: seen 194700 examples : 67.6 eps, Loss: 5.608, Avg loss: 5.643, Best loss: 5.642\n",
      "    [batch 1954]: seen 195400 examples : 67.6 eps, Loss: 5.525, Avg loss: 5.641, Best loss: 5.641\n",
      "    [batch 1961]: seen 196100 examples : 67.6 eps, Loss: 5.699, Avg loss: 5.640, Best loss: 5.639\n",
      "    [batch 1968]: seen 196800 examples : 67.6 eps, Loss: 5.696, Avg loss: 5.639, Best loss: 5.638\n",
      "    [batch 1975]: seen 197500 examples : 67.6 eps, Loss: 5.645, Avg loss: 5.639, Best loss: 5.638\n",
      "    [batch 1980]: seen 198000 examples : 67.5 eps, Loss: 5.612, Avg loss: 5.640, Best loss: 5.638\n",
      "    [batch 1987]: seen 198700 examples : 67.5 eps, Loss: 5.614, Avg loss: 5.641, Best loss: 5.638\n",
      "    [batch 1994]: seen 199400 examples : 67.5 eps, Loss: 5.601, Avg loss: 5.643, Best loss: 5.638\n",
      "    [batch 2001]: seen 200100 examples : 67.5 eps, Loss: 5.598, Avg loss: 5.639, Best loss: 5.638\n",
      "    [batch 2008]: seen 200800 examples : 67.5 eps, Loss: 5.548, Avg loss: 5.639, Best loss: 5.638\n",
      "    [batch 2015]: seen 201500 examples : 67.5 eps, Loss: 5.638, Avg loss: 5.639, Best loss: 5.638\n",
      "    [batch 2022]: seen 202200 examples : 67.5 eps, Loss: 5.641, Avg loss: 5.640, Best loss: 5.638\n",
      "    [batch 2029]: seen 202900 examples : 67.5 eps, Loss: 5.576, Avg loss: 5.638, Best loss: 5.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2036]: seen 203600 examples : 67.5 eps, Loss: 5.627, Avg loss: 5.639, Best loss: 5.637\n",
      "    [batch 2043]: seen 204300 examples : 67.5 eps, Loss: 5.499, Avg loss: 5.638, Best loss: 5.637\n",
      "    [batch 2050]: seen 205000 examples : 67.5 eps, Loss: 5.615, Avg loss: 5.639, Best loss: 5.637\n",
      "    [batch 2057]: seen 205700 examples : 67.5 eps, Loss: 5.749, Avg loss: 5.641, Best loss: 5.637\n",
      "    [batch 2064]: seen 206400 examples : 67.5 eps, Loss: 5.595, Avg loss: 5.641, Best loss: 5.637\n",
      "    [batch 2071]: seen 207100 examples : 67.6 eps, Loss: 5.695, Avg loss: 5.642, Best loss: 5.637\n",
      "    [batch 2078]: seen 207800 examples : 67.6 eps, Loss: 5.656, Avg loss: 5.642, Best loss: 5.637\n",
      "    [batch 2085]: seen 208500 examples : 67.6 eps, Loss: 5.629, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2092]: seen 209200 examples : 67.6 eps, Loss: 5.690, Avg loss: 5.641, Best loss: 5.637\n",
      "    [batch 2099]: seen 209900 examples : 67.6 eps, Loss: 5.646, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2106]: seen 210600 examples : 67.6 eps, Loss: 5.592, Avg loss: 5.641, Best loss: 5.637\n",
      "    [batch 2113]: seen 211300 examples : 67.6 eps, Loss: 5.552, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2120]: seen 212000 examples : 67.6 eps, Loss: 5.584, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2127]: seen 212700 examples : 67.6 eps, Loss: 5.680, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2134]: seen 213400 examples : 67.6 eps, Loss: 5.517, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2141]: seen 214100 examples : 67.6 eps, Loss: 5.566, Avg loss: 5.640, Best loss: 5.637\n",
      "    [batch 2148]: seen 214800 examples : 67.6 eps, Loss: 5.611, Avg loss: 5.638, Best loss: 5.637\n",
      "    [batch 2155]: seen 215500 examples : 67.6 eps, Loss: 5.617, Avg loss: 5.636, Best loss: 5.636\n",
      "    [batch 2162]: seen 216200 examples : 67.6 eps, Loss: 5.642, Avg loss: 5.632, Best loss: 5.632\n",
      "    [batch 2169]: seen 216900 examples : 67.6 eps, Loss: 5.651, Avg loss: 5.634, Best loss: 5.632\n",
      "    [batch 2176]: seen 217600 examples : 67.6 eps, Loss: 5.636, Avg loss: 5.636, Best loss: 5.632\n",
      "    [batch 2183]: seen 218300 examples : 67.6 eps, Loss: 5.674, Avg loss: 5.635, Best loss: 5.632\n",
      "    [batch 2190]: seen 219000 examples : 67.6 eps, Loss: 5.600, Avg loss: 5.634, Best loss: 5.632\n",
      "    [batch 2197]: seen 219700 examples : 67.6 eps, Loss: 5.675, Avg loss: 5.636, Best loss: 5.632\n",
      "    [batch 2204]: seen 220400 examples : 67.6 eps, Loss: 5.597, Avg loss: 5.637, Best loss: 5.632\n",
      "    [batch 2211]: seen 221100 examples : 67.6 eps, Loss: 5.647, Avg loss: 5.637, Best loss: 5.632\n",
      "    [batch 2218]: seen 221800 examples : 67.6 eps, Loss: 5.617, Avg loss: 5.635, Best loss: 5.632\n",
      "    [batch 2225]: seen 222500 examples : 67.6 eps, Loss: 5.570, Avg loss: 5.633, Best loss: 5.632\n",
      "    [batch 2232]: seen 223200 examples : 67.6 eps, Loss: 5.740, Avg loss: 5.634, Best loss: 5.632\n",
      "    [batch 2239]: seen 223900 examples : 67.6 eps, Loss: 5.532, Avg loss: 5.632, Best loss: 5.632\n",
      "    [batch 2246]: seen 224600 examples : 67.6 eps, Loss: 5.719, Avg loss: 5.634, Best loss: 5.632\n",
      "    [batch 2253]: seen 225300 examples : 67.6 eps, Loss: 5.557, Avg loss: 5.631, Best loss: 5.631\n",
      "    [batch 2260]: seen 226000 examples : 67.6 eps, Loss: 5.685, Avg loss: 5.629, Best loss: 5.629\n",
      "    [batch 2267]: seen 226700 examples : 67.5 eps, Loss: 5.637, Avg loss: 5.631, Best loss: 5.629\n",
      "    [batch 2274]: seen 227400 examples : 67.6 eps, Loss: 5.640, Avg loss: 5.631, Best loss: 5.629\n",
      "    [batch 2281]: seen 228100 examples : 67.6 eps, Loss: 5.619, Avg loss: 5.630, Best loss: 5.629\n",
      "    [batch 2288]: seen 228800 examples : 67.6 eps, Loss: 5.653, Avg loss: 5.627, Best loss: 5.627\n",
      "    [batch 2295]: seen 229500 examples : 67.6 eps, Loss: 5.625, Avg loss: 5.627, Best loss: 5.626\n",
      "    [batch 2302]: seen 230200 examples : 67.6 eps, Loss: 5.654, Avg loss: 5.628, Best loss: 5.626\n",
      "    [batch 2309]: seen 230900 examples : 67.6 eps, Loss: 5.646, Avg loss: 5.627, Best loss: 5.626\n",
      "    [batch 2316]: seen 231600 examples : 67.6 eps, Loss: 5.596, Avg loss: 5.626, Best loss: 5.626\n",
      "    [batch 2323]: seen 232300 examples : 67.6 eps, Loss: 5.646, Avg loss: 5.626, Best loss: 5.626\n",
      "    [batch 2330]: seen 233000 examples : 67.6 eps, Loss: 5.556, Avg loss: 5.626, Best loss: 5.625\n",
      "    [batch 2337]: seen 233700 examples : 67.6 eps, Loss: 5.618, Avg loss: 5.626, Best loss: 5.625\n",
      "    [batch 2344]: seen 234400 examples : 67.6 eps, Loss: 5.571, Avg loss: 5.625, Best loss: 5.623\n",
      "    [batch 2351]: seen 235100 examples : 67.6 eps, Loss: 5.532, Avg loss: 5.625, Best loss: 5.623\n",
      "    [batch 2358]: seen 235800 examples : 67.6 eps, Loss: 5.711, Avg loss: 5.624, Best loss: 5.623\n",
      "    [batch 2365]: seen 236500 examples : 67.6 eps, Loss: 5.597, Avg loss: 5.625, Best loss: 5.623\n",
      "    [batch 2372]: seen 237200 examples : 67.6 eps, Loss: 5.655, Avg loss: 5.625, Best loss: 5.623\n",
      "    [batch 2379]: seen 237900 examples : 67.6 eps, Loss: 5.638, Avg loss: 5.626, Best loss: 5.623\n",
      "    [batch 2386]: seen 238600 examples : 67.6 eps, Loss: 5.587, Avg loss: 5.627, Best loss: 5.623\n",
      "    [batch 2393]: seen 239300 examples : 67.6 eps, Loss: 5.616, Avg loss: 5.629, Best loss: 5.623\n",
      "    [batch 2400]: seen 240000 examples : 67.6 eps, Loss: 5.585, Avg loss: 5.629, Best loss: 5.623\n",
      "    [batch 2407]: seen 240700 examples : 67.6 eps, Loss: 5.663, Avg loss: 5.629, Best loss: 5.623\n",
      "    [batch 2414]: seen 241400 examples : 67.6 eps, Loss: 5.586, Avg loss: 5.627, Best loss: 5.623\n",
      "    [batch 2421]: seen 242100 examples : 67.6 eps, Loss: 5.616, Avg loss: 5.624, Best loss: 5.623\n",
      "    [batch 2428]: seen 242800 examples : 67.6 eps, Loss: 5.603, Avg loss: 5.623, Best loss: 5.623\n",
      "    [batch 2435]: seen 243500 examples : 67.6 eps, Loss: 5.608, Avg loss: 5.620, Best loss: 5.620\n",
      "    [batch 2442]: seen 244200 examples : 67.6 eps, Loss: 5.647, Avg loss: 5.620, Best loss: 5.619\n",
      "    [batch 2449]: seen 244900 examples : 67.6 eps, Loss: 5.599, Avg loss: 5.616, Best loss: 5.616\n",
      "    [batch 2456]: seen 245600 examples : 67.6 eps, Loss: 5.582, Avg loss: 5.615, Best loss: 5.615\n",
      "    [batch 2463]: seen 246300 examples : 67.6 eps, Loss: 5.546, Avg loss: 5.614, Best loss: 5.613\n",
      "    [batch 2470]: seen 247000 examples : 67.6 eps, Loss: 5.674, Avg loss: 5.612, Best loss: 5.612\n",
      "    [batch 2477]: seen 247700 examples : 67.6 eps, Loss: 5.545, Avg loss: 5.611, Best loss: 5.611\n",
      "    [batch 2484]: seen 248400 examples : 67.6 eps, Loss: 5.551, Avg loss: 5.609, Best loss: 5.609\n",
      "    [batch 2491]: seen 249100 examples : 67.6 eps, Loss: 5.567, Avg loss: 5.612, Best loss: 5.609\n",
      "    [batch 2498]: seen 249800 examples : 67.6 eps, Loss: 5.624, Avg loss: 5.613, Best loss: 5.609\n",
      "    [batch 2505]: seen 250500 examples : 67.6 eps, Loss: 5.620, Avg loss: 5.610, Best loss: 5.609\n",
      "    [batch 2512]: seen 251200 examples : 67.6 eps, Loss: 5.680, Avg loss: 5.609, Best loss: 5.608\n",
      "    [batch 2519]: seen 251900 examples : 67.6 eps, Loss: 5.655, Avg loss: 5.610, Best loss: 5.608\n",
      "    [batch 2526]: seen 252600 examples : 67.6 eps, Loss: 5.643, Avg loss: 5.612, Best loss: 5.608\n",
      "    [batch 2533]: seen 253300 examples : 67.6 eps, Loss: 5.497, Avg loss: 5.608, Best loss: 5.608\n",
      "    [batch 2540]: seen 254000 examples : 67.6 eps, Loss: 5.649, Avg loss: 5.608, Best loss: 5.608\n",
      "    [batch 2547]: seen 254700 examples : 67.6 eps, Loss: 5.566, Avg loss: 5.608, Best loss: 5.607\n",
      "    [batch 2554]: seen 255400 examples : 67.6 eps, Loss: 5.685, Avg loss: 5.607, Best loss: 5.606\n",
      "    [batch 2561]: seen 256100 examples : 67.6 eps, Loss: 5.617, Avg loss: 5.607, Best loss: 5.606\n",
      "    [batch 2568]: seen 256800 examples : 67.6 eps, Loss: 5.530, Avg loss: 5.608, Best loss: 5.606\n",
      "    [batch 2575]: seen 257500 examples : 67.6 eps, Loss: 5.479, Avg loss: 5.606, Best loss: 5.606\n",
      "    [batch 2582]: seen 258200 examples : 67.6 eps, Loss: 5.620, Avg loss: 5.606, Best loss: 5.605\n",
      "    [batch 2589]: seen 258900 examples : 67.6 eps, Loss: 5.627, Avg loss: 5.607, Best loss: 5.605\n",
      "    [batch 2596]: seen 259600 examples : 67.6 eps, Loss: 5.567, Avg loss: 5.609, Best loss: 5.605\n",
      "    [batch 2603]: seen 260300 examples : 67.6 eps, Loss: 5.664, Avg loss: 5.609, Best loss: 5.605\n",
      "    [batch 2610]: seen 261000 examples : 67.6 eps, Loss: 5.659, Avg loss: 5.610, Best loss: 5.605\n",
      "    [batch 2617]: seen 261700 examples : 67.6 eps, Loss: 5.626, Avg loss: 5.609, Best loss: 5.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2624]: seen 262400 examples : 67.6 eps, Loss: 5.618, Avg loss: 5.609, Best loss: 5.605\n",
      "    [batch 2631]: seen 263100 examples : 67.6 eps, Loss: 5.636, Avg loss: 5.610, Best loss: 5.605\n",
      "    [batch 2638]: seen 263800 examples : 67.6 eps, Loss: 5.632, Avg loss: 5.610, Best loss: 5.605\n",
      "    [batch 2645]: seen 264500 examples : 67.6 eps, Loss: 5.560, Avg loss: 5.611, Best loss: 5.605\n",
      "    [batch 2652]: seen 265200 examples : 67.6 eps, Loss: 5.571, Avg loss: 5.609, Best loss: 5.605\n",
      "    [batch 2659]: seen 265900 examples : 67.6 eps, Loss: 5.632, Avg loss: 5.606, Best loss: 5.605\n",
      "    [batch 2666]: seen 266600 examples : 67.6 eps, Loss: 5.530, Avg loss: 5.605, Best loss: 5.605\n",
      "    [batch 2673]: seen 267300 examples : 67.6 eps, Loss: 5.617, Avg loss: 5.606, Best loss: 5.604\n",
      "    [batch 2680]: seen 268000 examples : 67.6 eps, Loss: 5.614, Avg loss: 5.607, Best loss: 5.604\n",
      "    [batch 2687]: seen 268700 examples : 67.6 eps, Loss: 5.655, Avg loss: 5.607, Best loss: 5.604\n",
      "    [batch 2694]: seen 269400 examples : 67.6 eps, Loss: 5.539, Avg loss: 5.607, Best loss: 5.604\n",
      "    [batch 2701]: seen 270100 examples : 67.6 eps, Loss: 5.495, Avg loss: 5.606, Best loss: 5.604\n",
      "    [batch 2708]: seen 270800 examples : 67.6 eps, Loss: 5.656, Avg loss: 5.606, Best loss: 5.604\n",
      "    [batch 2715]: seen 271500 examples : 67.6 eps, Loss: 5.637, Avg loss: 5.608, Best loss: 5.604\n",
      "    [batch 2722]: seen 272200 examples : 67.6 eps, Loss: 5.533, Avg loss: 5.607, Best loss: 5.604\n",
      "    [batch 2729]: seen 272900 examples : 67.6 eps, Loss: 5.652, Avg loss: 5.608, Best loss: 5.604\n",
      "    [batch 2736]: seen 273600 examples : 67.6 eps, Loss: 5.539, Avg loss: 5.604, Best loss: 5.604\n",
      "    [batch 2743]: seen 274300 examples : 67.6 eps, Loss: 5.689, Avg loss: 5.605, Best loss: 5.604\n",
      "    [batch 2750]: seen 275000 examples : 67.6 eps, Loss: 5.650, Avg loss: 5.606, Best loss: 5.602\n",
      "    [batch 2757]: seen 275700 examples : 67.6 eps, Loss: 5.637, Avg loss: 5.606, Best loss: 5.602\n",
      "    [batch 2764]: seen 276400 examples : 67.6 eps, Loss: 5.602, Avg loss: 5.604, Best loss: 5.602\n",
      "    [batch 2771]: seen 277100 examples : 67.6 eps, Loss: 5.731, Avg loss: 5.606, Best loss: 5.602\n",
      "    [batch 2778]: seen 277800 examples : 67.6 eps, Loss: 5.622, Avg loss: 5.603, Best loss: 5.602\n",
      "    [batch 2785]: seen 278500 examples : 67.6 eps, Loss: 5.630, Avg loss: 5.602, Best loss: 5.601\n",
      "    [batch 2792]: seen 279200 examples : 67.6 eps, Loss: 5.629, Avg loss: 5.602, Best loss: 5.601\n",
      "    [batch 2799]: seen 279900 examples : 67.6 eps, Loss: 5.600, Avg loss: 5.603, Best loss: 5.601\n",
      "    [batch 2806]: seen 280600 examples : 67.6 eps, Loss: 5.595, Avg loss: 5.604, Best loss: 5.601\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:16\n",
      "[EPOCH 7] Complete. Avg Loss: 5.603849202519363; Best Loss: 5.601329039026666\n",
      "[EPOCH 8] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.1 eps, Loss: 5.652, Avg loss: 5.604, Best loss: 5.601\n",
      "    [batch 16]: seen 1600 examples : 78.0 eps, Loss: 5.544, Avg loss: 5.601, Best loss: 5.601\n",
      "    [batch 23]: seen 2300 examples : 74.9 eps, Loss: 5.502, Avg loss: 5.599, Best loss: 5.599\n",
      "    [batch 30]: seen 3000 examples : 73.4 eps, Loss: 5.521, Avg loss: 5.597, Best loss: 5.597\n",
      "    [batch 37]: seen 3700 examples : 72.5 eps, Loss: 5.534, Avg loss: 5.594, Best loss: 5.594\n",
      "    [batch 44]: seen 4400 examples : 71.9 eps, Loss: 5.594, Avg loss: 5.591, Best loss: 5.591\n",
      "    [batch 51]: seen 5100 examples : 71.5 eps, Loss: 5.695, Avg loss: 5.594, Best loss: 5.591\n",
      "    [batch 58]: seen 5800 examples : 71.1 eps, Loss: 5.607, Avg loss: 5.595, Best loss: 5.591\n",
      "    [batch 65]: seen 6500 examples : 70.9 eps, Loss: 5.677, Avg loss: 5.595, Best loss: 5.591\n",
      "    [batch 72]: seen 7200 examples : 70.7 eps, Loss: 5.566, Avg loss: 5.596, Best loss: 5.591\n",
      "    [batch 79]: seen 7900 examples : 70.5 eps, Loss: 5.531, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 86]: seen 8600 examples : 70.4 eps, Loss: 5.626, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 93]: seen 9300 examples : 70.3 eps, Loss: 5.541, Avg loss: 5.598, Best loss: 5.591\n",
      "    [batch 100]: seen 10000 examples : 70.2 eps, Loss: 5.626, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 107]: seen 10700 examples : 70.1 eps, Loss: 5.574, Avg loss: 5.595, Best loss: 5.591\n",
      "    [batch 114]: seen 11400 examples : 69.8 eps, Loss: 5.633, Avg loss: 5.595, Best loss: 5.591\n",
      "    [batch 121]: seen 12100 examples : 69.7 eps, Loss: 5.548, Avg loss: 5.594, Best loss: 5.591\n",
      "    [batch 128]: seen 12800 examples : 69.5 eps, Loss: 5.538, Avg loss: 5.595, Best loss: 5.591\n",
      "    [batch 135]: seen 13500 examples : 69.4 eps, Loss: 5.622, Avg loss: 5.591, Best loss: 5.591\n",
      "    [batch 142]: seen 14200 examples : 69.3 eps, Loss: 5.668, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 149]: seen 14900 examples : 69.2 eps, Loss: 5.605, Avg loss: 5.599, Best loss: 5.591\n",
      "    [batch 156]: seen 15600 examples : 69.2 eps, Loss: 5.621, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 163]: seen 16300 examples : 69.1 eps, Loss: 5.579, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 170]: seen 17000 examples : 69.0 eps, Loss: 5.611, Avg loss: 5.597, Best loss: 5.591\n",
      "    [batch 177]: seen 17700 examples : 69.0 eps, Loss: 5.463, Avg loss: 5.596, Best loss: 5.591\n",
      "    [batch 184]: seen 18400 examples : 68.9 eps, Loss: 5.605, Avg loss: 5.594, Best loss: 5.591\n",
      "    [batch 191]: seen 19100 examples : 68.9 eps, Loss: 5.598, Avg loss: 5.592, Best loss: 5.591\n",
      "    [batch 198]: seen 19800 examples : 68.9 eps, Loss: 5.653, Avg loss: 5.593, Best loss: 5.590\n",
      "    [batch 205]: seen 20500 examples : 68.8 eps, Loss: 5.592, Avg loss: 5.593, Best loss: 5.590\n",
      "    [batch 212]: seen 21200 examples : 68.8 eps, Loss: 5.683, Avg loss: 5.593, Best loss: 5.590\n",
      "    [batch 219]: seen 21900 examples : 68.7 eps, Loss: 5.517, Avg loss: 5.591, Best loss: 5.590\n",
      "    [batch 226]: seen 22600 examples : 68.7 eps, Loss: 5.501, Avg loss: 5.592, Best loss: 5.590\n",
      "    [batch 233]: seen 23300 examples : 68.6 eps, Loss: 5.601, Avg loss: 5.591, Best loss: 5.590\n",
      "    [batch 240]: seen 24000 examples : 68.5 eps, Loss: 5.548, Avg loss: 5.592, Best loss: 5.590\n",
      "    [batch 247]: seen 24700 examples : 68.5 eps, Loss: 5.541, Avg loss: 5.592, Best loss: 5.590\n",
      "    [batch 254]: seen 25400 examples : 68.5 eps, Loss: 5.535, Avg loss: 5.592, Best loss: 5.590\n",
      "    [batch 261]: seen 26100 examples : 68.5 eps, Loss: 5.509, Avg loss: 5.592, Best loss: 5.590\n",
      "    [batch 268]: seen 26800 examples : 68.5 eps, Loss: 5.541, Avg loss: 5.588, Best loss: 5.588\n",
      "    [batch 275]: seen 27500 examples : 68.4 eps, Loss: 5.496, Avg loss: 5.585, Best loss: 5.585\n",
      "    [batch 282]: seen 28200 examples : 68.4 eps, Loss: 5.640, Avg loss: 5.585, Best loss: 5.584\n",
      "    [batch 289]: seen 28900 examples : 68.4 eps, Loss: 5.619, Avg loss: 5.585, Best loss: 5.584\n",
      "    [batch 296]: seen 29600 examples : 68.4 eps, Loss: 5.598, Avg loss: 5.582, Best loss: 5.582\n",
      "    [batch 303]: seen 30300 examples : 68.3 eps, Loss: 5.488, Avg loss: 5.580, Best loss: 5.580\n",
      "    [batch 310]: seen 31000 examples : 68.3 eps, Loss: 5.610, Avg loss: 5.580, Best loss: 5.580\n",
      "    [batch 317]: seen 31700 examples : 68.3 eps, Loss: 5.620, Avg loss: 5.581, Best loss: 5.580\n",
      "    [batch 324]: seen 32400 examples : 68.3 eps, Loss: 5.559, Avg loss: 5.581, Best loss: 5.580\n",
      "    [batch 331]: seen 33100 examples : 68.3 eps, Loss: 5.402, Avg loss: 5.580, Best loss: 5.580\n",
      "    [batch 338]: seen 33800 examples : 68.3 eps, Loss: 5.609, Avg loss: 5.581, Best loss: 5.579\n",
      "    [batch 345]: seen 34500 examples : 68.3 eps, Loss: 5.479, Avg loss: 5.578, Best loss: 5.578\n",
      "    [batch 352]: seen 35200 examples : 68.2 eps, Loss: 5.493, Avg loss: 5.579, Best loss: 5.577\n",
      "    [batch 359]: seen 35900 examples : 68.2 eps, Loss: 5.568, Avg loss: 5.579, Best loss: 5.577\n",
      "    [batch 366]: seen 36600 examples : 68.1 eps, Loss: 5.703, Avg loss: 5.577, Best loss: 5.575\n",
      "    [batch 373]: seen 37300 examples : 68.1 eps, Loss: 5.566, Avg loss: 5.577, Best loss: 5.575\n",
      "    [batch 380]: seen 38000 examples : 68.1 eps, Loss: 5.541, Avg loss: 5.577, Best loss: 5.575\n",
      "    [batch 387]: seen 38700 examples : 68.1 eps, Loss: 5.542, Avg loss: 5.577, Best loss: 5.575\n",
      "    [batch 394]: seen 39400 examples : 68.1 eps, Loss: 5.588, Avg loss: 5.579, Best loss: 5.575\n",
      "    [batch 401]: seen 40100 examples : 68.1 eps, Loss: 5.562, Avg loss: 5.579, Best loss: 5.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 408]: seen 40800 examples : 68.1 eps, Loss: 5.543, Avg loss: 5.578, Best loss: 5.575\n",
      "    [batch 415]: seen 41500 examples : 68.0 eps, Loss: 5.574, Avg loss: 5.579, Best loss: 5.575\n",
      "    [batch 422]: seen 42200 examples : 68.0 eps, Loss: 5.462, Avg loss: 5.577, Best loss: 5.575\n",
      "    [batch 429]: seen 42900 examples : 68.0 eps, Loss: 5.494, Avg loss: 5.575, Best loss: 5.575\n",
      "    [batch 436]: seen 43600 examples : 68.0 eps, Loss: 5.659, Avg loss: 5.574, Best loss: 5.573\n",
      "    [batch 443]: seen 44300 examples : 68.0 eps, Loss: 5.528, Avg loss: 5.571, Best loss: 5.571\n",
      "    [batch 450]: seen 45000 examples : 68.0 eps, Loss: 5.583, Avg loss: 5.569, Best loss: 5.569\n",
      "    [batch 457]: seen 45700 examples : 67.9 eps, Loss: 5.573, Avg loss: 5.571, Best loss: 5.569\n",
      "    [batch 464]: seen 46400 examples : 67.9 eps, Loss: 5.578, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 471]: seen 47100 examples : 67.9 eps, Loss: 5.542, Avg loss: 5.575, Best loss: 5.569\n",
      "    [batch 478]: seen 47800 examples : 67.9 eps, Loss: 5.521, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 485]: seen 48500 examples : 67.9 eps, Loss: 5.566, Avg loss: 5.573, Best loss: 5.569\n",
      "    [batch 492]: seen 49200 examples : 67.9 eps, Loss: 5.622, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 499]: seen 49900 examples : 67.9 eps, Loss: 5.586, Avg loss: 5.573, Best loss: 5.569\n",
      "    [batch 506]: seen 50600 examples : 67.9 eps, Loss: 5.541, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 513]: seen 51300 examples : 67.9 eps, Loss: 5.511, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 520]: seen 52000 examples : 67.9 eps, Loss: 5.625, Avg loss: 5.575, Best loss: 5.569\n",
      "    [batch 527]: seen 52700 examples : 67.9 eps, Loss: 5.623, Avg loss: 5.576, Best loss: 5.569\n",
      "    [batch 534]: seen 53400 examples : 67.8 eps, Loss: 5.493, Avg loss: 5.576, Best loss: 5.569\n",
      "    [batch 541]: seen 54100 examples : 67.8 eps, Loss: 5.528, Avg loss: 5.575, Best loss: 5.569\n",
      "    [batch 548]: seen 54800 examples : 67.8 eps, Loss: 5.633, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 555]: seen 55500 examples : 67.8 eps, Loss: 5.415, Avg loss: 5.572, Best loss: 5.569\n",
      "    [batch 562]: seen 56200 examples : 67.8 eps, Loss: 5.617, Avg loss: 5.570, Best loss: 5.569\n",
      "    [batch 569]: seen 56900 examples : 67.8 eps, Loss: 5.611, Avg loss: 5.570, Best loss: 5.569\n",
      "    [batch 576]: seen 57600 examples : 67.8 eps, Loss: 5.605, Avg loss: 5.571, Best loss: 5.569\n",
      "    [batch 583]: seen 58300 examples : 67.8 eps, Loss: 5.679, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 590]: seen 59000 examples : 67.8 eps, Loss: 5.670, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 597]: seen 59700 examples : 67.7 eps, Loss: 5.536, Avg loss: 5.574, Best loss: 5.569\n",
      "    [batch 604]: seen 60400 examples : 67.7 eps, Loss: 5.523, Avg loss: 5.572, Best loss: 5.569\n",
      "    [batch 611]: seen 61100 examples : 67.7 eps, Loss: 5.598, Avg loss: 5.572, Best loss: 5.569\n",
      "    [batch 618]: seen 61800 examples : 67.7 eps, Loss: 5.522, Avg loss: 5.570, Best loss: 5.569\n",
      "    [batch 625]: seen 62500 examples : 67.7 eps, Loss: 5.574, Avg loss: 5.568, Best loss: 5.568\n",
      "    [batch 631]: seen 63100 examples : 67.7 eps, Loss: 5.532, Avg loss: 5.566, Best loss: 5.566\n",
      "    [batch 638]: seen 63800 examples : 67.7 eps, Loss: 5.621, Avg loss: 5.568, Best loss: 5.566\n",
      "    [batch 645]: seen 64500 examples : 67.7 eps, Loss: 5.486, Avg loss: 5.566, Best loss: 5.566\n",
      "    [batch 652]: seen 65200 examples : 67.7 eps, Loss: 5.656, Avg loss: 5.566, Best loss: 5.565\n",
      "    [batch 659]: seen 65900 examples : 67.7 eps, Loss: 5.653, Avg loss: 5.568, Best loss: 5.565\n",
      "    [batch 666]: seen 66600 examples : 67.7 eps, Loss: 5.467, Avg loss: 5.567, Best loss: 5.565\n",
      "    [batch 673]: seen 67300 examples : 67.7 eps, Loss: 5.582, Avg loss: 5.568, Best loss: 5.565\n",
      "    [batch 680]: seen 68000 examples : 67.7 eps, Loss: 5.576, Avg loss: 5.567, Best loss: 5.565\n",
      "    [batch 687]: seen 68700 examples : 67.6 eps, Loss: 5.455, Avg loss: 5.564, Best loss: 5.564\n",
      "    [batch 694]: seen 69400 examples : 67.6 eps, Loss: 5.584, Avg loss: 5.566, Best loss: 5.564\n",
      "    [batch 701]: seen 70100 examples : 67.6 eps, Loss: 5.591, Avg loss: 5.566, Best loss: 5.564\n",
      "    [batch 708]: seen 70800 examples : 67.6 eps, Loss: 5.654, Avg loss: 5.567, Best loss: 5.564\n",
      "    [batch 715]: seen 71500 examples : 67.6 eps, Loss: 5.580, Avg loss: 5.565, Best loss: 5.564\n",
      "    [batch 722]: seen 72200 examples : 67.6 eps, Loss: 5.506, Avg loss: 5.567, Best loss: 5.564\n",
      "    [batch 729]: seen 72900 examples : 67.6 eps, Loss: 5.550, Avg loss: 5.568, Best loss: 5.564\n",
      "    [batch 736]: seen 73600 examples : 67.6 eps, Loss: 5.612, Avg loss: 5.569, Best loss: 5.564\n",
      "    [batch 743]: seen 74300 examples : 67.6 eps, Loss: 5.626, Avg loss: 5.569, Best loss: 5.564\n",
      "    [batch 750]: seen 75000 examples : 67.6 eps, Loss: 5.622, Avg loss: 5.571, Best loss: 5.564\n",
      "    [batch 757]: seen 75700 examples : 67.6 eps, Loss: 5.440, Avg loss: 5.568, Best loss: 5.564\n",
      "    [batch 763]: seen 76300 examples : 67.5 eps, Loss: 5.593, Avg loss: 5.568, Best loss: 5.564\n",
      "    [batch 770]: seen 77000 examples : 67.5 eps, Loss: 5.539, Avg loss: 5.567, Best loss: 5.564\n",
      "    [batch 777]: seen 77700 examples : 67.5 eps, Loss: 5.609, Avg loss: 5.568, Best loss: 5.564\n",
      "    [batch 784]: seen 78400 examples : 67.5 eps, Loss: 5.525, Avg loss: 5.565, Best loss: 5.564\n",
      "    [batch 791]: seen 79100 examples : 67.5 eps, Loss: 5.615, Avg loss: 5.563, Best loss: 5.563\n",
      "    [batch 798]: seen 79800 examples : 67.5 eps, Loss: 5.624, Avg loss: 5.562, Best loss: 5.561\n",
      "    [batch 805]: seen 80500 examples : 67.5 eps, Loss: 5.557, Avg loss: 5.561, Best loss: 5.561\n",
      "    [batch 812]: seen 81200 examples : 67.5 eps, Loss: 5.654, Avg loss: 5.560, Best loss: 5.559\n",
      "    [batch 819]: seen 81900 examples : 67.5 eps, Loss: 5.584, Avg loss: 5.560, Best loss: 5.559\n",
      "    [batch 826]: seen 82600 examples : 67.5 eps, Loss: 5.609, Avg loss: 5.560, Best loss: 5.559\n",
      "    [batch 833]: seen 83300 examples : 67.5 eps, Loss: 5.555, Avg loss: 5.559, Best loss: 5.559\n",
      "    [batch 840]: seen 84000 examples : 67.5 eps, Loss: 5.633, Avg loss: 5.561, Best loss: 5.559\n",
      "    [batch 847]: seen 84700 examples : 67.5 eps, Loss: 5.553, Avg loss: 5.563, Best loss: 5.559\n",
      "    [batch 854]: seen 85400 examples : 67.4 eps, Loss: 5.568, Avg loss: 5.564, Best loss: 5.559\n",
      "    [batch 861]: seen 86100 examples : 67.4 eps, Loss: 5.635, Avg loss: 5.564, Best loss: 5.559\n",
      "    [batch 868]: seen 86800 examples : 67.4 eps, Loss: 5.610, Avg loss: 5.564, Best loss: 5.559\n",
      "    [batch 875]: seen 87500 examples : 67.4 eps, Loss: 5.512, Avg loss: 5.564, Best loss: 5.559\n",
      "    [batch 882]: seen 88200 examples : 67.4 eps, Loss: 5.582, Avg loss: 5.564, Best loss: 5.559\n",
      "    [batch 888]: seen 88800 examples : 67.4 eps, Loss: 5.478, Avg loss: 5.562, Best loss: 5.559\n",
      "    [batch 895]: seen 89500 examples : 67.4 eps, Loss: 5.590, Avg loss: 5.562, Best loss: 5.559\n",
      "    [batch 902]: seen 90200 examples : 67.4 eps, Loss: 5.531, Avg loss: 5.560, Best loss: 5.559\n",
      "    [batch 909]: seen 90900 examples : 67.4 eps, Loss: 5.520, Avg loss: 5.558, Best loss: 5.558\n",
      "    [batch 916]: seen 91600 examples : 67.4 eps, Loss: 5.538, Avg loss: 5.557, Best loss: 5.557\n",
      "    [batch 923]: seen 92300 examples : 67.4 eps, Loss: 5.551, Avg loss: 5.558, Best loss: 5.557\n",
      "    [batch 930]: seen 93000 examples : 67.4 eps, Loss: 5.450, Avg loss: 5.557, Best loss: 5.557\n",
      "    [batch 937]: seen 93700 examples : 67.4 eps, Loss: 5.492, Avg loss: 5.561, Best loss: 5.557\n",
      "    [batch 944]: seen 94400 examples : 67.4 eps, Loss: 5.530, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 951]: seen 95100 examples : 67.4 eps, Loss: 5.586, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 958]: seen 95800 examples : 67.4 eps, Loss: 5.537, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 965]: seen 96500 examples : 67.4 eps, Loss: 5.560, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 972]: seen 97200 examples : 67.4 eps, Loss: 5.546, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 979]: seen 97900 examples : 67.4 eps, Loss: 5.572, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 986]: seen 98600 examples : 67.4 eps, Loss: 5.567, Avg loss: 5.566, Best loss: 5.557\n",
      "    [batch 993]: seen 99300 examples : 67.4 eps, Loss: 5.650, Avg loss: 5.570, Best loss: 5.557\n",
      "    [batch 1000]: seen 100000 examples : 67.3 eps, Loss: 5.587, Avg loss: 5.570, Best loss: 5.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1007]: seen 100700 examples : 67.3 eps, Loss: 5.478, Avg loss: 5.566, Best loss: 5.557\n",
      "    [batch 1013]: seen 101300 examples : 67.3 eps, Loss: 5.633, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 1020]: seen 102000 examples : 67.3 eps, Loss: 5.558, Avg loss: 5.563, Best loss: 5.557\n",
      "    [batch 1027]: seen 102700 examples : 67.3 eps, Loss: 5.470, Avg loss: 5.563, Best loss: 5.557\n",
      "    [batch 1034]: seen 103400 examples : 67.3 eps, Loss: 5.604, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 1041]: seen 104100 examples : 67.3 eps, Loss: 5.549, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 1048]: seen 104800 examples : 67.3 eps, Loss: 5.558, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 1055]: seen 105500 examples : 67.3 eps, Loss: 5.503, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 1062]: seen 106200 examples : 67.3 eps, Loss: 5.601, Avg loss: 5.566, Best loss: 5.557\n",
      "    [batch 1069]: seen 106900 examples : 67.3 eps, Loss: 5.590, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 1076]: seen 107600 examples : 67.3 eps, Loss: 5.485, Avg loss: 5.565, Best loss: 5.557\n",
      "    [batch 1083]: seen 108300 examples : 67.3 eps, Loss: 5.555, Avg loss: 5.563, Best loss: 5.557\n",
      "    [batch 1090]: seen 109000 examples : 67.3 eps, Loss: 5.581, Avg loss: 5.564, Best loss: 5.557\n",
      "    [batch 1097]: seen 109700 examples : 67.3 eps, Loss: 5.577, Avg loss: 5.562, Best loss: 5.557\n",
      "    [batch 1104]: seen 110400 examples : 67.3 eps, Loss: 5.585, Avg loss: 5.560, Best loss: 5.557\n",
      "    [batch 1111]: seen 111100 examples : 67.2 eps, Loss: 5.445, Avg loss: 5.558, Best loss: 5.557\n",
      "    [batch 1118]: seen 111800 examples : 67.3 eps, Loss: 5.468, Avg loss: 5.557, Best loss: 5.556\n",
      "    [batch 1124]: seen 112400 examples : 67.2 eps, Loss: 5.680, Avg loss: 5.557, Best loss: 5.555\n",
      "    [batch 1131]: seen 113100 examples : 67.2 eps, Loss: 5.567, Avg loss: 5.556, Best loss: 5.555\n",
      "    [batch 1138]: seen 113800 examples : 67.2 eps, Loss: 5.562, Avg loss: 5.554, Best loss: 5.554\n",
      "    [batch 1145]: seen 114500 examples : 67.2 eps, Loss: 5.553, Avg loss: 5.553, Best loss: 5.553\n",
      "    [batch 1152]: seen 115200 examples : 67.2 eps, Loss: 5.643, Avg loss: 5.554, Best loss: 5.553\n",
      "    [batch 1159]: seen 115900 examples : 67.2 eps, Loss: 5.554, Avg loss: 5.552, Best loss: 5.552\n",
      "    [batch 1166]: seen 116600 examples : 67.2 eps, Loss: 5.573, Avg loss: 5.554, Best loss: 5.552\n",
      "    [batch 1173]: seen 117300 examples : 67.2 eps, Loss: 5.633, Avg loss: 5.556, Best loss: 5.552\n",
      "    [batch 1180]: seen 118000 examples : 67.2 eps, Loss: 5.602, Avg loss: 5.557, Best loss: 5.552\n",
      "    [batch 1187]: seen 118700 examples : 67.2 eps, Loss: 5.507, Avg loss: 5.558, Best loss: 5.552\n",
      "    [batch 1193]: seen 119300 examples : 67.1 eps, Loss: 5.607, Avg loss: 5.557, Best loss: 5.552\n",
      "    [batch 1200]: seen 120000 examples : 67.2 eps, Loss: 5.545, Avg loss: 5.555, Best loss: 5.552\n",
      "    [batch 1207]: seen 120700 examples : 67.2 eps, Loss: 5.465, Avg loss: 5.552, Best loss: 5.552\n",
      "    [batch 1214]: seen 121400 examples : 67.2 eps, Loss: 5.452, Avg loss: 5.552, Best loss: 5.552\n",
      "    [batch 1221]: seen 122100 examples : 67.2 eps, Loss: 5.660, Avg loss: 5.551, Best loss: 5.550\n",
      "    [batch 1228]: seen 122800 examples : 67.2 eps, Loss: 5.561, Avg loss: 5.550, Best loss: 5.550\n",
      "    [batch 1235]: seen 123500 examples : 67.2 eps, Loss: 5.527, Avg loss: 5.549, Best loss: 5.549\n",
      "    [batch 1242]: seen 124200 examples : 67.2 eps, Loss: 5.487, Avg loss: 5.547, Best loss: 5.547\n",
      "    [batch 1249]: seen 124900 examples : 67.2 eps, Loss: 5.465, Avg loss: 5.546, Best loss: 5.546\n",
      "    [batch 1256]: seen 125600 examples : 67.2 eps, Loss: 5.608, Avg loss: 5.547, Best loss: 5.545\n",
      "    [batch 1263]: seen 126300 examples : 67.2 eps, Loss: 5.466, Avg loss: 5.547, Best loss: 5.545\n",
      "    [batch 1270]: seen 127000 examples : 67.2 eps, Loss: 5.543, Avg loss: 5.546, Best loss: 5.545\n",
      "    [batch 1277]: seen 127700 examples : 67.2 eps, Loss: 5.582, Avg loss: 5.544, Best loss: 5.544\n",
      "    [batch 1284]: seen 128400 examples : 67.2 eps, Loss: 5.508, Avg loss: 5.544, Best loss: 5.543\n",
      "    [batch 1291]: seen 129100 examples : 67.3 eps, Loss: 5.469, Avg loss: 5.541, Best loss: 5.541\n",
      "    [batch 1298]: seen 129800 examples : 67.2 eps, Loss: 5.469, Avg loss: 5.540, Best loss: 5.540\n",
      "    [batch 1305]: seen 130500 examples : 67.2 eps, Loss: 5.552, Avg loss: 5.540, Best loss: 5.539\n",
      "    [batch 1312]: seen 131200 examples : 67.2 eps, Loss: 5.513, Avg loss: 5.541, Best loss: 5.539\n",
      "    [batch 1319]: seen 131900 examples : 67.2 eps, Loss: 5.512, Avg loss: 5.542, Best loss: 5.539\n",
      "    [batch 1326]: seen 132600 examples : 67.2 eps, Loss: 5.658, Avg loss: 5.540, Best loss: 5.539\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-20955\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-20955\n",
      "    [batch 1332]: seen 133200 examples : 67.2 eps, Loss: 5.569, Avg loss: 5.540, Best loss: 5.539\n",
      "    [batch 1339]: seen 133900 examples : 67.2 eps, Loss: 5.562, Avg loss: 5.539, Best loss: 5.538\n",
      "    [batch 1346]: seen 134600 examples : 67.2 eps, Loss: 5.583, Avg loss: 5.537, Best loss: 5.536\n",
      "    [batch 1353]: seen 135300 examples : 67.2 eps, Loss: 5.539, Avg loss: 5.540, Best loss: 5.536\n",
      "    [batch 1360]: seen 136000 examples : 67.2 eps, Loss: 5.628, Avg loss: 5.539, Best loss: 5.536\n",
      "    [batch 1367]: seen 136700 examples : 67.2 eps, Loss: 5.504, Avg loss: 5.536, Best loss: 5.536\n",
      "    [batch 1374]: seen 137400 examples : 67.2 eps, Loss: 5.513, Avg loss: 5.536, Best loss: 5.536\n",
      "    [batch 1381]: seen 138100 examples : 67.2 eps, Loss: 5.411, Avg loss: 5.536, Best loss: 5.536\n",
      "    [batch 1388]: seen 138800 examples : 67.2 eps, Loss: 5.619, Avg loss: 5.537, Best loss: 5.536\n",
      "    [batch 1395]: seen 139500 examples : 67.2 eps, Loss: 5.578, Avg loss: 5.536, Best loss: 5.536\n",
      "    [batch 1402]: seen 140200 examples : 67.1 eps, Loss: 5.585, Avg loss: 5.536, Best loss: 5.535\n",
      "    [batch 1409]: seen 140900 examples : 67.2 eps, Loss: 5.447, Avg loss: 5.535, Best loss: 5.534\n",
      "    [batch 1416]: seen 141600 examples : 67.1 eps, Loss: 5.577, Avg loss: 5.538, Best loss: 5.534\n",
      "    [batch 1423]: seen 142300 examples : 67.1 eps, Loss: 5.565, Avg loss: 5.539, Best loss: 5.534\n",
      "    [batch 1430]: seen 143000 examples : 67.1 eps, Loss: 5.497, Avg loss: 5.539, Best loss: 5.534\n",
      "    [batch 1437]: seen 143700 examples : 67.1 eps, Loss: 5.556, Avg loss: 5.537, Best loss: 5.534\n",
      "    [batch 1444]: seen 144400 examples : 67.1 eps, Loss: 5.540, Avg loss: 5.536, Best loss: 5.534\n",
      "    [batch 1451]: seen 145100 examples : 67.1 eps, Loss: 5.587, Avg loss: 5.538, Best loss: 5.534\n",
      "    [batch 1458]: seen 145800 examples : 67.1 eps, Loss: 5.561, Avg loss: 5.541, Best loss: 5.534\n",
      "    [batch 1465]: seen 146500 examples : 67.1 eps, Loss: 5.647, Avg loss: 5.544, Best loss: 5.534\n",
      "    [batch 1472]: seen 147200 examples : 67.1 eps, Loss: 5.609, Avg loss: 5.542, Best loss: 5.534\n",
      "    [batch 1479]: seen 147900 examples : 67.1 eps, Loss: 5.521, Avg loss: 5.540, Best loss: 5.534\n",
      "    [batch 1486]: seen 148600 examples : 67.1 eps, Loss: 5.538, Avg loss: 5.546, Best loss: 5.534\n",
      "    [batch 1493]: seen 149300 examples : 67.1 eps, Loss: 5.497, Avg loss: 5.544, Best loss: 5.534\n",
      "    [batch 1500]: seen 150000 examples : 67.1 eps, Loss: 5.486, Avg loss: 5.541, Best loss: 5.534\n",
      "    [batch 1507]: seen 150700 examples : 67.1 eps, Loss: 5.577, Avg loss: 5.542, Best loss: 5.534\n",
      "    [batch 1514]: seen 151400 examples : 67.1 eps, Loss: 5.514, Avg loss: 5.540, Best loss: 5.534\n",
      "    [batch 1521]: seen 152100 examples : 67.1 eps, Loss: 5.517, Avg loss: 5.542, Best loss: 5.534\n",
      "    [batch 1528]: seen 152800 examples : 67.1 eps, Loss: 5.597, Avg loss: 5.543, Best loss: 5.534\n",
      "    [batch 1535]: seen 153500 examples : 67.1 eps, Loss: 5.523, Avg loss: 5.543, Best loss: 5.534\n",
      "    [batch 1542]: seen 154200 examples : 67.1 eps, Loss: 5.514, Avg loss: 5.541, Best loss: 5.534\n",
      "    [batch 1549]: seen 154900 examples : 67.1 eps, Loss: 5.549, Avg loss: 5.539, Best loss: 5.534\n",
      "    [batch 1556]: seen 155600 examples : 67.1 eps, Loss: 5.485, Avg loss: 5.537, Best loss: 5.534\n",
      "    [batch 1563]: seen 156300 examples : 67.1 eps, Loss: 5.382, Avg loss: 5.534, Best loss: 5.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1570]: seen 157000 examples : 67.1 eps, Loss: 5.717, Avg loss: 5.540, Best loss: 5.534\n",
      "    [batch 1577]: seen 157700 examples : 67.1 eps, Loss: 5.511, Avg loss: 5.541, Best loss: 5.534\n",
      "    [batch 1584]: seen 158400 examples : 67.1 eps, Loss: 5.494, Avg loss: 5.539, Best loss: 5.534\n",
      "    [batch 1591]: seen 159100 examples : 67.1 eps, Loss: 5.478, Avg loss: 5.538, Best loss: 5.534\n",
      "    [batch 1598]: seen 159800 examples : 67.1 eps, Loss: 5.478, Avg loss: 5.538, Best loss: 5.534\n",
      "    [batch 1605]: seen 160500 examples : 67.1 eps, Loss: 5.489, Avg loss: 5.537, Best loss: 5.534\n",
      "    [batch 1612]: seen 161200 examples : 67.1 eps, Loss: 5.455, Avg loss: 5.535, Best loss: 5.534\n",
      "    [batch 1619]: seen 161900 examples : 67.1 eps, Loss: 5.436, Avg loss: 5.535, Best loss: 5.534\n",
      "    [batch 1626]: seen 162600 examples : 67.1 eps, Loss: 5.555, Avg loss: 5.535, Best loss: 5.534\n",
      "    [batch 1633]: seen 163300 examples : 67.1 eps, Loss: 5.630, Avg loss: 5.535, Best loss: 5.534\n",
      "    [batch 1640]: seen 164000 examples : 67.1 eps, Loss: 5.533, Avg loss: 5.537, Best loss: 5.534\n",
      "    [batch 1647]: seen 164700 examples : 67.1 eps, Loss: 5.597, Avg loss: 5.535, Best loss: 5.534\n",
      "    [batch 1654]: seen 165400 examples : 67.1 eps, Loss: 5.540, Avg loss: 5.533, Best loss: 5.533\n",
      "    [batch 1661]: seen 166100 examples : 67.1 eps, Loss: 5.522, Avg loss: 5.533, Best loss: 5.532\n",
      "    [batch 1668]: seen 166800 examples : 67.1 eps, Loss: 5.503, Avg loss: 5.532, Best loss: 5.532\n",
      "    [batch 1675]: seen 167500 examples : 67.1 eps, Loss: 5.469, Avg loss: 5.529, Best loss: 5.529\n",
      "    [batch 1682]: seen 168200 examples : 67.1 eps, Loss: 5.587, Avg loss: 5.531, Best loss: 5.529\n",
      "    [batch 1689]: seen 168900 examples : 67.1 eps, Loss: 5.530, Avg loss: 5.533, Best loss: 5.529\n",
      "    [batch 1696]: seen 169600 examples : 67.1 eps, Loss: 5.582, Avg loss: 5.532, Best loss: 5.529\n",
      "    [batch 1703]: seen 170300 examples : 67.1 eps, Loss: 5.567, Avg loss: 5.532, Best loss: 5.529\n",
      "    [batch 1710]: seen 171000 examples : 67.1 eps, Loss: 5.518, Avg loss: 5.532, Best loss: 5.529\n",
      "    [batch 1717]: seen 171700 examples : 67.1 eps, Loss: 5.580, Avg loss: 5.532, Best loss: 5.529\n",
      "    [batch 1724]: seen 172400 examples : 67.1 eps, Loss: 5.474, Avg loss: 5.530, Best loss: 5.529\n",
      "    [batch 1731]: seen 173100 examples : 67.1 eps, Loss: 5.415, Avg loss: 5.528, Best loss: 5.528\n",
      "    [batch 1738]: seen 173800 examples : 67.1 eps, Loss: 5.544, Avg loss: 5.529, Best loss: 5.528\n",
      "    [batch 1745]: seen 174500 examples : 67.1 eps, Loss: 5.501, Avg loss: 5.527, Best loss: 5.527\n",
      "    [batch 1752]: seen 175200 examples : 67.1 eps, Loss: 5.513, Avg loss: 5.527, Best loss: 5.527\n",
      "    [batch 1759]: seen 175900 examples : 67.1 eps, Loss: 5.578, Avg loss: 5.528, Best loss: 5.526\n",
      "    [batch 1766]: seen 176600 examples : 67.1 eps, Loss: 5.541, Avg loss: 5.527, Best loss: 5.526\n",
      "    [batch 1773]: seen 177300 examples : 67.1 eps, Loss: 5.583, Avg loss: 5.529, Best loss: 5.526\n",
      "    [batch 1780]: seen 178000 examples : 67.1 eps, Loss: 5.505, Avg loss: 5.528, Best loss: 5.526\n",
      "    [batch 1787]: seen 178700 examples : 67.1 eps, Loss: 5.473, Avg loss: 5.527, Best loss: 5.526\n",
      "    [batch 1793]: seen 179300 examples : 67.1 eps, Loss: 5.571, Avg loss: 5.525, Best loss: 5.524\n",
      "    [batch 1800]: seen 180000 examples : 67.1 eps, Loss: 5.528, Avg loss: 5.523, Best loss: 5.523\n",
      "    [batch 1807]: seen 180700 examples : 67.1 eps, Loss: 5.348, Avg loss: 5.522, Best loss: 5.522\n",
      "    [batch 1814]: seen 181400 examples : 67.1 eps, Loss: 5.545, Avg loss: 5.525, Best loss: 5.522\n",
      "    [batch 1821]: seen 182100 examples : 67.1 eps, Loss: 5.416, Avg loss: 5.523, Best loss: 5.522\n",
      "    [batch 1828]: seen 182800 examples : 67.1 eps, Loss: 5.463, Avg loss: 5.520, Best loss: 5.520\n",
      "    [batch 1835]: seen 183500 examples : 67.1 eps, Loss: 5.559, Avg loss: 5.520, Best loss: 5.519\n",
      "    [batch 1842]: seen 184200 examples : 67.1 eps, Loss: 5.588, Avg loss: 5.522, Best loss: 5.519\n",
      "    [batch 1849]: seen 184900 examples : 67.1 eps, Loss: 5.521, Avg loss: 5.524, Best loss: 5.519\n",
      "    [batch 1856]: seen 185600 examples : 67.1 eps, Loss: 5.456, Avg loss: 5.522, Best loss: 5.519\n",
      "    [batch 1863]: seen 186300 examples : 67.1 eps, Loss: 5.491, Avg loss: 5.523, Best loss: 5.519\n",
      "    [batch 1870]: seen 187000 examples : 67.1 eps, Loss: 5.633, Avg loss: 5.524, Best loss: 5.519\n",
      "    [batch 1877]: seen 187700 examples : 67.1 eps, Loss: 5.496, Avg loss: 5.524, Best loss: 5.519\n",
      "    [batch 1884]: seen 188400 examples : 67.1 eps, Loss: 5.579, Avg loss: 5.525, Best loss: 5.519\n",
      "    [batch 1891]: seen 189100 examples : 67.1 eps, Loss: 5.609, Avg loss: 5.521, Best loss: 5.519\n",
      "    [batch 1898]: seen 189800 examples : 67.1 eps, Loss: 5.518, Avg loss: 5.517, Best loss: 5.517\n",
      "    [batch 1905]: seen 190500 examples : 67.1 eps, Loss: 5.441, Avg loss: 5.517, Best loss: 5.517\n",
      "    [batch 1912]: seen 191200 examples : 67.1 eps, Loss: 5.577, Avg loss: 5.519, Best loss: 5.517\n",
      "    [batch 1918]: seen 191800 examples : 67.0 eps, Loss: 5.539, Avg loss: 5.519, Best loss: 5.517\n",
      "    [batch 1925]: seen 192500 examples : 67.0 eps, Loss: 5.477, Avg loss: 5.520, Best loss: 5.517\n",
      "    [batch 1932]: seen 193200 examples : 67.0 eps, Loss: 5.442, Avg loss: 5.521, Best loss: 5.517\n",
      "    [batch 1939]: seen 193900 examples : 67.1 eps, Loss: 5.486, Avg loss: 5.523, Best loss: 5.517\n",
      "    [batch 1946]: seen 194600 examples : 67.1 eps, Loss: 5.513, Avg loss: 5.520, Best loss: 5.517\n",
      "    [batch 1953]: seen 195300 examples : 67.1 eps, Loss: 5.525, Avg loss: 5.520, Best loss: 5.517\n",
      "    [batch 1960]: seen 196000 examples : 67.1 eps, Loss: 5.620, Avg loss: 5.519, Best loss: 5.517\n",
      "    [batch 1967]: seen 196700 examples : 67.1 eps, Loss: 5.424, Avg loss: 5.516, Best loss: 5.516\n",
      "    [batch 1974]: seen 197400 examples : 67.0 eps, Loss: 5.471, Avg loss: 5.516, Best loss: 5.516\n",
      "    [batch 1981]: seen 198100 examples : 67.0 eps, Loss: 5.567, Avg loss: 5.518, Best loss: 5.516\n",
      "    [batch 1988]: seen 198800 examples : 67.0 eps, Loss: 5.611, Avg loss: 5.514, Best loss: 5.513\n",
      "    [batch 1995]: seen 199500 examples : 67.0 eps, Loss: 5.466, Avg loss: 5.515, Best loss: 5.513\n",
      "    [batch 2002]: seen 200200 examples : 67.0 eps, Loss: 5.477, Avg loss: 5.514, Best loss: 5.513\n",
      "    [batch 2008]: seen 200800 examples : 67.0 eps, Loss: 5.554, Avg loss: 5.515, Best loss: 5.513\n",
      "    [batch 2015]: seen 201500 examples : 67.0 eps, Loss: 5.554, Avg loss: 5.515, Best loss: 5.513\n",
      "    [batch 2022]: seen 202200 examples : 67.0 eps, Loss: 5.569, Avg loss: 5.514, Best loss: 5.513\n",
      "    [batch 2029]: seen 202900 examples : 67.0 eps, Loss: 5.558, Avg loss: 5.517, Best loss: 5.513\n",
      "    [batch 2036]: seen 203600 examples : 67.0 eps, Loss: 5.582, Avg loss: 5.517, Best loss: 5.513\n",
      "    [batch 2043]: seen 204300 examples : 67.0 eps, Loss: 5.533, Avg loss: 5.517, Best loss: 5.513\n",
      "    [batch 2050]: seen 205000 examples : 67.0 eps, Loss: 5.504, Avg loss: 5.518, Best loss: 5.513\n",
      "    [batch 2057]: seen 205700 examples : 67.0 eps, Loss: 5.539, Avg loss: 5.519, Best loss: 5.513\n",
      "    [batch 2064]: seen 206400 examples : 67.0 eps, Loss: 5.592, Avg loss: 5.521, Best loss: 5.513\n",
      "    [batch 2071]: seen 207100 examples : 67.0 eps, Loss: 5.585, Avg loss: 5.523, Best loss: 5.513\n",
      "    [batch 2078]: seen 207800 examples : 67.0 eps, Loss: 5.575, Avg loss: 5.523, Best loss: 5.513\n",
      "    [batch 2085]: seen 208500 examples : 67.0 eps, Loss: 5.402, Avg loss: 5.523, Best loss: 5.513\n",
      "    [batch 2092]: seen 209200 examples : 67.0 eps, Loss: 5.598, Avg loss: 5.525, Best loss: 5.513\n",
      "    [batch 2099]: seen 209900 examples : 67.0 eps, Loss: 5.432, Avg loss: 5.524, Best loss: 5.513\n",
      "    [batch 2106]: seen 210600 examples : 67.0 eps, Loss: 5.468, Avg loss: 5.521, Best loss: 5.513\n",
      "    [batch 2113]: seen 211300 examples : 67.0 eps, Loss: 5.504, Avg loss: 5.522, Best loss: 5.513\n",
      "    [batch 2120]: seen 212000 examples : 67.0 eps, Loss: 5.531, Avg loss: 5.521, Best loss: 5.513\n",
      "    [batch 2127]: seen 212700 examples : 67.0 eps, Loss: 5.480, Avg loss: 5.521, Best loss: 5.513\n",
      "    [batch 2134]: seen 213400 examples : 67.0 eps, Loss: 5.563, Avg loss: 5.520, Best loss: 5.513\n",
      "    [batch 2141]: seen 214100 examples : 67.0 eps, Loss: 5.517, Avg loss: 5.518, Best loss: 5.513\n",
      "    [batch 2148]: seen 214800 examples : 67.0 eps, Loss: 5.465, Avg loss: 5.514, Best loss: 5.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2155]: seen 215500 examples : 67.0 eps, Loss: 5.522, Avg loss: 5.513, Best loss: 5.512\n",
      "    [batch 2162]: seen 216200 examples : 67.0 eps, Loss: 5.582, Avg loss: 5.513, Best loss: 5.512\n",
      "    [batch 2169]: seen 216900 examples : 67.0 eps, Loss: 5.490, Avg loss: 5.512, Best loss: 5.512\n",
      "    [batch 2176]: seen 217600 examples : 67.0 eps, Loss: 5.483, Avg loss: 5.511, Best loss: 5.511\n",
      "    [batch 2183]: seen 218300 examples : 67.0 eps, Loss: 5.582, Avg loss: 5.511, Best loss: 5.509\n",
      "    [batch 2190]: seen 219000 examples : 67.0 eps, Loss: 5.509, Avg loss: 5.510, Best loss: 5.509\n",
      "    [batch 2197]: seen 219700 examples : 67.0 eps, Loss: 5.569, Avg loss: 5.511, Best loss: 5.509\n",
      "    [batch 2204]: seen 220400 examples : 67.0 eps, Loss: 5.528, Avg loss: 5.512, Best loss: 5.509\n",
      "    [batch 2211]: seen 221100 examples : 67.0 eps, Loss: 5.477, Avg loss: 5.512, Best loss: 5.509\n",
      "    [batch 2218]: seen 221800 examples : 67.0 eps, Loss: 5.507, Avg loss: 5.512, Best loss: 5.509\n",
      "    [batch 2225]: seen 222500 examples : 67.0 eps, Loss: 5.526, Avg loss: 5.511, Best loss: 5.509\n",
      "    [batch 2232]: seen 223200 examples : 67.0 eps, Loss: 5.530, Avg loss: 5.511, Best loss: 5.509\n",
      "    [batch 2239]: seen 223900 examples : 67.0 eps, Loss: 5.432, Avg loss: 5.510, Best loss: 5.509\n",
      "    [batch 2246]: seen 224600 examples : 67.0 eps, Loss: 5.563, Avg loss: 5.511, Best loss: 5.509\n",
      "    [batch 2253]: seen 225300 examples : 67.0 eps, Loss: 5.638, Avg loss: 5.511, Best loss: 5.509\n",
      "    [batch 2260]: seen 226000 examples : 67.0 eps, Loss: 5.466, Avg loss: 5.510, Best loss: 5.509\n",
      "    [batch 2267]: seen 226700 examples : 67.0 eps, Loss: 5.492, Avg loss: 5.508, Best loss: 5.508\n",
      "    [batch 2274]: seen 227400 examples : 67.0 eps, Loss: 5.359, Avg loss: 5.508, Best loss: 5.508\n",
      "    [batch 2281]: seen 228100 examples : 67.0 eps, Loss: 5.452, Avg loss: 5.508, Best loss: 5.508\n",
      "    [batch 2288]: seen 228800 examples : 67.0 eps, Loss: 5.529, Avg loss: 5.508, Best loss: 5.508\n",
      "    [batch 2295]: seen 229500 examples : 67.0 eps, Loss: 5.456, Avg loss: 5.510, Best loss: 5.508\n",
      "    [batch 2302]: seen 230200 examples : 67.0 eps, Loss: 5.411, Avg loss: 5.510, Best loss: 5.508\n",
      "    [batch 2309]: seen 230900 examples : 67.0 eps, Loss: 5.517, Avg loss: 5.510, Best loss: 5.508\n",
      "    [batch 2316]: seen 231600 examples : 67.0 eps, Loss: 5.537, Avg loss: 5.509, Best loss: 5.508\n",
      "    [batch 2323]: seen 232300 examples : 67.0 eps, Loss: 5.463, Avg loss: 5.507, Best loss: 5.506\n",
      "    [batch 2330]: seen 233000 examples : 67.0 eps, Loss: 5.517, Avg loss: 5.507, Best loss: 5.506\n",
      "    [batch 2337]: seen 233700 examples : 67.0 eps, Loss: 5.408, Avg loss: 5.506, Best loss: 5.506\n",
      "    [batch 2344]: seen 234400 examples : 67.0 eps, Loss: 5.474, Avg loss: 5.507, Best loss: 5.506\n",
      "    [batch 2351]: seen 235100 examples : 67.0 eps, Loss: 5.564, Avg loss: 5.508, Best loss: 5.506\n",
      "    [batch 2358]: seen 235800 examples : 67.0 eps, Loss: 5.514, Avg loss: 5.507, Best loss: 5.506\n",
      "    [batch 2365]: seen 236500 examples : 67.0 eps, Loss: 5.501, Avg loss: 5.508, Best loss: 5.506\n",
      "    [batch 2372]: seen 237200 examples : 67.0 eps, Loss: 5.449, Avg loss: 5.507, Best loss: 5.506\n",
      "    [batch 2379]: seen 237900 examples : 67.0 eps, Loss: 5.480, Avg loss: 5.504, Best loss: 5.504\n",
      "    [batch 2386]: seen 238600 examples : 67.0 eps, Loss: 5.527, Avg loss: 5.502, Best loss: 5.501\n",
      "    [batch 2393]: seen 239300 examples : 67.0 eps, Loss: 5.442, Avg loss: 5.501, Best loss: 5.501\n",
      "    [batch 2400]: seen 240000 examples : 67.0 eps, Loss: 5.381, Avg loss: 5.500, Best loss: 5.500\n",
      "    [batch 2407]: seen 240700 examples : 67.0 eps, Loss: 5.501, Avg loss: 5.502, Best loss: 5.500\n",
      "    [batch 2414]: seen 241400 examples : 67.0 eps, Loss: 5.360, Avg loss: 5.499, Best loss: 5.499\n",
      "    [batch 2421]: seen 242100 examples : 67.0 eps, Loss: 5.480, Avg loss: 5.500, Best loss: 5.499\n",
      "    [batch 2428]: seen 242800 examples : 67.0 eps, Loss: 5.510, Avg loss: 5.500, Best loss: 5.499\n",
      "    [batch 2435]: seen 243500 examples : 67.0 eps, Loss: 5.535, Avg loss: 5.502, Best loss: 5.499\n",
      "    [batch 2442]: seen 244200 examples : 67.0 eps, Loss: 5.628, Avg loss: 5.504, Best loss: 5.499\n",
      "    [batch 2449]: seen 244900 examples : 67.0 eps, Loss: 5.426, Avg loss: 5.503, Best loss: 5.499\n",
      "    [batch 2456]: seen 245600 examples : 67.0 eps, Loss: 5.392, Avg loss: 5.501, Best loss: 5.499\n",
      "    [batch 2463]: seen 246300 examples : 67.0 eps, Loss: 5.488, Avg loss: 5.500, Best loss: 5.499\n",
      "    [batch 2470]: seen 247000 examples : 67.0 eps, Loss: 5.473, Avg loss: 5.499, Best loss: 5.499\n",
      "    [batch 2477]: seen 247700 examples : 67.0 eps, Loss: 5.595, Avg loss: 5.498, Best loss: 5.497\n",
      "    [batch 2484]: seen 248400 examples : 67.0 eps, Loss: 5.465, Avg loss: 5.496, Best loss: 5.496\n",
      "    [batch 2491]: seen 249100 examples : 67.0 eps, Loss: 5.441, Avg loss: 5.494, Best loss: 5.494\n",
      "    [batch 2498]: seen 249800 examples : 67.0 eps, Loss: 5.527, Avg loss: 5.494, Best loss: 5.493\n",
      "    [batch 2505]: seen 250500 examples : 67.0 eps, Loss: 5.567, Avg loss: 5.493, Best loss: 5.492\n",
      "    [batch 2512]: seen 251200 examples : 67.0 eps, Loss: 5.468, Avg loss: 5.496, Best loss: 5.492\n",
      "    [batch 2519]: seen 251900 examples : 67.0 eps, Loss: 5.549, Avg loss: 5.495, Best loss: 5.492\n",
      "    [batch 2526]: seen 252600 examples : 67.0 eps, Loss: 5.408, Avg loss: 5.492, Best loss: 5.492\n",
      "    [batch 2533]: seen 253300 examples : 67.0 eps, Loss: 5.512, Avg loss: 5.492, Best loss: 5.490\n",
      "    [batch 2540]: seen 254000 examples : 67.0 eps, Loss: 5.427, Avg loss: 5.490, Best loss: 5.490\n",
      "    [batch 2547]: seen 254700 examples : 67.0 eps, Loss: 5.476, Avg loss: 5.488, Best loss: 5.488\n",
      "    [batch 2554]: seen 255400 examples : 67.0 eps, Loss: 5.514, Avg loss: 5.488, Best loss: 5.488\n",
      "    [batch 2561]: seen 256100 examples : 67.0 eps, Loss: 5.506, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2568]: seen 256800 examples : 67.0 eps, Loss: 5.499, Avg loss: 5.491, Best loss: 5.488\n",
      "    [batch 2575]: seen 257500 examples : 67.0 eps, Loss: 5.428, Avg loss: 5.491, Best loss: 5.488\n",
      "    [batch 2582]: seen 258200 examples : 67.0 eps, Loss: 5.500, Avg loss: 5.492, Best loss: 5.488\n",
      "    [batch 2589]: seen 258900 examples : 67.0 eps, Loss: 5.459, Avg loss: 5.491, Best loss: 5.488\n",
      "    [batch 2596]: seen 259600 examples : 67.0 eps, Loss: 5.456, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2603]: seen 260300 examples : 67.0 eps, Loss: 5.531, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2610]: seen 261000 examples : 67.0 eps, Loss: 5.367, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2617]: seen 261700 examples : 67.0 eps, Loss: 5.376, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2624]: seen 262400 examples : 67.0 eps, Loss: 5.512, Avg loss: 5.490, Best loss: 5.488\n",
      "    [batch 2631]: seen 263100 examples : 67.0 eps, Loss: 5.565, Avg loss: 5.491, Best loss: 5.488\n",
      "    [batch 2638]: seen 263800 examples : 67.0 eps, Loss: 5.431, Avg loss: 5.491, Best loss: 5.488\n",
      "    [batch 2645]: seen 264500 examples : 67.0 eps, Loss: 5.546, Avg loss: 5.492, Best loss: 5.488\n",
      "    [batch 2652]: seen 265200 examples : 67.0 eps, Loss: 5.456, Avg loss: 5.494, Best loss: 5.488\n",
      "    [batch 2659]: seen 265900 examples : 67.0 eps, Loss: 5.511, Avg loss: 5.496, Best loss: 5.488\n",
      "    [batch 2666]: seen 266600 examples : 67.0 eps, Loss: 5.629, Avg loss: 5.497, Best loss: 5.488\n",
      "    [batch 2673]: seen 267300 examples : 67.0 eps, Loss: 5.427, Avg loss: 5.493, Best loss: 5.488\n",
      "    [batch 2680]: seen 268000 examples : 67.0 eps, Loss: 5.590, Avg loss: 5.495, Best loss: 5.488\n",
      "    [batch 2687]: seen 268700 examples : 67.0 eps, Loss: 5.468, Avg loss: 5.491, Best loss: 5.488\n",
      "    [batch 2694]: seen 269400 examples : 67.0 eps, Loss: 5.441, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2701]: seen 270100 examples : 67.0 eps, Loss: 5.424, Avg loss: 5.488, Best loss: 5.488\n",
      "    [batch 2708]: seen 270800 examples : 67.0 eps, Loss: 5.386, Avg loss: 5.488, Best loss: 5.488\n",
      "    [batch 2715]: seen 271500 examples : 67.0 eps, Loss: 5.446, Avg loss: 5.489, Best loss: 5.488\n",
      "    [batch 2722]: seen 272200 examples : 67.0 eps, Loss: 5.494, Avg loss: 5.487, Best loss: 5.486\n",
      "    [batch 2729]: seen 272900 examples : 67.0 eps, Loss: 5.495, Avg loss: 5.486, Best loss: 5.486\n",
      "    [batch 2736]: seen 273600 examples : 67.0 eps, Loss: 5.495, Avg loss: 5.486, Best loss: 5.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2743]: seen 274300 examples : 66.9 eps, Loss: 5.544, Avg loss: 5.488, Best loss: 5.486\n",
      "    [batch 2750]: seen 275000 examples : 66.9 eps, Loss: 5.368, Avg loss: 5.486, Best loss: 5.486\n",
      "    [batch 2756]: seen 275600 examples : 66.9 eps, Loss: 5.550, Avg loss: 5.487, Best loss: 5.486\n",
      "    [batch 2763]: seen 276300 examples : 66.9 eps, Loss: 5.465, Avg loss: 5.488, Best loss: 5.486\n",
      "    [batch 2770]: seen 277000 examples : 66.9 eps, Loss: 5.524, Avg loss: 5.486, Best loss: 5.485\n",
      "    [batch 2777]: seen 277700 examples : 66.9 eps, Loss: 5.523, Avg loss: 5.486, Best loss: 5.485\n",
      "    [batch 2784]: seen 278400 examples : 66.9 eps, Loss: 5.440, Avg loss: 5.484, Best loss: 5.484\n",
      "    [batch 2791]: seen 279100 examples : 67.0 eps, Loss: 5.437, Avg loss: 5.484, Best loss: 5.483\n",
      "    [batch 2798]: seen 279800 examples : 67.0 eps, Loss: 5.474, Avg loss: 5.486, Best loss: 5.483\n",
      "    [batch 2805]: seen 280500 examples : 67.0 eps, Loss: 5.534, Avg loss: 5.485, Best loss: 5.483\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:53\n",
      "[EPOCH 8] Complete. Avg Loss: 5.484177918285354; Best Loss: 5.483276740655519\n",
      "[EPOCH 9] Starting training..\n",
      "    [batch 9]: seen 900 examples : 86.7 eps, Loss: 5.518, Avg loss: 5.481, Best loss: 5.480\n",
      "    [batch 16]: seen 1600 examples : 77.7 eps, Loss: 5.527, Avg loss: 5.481, Best loss: 5.480\n",
      "    [batch 23]: seen 2300 examples : 74.9 eps, Loss: 5.558, Avg loss: 5.482, Best loss: 5.480\n",
      "    [batch 30]: seen 3000 examples : 72.7 eps, Loss: 5.342, Avg loss: 5.480, Best loss: 5.480\n",
      "    [batch 37]: seen 3700 examples : 71.9 eps, Loss: 5.443, Avg loss: 5.477, Best loss: 5.477\n",
      "    [batch 44]: seen 4400 examples : 71.4 eps, Loss: 5.481, Avg loss: 5.477, Best loss: 5.476\n",
      "    [batch 51]: seen 5100 examples : 71.1 eps, Loss: 5.464, Avg loss: 5.474, Best loss: 5.474\n",
      "    [batch 58]: seen 5800 examples : 70.8 eps, Loss: 5.425, Avg loss: 5.476, Best loss: 5.474\n",
      "    [batch 65]: seen 6500 examples : 70.6 eps, Loss: 5.456, Avg loss: 5.475, Best loss: 5.474\n",
      "    [batch 72]: seen 7200 examples : 70.4 eps, Loss: 5.456, Avg loss: 5.473, Best loss: 5.473\n",
      "    [batch 79]: seen 7900 examples : 70.3 eps, Loss: 5.574, Avg loss: 5.474, Best loss: 5.473\n",
      "    [batch 86]: seen 8600 examples : 70.2 eps, Loss: 5.485, Avg loss: 5.476, Best loss: 5.473\n",
      "    [batch 93]: seen 9300 examples : 70.1 eps, Loss: 5.381, Avg loss: 5.477, Best loss: 5.473\n",
      "    [batch 100]: seen 10000 examples : 70.0 eps, Loss: 5.832, Avg loss: 5.512, Best loss: 5.473\n",
      "    [batch 107]: seen 10700 examples : 69.6 eps, Loss: 5.528, Avg loss: 5.513, Best loss: 5.473\n",
      "    [batch 114]: seen 11400 examples : 69.4 eps, Loss: 5.428, Avg loss: 5.510, Best loss: 5.473\n",
      "    [batch 121]: seen 12100 examples : 69.1 eps, Loss: 5.434, Avg loss: 5.508, Best loss: 5.473\n",
      "    [batch 128]: seen 12800 examples : 69.1 eps, Loss: 5.432, Avg loss: 5.507, Best loss: 5.473\n",
      "    [batch 135]: seen 13500 examples : 68.8 eps, Loss: 5.535, Avg loss: 5.502, Best loss: 5.473\n",
      "    [batch 142]: seen 14200 examples : 68.7 eps, Loss: 5.425, Avg loss: 5.502, Best loss: 5.473\n",
      "    [batch 149]: seen 14900 examples : 68.6 eps, Loss: 5.495, Avg loss: 5.500, Best loss: 5.473\n",
      "    [batch 156]: seen 15600 examples : 68.4 eps, Loss: 5.464, Avg loss: 5.497, Best loss: 5.473\n",
      "    [batch 163]: seen 16300 examples : 68.4 eps, Loss: 5.427, Avg loss: 5.494, Best loss: 5.473\n",
      "    [batch 170]: seen 17000 examples : 68.4 eps, Loss: 5.602, Avg loss: 5.495, Best loss: 5.473\n",
      "    [batch 177]: seen 17700 examples : 68.3 eps, Loss: 5.482, Avg loss: 5.493, Best loss: 5.473\n",
      "    [batch 184]: seen 18400 examples : 68.2 eps, Loss: 5.470, Avg loss: 5.492, Best loss: 5.473\n",
      "    [batch 191]: seen 19100 examples : 68.2 eps, Loss: 5.423, Avg loss: 5.489, Best loss: 5.473\n",
      "    [batch 198]: seen 19800 examples : 68.2 eps, Loss: 5.477, Avg loss: 5.487, Best loss: 5.473\n",
      "    [batch 205]: seen 20500 examples : 68.1 eps, Loss: 5.400, Avg loss: 5.485, Best loss: 5.473\n",
      "    [batch 212]: seen 21200 examples : 68.1 eps, Loss: 5.439, Avg loss: 5.482, Best loss: 5.473\n",
      "    [batch 219]: seen 21900 examples : 68.1 eps, Loss: 5.421, Avg loss: 5.482, Best loss: 5.473\n",
      "    [batch 226]: seen 22600 examples : 68.0 eps, Loss: 5.475, Avg loss: 5.481, Best loss: 5.473\n",
      "    [batch 233]: seen 23300 examples : 68.0 eps, Loss: 5.557, Avg loss: 5.481, Best loss: 5.473\n",
      "    [batch 240]: seen 24000 examples : 68.0 eps, Loss: 5.431, Avg loss: 5.481, Best loss: 5.473\n",
      "    [batch 247]: seen 24700 examples : 67.9 eps, Loss: 5.505, Avg loss: 5.479, Best loss: 5.473\n",
      "    [batch 254]: seen 25400 examples : 67.9 eps, Loss: 5.463, Avg loss: 5.477, Best loss: 5.473\n",
      "    [batch 261]: seen 26100 examples : 67.9 eps, Loss: 5.367, Avg loss: 5.475, Best loss: 5.473\n",
      "    [batch 268]: seen 26800 examples : 67.9 eps, Loss: 5.443, Avg loss: 5.473, Best loss: 5.473\n",
      "    [batch 275]: seen 27500 examples : 67.8 eps, Loss: 5.485, Avg loss: 5.475, Best loss: 5.473\n",
      "    [batch 282]: seen 28200 examples : 67.7 eps, Loss: 5.408, Avg loss: 5.475, Best loss: 5.473\n",
      "    [batch 289]: seen 28900 examples : 67.6 eps, Loss: 5.416, Avg loss: 5.472, Best loss: 5.472\n",
      "    [batch 296]: seen 29600 examples : 67.7 eps, Loss: 5.513, Avg loss: 5.475, Best loss: 5.472\n",
      "    [batch 303]: seen 30300 examples : 67.6 eps, Loss: 5.460, Avg loss: 5.472, Best loss: 5.472\n",
      "    [batch 310]: seen 31000 examples : 67.6 eps, Loss: 5.451, Avg loss: 5.473, Best loss: 5.472\n",
      "    [batch 317]: seen 31700 examples : 67.6 eps, Loss: 5.536, Avg loss: 5.473, Best loss: 5.472\n",
      "    [batch 324]: seen 32400 examples : 67.6 eps, Loss: 5.334, Avg loss: 5.470, Best loss: 5.470\n",
      "    [batch 331]: seen 33100 examples : 67.6 eps, Loss: 5.474, Avg loss: 5.468, Best loss: 5.468\n",
      "    [batch 338]: seen 33800 examples : 67.6 eps, Loss: 5.535, Avg loss: 5.471, Best loss: 5.468\n",
      "    [batch 345]: seen 34500 examples : 67.6 eps, Loss: 5.464, Avg loss: 5.470, Best loss: 5.468\n",
      "    [batch 352]: seen 35200 examples : 67.6 eps, Loss: 5.429, Avg loss: 5.470, Best loss: 5.468\n",
      "    [batch 359]: seen 35900 examples : 67.6 eps, Loss: 5.493, Avg loss: 5.470, Best loss: 5.468\n",
      "    [batch 366]: seen 36600 examples : 67.6 eps, Loss: 5.439, Avg loss: 5.471, Best loss: 5.468\n",
      "    [batch 373]: seen 37300 examples : 67.5 eps, Loss: 5.499, Avg loss: 5.468, Best loss: 5.468\n",
      "    [batch 380]: seen 38000 examples : 67.5 eps, Loss: 5.672, Avg loss: 5.468, Best loss: 5.466\n",
      "    [batch 387]: seen 38700 examples : 67.5 eps, Loss: 5.470, Avg loss: 5.469, Best loss: 5.466\n",
      "    [batch 394]: seen 39400 examples : 67.5 eps, Loss: 5.543, Avg loss: 5.470, Best loss: 5.466\n",
      "    [batch 401]: seen 40100 examples : 67.5 eps, Loss: 5.498, Avg loss: 5.468, Best loss: 5.466\n",
      "    [batch 408]: seen 40800 examples : 67.5 eps, Loss: 5.429, Avg loss: 5.467, Best loss: 5.466\n",
      "    [batch 414]: seen 41400 examples : 67.4 eps, Loss: 5.407, Avg loss: 5.466, Best loss: 5.466\n",
      "    [batch 421]: seen 42100 examples : 67.4 eps, Loss: 5.337, Avg loss: 5.465, Best loss: 5.465\n",
      "    [batch 428]: seen 42800 examples : 67.4 eps, Loss: 5.433, Avg loss: 5.466, Best loss: 5.465\n",
      "    [batch 435]: seen 43500 examples : 67.5 eps, Loss: 5.520, Avg loss: 5.464, Best loss: 5.463\n",
      "    [batch 442]: seen 44200 examples : 67.5 eps, Loss: 5.348, Avg loss: 5.462, Best loss: 5.462\n",
      "    [batch 449]: seen 44900 examples : 67.5 eps, Loss: 5.495, Avg loss: 5.461, Best loss: 5.461\n",
      "    [batch 456]: seen 45600 examples : 67.4 eps, Loss: 5.424, Avg loss: 5.458, Best loss: 5.458\n",
      "    [batch 463]: seen 46300 examples : 67.4 eps, Loss: 5.507, Avg loss: 5.457, Best loss: 5.457\n",
      "    [batch 470]: seen 47000 examples : 67.4 eps, Loss: 5.489, Avg loss: 5.457, Best loss: 5.455\n",
      "    [batch 477]: seen 47700 examples : 67.4 eps, Loss: 5.484, Avg loss: 5.459, Best loss: 5.455\n",
      "    [batch 484]: seen 48400 examples : 67.4 eps, Loss: 5.470, Avg loss: 5.461, Best loss: 5.455\n",
      "    [batch 491]: seen 49100 examples : 67.4 eps, Loss: 5.528, Avg loss: 5.461, Best loss: 5.455\n",
      "    [batch 498]: seen 49800 examples : 67.4 eps, Loss: 5.447, Avg loss: 5.458, Best loss: 5.455\n",
      "    [batch 505]: seen 50500 examples : 67.5 eps, Loss: 5.445, Avg loss: 5.458, Best loss: 5.455\n",
      "    [batch 512]: seen 51200 examples : 67.4 eps, Loss: 5.484, Avg loss: 5.458, Best loss: 5.455\n",
      "    [batch 519]: seen 51900 examples : 67.4 eps, Loss: 5.491, Avg loss: 5.457, Best loss: 5.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 526]: seen 52600 examples : 67.5 eps, Loss: 5.496, Avg loss: 5.459, Best loss: 5.455\n",
      "    [batch 533]: seen 53300 examples : 67.4 eps, Loss: 5.513, Avg loss: 5.459, Best loss: 5.455\n",
      "    [batch 540]: seen 54000 examples : 67.4 eps, Loss: 5.457, Avg loss: 5.458, Best loss: 5.455\n",
      "    [batch 547]: seen 54700 examples : 67.4 eps, Loss: 5.464, Avg loss: 5.458, Best loss: 5.455\n",
      "    [batch 554]: seen 55400 examples : 67.4 eps, Loss: 5.478, Avg loss: 5.456, Best loss: 5.455\n",
      "    [batch 561]: seen 56100 examples : 67.4 eps, Loss: 5.496, Avg loss: 5.455, Best loss: 5.454\n",
      "    [batch 568]: seen 56800 examples : 67.4 eps, Loss: 5.453, Avg loss: 5.453, Best loss: 5.453\n",
      "    [batch 575]: seen 57500 examples : 67.4 eps, Loss: 5.340, Avg loss: 5.454, Best loss: 5.453\n",
      "    [batch 582]: seen 58200 examples : 67.4 eps, Loss: 5.405, Avg loss: 5.453, Best loss: 5.453\n",
      "    [batch 589]: seen 58900 examples : 67.4 eps, Loss: 5.540, Avg loss: 5.456, Best loss: 5.453\n",
      "    [batch 596]: seen 59600 examples : 67.4 eps, Loss: 5.541, Avg loss: 5.458, Best loss: 5.453\n",
      "    [batch 603]: seen 60300 examples : 67.4 eps, Loss: 5.459, Avg loss: 5.456, Best loss: 5.453\n",
      "    [batch 610]: seen 61000 examples : 67.4 eps, Loss: 5.350, Avg loss: 5.456, Best loss: 5.453\n",
      "    [batch 617]: seen 61700 examples : 67.4 eps, Loss: 5.435, Avg loss: 5.457, Best loss: 5.453\n",
      "    [batch 624]: seen 62400 examples : 67.4 eps, Loss: 5.491, Avg loss: 5.455, Best loss: 5.453\n",
      "    [batch 631]: seen 63100 examples : 67.4 eps, Loss: 5.413, Avg loss: 5.456, Best loss: 5.453\n",
      "    [batch 638]: seen 63800 examples : 67.4 eps, Loss: 5.460, Avg loss: 5.454, Best loss: 5.453\n",
      "    [batch 645]: seen 64500 examples : 67.4 eps, Loss: 5.529, Avg loss: 5.452, Best loss: 5.451\n",
      "    [batch 652]: seen 65200 examples : 67.4 eps, Loss: 5.462, Avg loss: 5.451, Best loss: 5.451\n",
      "    [batch 659]: seen 65900 examples : 67.4 eps, Loss: 5.466, Avg loss: 5.452, Best loss: 5.451\n",
      "    [batch 666]: seen 66600 examples : 67.4 eps, Loss: 5.377, Avg loss: 5.451, Best loss: 5.450\n",
      "    [batch 673]: seen 67300 examples : 67.4 eps, Loss: 5.508, Avg loss: 5.451, Best loss: 5.450\n",
      "    [batch 680]: seen 68000 examples : 67.4 eps, Loss: 5.409, Avg loss: 5.451, Best loss: 5.450\n",
      "    [batch 687]: seen 68700 examples : 67.4 eps, Loss: 5.330, Avg loss: 5.449, Best loss: 5.449\n",
      "    [batch 694]: seen 69400 examples : 67.4 eps, Loss: 5.533, Avg loss: 5.451, Best loss: 5.449\n",
      "    [batch 701]: seen 70100 examples : 67.3 eps, Loss: 5.432, Avg loss: 5.453, Best loss: 5.449\n",
      "    [batch 708]: seen 70800 examples : 67.3 eps, Loss: 5.447, Avg loss: 5.453, Best loss: 5.449\n",
      "    [batch 715]: seen 71500 examples : 67.3 eps, Loss: 5.445, Avg loss: 5.455, Best loss: 5.449\n",
      "    [batch 722]: seen 72200 examples : 67.3 eps, Loss: 5.342, Avg loss: 5.455, Best loss: 5.449\n",
      "    [batch 729]: seen 72900 examples : 67.3 eps, Loss: 5.512, Avg loss: 5.454, Best loss: 5.449\n",
      "    [batch 736]: seen 73600 examples : 67.3 eps, Loss: 5.386, Avg loss: 5.452, Best loss: 5.449\n",
      "    [batch 743]: seen 74300 examples : 67.3 eps, Loss: 5.534, Avg loss: 5.452, Best loss: 5.449\n",
      "    [batch 750]: seen 75000 examples : 67.3 eps, Loss: 5.341, Avg loss: 5.450, Best loss: 5.449\n",
      "    [batch 757]: seen 75700 examples : 67.3 eps, Loss: 5.472, Avg loss: 5.450, Best loss: 5.449\n",
      "    [batch 764]: seen 76400 examples : 67.3 eps, Loss: 5.362, Avg loss: 5.448, Best loss: 5.448\n",
      "    [batch 771]: seen 77100 examples : 67.3 eps, Loss: 5.460, Avg loss: 5.448, Best loss: 5.448\n",
      "    [batch 778]: seen 77800 examples : 67.3 eps, Loss: 5.390, Avg loss: 5.447, Best loss: 5.447\n",
      "    [batch 785]: seen 78500 examples : 67.2 eps, Loss: 5.483, Avg loss: 5.446, Best loss: 5.446\n",
      "    [batch 792]: seen 79200 examples : 67.3 eps, Loss: 5.528, Avg loss: 5.450, Best loss: 5.446\n",
      "    [batch 799]: seen 79900 examples : 67.2 eps, Loss: 5.452, Avg loss: 5.447, Best loss: 5.446\n",
      "    [batch 806]: seen 80600 examples : 67.2 eps, Loss: 5.464, Avg loss: 5.447, Best loss: 5.446\n",
      "    [batch 813]: seen 81300 examples : 67.2 eps, Loss: 5.467, Avg loss: 5.450, Best loss: 5.446\n",
      "    [batch 820]: seen 82000 examples : 67.2 eps, Loss: 5.440, Avg loss: 5.451, Best loss: 5.446\n",
      "    [batch 827]: seen 82700 examples : 67.2 eps, Loss: 5.495, Avg loss: 5.451, Best loss: 5.446\n",
      "    [batch 834]: seen 83400 examples : 67.2 eps, Loss: 5.391, Avg loss: 5.451, Best loss: 5.446\n",
      "    [batch 841]: seen 84100 examples : 67.2 eps, Loss: 5.441, Avg loss: 5.449, Best loss: 5.446\n",
      "    [batch 848]: seen 84800 examples : 67.2 eps, Loss: 5.434, Avg loss: 5.450, Best loss: 5.446\n",
      "    [batch 855]: seen 85500 examples : 67.1 eps, Loss: 5.437, Avg loss: 5.451, Best loss: 5.446\n",
      "    [batch 862]: seen 86200 examples : 67.1 eps, Loss: 5.480, Avg loss: 5.450, Best loss: 5.446\n",
      "    [batch 869]: seen 86900 examples : 67.2 eps, Loss: 5.440, Avg loss: 5.447, Best loss: 5.446\n",
      "    [batch 876]: seen 87600 examples : 67.1 eps, Loss: 5.586, Avg loss: 5.445, Best loss: 5.444\n",
      "    [batch 883]: seen 88300 examples : 67.1 eps, Loss: 5.588, Avg loss: 5.446, Best loss: 5.444\n",
      "    [batch 890]: seen 89000 examples : 67.1 eps, Loss: 5.476, Avg loss: 5.447, Best loss: 5.444\n",
      "    [batch 897]: seen 89700 examples : 67.1 eps, Loss: 5.444, Avg loss: 5.445, Best loss: 5.444\n",
      "    [batch 904]: seen 90400 examples : 67.1 eps, Loss: 5.477, Avg loss: 5.446, Best loss: 5.444\n",
      "    [batch 911]: seen 91100 examples : 67.1 eps, Loss: 5.403, Avg loss: 5.444, Best loss: 5.444\n",
      "    [batch 918]: seen 91800 examples : 67.1 eps, Loss: 5.545, Avg loss: 5.446, Best loss: 5.444\n",
      "    [batch 925]: seen 92500 examples : 67.1 eps, Loss: 5.455, Avg loss: 5.448, Best loss: 5.444\n",
      "    [batch 932]: seen 93200 examples : 67.1 eps, Loss: 5.421, Avg loss: 5.449, Best loss: 5.444\n",
      "    [batch 938]: seen 93800 examples : 67.1 eps, Loss: 5.444, Avg loss: 5.447, Best loss: 5.444\n",
      "    [batch 945]: seen 94500 examples : 67.1 eps, Loss: 5.371, Avg loss: 5.447, Best loss: 5.444\n",
      "    [batch 952]: seen 95200 examples : 67.1 eps, Loss: 5.519, Avg loss: 5.447, Best loss: 5.444\n",
      "    [batch 959]: seen 95900 examples : 67.1 eps, Loss: 5.521, Avg loss: 5.446, Best loss: 5.444\n",
      "    [batch 966]: seen 96600 examples : 67.1 eps, Loss: 5.448, Avg loss: 5.446, Best loss: 5.444\n",
      "    [batch 973]: seen 97300 examples : 67.1 eps, Loss: 5.433, Avg loss: 5.444, Best loss: 5.444\n",
      "    [batch 980]: seen 98000 examples : 67.1 eps, Loss: 5.400, Avg loss: 5.443, Best loss: 5.443\n",
      "    [batch 987]: seen 98700 examples : 67.0 eps, Loss: 5.335, Avg loss: 5.442, Best loss: 5.442\n",
      "    [batch 994]: seen 99400 examples : 67.0 eps, Loss: 5.518, Avg loss: 5.443, Best loss: 5.442\n",
      "    [batch 1001]: seen 100100 examples : 67.0 eps, Loss: 5.398, Avg loss: 5.445, Best loss: 5.442\n",
      "    [batch 1008]: seen 100800 examples : 67.0 eps, Loss: 5.457, Avg loss: 5.440, Best loss: 5.440\n",
      "    [batch 1015]: seen 101500 examples : 67.0 eps, Loss: 5.582, Avg loss: 5.443, Best loss: 5.440\n",
      "    [batch 1022]: seen 102200 examples : 67.0 eps, Loss: 5.466, Avg loss: 5.444, Best loss: 5.440\n",
      "    [batch 1029]: seen 102900 examples : 67.0 eps, Loss: 5.396, Avg loss: 5.442, Best loss: 5.440\n",
      "    [batch 1036]: seen 103600 examples : 66.9 eps, Loss: 5.411, Avg loss: 5.439, Best loss: 5.439\n",
      "    [batch 1043]: seen 104300 examples : 66.9 eps, Loss: 5.434, Avg loss: 5.441, Best loss: 5.439\n",
      "    [batch 1049]: seen 104900 examples : 66.9 eps, Loss: 5.289, Avg loss: 5.439, Best loss: 5.439\n",
      "    [batch 1056]: seen 105600 examples : 66.9 eps, Loss: 5.439, Avg loss: 5.437, Best loss: 5.437\n",
      "    [batch 1063]: seen 106300 examples : 66.9 eps, Loss: 5.485, Avg loss: 5.439, Best loss: 5.437\n",
      "    [batch 1070]: seen 107000 examples : 66.9 eps, Loss: 5.438, Avg loss: 5.437, Best loss: 5.437\n",
      "    [batch 1077]: seen 107700 examples : 66.9 eps, Loss: 5.419, Avg loss: 5.437, Best loss: 5.436\n",
      "    [batch 1084]: seen 108400 examples : 66.9 eps, Loss: 5.397, Avg loss: 5.436, Best loss: 5.436\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-23517\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-23517\n",
      "    [batch 1090]: seen 109000 examples : 66.8 eps, Loss: 5.402, Avg loss: 5.436, Best loss: 5.436\n",
      "    [batch 1097]: seen 109700 examples : 66.8 eps, Loss: 5.360, Avg loss: 5.437, Best loss: 5.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1104]: seen 110400 examples : 66.9 eps, Loss: 5.465, Avg loss: 5.436, Best loss: 5.436\n",
      "    [batch 1111]: seen 111100 examples : 66.9 eps, Loss: 5.481, Avg loss: 5.435, Best loss: 5.434\n",
      "    [batch 1118]: seen 111800 examples : 66.8 eps, Loss: 5.409, Avg loss: 5.434, Best loss: 5.434\n",
      "    [batch 1125]: seen 112500 examples : 66.9 eps, Loss: 5.484, Avg loss: 5.435, Best loss: 5.433\n",
      "    [batch 1132]: seen 113200 examples : 66.9 eps, Loss: 5.463, Avg loss: 5.436, Best loss: 5.433\n",
      "    [batch 1139]: seen 113900 examples : 66.9 eps, Loss: 5.379, Avg loss: 5.434, Best loss: 5.433\n",
      "    [batch 1146]: seen 114600 examples : 66.9 eps, Loss: 5.314, Avg loss: 5.431, Best loss: 5.431\n",
      "    [batch 1153]: seen 115300 examples : 66.8 eps, Loss: 5.539, Avg loss: 5.434, Best loss: 5.431\n",
      "    [batch 1160]: seen 116000 examples : 66.9 eps, Loss: 5.576, Avg loss: 5.437, Best loss: 5.431\n",
      "    [batch 1167]: seen 116700 examples : 66.9 eps, Loss: 5.421, Avg loss: 5.436, Best loss: 5.431\n",
      "    [batch 1174]: seen 117400 examples : 66.9 eps, Loss: 5.437, Avg loss: 5.436, Best loss: 5.431\n",
      "    [batch 1181]: seen 118100 examples : 66.9 eps, Loss: 5.450, Avg loss: 5.436, Best loss: 5.431\n",
      "    [batch 1188]: seen 118800 examples : 66.9 eps, Loss: 5.478, Avg loss: 5.434, Best loss: 5.431\n",
      "    [batch 1195]: seen 119500 examples : 66.8 eps, Loss: 5.368, Avg loss: 5.433, Best loss: 5.431\n",
      "    [batch 1202]: seen 120200 examples : 66.8 eps, Loss: 5.454, Avg loss: 5.430, Best loss: 5.430\n",
      "    [batch 1209]: seen 120900 examples : 66.8 eps, Loss: 5.367, Avg loss: 5.432, Best loss: 5.430\n",
      "    [batch 1216]: seen 121600 examples : 66.8 eps, Loss: 5.491, Avg loss: 5.433, Best loss: 5.430\n",
      "    [batch 1223]: seen 122300 examples : 66.8 eps, Loss: 5.498, Avg loss: 5.434, Best loss: 5.430\n",
      "    [batch 1230]: seen 123000 examples : 66.8 eps, Loss: 5.462, Avg loss: 5.434, Best loss: 5.430\n",
      "    [batch 1237]: seen 123700 examples : 66.8 eps, Loss: 5.411, Avg loss: 5.433, Best loss: 5.430\n",
      "    [batch 1244]: seen 124400 examples : 66.8 eps, Loss: 5.271, Avg loss: 5.432, Best loss: 5.430\n",
      "    [batch 1251]: seen 125100 examples : 66.8 eps, Loss: 5.546, Avg loss: 5.434, Best loss: 5.430\n",
      "    [batch 1258]: seen 125800 examples : 66.8 eps, Loss: 5.428, Avg loss: 5.433, Best loss: 5.430\n",
      "    [batch 1265]: seen 126500 examples : 66.8 eps, Loss: 5.383, Avg loss: 5.431, Best loss: 5.430\n",
      "    [batch 1272]: seen 127200 examples : 66.8 eps, Loss: 5.391, Avg loss: 5.429, Best loss: 5.429\n",
      "    [batch 1279]: seen 127900 examples : 66.8 eps, Loss: 5.407, Avg loss: 5.427, Best loss: 5.427\n",
      "    [batch 1286]: seen 128600 examples : 66.8 eps, Loss: 5.429, Avg loss: 5.427, Best loss: 5.426\n",
      "    [batch 1292]: seen 129200 examples : 66.8 eps, Loss: 5.500, Avg loss: 5.426, Best loss: 5.425\n",
      "    [batch 1299]: seen 129900 examples : 66.8 eps, Loss: 5.415, Avg loss: 5.427, Best loss: 5.425\n",
      "    [batch 1306]: seen 130600 examples : 66.8 eps, Loss: 5.460, Avg loss: 5.424, Best loss: 5.423\n",
      "    [batch 1313]: seen 131300 examples : 66.8 eps, Loss: 5.446, Avg loss: 5.424, Best loss: 5.423\n",
      "    [batch 1320]: seen 132000 examples : 66.8 eps, Loss: 5.456, Avg loss: 5.423, Best loss: 5.423\n",
      "    [batch 1327]: seen 132700 examples : 66.8 eps, Loss: 5.447, Avg loss: 5.425, Best loss: 5.423\n",
      "    [batch 1334]: seen 133400 examples : 66.8 eps, Loss: 5.454, Avg loss: 5.425, Best loss: 5.423\n",
      "    [batch 1341]: seen 134100 examples : 66.8 eps, Loss: 5.396, Avg loss: 5.423, Best loss: 5.423\n",
      "    [batch 1348]: seen 134800 examples : 66.8 eps, Loss: 5.401, Avg loss: 5.423, Best loss: 5.422\n",
      "    [batch 1355]: seen 135500 examples : 66.8 eps, Loss: 5.436, Avg loss: 5.424, Best loss: 5.422\n",
      "    [batch 1362]: seen 136200 examples : 66.8 eps, Loss: 5.402, Avg loss: 5.422, Best loss: 5.422\n",
      "    [batch 1369]: seen 136900 examples : 66.8 eps, Loss: 5.404, Avg loss: 5.422, Best loss: 5.422\n",
      "    [batch 1376]: seen 137600 examples : 66.8 eps, Loss: 5.499, Avg loss: 5.419, Best loss: 5.418\n",
      "    [batch 1383]: seen 138300 examples : 66.8 eps, Loss: 5.378, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1389]: seen 138900 examples : 66.7 eps, Loss: 5.556, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1396]: seen 139600 examples : 66.7 eps, Loss: 5.345, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1403]: seen 140300 examples : 66.8 eps, Loss: 5.351, Avg loss: 5.421, Best loss: 5.418\n",
      "    [batch 1410]: seen 141000 examples : 66.8 eps, Loss: 5.415, Avg loss: 5.420, Best loss: 5.418\n",
      "    [batch 1417]: seen 141700 examples : 66.8 eps, Loss: 5.506, Avg loss: 5.421, Best loss: 5.418\n",
      "    [batch 1424]: seen 142400 examples : 66.8 eps, Loss: 5.462, Avg loss: 5.424, Best loss: 5.418\n",
      "    [batch 1431]: seen 143100 examples : 66.8 eps, Loss: 5.303, Avg loss: 5.426, Best loss: 5.418\n",
      "    [batch 1438]: seen 143800 examples : 66.8 eps, Loss: 5.437, Avg loss: 5.425, Best loss: 5.418\n",
      "    [batch 1444]: seen 144400 examples : 66.7 eps, Loss: 5.417, Avg loss: 5.424, Best loss: 5.418\n",
      "    [batch 1451]: seen 145100 examples : 66.7 eps, Loss: 5.424, Avg loss: 5.423, Best loss: 5.418\n",
      "    [batch 1458]: seen 145800 examples : 66.8 eps, Loss: 5.464, Avg loss: 5.427, Best loss: 5.418\n",
      "    [batch 1465]: seen 146500 examples : 66.8 eps, Loss: 5.425, Avg loss: 5.424, Best loss: 5.418\n",
      "    [batch 1472]: seen 147200 examples : 66.8 eps, Loss: 5.348, Avg loss: 5.424, Best loss: 5.418\n",
      "    [batch 1479]: seen 147900 examples : 66.8 eps, Loss: 5.463, Avg loss: 5.424, Best loss: 5.418\n",
      "    [batch 1486]: seen 148600 examples : 66.8 eps, Loss: 5.408, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1492]: seen 149200 examples : 66.7 eps, Loss: 5.376, Avg loss: 5.421, Best loss: 5.418\n",
      "    [batch 1499]: seen 149900 examples : 66.7 eps, Loss: 5.407, Avg loss: 5.423, Best loss: 5.418\n",
      "    [batch 1506]: seen 150600 examples : 66.8 eps, Loss: 5.387, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1513]: seen 151300 examples : 66.8 eps, Loss: 5.474, Avg loss: 5.423, Best loss: 5.418\n",
      "    [batch 1520]: seen 152000 examples : 66.8 eps, Loss: 5.379, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1527]: seen 152700 examples : 66.8 eps, Loss: 5.388, Avg loss: 5.421, Best loss: 5.418\n",
      "    [batch 1534]: seen 153400 examples : 66.8 eps, Loss: 5.443, Avg loss: 5.422, Best loss: 5.418\n",
      "    [batch 1541]: seen 154100 examples : 66.8 eps, Loss: 5.381, Avg loss: 5.420, Best loss: 5.418\n",
      "    [batch 1548]: seen 154800 examples : 66.8 eps, Loss: 5.341, Avg loss: 5.420, Best loss: 5.418\n",
      "    [batch 1555]: seen 155500 examples : 66.8 eps, Loss: 5.344, Avg loss: 5.418, Best loss: 5.418\n",
      "    [batch 1562]: seen 156200 examples : 66.8 eps, Loss: 5.443, Avg loss: 5.417, Best loss: 5.417\n",
      "    [batch 1569]: seen 156900 examples : 66.8 eps, Loss: 5.339, Avg loss: 5.415, Best loss: 5.415\n",
      "    [batch 1575]: seen 157500 examples : 66.8 eps, Loss: 5.407, Avg loss: 5.415, Best loss: 5.414\n",
      "    [batch 1582]: seen 158200 examples : 66.8 eps, Loss: 5.418, Avg loss: 5.415, Best loss: 5.414\n",
      "    [batch 1589]: seen 158900 examples : 66.8 eps, Loss: 5.349, Avg loss: 5.416, Best loss: 5.414\n",
      "    [batch 1596]: seen 159600 examples : 66.8 eps, Loss: 5.402, Avg loss: 5.418, Best loss: 5.414\n",
      "    [batch 1603]: seen 160300 examples : 66.8 eps, Loss: 5.370, Avg loss: 5.418, Best loss: 5.414\n",
      "    [batch 1609]: seen 160900 examples : 66.8 eps, Loss: 5.448, Avg loss: 5.417, Best loss: 5.414\n",
      "    [batch 1616]: seen 161600 examples : 66.8 eps, Loss: 5.401, Avg loss: 5.416, Best loss: 5.414\n",
      "    [batch 1623]: seen 162300 examples : 66.8 eps, Loss: 5.330, Avg loss: 5.415, Best loss: 5.414\n",
      "    [batch 1630]: seen 163000 examples : 66.8 eps, Loss: 5.290, Avg loss: 5.414, Best loss: 5.414\n",
      "    [batch 1637]: seen 163700 examples : 66.8 eps, Loss: 5.379, Avg loss: 5.414, Best loss: 5.413\n",
      "    [batch 1644]: seen 164400 examples : 66.8 eps, Loss: 5.484, Avg loss: 5.413, Best loss: 5.412\n",
      "    [batch 1651]: seen 165100 examples : 66.8 eps, Loss: 5.310, Avg loss: 5.412, Best loss: 5.412\n",
      "    [batch 1658]: seen 165800 examples : 66.8 eps, Loss: 5.414, Avg loss: 5.410, Best loss: 5.410\n",
      "    [batch 1665]: seen 166500 examples : 66.8 eps, Loss: 5.390, Avg loss: 5.408, Best loss: 5.408\n",
      "    [batch 1672]: seen 167200 examples : 66.8 eps, Loss: 5.392, Avg loss: 5.408, Best loss: 5.407\n",
      "    [batch 1679]: seen 167900 examples : 66.8 eps, Loss: 5.424, Avg loss: 5.408, Best loss: 5.407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1686]: seen 168600 examples : 66.8 eps, Loss: 5.490, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1693]: seen 169300 examples : 66.8 eps, Loss: 5.361, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 1699]: seen 169900 examples : 66.7 eps, Loss: 5.424, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1706]: seen 170600 examples : 66.7 eps, Loss: 5.345, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1713]: seen 171300 examples : 66.8 eps, Loss: 5.515, Avg loss: 5.414, Best loss: 5.407\n",
      "    [batch 1720]: seen 172000 examples : 66.8 eps, Loss: 5.334, Avg loss: 5.413, Best loss: 5.407\n",
      "    [batch 1727]: seen 172700 examples : 66.8 eps, Loss: 5.460, Avg loss: 5.413, Best loss: 5.407\n",
      "    [batch 1734]: seen 173400 examples : 66.8 eps, Loss: 5.426, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 1741]: seen 174100 examples : 66.7 eps, Loss: 5.461, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1748]: seen 174800 examples : 66.7 eps, Loss: 5.497, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 1754]: seen 175400 examples : 66.7 eps, Loss: 5.430, Avg loss: 5.414, Best loss: 5.407\n",
      "    [batch 1761]: seen 176100 examples : 66.7 eps, Loss: 5.483, Avg loss: 5.416, Best loss: 5.407\n",
      "    [batch 1768]: seen 176800 examples : 66.7 eps, Loss: 5.371, Avg loss: 5.413, Best loss: 5.407\n",
      "    [batch 1775]: seen 177500 examples : 66.7 eps, Loss: 5.373, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1782]: seen 178200 examples : 66.7 eps, Loss: 5.366, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1789]: seen 178900 examples : 66.7 eps, Loss: 5.445, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 1796]: seen 179600 examples : 66.8 eps, Loss: 5.321, Avg loss: 5.408, Best loss: 5.407\n",
      "    [batch 1803]: seen 180300 examples : 66.8 eps, Loss: 5.434, Avg loss: 5.408, Best loss: 5.407\n",
      "    [batch 1810]: seen 181000 examples : 66.8 eps, Loss: 5.402, Avg loss: 5.407, Best loss: 5.407\n",
      "    [batch 1817]: seen 181700 examples : 66.8 eps, Loss: 5.444, Avg loss: 5.408, Best loss: 5.407\n",
      "    [batch 1824]: seen 182400 examples : 66.8 eps, Loss: 5.359, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1831]: seen 183100 examples : 66.8 eps, Loss: 5.525, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 1838]: seen 183800 examples : 66.7 eps, Loss: 5.401, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1845]: seen 184500 examples : 66.8 eps, Loss: 5.475, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1852]: seen 185200 examples : 66.8 eps, Loss: 5.286, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1859]: seen 185900 examples : 66.8 eps, Loss: 5.445, Avg loss: 5.413, Best loss: 5.407\n",
      "    [batch 1866]: seen 186600 examples : 66.8 eps, Loss: 5.487, Avg loss: 5.413, Best loss: 5.407\n",
      "    [batch 1873]: seen 187300 examples : 66.8 eps, Loss: 5.394, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1879]: seen 187900 examples : 66.7 eps, Loss: 5.465, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1886]: seen 188600 examples : 66.7 eps, Loss: 5.275, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 1893]: seen 189300 examples : 66.7 eps, Loss: 5.484, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1900]: seen 190000 examples : 66.7 eps, Loss: 5.433, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1907]: seen 190700 examples : 66.8 eps, Loss: 5.509, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 1914]: seen 191400 examples : 66.8 eps, Loss: 5.438, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1921]: seen 192100 examples : 66.8 eps, Loss: 5.378, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 1928]: seen 192800 examples : 66.8 eps, Loss: 5.365, Avg loss: 5.408, Best loss: 5.407\n",
      "    [batch 1935]: seen 193500 examples : 66.8 eps, Loss: 5.416, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 1942]: seen 194200 examples : 66.8 eps, Loss: 5.422, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 1949]: seen 194900 examples : 66.8 eps, Loss: 5.490, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1956]: seen 195600 examples : 66.8 eps, Loss: 5.381, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1963]: seen 196300 examples : 66.8 eps, Loss: 5.412, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1970]: seen 197000 examples : 66.8 eps, Loss: 5.465, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 1977]: seen 197700 examples : 66.7 eps, Loss: 5.459, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 1984]: seen 198400 examples : 66.7 eps, Loss: 5.439, Avg loss: 5.411, Best loss: 5.407\n",
      "    [batch 1991]: seen 199100 examples : 66.7 eps, Loss: 5.453, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 1998]: seen 199800 examples : 66.7 eps, Loss: 5.452, Avg loss: 5.414, Best loss: 5.407\n",
      "    [batch 2005]: seen 200500 examples : 66.7 eps, Loss: 5.344, Avg loss: 5.412, Best loss: 5.407\n",
      "    [batch 2012]: seen 201200 examples : 66.7 eps, Loss: 5.315, Avg loss: 5.413, Best loss: 5.407\n",
      "    [batch 2018]: seen 201800 examples : 66.7 eps, Loss: 5.375, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 2025]: seen 202500 examples : 66.7 eps, Loss: 5.398, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 2032]: seen 203200 examples : 66.7 eps, Loss: 5.498, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 2039]: seen 203900 examples : 66.7 eps, Loss: 5.400, Avg loss: 5.407, Best loss: 5.407\n",
      "    [batch 2046]: seen 204600 examples : 66.7 eps, Loss: 5.379, Avg loss: 5.408, Best loss: 5.407\n",
      "    [batch 2053]: seen 205300 examples : 66.7 eps, Loss: 5.369, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 2060]: seen 206000 examples : 66.8 eps, Loss: 5.432, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 2067]: seen 206700 examples : 66.8 eps, Loss: 5.466, Avg loss: 5.410, Best loss: 5.407\n",
      "    [batch 2074]: seen 207400 examples : 66.8 eps, Loss: 5.383, Avg loss: 5.409, Best loss: 5.407\n",
      "    [batch 2081]: seen 208100 examples : 66.8 eps, Loss: 5.356, Avg loss: 5.407, Best loss: 5.407\n",
      "    [batch 2088]: seen 208800 examples : 66.8 eps, Loss: 5.503, Avg loss: 5.407, Best loss: 5.405\n",
      "    [batch 2095]: seen 209500 examples : 66.7 eps, Loss: 5.424, Avg loss: 5.408, Best loss: 5.405\n",
      "    [batch 2102]: seen 210200 examples : 66.8 eps, Loss: 5.322, Avg loss: 5.408, Best loss: 5.405\n",
      "    [batch 2109]: seen 210900 examples : 66.8 eps, Loss: 5.373, Avg loss: 5.407, Best loss: 5.405\n",
      "    [batch 2116]: seen 211600 examples : 66.8 eps, Loss: 5.335, Avg loss: 5.405, Best loss: 5.405\n",
      "    [batch 2123]: seen 212300 examples : 66.8 eps, Loss: 5.428, Avg loss: 5.405, Best loss: 5.404\n",
      "    [batch 2130]: seen 213000 examples : 66.8 eps, Loss: 5.366, Avg loss: 5.408, Best loss: 5.404\n",
      "    [batch 2137]: seen 213700 examples : 66.8 eps, Loss: 5.425, Avg loss: 5.409, Best loss: 5.404\n",
      "    [batch 2144]: seen 214400 examples : 66.8 eps, Loss: 5.364, Avg loss: 5.408, Best loss: 5.404\n",
      "    [batch 2151]: seen 215100 examples : 66.7 eps, Loss: 5.367, Avg loss: 5.408, Best loss: 5.404\n",
      "    [batch 2158]: seen 215800 examples : 66.7 eps, Loss: 5.371, Avg loss: 5.407, Best loss: 5.404\n",
      "    [batch 2165]: seen 216500 examples : 66.8 eps, Loss: 5.397, Avg loss: 5.405, Best loss: 5.404\n",
      "    [batch 2172]: seen 217200 examples : 66.8 eps, Loss: 5.439, Avg loss: 5.406, Best loss: 5.404\n",
      "    [batch 2179]: seen 217900 examples : 66.8 eps, Loss: 5.355, Avg loss: 5.404, Best loss: 5.404\n",
      "    [batch 2186]: seen 218600 examples : 66.8 eps, Loss: 5.226, Avg loss: 5.402, Best loss: 5.402\n",
      "    [batch 2193]: seen 219300 examples : 66.7 eps, Loss: 5.397, Avg loss: 5.401, Best loss: 5.401\n",
      "    [batch 2199]: seen 219900 examples : 66.7 eps, Loss: 5.416, Avg loss: 5.401, Best loss: 5.401\n",
      "    [batch 2206]: seen 220600 examples : 66.7 eps, Loss: 5.334, Avg loss: 5.400, Best loss: 5.400\n",
      "    [batch 2213]: seen 221300 examples : 66.7 eps, Loss: 5.401, Avg loss: 5.401, Best loss: 5.399\n",
      "    [batch 2220]: seen 222000 examples : 66.7 eps, Loss: 5.476, Avg loss: 5.402, Best loss: 5.399\n",
      "    [batch 2227]: seen 222700 examples : 66.7 eps, Loss: 5.356, Avg loss: 5.400, Best loss: 5.399\n",
      "    [batch 2234]: seen 223400 examples : 66.7 eps, Loss: 5.373, Avg loss: 5.400, Best loss: 5.399\n",
      "    [batch 2241]: seen 224100 examples : 66.7 eps, Loss: 5.397, Avg loss: 5.398, Best loss: 5.398\n",
      "    [batch 2248]: seen 224800 examples : 66.7 eps, Loss: 5.428, Avg loss: 5.397, Best loss: 5.396\n",
      "    [batch 2255]: seen 225500 examples : 66.7 eps, Loss: 5.308, Avg loss: 5.399, Best loss: 5.396\n",
      "    [batch 2262]: seen 226200 examples : 66.7 eps, Loss: 5.384, Avg loss: 5.401, Best loss: 5.396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2269]: seen 226900 examples : 66.7 eps, Loss: 5.402, Avg loss: 5.404, Best loss: 5.396\n",
      "    [batch 2276]: seen 227600 examples : 66.7 eps, Loss: 5.423, Avg loss: 5.401, Best loss: 5.396\n",
      "    [batch 2283]: seen 228300 examples : 66.7 eps, Loss: 5.419, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2290]: seen 229000 examples : 66.7 eps, Loss: 5.442, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2297]: seen 229700 examples : 66.7 eps, Loss: 5.333, Avg loss: 5.399, Best loss: 5.396\n",
      "    [batch 2304]: seen 230400 examples : 66.7 eps, Loss: 5.363, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2311]: seen 231100 examples : 66.7 eps, Loss: 5.477, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2318]: seen 231800 examples : 66.7 eps, Loss: 5.401, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2325]: seen 232500 examples : 66.7 eps, Loss: 5.351, Avg loss: 5.398, Best loss: 5.396\n",
      "    [batch 2332]: seen 233200 examples : 66.7 eps, Loss: 5.451, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2339]: seen 233900 examples : 66.7 eps, Loss: 5.431, Avg loss: 5.398, Best loss: 5.396\n",
      "    [batch 2346]: seen 234600 examples : 66.7 eps, Loss: 5.400, Avg loss: 5.401, Best loss: 5.396\n",
      "    [batch 2352]: seen 235200 examples : 66.7 eps, Loss: 5.378, Avg loss: 5.403, Best loss: 5.396\n",
      "    [batch 2359]: seen 235900 examples : 66.7 eps, Loss: 5.412, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2366]: seen 236600 examples : 66.7 eps, Loss: 5.397, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2373]: seen 237300 examples : 66.7 eps, Loss: 5.363, Avg loss: 5.400, Best loss: 5.396\n",
      "    [batch 2380]: seen 238000 examples : 66.7 eps, Loss: 5.363, Avg loss: 5.399, Best loss: 5.396\n",
      "    [batch 2387]: seen 238700 examples : 66.7 eps, Loss: 5.395, Avg loss: 5.397, Best loss: 5.396\n",
      "    [batch 2394]: seen 239400 examples : 66.7 eps, Loss: 5.347, Avg loss: 5.397, Best loss: 5.396\n",
      "    [batch 2401]: seen 240100 examples : 66.7 eps, Loss: 5.434, Avg loss: 5.398, Best loss: 5.396\n",
      "    [batch 2407]: seen 240700 examples : 66.7 eps, Loss: 5.380, Avg loss: 5.399, Best loss: 5.396\n",
      "    [batch 2414]: seen 241400 examples : 66.7 eps, Loss: 5.375, Avg loss: 5.398, Best loss: 5.396\n",
      "    [batch 2421]: seen 242100 examples : 66.7 eps, Loss: 5.421, Avg loss: 5.397, Best loss: 5.396\n",
      "    [batch 2428]: seen 242800 examples : 66.7 eps, Loss: 5.320, Avg loss: 5.396, Best loss: 5.395\n",
      "    [batch 2435]: seen 243500 examples : 66.7 eps, Loss: 5.426, Avg loss: 5.397, Best loss: 5.394\n",
      "    [batch 2442]: seen 244200 examples : 66.7 eps, Loss: 5.400, Avg loss: 5.398, Best loss: 5.394\n",
      "    [batch 2449]: seen 244900 examples : 66.7 eps, Loss: 5.426, Avg loss: 5.397, Best loss: 5.394\n",
      "    [batch 2456]: seen 245600 examples : 66.7 eps, Loss: 5.380, Avg loss: 5.396, Best loss: 5.394\n",
      "    [batch 2463]: seen 246300 examples : 66.7 eps, Loss: 5.403, Avg loss: 5.394, Best loss: 5.394\n",
      "    [batch 2470]: seen 247000 examples : 66.7 eps, Loss: 5.504, Avg loss: 5.394, Best loss: 5.393\n",
      "    [batch 2477]: seen 247700 examples : 66.7 eps, Loss: 5.397, Avg loss: 5.396, Best loss: 5.393\n",
      "    [batch 2484]: seen 248400 examples : 66.7 eps, Loss: 5.349, Avg loss: 5.393, Best loss: 5.393\n",
      "    [batch 2491]: seen 249100 examples : 66.7 eps, Loss: 5.355, Avg loss: 5.392, Best loss: 5.391\n",
      "    [batch 2498]: seen 249800 examples : 66.7 eps, Loss: 5.429, Avg loss: 5.392, Best loss: 5.391\n",
      "    [batch 2505]: seen 250500 examples : 66.7 eps, Loss: 5.430, Avg loss: 5.392, Best loss: 5.391\n",
      "    [batch 2512]: seen 251200 examples : 66.7 eps, Loss: 5.440, Avg loss: 5.391, Best loss: 5.391\n",
      "    [batch 2519]: seen 251900 examples : 66.7 eps, Loss: 5.430, Avg loss: 5.394, Best loss: 5.391\n",
      "    [batch 2526]: seen 252600 examples : 66.7 eps, Loss: 5.407, Avg loss: 5.393, Best loss: 5.391\n",
      "    [batch 2533]: seen 253300 examples : 66.7 eps, Loss: 5.427, Avg loss: 5.394, Best loss: 5.391\n",
      "    [batch 2540]: seen 254000 examples : 66.7 eps, Loss: 5.285, Avg loss: 5.390, Best loss: 5.390\n",
      "    [batch 2547]: seen 254700 examples : 66.7 eps, Loss: 5.294, Avg loss: 5.389, Best loss: 5.389\n",
      "    [batch 2554]: seen 255400 examples : 66.7 eps, Loss: 5.484, Avg loss: 5.391, Best loss: 5.388\n",
      "    [batch 2561]: seen 256100 examples : 66.7 eps, Loss: 5.270, Avg loss: 5.389, Best loss: 5.388\n",
      "    [batch 2568]: seen 256800 examples : 66.7 eps, Loss: 5.353, Avg loss: 5.387, Best loss: 5.387\n",
      "    [batch 2575]: seen 257500 examples : 66.7 eps, Loss: 5.427, Avg loss: 5.390, Best loss: 5.387\n",
      "    [batch 2582]: seen 258200 examples : 66.7 eps, Loss: 5.403, Avg loss: 5.391, Best loss: 5.387\n",
      "    [batch 2589]: seen 258900 examples : 66.7 eps, Loss: 5.347, Avg loss: 5.391, Best loss: 5.387\n",
      "    [batch 2596]: seen 259600 examples : 66.7 eps, Loss: 5.306, Avg loss: 5.388, Best loss: 5.387\n",
      "    [batch 2603]: seen 260300 examples : 66.7 eps, Loss: 5.468, Avg loss: 5.391, Best loss: 5.387\n",
      "    [batch 2609]: seen 260900 examples : 66.7 eps, Loss: 5.315, Avg loss: 5.390, Best loss: 5.387\n",
      "    [batch 2616]: seen 261600 examples : 66.7 eps, Loss: 5.445, Avg loss: 5.387, Best loss: 5.387\n",
      "    [batch 2623]: seen 262300 examples : 66.7 eps, Loss: 5.402, Avg loss: 5.387, Best loss: 5.386\n",
      "    [batch 2630]: seen 263000 examples : 66.7 eps, Loss: 5.336, Avg loss: 5.387, Best loss: 5.386\n",
      "    [batch 2637]: seen 263700 examples : 66.7 eps, Loss: 5.401, Avg loss: 5.385, Best loss: 5.385\n",
      "    [batch 2644]: seen 264400 examples : 66.7 eps, Loss: 5.399, Avg loss: 5.385, Best loss: 5.384\n",
      "    [batch 2651]: seen 265100 examples : 66.7 eps, Loss: 5.278, Avg loss: 5.384, Best loss: 5.384\n",
      "    [batch 2658]: seen 265800 examples : 66.7 eps, Loss: 5.395, Avg loss: 5.386, Best loss: 5.384\n",
      "    [batch 2665]: seen 266500 examples : 66.7 eps, Loss: 5.385, Avg loss: 5.385, Best loss: 5.384\n",
      "    [batch 2672]: seen 267200 examples : 66.7 eps, Loss: 5.271, Avg loss: 5.385, Best loss: 5.384\n",
      "    [batch 2679]: seen 267900 examples : 66.7 eps, Loss: 5.372, Avg loss: 5.385, Best loss: 5.384\n",
      "    [batch 2686]: seen 268600 examples : 66.7 eps, Loss: 5.382, Avg loss: 5.384, Best loss: 5.383\n",
      "    [batch 2693]: seen 269300 examples : 66.7 eps, Loss: 5.420, Avg loss: 5.384, Best loss: 5.383\n",
      "    [batch 2700]: seen 270000 examples : 66.7 eps, Loss: 5.375, Avg loss: 5.381, Best loss: 5.381\n",
      "    [batch 2707]: seen 270700 examples : 66.7 eps, Loss: 5.433, Avg loss: 5.382, Best loss: 5.380\n",
      "    [batch 2714]: seen 271400 examples : 66.7 eps, Loss: 5.396, Avg loss: 5.384, Best loss: 5.380\n",
      "    [batch 2721]: seen 272100 examples : 66.7 eps, Loss: 5.373, Avg loss: 5.382, Best loss: 5.380\n",
      "    [batch 2728]: seen 272800 examples : 66.7 eps, Loss: 5.448, Avg loss: 5.381, Best loss: 5.380\n",
      "    [batch 2735]: seen 273500 examples : 66.7 eps, Loss: 5.422, Avg loss: 5.380, Best loss: 5.380\n",
      "    [batch 2742]: seen 274200 examples : 66.7 eps, Loss: 5.507, Avg loss: 5.382, Best loss: 5.380\n",
      "    [batch 2749]: seen 274900 examples : 66.7 eps, Loss: 5.333, Avg loss: 5.379, Best loss: 5.379\n",
      "    [batch 2756]: seen 275600 examples : 66.7 eps, Loss: 5.498, Avg loss: 5.379, Best loss: 5.377\n",
      "    [batch 2763]: seen 276300 examples : 66.7 eps, Loss: 5.374, Avg loss: 5.379, Best loss: 5.377\n",
      "    [batch 2770]: seen 277000 examples : 66.7 eps, Loss: 5.355, Avg loss: 5.380, Best loss: 5.377\n",
      "    [batch 2777]: seen 277700 examples : 66.7 eps, Loss: 5.412, Avg loss: 5.380, Best loss: 5.377\n",
      "    [batch 2784]: seen 278400 examples : 66.7 eps, Loss: 5.380, Avg loss: 5.379, Best loss: 5.377\n",
      "    [batch 2791]: seen 279100 examples : 66.7 eps, Loss: 5.308, Avg loss: 5.379, Best loss: 5.377\n",
      "    [batch 2798]: seen 279800 examples : 66.7 eps, Loss: 5.367, Avg loss: 5.380, Best loss: 5.377\n",
      "    [batch 2805]: seen 280500 examples : 66.7 eps, Loss: 5.392, Avg loss: 5.378, Best loss: 5.377\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:10:12\n",
      "[EPOCH 9] Complete. Avg Loss: 5.3773888624235475; Best Loss: 5.377369941086171\n",
      "[EPOCH 10] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.3 eps, Loss: 5.326, Avg loss: 5.374, Best loss: 5.374\n",
      "    [batch 16]: seen 1600 examples : 78.1 eps, Loss: 5.339, Avg loss: 5.373, Best loss: 5.372\n",
      "    [batch 23]: seen 2300 examples : 75.1 eps, Loss: 5.402, Avg loss: 5.372, Best loss: 5.372\n",
      "    [batch 30]: seen 3000 examples : 73.5 eps, Loss: 5.328, Avg loss: 5.372, Best loss: 5.372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 37]: seen 3700 examples : 72.5 eps, Loss: 5.440, Avg loss: 5.371, Best loss: 5.370\n",
      "    [batch 44]: seen 4400 examples : 71.9 eps, Loss: 5.402, Avg loss: 5.372, Best loss: 5.370\n",
      "    [batch 51]: seen 5100 examples : 71.5 eps, Loss: 5.281, Avg loss: 5.370, Best loss: 5.370\n",
      "    [batch 58]: seen 5800 examples : 71.1 eps, Loss: 5.369, Avg loss: 5.371, Best loss: 5.370\n",
      "    [batch 65]: seen 6500 examples : 70.5 eps, Loss: 5.313, Avg loss: 5.371, Best loss: 5.370\n",
      "    [batch 72]: seen 7200 examples : 70.4 eps, Loss: 5.298, Avg loss: 5.371, Best loss: 5.370\n",
      "    [batch 79]: seen 7900 examples : 70.2 eps, Loss: 5.267, Avg loss: 5.369, Best loss: 5.369\n",
      "    [batch 86]: seen 8600 examples : 70.1 eps, Loss: 5.447, Avg loss: 5.371, Best loss: 5.368\n",
      "    [batch 93]: seen 9300 examples : 70.0 eps, Loss: 5.222, Avg loss: 5.372, Best loss: 5.368\n",
      "    [batch 100]: seen 10000 examples : 69.9 eps, Loss: 5.384, Avg loss: 5.371, Best loss: 5.368\n",
      "    [batch 107]: seen 10700 examples : 69.8 eps, Loss: 5.385, Avg loss: 5.369, Best loss: 5.368\n",
      "    [batch 114]: seen 11400 examples : 69.8 eps, Loss: 5.303, Avg loss: 5.366, Best loss: 5.366\n",
      "    [batch 121]: seen 12100 examples : 69.7 eps, Loss: 5.332, Avg loss: 5.365, Best loss: 5.364\n",
      "    [batch 128]: seen 12800 examples : 69.7 eps, Loss: 5.273, Avg loss: 5.364, Best loss: 5.364\n",
      "    [batch 135]: seen 13500 examples : 69.6 eps, Loss: 5.350, Avg loss: 5.363, Best loss: 5.362\n",
      "    [batch 142]: seen 14200 examples : 69.6 eps, Loss: 5.380, Avg loss: 5.365, Best loss: 5.362\n",
      "    [batch 149]: seen 14900 examples : 69.5 eps, Loss: 5.420, Avg loss: 5.368, Best loss: 5.362\n",
      "    [batch 156]: seen 15600 examples : 69.5 eps, Loss: 5.242, Avg loss: 5.366, Best loss: 5.362\n",
      "    [batch 163]: seen 16300 examples : 69.4 eps, Loss: 5.382, Avg loss: 5.367, Best loss: 5.362\n",
      "    [batch 170]: seen 17000 examples : 69.3 eps, Loss: 5.335, Avg loss: 5.366, Best loss: 5.362\n",
      "    [batch 177]: seen 17700 examples : 69.3 eps, Loss: 5.289, Avg loss: 5.365, Best loss: 5.362\n",
      "    [batch 184]: seen 18400 examples : 69.2 eps, Loss: 5.327, Avg loss: 5.363, Best loss: 5.362\n",
      "    [batch 191]: seen 19100 examples : 69.2 eps, Loss: 5.370, Avg loss: 5.364, Best loss: 5.362\n",
      "    [batch 198]: seen 19800 examples : 69.0 eps, Loss: 5.288, Avg loss: 5.362, Best loss: 5.362\n",
      "    [batch 205]: seen 20500 examples : 69.0 eps, Loss: 5.328, Avg loss: 5.358, Best loss: 5.358\n",
      "    [batch 212]: seen 21200 examples : 69.0 eps, Loss: 5.411, Avg loss: 5.359, Best loss: 5.358\n",
      "    [batch 219]: seen 21900 examples : 69.0 eps, Loss: 5.344, Avg loss: 5.361, Best loss: 5.358\n",
      "    [batch 226]: seen 22600 examples : 68.9 eps, Loss: 5.297, Avg loss: 5.362, Best loss: 5.358\n",
      "    [batch 233]: seen 23300 examples : 68.9 eps, Loss: 5.407, Avg loss: 5.362, Best loss: 5.358\n",
      "    [batch 240]: seen 24000 examples : 68.8 eps, Loss: 5.413, Avg loss: 5.362, Best loss: 5.358\n",
      "    [batch 247]: seen 24700 examples : 68.7 eps, Loss: 5.361, Avg loss: 5.360, Best loss: 5.358\n",
      "    [batch 254]: seen 25400 examples : 68.7 eps, Loss: 5.409, Avg loss: 5.360, Best loss: 5.358\n",
      "    [batch 261]: seen 26100 examples : 68.6 eps, Loss: 5.368, Avg loss: 5.365, Best loss: 5.358\n",
      "    [batch 268]: seen 26800 examples : 68.6 eps, Loss: 5.317, Avg loss: 5.365, Best loss: 5.358\n",
      "    [batch 275]: seen 27500 examples : 68.6 eps, Loss: 5.315, Avg loss: 5.365, Best loss: 5.358\n",
      "    [batch 282]: seen 28200 examples : 68.5 eps, Loss: 5.293, Avg loss: 5.366, Best loss: 5.358\n",
      "    [batch 289]: seen 28900 examples : 68.5 eps, Loss: 5.370, Avg loss: 5.366, Best loss: 5.358\n",
      "    [batch 296]: seen 29600 examples : 68.5 eps, Loss: 5.348, Avg loss: 5.366, Best loss: 5.358\n",
      "    [batch 303]: seen 30300 examples : 68.5 eps, Loss: 5.301, Avg loss: 5.364, Best loss: 5.358\n",
      "    [batch 310]: seen 31000 examples : 68.4 eps, Loss: 5.355, Avg loss: 5.363, Best loss: 5.358\n",
      "    [batch 317]: seen 31700 examples : 68.4 eps, Loss: 5.358, Avg loss: 5.363, Best loss: 5.358\n",
      "    [batch 324]: seen 32400 examples : 68.3 eps, Loss: 5.300, Avg loss: 5.365, Best loss: 5.358\n",
      "    [batch 331]: seen 33100 examples : 68.3 eps, Loss: 5.320, Avg loss: 5.365, Best loss: 5.358\n",
      "    [batch 338]: seen 33800 examples : 68.3 eps, Loss: 5.408, Avg loss: 5.364, Best loss: 5.358\n",
      "    [batch 345]: seen 34500 examples : 68.3 eps, Loss: 5.384, Avg loss: 5.364, Best loss: 5.358\n",
      "    [batch 352]: seen 35200 examples : 68.3 eps, Loss: 5.449, Avg loss: 5.364, Best loss: 5.358\n",
      "    [batch 359]: seen 35900 examples : 68.3 eps, Loss: 5.428, Avg loss: 5.365, Best loss: 5.358\n",
      "    [batch 366]: seen 36600 examples : 68.3 eps, Loss: 5.347, Avg loss: 5.364, Best loss: 5.358\n",
      "    [batch 373]: seen 37300 examples : 68.2 eps, Loss: 5.330, Avg loss: 5.363, Best loss: 5.358\n",
      "    [batch 380]: seen 38000 examples : 68.2 eps, Loss: 5.343, Avg loss: 5.362, Best loss: 5.358\n",
      "    [batch 387]: seen 38700 examples : 68.2 eps, Loss: 5.312, Avg loss: 5.360, Best loss: 5.358\n",
      "    [batch 394]: seen 39400 examples : 68.2 eps, Loss: 5.316, Avg loss: 5.359, Best loss: 5.358\n",
      "    [batch 401]: seen 40100 examples : 68.2 eps, Loss: 5.388, Avg loss: 5.357, Best loss: 5.356\n",
      "    [batch 408]: seen 40800 examples : 68.2 eps, Loss: 5.302, Avg loss: 5.356, Best loss: 5.356\n",
      "    [batch 415]: seen 41500 examples : 68.1 eps, Loss: 5.377, Avg loss: 5.355, Best loss: 5.355\n",
      "    [batch 422]: seen 42200 examples : 68.1 eps, Loss: 5.288, Avg loss: 5.355, Best loss: 5.354\n",
      "    [batch 429]: seen 42900 examples : 68.1 eps, Loss: 5.453, Avg loss: 5.356, Best loss: 5.354\n",
      "    [batch 436]: seen 43600 examples : 68.1 eps, Loss: 5.373, Avg loss: 5.355, Best loss: 5.354\n",
      "    [batch 443]: seen 44300 examples : 68.1 eps, Loss: 5.404, Avg loss: 5.354, Best loss: 5.354\n",
      "    [batch 450]: seen 45000 examples : 68.1 eps, Loss: 5.220, Avg loss: 5.350, Best loss: 5.350\n",
      "    [batch 457]: seen 45700 examples : 68.0 eps, Loss: 5.370, Avg loss: 5.352, Best loss: 5.350\n",
      "    [batch 464]: seen 46400 examples : 68.0 eps, Loss: 5.308, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 471]: seen 47100 examples : 68.0 eps, Loss: 5.351, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 478]: seen 47800 examples : 68.0 eps, Loss: 5.492, Avg loss: 5.357, Best loss: 5.350\n",
      "    [batch 485]: seen 48500 examples : 68.0 eps, Loss: 5.327, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 492]: seen 49200 examples : 68.0 eps, Loss: 5.331, Avg loss: 5.356, Best loss: 5.350\n",
      "    [batch 499]: seen 49900 examples : 68.0 eps, Loss: 5.315, Avg loss: 5.357, Best loss: 5.350\n",
      "    [batch 506]: seen 50600 examples : 68.0 eps, Loss: 5.403, Avg loss: 5.359, Best loss: 5.350\n",
      "    [batch 513]: seen 51300 examples : 68.0 eps, Loss: 5.377, Avg loss: 5.357, Best loss: 5.350\n",
      "    [batch 520]: seen 52000 examples : 67.9 eps, Loss: 5.329, Avg loss: 5.356, Best loss: 5.350\n",
      "    [batch 527]: seen 52700 examples : 67.9 eps, Loss: 5.312, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 534]: seen 53400 examples : 67.9 eps, Loss: 5.422, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 541]: seen 54100 examples : 67.9 eps, Loss: 5.335, Avg loss: 5.357, Best loss: 5.350\n",
      "    [batch 548]: seen 54800 examples : 67.9 eps, Loss: 5.355, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 555]: seen 55500 examples : 67.9 eps, Loss: 5.382, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 562]: seen 56200 examples : 67.9 eps, Loss: 5.459, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 569]: seen 56900 examples : 67.9 eps, Loss: 5.224, Avg loss: 5.353, Best loss: 5.350\n",
      "    [batch 576]: seen 57600 examples : 67.9 eps, Loss: 5.293, Avg loss: 5.354, Best loss: 5.350\n",
      "    [batch 583]: seen 58300 examples : 67.9 eps, Loss: 5.376, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 590]: seen 59000 examples : 67.9 eps, Loss: 5.366, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 597]: seen 59700 examples : 67.9 eps, Loss: 5.447, Avg loss: 5.355, Best loss: 5.350\n",
      "    [batch 604]: seen 60400 examples : 67.9 eps, Loss: 5.410, Avg loss: 5.354, Best loss: 5.350\n",
      "    [batch 611]: seen 61100 examples : 67.9 eps, Loss: 5.427, Avg loss: 5.354, Best loss: 5.350\n",
      "    [batch 618]: seen 61800 examples : 67.9 eps, Loss: 5.417, Avg loss: 5.352, Best loss: 5.350\n",
      "    [batch 625]: seen 62500 examples : 67.9 eps, Loss: 5.319, Avg loss: 5.353, Best loss: 5.350\n",
      "    [batch 632]: seen 63200 examples : 67.9 eps, Loss: 5.382, Avg loss: 5.353, Best loss: 5.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 639]: seen 63900 examples : 67.9 eps, Loss: 5.383, Avg loss: 5.351, Best loss: 5.350\n",
      "    [batch 646]: seen 64600 examples : 67.9 eps, Loss: 5.363, Avg loss: 5.352, Best loss: 5.350\n",
      "    [batch 653]: seen 65300 examples : 67.8 eps, Loss: 5.178, Avg loss: 5.348, Best loss: 5.348\n",
      "    [batch 660]: seen 66000 examples : 67.8 eps, Loss: 5.376, Avg loss: 5.349, Best loss: 5.348\n",
      "    [batch 667]: seen 66700 examples : 67.8 eps, Loss: 5.387, Avg loss: 5.350, Best loss: 5.348\n",
      "    [batch 674]: seen 67400 examples : 67.8 eps, Loss: 5.375, Avg loss: 5.349, Best loss: 5.348\n",
      "    [batch 681]: seen 68100 examples : 67.8 eps, Loss: 5.381, Avg loss: 5.349, Best loss: 5.348\n",
      "    [batch 688]: seen 68800 examples : 67.8 eps, Loss: 5.297, Avg loss: 5.348, Best loss: 5.348\n",
      "    [batch 695]: seen 69500 examples : 67.8 eps, Loss: 5.388, Avg loss: 5.346, Best loss: 5.346\n",
      "    [batch 702]: seen 70200 examples : 67.8 eps, Loss: 5.328, Avg loss: 5.349, Best loss: 5.346\n",
      "    [batch 709]: seen 70900 examples : 67.8 eps, Loss: 5.451, Avg loss: 5.348, Best loss: 5.346\n",
      "    [batch 716]: seen 71600 examples : 67.8 eps, Loss: 5.234, Avg loss: 5.346, Best loss: 5.346\n",
      "    [batch 723]: seen 72300 examples : 67.8 eps, Loss: 5.278, Avg loss: 5.347, Best loss: 5.346\n",
      "    [batch 730]: seen 73000 examples : 67.8 eps, Loss: 5.359, Avg loss: 5.347, Best loss: 5.346\n",
      "    [batch 737]: seen 73700 examples : 67.8 eps, Loss: 5.291, Avg loss: 5.346, Best loss: 5.346\n",
      "    [batch 744]: seen 74400 examples : 67.8 eps, Loss: 5.483, Avg loss: 5.348, Best loss: 5.346\n",
      "    [batch 751]: seen 75100 examples : 67.8 eps, Loss: 5.346, Avg loss: 5.350, Best loss: 5.346\n",
      "    [batch 758]: seen 75800 examples : 67.8 eps, Loss: 5.311, Avg loss: 5.347, Best loss: 5.346\n",
      "    [batch 765]: seen 76500 examples : 67.8 eps, Loss: 5.239, Avg loss: 5.346, Best loss: 5.346\n",
      "    [batch 772]: seen 77200 examples : 67.8 eps, Loss: 5.300, Avg loss: 5.348, Best loss: 5.346\n",
      "    [batch 779]: seen 77900 examples : 67.7 eps, Loss: 5.433, Avg loss: 5.348, Best loss: 5.346\n",
      "    [batch 786]: seen 78600 examples : 67.7 eps, Loss: 5.413, Avg loss: 5.349, Best loss: 5.346\n",
      "    [batch 793]: seen 79300 examples : 67.7 eps, Loss: 5.359, Avg loss: 5.351, Best loss: 5.346\n",
      "    [batch 800]: seen 80000 examples : 67.7 eps, Loss: 5.220, Avg loss: 5.348, Best loss: 5.346\n",
      "    [batch 807]: seen 80700 examples : 67.7 eps, Loss: 5.280, Avg loss: 5.346, Best loss: 5.346\n",
      "    [batch 814]: seen 81400 examples : 67.7 eps, Loss: 5.360, Avg loss: 5.346, Best loss: 5.345\n",
      "    [batch 821]: seen 82100 examples : 67.7 eps, Loss: 5.309, Avg loss: 5.344, Best loss: 5.344\n",
      "    [batch 828]: seen 82800 examples : 67.7 eps, Loss: 5.330, Avg loss: 5.343, Best loss: 5.343\n",
      "    [batch 835]: seen 83500 examples : 67.7 eps, Loss: 5.426, Avg loss: 5.345, Best loss: 5.343\n",
      "    [batch 842]: seen 84200 examples : 67.7 eps, Loss: 5.385, Avg loss: 5.341, Best loss: 5.340\n",
      "    [batch 849]: seen 84900 examples : 67.7 eps, Loss: 5.484, Avg loss: 5.344, Best loss: 5.340\n",
      "    [batch 856]: seen 85600 examples : 67.7 eps, Loss: 5.380, Avg loss: 5.343, Best loss: 5.340\n",
      "    [batch 863]: seen 86300 examples : 67.7 eps, Loss: 5.416, Avg loss: 5.344, Best loss: 5.340\n",
      "    [batch 870]: seen 87000 examples : 67.7 eps, Loss: 5.281, Avg loss: 5.345, Best loss: 5.340\n",
      "    [batch 877]: seen 87700 examples : 67.7 eps, Loss: 5.252, Avg loss: 5.345, Best loss: 5.340\n",
      "    [batch 884]: seen 88400 examples : 67.7 eps, Loss: 5.287, Avg loss: 5.344, Best loss: 5.340\n",
      "    [batch 891]: seen 89100 examples : 67.7 eps, Loss: 5.354, Avg loss: 5.344, Best loss: 5.340\n",
      "    [batch 898]: seen 89800 examples : 67.7 eps, Loss: 5.221, Avg loss: 5.342, Best loss: 5.340\n",
      "    [batch 905]: seen 90500 examples : 67.7 eps, Loss: 5.324, Avg loss: 5.341, Best loss: 5.340\n",
      "    [batch 912]: seen 91200 examples : 67.7 eps, Loss: 5.395, Avg loss: 5.339, Best loss: 5.338\n",
      "    [batch 919]: seen 91900 examples : 67.7 eps, Loss: 5.345, Avg loss: 5.338, Best loss: 5.337\n",
      "    [batch 926]: seen 92600 examples : 67.7 eps, Loss: 5.307, Avg loss: 5.337, Best loss: 5.337\n",
      "    [batch 933]: seen 93300 examples : 67.7 eps, Loss: 5.332, Avg loss: 5.336, Best loss: 5.336\n",
      "    [batch 940]: seen 94000 examples : 67.7 eps, Loss: 5.221, Avg loss: 5.336, Best loss: 5.336\n",
      "    [batch 947]: seen 94700 examples : 67.7 eps, Loss: 5.327, Avg loss: 5.338, Best loss: 5.336\n",
      "    [batch 954]: seen 95400 examples : 67.7 eps, Loss: 5.410, Avg loss: 5.337, Best loss: 5.336\n",
      "    [batch 961]: seen 96100 examples : 67.7 eps, Loss: 5.352, Avg loss: 5.340, Best loss: 5.336\n",
      "    [batch 968]: seen 96800 examples : 67.7 eps, Loss: 5.379, Avg loss: 5.340, Best loss: 5.336\n",
      "    [batch 975]: seen 97500 examples : 67.7 eps, Loss: 5.256, Avg loss: 5.336, Best loss: 5.336\n",
      "    [batch 982]: seen 98200 examples : 67.7 eps, Loss: 5.355, Avg loss: 5.338, Best loss: 5.336\n",
      "    [batch 989]: seen 98900 examples : 67.7 eps, Loss: 5.316, Avg loss: 5.341, Best loss: 5.336\n",
      "    [batch 996]: seen 99600 examples : 67.7 eps, Loss: 5.392, Avg loss: 5.342, Best loss: 5.336\n",
      "    [batch 1003]: seen 100300 examples : 67.7 eps, Loss: 5.351, Avg loss: 5.341, Best loss: 5.336\n",
      "    [batch 1010]: seen 101000 examples : 67.7 eps, Loss: 5.240, Avg loss: 5.339, Best loss: 5.336\n",
      "    [batch 1017]: seen 101700 examples : 67.7 eps, Loss: 5.296, Avg loss: 5.338, Best loss: 5.336\n",
      "    [batch 1024]: seen 102400 examples : 67.7 eps, Loss: 5.211, Avg loss: 5.338, Best loss: 5.336\n",
      "    [batch 1031]: seen 103100 examples : 67.7 eps, Loss: 5.240, Avg loss: 5.338, Best loss: 5.336\n",
      "    [batch 1038]: seen 103800 examples : 67.7 eps, Loss: 5.318, Avg loss: 5.337, Best loss: 5.336\n",
      "    [batch 1045]: seen 104500 examples : 67.7 eps, Loss: 5.317, Avg loss: 5.337, Best loss: 5.336\n",
      "    [batch 1052]: seen 105200 examples : 67.7 eps, Loss: 5.172, Avg loss: 5.335, Best loss: 5.335\n",
      "    [batch 1059]: seen 105900 examples : 67.7 eps, Loss: 5.240, Avg loss: 5.336, Best loss: 5.335\n",
      "    [batch 1066]: seen 106600 examples : 67.7 eps, Loss: 5.441, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1073]: seen 107300 examples : 67.7 eps, Loss: 5.348, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1080]: seen 108000 examples : 67.7 eps, Loss: 5.358, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1087]: seen 108700 examples : 67.7 eps, Loss: 5.357, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1094]: seen 109400 examples : 67.7 eps, Loss: 5.285, Avg loss: 5.337, Best loss: 5.335\n",
      "    [batch 1101]: seen 110100 examples : 67.7 eps, Loss: 5.372, Avg loss: 5.340, Best loss: 5.335\n",
      "    [batch 1108]: seen 110800 examples : 67.6 eps, Loss: 5.290, Avg loss: 5.340, Best loss: 5.335\n",
      "    [batch 1115]: seen 111500 examples : 67.6 eps, Loss: 5.291, Avg loss: 5.339, Best loss: 5.335\n",
      "    [batch 1122]: seen 112200 examples : 67.7 eps, Loss: 5.252, Avg loss: 5.339, Best loss: 5.335\n",
      "    [batch 1129]: seen 112900 examples : 67.7 eps, Loss: 5.301, Avg loss: 5.337, Best loss: 5.335\n",
      "    [batch 1136]: seen 113600 examples : 67.7 eps, Loss: 5.330, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1143]: seen 114300 examples : 67.7 eps, Loss: 5.300, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1150]: seen 115000 examples : 67.7 eps, Loss: 5.327, Avg loss: 5.337, Best loss: 5.335\n",
      "    [batch 1157]: seen 115700 examples : 67.7 eps, Loss: 5.416, Avg loss: 5.339, Best loss: 5.335\n",
      "    [batch 1163]: seen 116300 examples : 67.6 eps, Loss: 5.305, Avg loss: 5.339, Best loss: 5.335\n",
      "    [batch 1170]: seen 117000 examples : 67.6 eps, Loss: 5.329, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1177]: seen 117700 examples : 67.6 eps, Loss: 5.392, Avg loss: 5.340, Best loss: 5.335\n",
      "    [batch 1184]: seen 118400 examples : 67.6 eps, Loss: 5.366, Avg loss: 5.341, Best loss: 5.335\n",
      "    [batch 1191]: seen 119100 examples : 67.6 eps, Loss: 5.225, Avg loss: 5.340, Best loss: 5.335\n",
      "    [batch 1198]: seen 119800 examples : 67.6 eps, Loss: 5.328, Avg loss: 5.341, Best loss: 5.335\n",
      "    [batch 1205]: seen 120500 examples : 67.6 eps, Loss: 5.213, Avg loss: 5.341, Best loss: 5.335\n",
      "    [batch 1212]: seen 121200 examples : 67.6 eps, Loss: 5.241, Avg loss: 5.341, Best loss: 5.335\n",
      "    [batch 1219]: seen 121900 examples : 67.7 eps, Loss: 5.377, Avg loss: 5.342, Best loss: 5.335\n",
      "    [batch 1226]: seen 122600 examples : 67.7 eps, Loss: 5.235, Avg loss: 5.340, Best loss: 5.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1233]: seen 123300 examples : 67.6 eps, Loss: 5.256, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1240]: seen 124000 examples : 67.7 eps, Loss: 5.302, Avg loss: 5.337, Best loss: 5.335\n",
      "    [batch 1247]: seen 124700 examples : 67.7 eps, Loss: 5.314, Avg loss: 5.338, Best loss: 5.335\n",
      "    [batch 1254]: seen 125400 examples : 67.7 eps, Loss: 5.301, Avg loss: 5.337, Best loss: 5.335\n",
      "    [batch 1261]: seen 126100 examples : 67.7 eps, Loss: 5.363, Avg loss: 5.336, Best loss: 5.335\n",
      "    [batch 1268]: seen 126800 examples : 67.7 eps, Loss: 5.335, Avg loss: 5.336, Best loss: 5.335\n",
      "    [batch 1275]: seen 127500 examples : 67.7 eps, Loss: 5.308, Avg loss: 5.333, Best loss: 5.333\n",
      "    [batch 1282]: seen 128200 examples : 67.7 eps, Loss: 5.259, Avg loss: 5.334, Best loss: 5.333\n",
      "    [batch 1289]: seen 128900 examples : 67.7 eps, Loss: 5.307, Avg loss: 5.334, Best loss: 5.333\n",
      "    [batch 1296]: seen 129600 examples : 67.7 eps, Loss: 5.299, Avg loss: 5.336, Best loss: 5.333\n",
      "    [batch 1303]: seen 130300 examples : 67.7 eps, Loss: 5.361, Avg loss: 5.336, Best loss: 5.333\n",
      "    [batch 1310]: seen 131000 examples : 67.7 eps, Loss: 5.315, Avg loss: 5.335, Best loss: 5.333\n",
      "    [batch 1317]: seen 131700 examples : 67.7 eps, Loss: 5.520, Avg loss: 5.336, Best loss: 5.333\n",
      "    [batch 1324]: seen 132400 examples : 67.7 eps, Loss: 5.359, Avg loss: 5.337, Best loss: 5.333\n",
      "    [batch 1331]: seen 133100 examples : 67.7 eps, Loss: 5.393, Avg loss: 5.335, Best loss: 5.333\n",
      "    [batch 1338]: seen 133800 examples : 67.7 eps, Loss: 5.340, Avg loss: 5.333, Best loss: 5.333\n",
      "    [batch 1345]: seen 134500 examples : 67.7 eps, Loss: 5.353, Avg loss: 5.333, Best loss: 5.332\n",
      "    [batch 1352]: seen 135200 examples : 67.7 eps, Loss: 5.383, Avg loss: 5.335, Best loss: 5.332\n",
      "    [batch 1359]: seen 135900 examples : 67.7 eps, Loss: 5.148, Avg loss: 5.330, Best loss: 5.330\n",
      "    [batch 1366]: seen 136600 examples : 67.6 eps, Loss: 5.340, Avg loss: 5.329, Best loss: 5.329\n",
      "    [batch 1373]: seen 137300 examples : 67.6 eps, Loss: 5.367, Avg loss: 5.330, Best loss: 5.328\n",
      "    [batch 1380]: seen 138000 examples : 67.6 eps, Loss: 5.356, Avg loss: 5.332, Best loss: 5.328\n",
      "    [batch 1387]: seen 138700 examples : 67.6 eps, Loss: 5.350, Avg loss: 5.333, Best loss: 5.328\n",
      "    [batch 1394]: seen 139400 examples : 67.6 eps, Loss: 5.237, Avg loss: 5.332, Best loss: 5.328\n",
      "    [batch 1401]: seen 140100 examples : 67.6 eps, Loss: 5.291, Avg loss: 5.333, Best loss: 5.328\n",
      "    [batch 1408]: seen 140800 examples : 67.6 eps, Loss: 5.304, Avg loss: 5.332, Best loss: 5.328\n",
      "    [batch 1415]: seen 141500 examples : 67.6 eps, Loss: 5.214, Avg loss: 5.331, Best loss: 5.328\n",
      "    [batch 1422]: seen 142200 examples : 67.6 eps, Loss: 5.392, Avg loss: 5.332, Best loss: 5.328\n",
      "    [batch 1429]: seen 142900 examples : 67.6 eps, Loss: 5.312, Avg loss: 5.332, Best loss: 5.328\n",
      "    [batch 1436]: seen 143600 examples : 67.6 eps, Loss: 5.337, Avg loss: 5.330, Best loss: 5.328\n",
      "    [batch 1443]: seen 144300 examples : 67.6 eps, Loss: 5.426, Avg loss: 5.331, Best loss: 5.328\n",
      "    [batch 1450]: seen 145000 examples : 67.6 eps, Loss: 5.318, Avg loss: 5.329, Best loss: 5.328\n",
      "    [batch 1457]: seen 145700 examples : 67.6 eps, Loss: 5.413, Avg loss: 5.328, Best loss: 5.327\n",
      "    [batch 1464]: seen 146400 examples : 67.6 eps, Loss: 5.240, Avg loss: 5.326, Best loss: 5.326\n",
      "    [batch 1471]: seen 147100 examples : 67.6 eps, Loss: 5.294, Avg loss: 5.326, Best loss: 5.326\n",
      "    [batch 1478]: seen 147800 examples : 67.6 eps, Loss: 5.355, Avg loss: 5.327, Best loss: 5.326\n",
      "    [batch 1485]: seen 148500 examples : 67.6 eps, Loss: 5.324, Avg loss: 5.326, Best loss: 5.326\n",
      "    [batch 1492]: seen 149200 examples : 67.6 eps, Loss: 5.376, Avg loss: 5.328, Best loss: 5.325\n",
      "    [batch 1499]: seen 149900 examples : 67.6 eps, Loss: 5.419, Avg loss: 5.328, Best loss: 5.325\n",
      "    [batch 1506]: seen 150600 examples : 67.6 eps, Loss: 5.254, Avg loss: 5.325, Best loss: 5.325\n",
      "    [batch 1513]: seen 151300 examples : 67.6 eps, Loss: 5.328, Avg loss: 5.324, Best loss: 5.324\n",
      "    [batch 1520]: seen 152000 examples : 67.6 eps, Loss: 5.381, Avg loss: 5.325, Best loss: 5.324\n",
      "    [batch 1527]: seen 152700 examples : 67.6 eps, Loss: 5.381, Avg loss: 5.323, Best loss: 5.321\n",
      "    [batch 1534]: seen 153400 examples : 67.6 eps, Loss: 5.271, Avg loss: 5.321, Best loss: 5.321\n",
      "    [batch 1541]: seen 154100 examples : 67.6 eps, Loss: 5.336, Avg loss: 5.322, Best loss: 5.320\n",
      "    [batch 1548]: seen 154800 examples : 67.6 eps, Loss: 5.332, Avg loss: 5.323, Best loss: 5.320\n",
      "    [batch 1555]: seen 155500 examples : 67.6 eps, Loss: 5.348, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1562]: seen 156200 examples : 67.6 eps, Loss: 5.171, Avg loss: 5.323, Best loss: 5.320\n",
      "    [batch 1569]: seen 156900 examples : 67.6 eps, Loss: 5.304, Avg loss: 5.323, Best loss: 5.320\n",
      "    [batch 1576]: seen 157600 examples : 67.6 eps, Loss: 5.481, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1583]: seen 158300 examples : 67.6 eps, Loss: 5.325, Avg loss: 5.324, Best loss: 5.320\n",
      "    [batch 1590]: seen 159000 examples : 67.5 eps, Loss: 5.253, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1597]: seen 159700 examples : 67.6 eps, Loss: 5.246, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1604]: seen 160400 examples : 67.6 eps, Loss: 5.234, Avg loss: 5.324, Best loss: 5.320\n",
      "    [batch 1611]: seen 161100 examples : 67.6 eps, Loss: 5.350, Avg loss: 5.326, Best loss: 5.320\n",
      "    [batch 1618]: seen 161800 examples : 67.6 eps, Loss: 5.315, Avg loss: 5.327, Best loss: 5.320\n",
      "    [batch 1625]: seen 162500 examples : 67.5 eps, Loss: 5.206, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1632]: seen 163200 examples : 67.5 eps, Loss: 5.288, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1639]: seen 163900 examples : 67.6 eps, Loss: 5.216, Avg loss: 5.326, Best loss: 5.320\n",
      "    [batch 1646]: seen 164600 examples : 67.6 eps, Loss: 5.319, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1653]: seen 165300 examples : 67.6 eps, Loss: 5.349, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1660]: seen 166000 examples : 67.6 eps, Loss: 5.312, Avg loss: 5.326, Best loss: 5.320\n",
      "    [batch 1667]: seen 166700 examples : 67.6 eps, Loss: 5.298, Avg loss: 5.326, Best loss: 5.320\n",
      "    [batch 1674]: seen 167400 examples : 67.6 eps, Loss: 5.212, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1681]: seen 168100 examples : 67.6 eps, Loss: 5.357, Avg loss: 5.326, Best loss: 5.320\n",
      "    [batch 1688]: seen 168800 examples : 67.6 eps, Loss: 5.328, Avg loss: 5.325, Best loss: 5.320\n",
      "    [batch 1695]: seen 169500 examples : 67.6 eps, Loss: 5.259, Avg loss: 5.323, Best loss: 5.320\n",
      "    [batch 1702]: seen 170200 examples : 67.6 eps, Loss: 5.198, Avg loss: 5.320, Best loss: 5.320\n",
      "    [batch 1709]: seen 170900 examples : 67.5 eps, Loss: 5.240, Avg loss: 5.318, Best loss: 5.318\n",
      "    [batch 1716]: seen 171600 examples : 67.5 eps, Loss: 5.371, Avg loss: 5.319, Best loss: 5.318\n",
      "    [batch 1723]: seen 172300 examples : 67.5 eps, Loss: 5.313, Avg loss: 5.317, Best loss: 5.317\n",
      "    [batch 1730]: seen 173000 examples : 67.5 eps, Loss: 5.320, Avg loss: 5.315, Best loss: 5.315\n",
      "    [batch 1737]: seen 173700 examples : 67.6 eps, Loss: 5.243, Avg loss: 5.316, Best loss: 5.315\n",
      "    [batch 1744]: seen 174400 examples : 67.5 eps, Loss: 5.309, Avg loss: 5.316, Best loss: 5.315\n",
      "    [batch 1751]: seen 175100 examples : 67.5 eps, Loss: 5.336, Avg loss: 5.316, Best loss: 5.315\n",
      "    [batch 1758]: seen 175800 examples : 67.5 eps, Loss: 5.307, Avg loss: 5.315, Best loss: 5.315\n",
      "    [batch 1765]: seen 176500 examples : 67.5 eps, Loss: 5.401, Avg loss: 5.317, Best loss: 5.315\n",
      "    [batch 1772]: seen 177200 examples : 67.5 eps, Loss: 5.379, Avg loss: 5.318, Best loss: 5.315\n",
      "    [batch 1779]: seen 177900 examples : 67.6 eps, Loss: 5.287, Avg loss: 5.318, Best loss: 5.315\n",
      "    [batch 1786]: seen 178600 examples : 67.6 eps, Loss: 5.376, Avg loss: 5.318, Best loss: 5.315\n",
      "    [batch 1793]: seen 179300 examples : 67.6 eps, Loss: 5.356, Avg loss: 5.319, Best loss: 5.315\n",
      "    [batch 1800]: seen 180000 examples : 67.6 eps, Loss: 5.446, Avg loss: 5.324, Best loss: 5.315\n",
      "    [batch 1807]: seen 180700 examples : 67.6 eps, Loss: 5.301, Avg loss: 5.326, Best loss: 5.315\n",
      "    [batch 1814]: seen 181400 examples : 67.6 eps, Loss: 5.221, Avg loss: 5.324, Best loss: 5.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1821]: seen 182100 examples : 67.6 eps, Loss: 5.249, Avg loss: 5.326, Best loss: 5.315\n",
      "    [batch 1828]: seen 182800 examples : 67.6 eps, Loss: 5.214, Avg loss: 5.325, Best loss: 5.315\n",
      "    [batch 1835]: seen 183500 examples : 67.6 eps, Loss: 5.307, Avg loss: 5.328, Best loss: 5.315\n",
      "    [batch 1842]: seen 184200 examples : 67.6 eps, Loss: 5.253, Avg loss: 5.326, Best loss: 5.315\n",
      "    [batch 1849]: seen 184900 examples : 67.6 eps, Loss: 5.457, Avg loss: 5.327, Best loss: 5.315\n",
      "    [batch 1856]: seen 185600 examples : 67.6 eps, Loss: 5.324, Avg loss: 5.328, Best loss: 5.315\n",
      "    [batch 1863]: seen 186300 examples : 67.6 eps, Loss: 5.224, Avg loss: 5.328, Best loss: 5.315\n",
      "    [batch 1870]: seen 187000 examples : 67.6 eps, Loss: 5.423, Avg loss: 5.328, Best loss: 5.315\n",
      "    [batch 1877]: seen 187700 examples : 67.6 eps, Loss: 5.269, Avg loss: 5.326, Best loss: 5.315\n",
      "    [batch 1884]: seen 188400 examples : 67.5 eps, Loss: 5.270, Avg loss: 5.325, Best loss: 5.315\n",
      "    [batch 1891]: seen 189100 examples : 67.5 eps, Loss: 5.149, Avg loss: 5.324, Best loss: 5.315\n",
      "    [batch 1898]: seen 189800 examples : 67.6 eps, Loss: 5.207, Avg loss: 5.321, Best loss: 5.315\n",
      "    [batch 1905]: seen 190500 examples : 67.6 eps, Loss: 5.204, Avg loss: 5.321, Best loss: 5.315\n",
      "    [batch 1912]: seen 191200 examples : 67.6 eps, Loss: 5.316, Avg loss: 5.322, Best loss: 5.315\n",
      "    [batch 1919]: seen 191900 examples : 67.6 eps, Loss: 5.286, Avg loss: 5.321, Best loss: 5.315\n",
      "    [batch 1926]: seen 192600 examples : 67.6 eps, Loss: 5.328, Avg loss: 5.322, Best loss: 5.315\n",
      "    [batch 1933]: seen 193300 examples : 67.6 eps, Loss: 5.314, Avg loss: 5.319, Best loss: 5.315\n",
      "    [batch 1940]: seen 194000 examples : 67.6 eps, Loss: 5.222, Avg loss: 5.315, Best loss: 5.315\n",
      "    [batch 1947]: seen 194700 examples : 67.6 eps, Loss: 5.330, Avg loss: 5.316, Best loss: 5.315\n",
      "    [batch 1954]: seen 195400 examples : 67.6 eps, Loss: 5.203, Avg loss: 5.317, Best loss: 5.315\n",
      "    [batch 1961]: seen 196100 examples : 67.6 eps, Loss: 5.359, Avg loss: 5.316, Best loss: 5.315\n",
      "    [batch 1968]: seen 196800 examples : 67.6 eps, Loss: 5.222, Avg loss: 5.316, Best loss: 5.315\n",
      "    [batch 1975]: seen 197500 examples : 67.6 eps, Loss: 5.350, Avg loss: 5.313, Best loss: 5.313\n",
      "    [batch 1982]: seen 198200 examples : 67.6 eps, Loss: 5.395, Avg loss: 5.316, Best loss: 5.313\n",
      "    [batch 1989]: seen 198900 examples : 67.6 eps, Loss: 5.259, Avg loss: 5.316, Best loss: 5.313\n",
      "    [batch 1996]: seen 199600 examples : 67.6 eps, Loss: 5.285, Avg loss: 5.316, Best loss: 5.313\n",
      "    [batch 2003]: seen 200300 examples : 67.6 eps, Loss: 5.307, Avg loss: 5.317, Best loss: 5.313\n",
      "    [batch 2010]: seen 201000 examples : 67.6 eps, Loss: 5.321, Avg loss: 5.315, Best loss: 5.313\n",
      "    [batch 2017]: seen 201700 examples : 67.6 eps, Loss: 5.343, Avg loss: 5.314, Best loss: 5.313\n",
      "    [batch 2024]: seen 202400 examples : 67.6 eps, Loss: 5.293, Avg loss: 5.315, Best loss: 5.313\n",
      "    [batch 2031]: seen 203100 examples : 67.6 eps, Loss: 5.390, Avg loss: 5.317, Best loss: 5.313\n",
      "    [batch 2038]: seen 203800 examples : 67.6 eps, Loss: 5.300, Avg loss: 5.314, Best loss: 5.313\n",
      "    [batch 2045]: seen 204500 examples : 67.6 eps, Loss: 5.183, Avg loss: 5.313, Best loss: 5.313\n",
      "    [batch 2052]: seen 205200 examples : 67.6 eps, Loss: 5.340, Avg loss: 5.312, Best loss: 5.312\n",
      "    [batch 2059]: seen 205900 examples : 67.6 eps, Loss: 5.344, Avg loss: 5.309, Best loss: 5.308\n",
      "    [batch 2066]: seen 206600 examples : 67.6 eps, Loss: 5.167, Avg loss: 5.307, Best loss: 5.307\n",
      "    [batch 2073]: seen 207300 examples : 67.6 eps, Loss: 5.255, Avg loss: 5.309, Best loss: 5.307\n",
      "    [batch 2080]: seen 208000 examples : 67.6 eps, Loss: 5.244, Avg loss: 5.309, Best loss: 5.307\n",
      "    [batch 2087]: seen 208700 examples : 67.6 eps, Loss: 5.282, Avg loss: 5.308, Best loss: 5.307\n",
      "    [batch 2094]: seen 209400 examples : 67.6 eps, Loss: 5.261, Avg loss: 5.309, Best loss: 5.307\n",
      "    [batch 2101]: seen 210100 examples : 67.6 eps, Loss: 5.234, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2108]: seen 210800 examples : 67.6 eps, Loss: 5.301, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2115]: seen 211500 examples : 67.6 eps, Loss: 5.367, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2122]: seen 212200 examples : 67.6 eps, Loss: 5.206, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2129]: seen 212900 examples : 67.6 eps, Loss: 5.353, Avg loss: 5.310, Best loss: 5.307\n",
      "    [batch 2136]: seen 213600 examples : 67.6 eps, Loss: 5.314, Avg loss: 5.310, Best loss: 5.307\n",
      "    [batch 2143]: seen 214300 examples : 67.6 eps, Loss: 5.267, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2150]: seen 215000 examples : 67.6 eps, Loss: 5.281, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2157]: seen 215700 examples : 67.6 eps, Loss: 5.403, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2164]: seen 216400 examples : 67.6 eps, Loss: 5.276, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2171]: seen 217100 examples : 67.6 eps, Loss: 5.379, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2178]: seen 217800 examples : 67.6 eps, Loss: 5.301, Avg loss: 5.315, Best loss: 5.307\n",
      "    [batch 2185]: seen 218500 examples : 67.6 eps, Loss: 5.298, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2192]: seen 219200 examples : 67.6 eps, Loss: 5.352, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2199]: seen 219900 examples : 67.6 eps, Loss: 5.274, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2206]: seen 220600 examples : 67.6 eps, Loss: 5.315, Avg loss: 5.315, Best loss: 5.307\n",
      "    [batch 2213]: seen 221300 examples : 67.6 eps, Loss: 5.231, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2220]: seen 222000 examples : 67.6 eps, Loss: 5.275, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2227]: seen 222700 examples : 67.6 eps, Loss: 5.351, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2234]: seen 223400 examples : 67.6 eps, Loss: 5.282, Avg loss: 5.314, Best loss: 5.307\n",
      "    [batch 2241]: seen 224100 examples : 67.6 eps, Loss: 5.290, Avg loss: 5.314, Best loss: 5.307\n",
      "    [batch 2248]: seen 224800 examples : 67.6 eps, Loss: 5.243, Avg loss: 5.315, Best loss: 5.307\n",
      "    [batch 2255]: seen 225500 examples : 67.6 eps, Loss: 5.314, Avg loss: 5.314, Best loss: 5.307\n",
      "    [batch 2262]: seen 226200 examples : 67.6 eps, Loss: 5.243, Avg loss: 5.314, Best loss: 5.307\n",
      "    [batch 2268]: seen 226800 examples : 67.5 eps, Loss: 5.301, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2275]: seen 227500 examples : 67.5 eps, Loss: 5.293, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2282]: seen 228200 examples : 67.5 eps, Loss: 5.336, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2289]: seen 228900 examples : 67.5 eps, Loss: 5.433, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2296]: seen 229600 examples : 67.5 eps, Loss: 5.251, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2303]: seen 230300 examples : 67.5 eps, Loss: 5.433, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2310]: seen 231000 examples : 67.5 eps, Loss: 5.357, Avg loss: 5.313, Best loss: 5.307\n",
      "    [batch 2317]: seen 231700 examples : 67.5 eps, Loss: 5.383, Avg loss: 5.310, Best loss: 5.307\n",
      "    [batch 2324]: seen 232400 examples : 67.5 eps, Loss: 5.356, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2331]: seen 233100 examples : 67.5 eps, Loss: 5.263, Avg loss: 5.310, Best loss: 5.307\n",
      "    [batch 2338]: seen 233800 examples : 67.5 eps, Loss: 5.299, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2345]: seen 234500 examples : 67.5 eps, Loss: 5.294, Avg loss: 5.310, Best loss: 5.307\n",
      "    [batch 2352]: seen 235200 examples : 67.5 eps, Loss: 5.340, Avg loss: 5.310, Best loss: 5.307\n",
      "    [batch 2359]: seen 235900 examples : 67.5 eps, Loss: 5.318, Avg loss: 5.312, Best loss: 5.307\n",
      "    [batch 2366]: seen 236600 examples : 67.5 eps, Loss: 5.380, Avg loss: 5.311, Best loss: 5.307\n",
      "    [batch 2373]: seen 237300 examples : 67.5 eps, Loss: 5.276, Avg loss: 5.308, Best loss: 5.307\n",
      "    [batch 2380]: seen 238000 examples : 67.5 eps, Loss: 5.387, Avg loss: 5.309, Best loss: 5.307\n",
      "    [batch 2387]: seen 238700 examples : 67.5 eps, Loss: 5.213, Avg loss: 5.307, Best loss: 5.307\n",
      "    [batch 2394]: seen 239400 examples : 67.5 eps, Loss: 5.276, Avg loss: 5.308, Best loss: 5.306\n",
      "    [batch 2401]: seen 240100 examples : 67.5 eps, Loss: 5.216, Avg loss: 5.308, Best loss: 5.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2408]: seen 240800 examples : 67.5 eps, Loss: 5.339, Avg loss: 5.308, Best loss: 5.306\n",
      "    [batch 2415]: seen 241500 examples : 67.5 eps, Loss: 5.420, Avg loss: 5.310, Best loss: 5.306\n",
      "    [batch 2422]: seen 242200 examples : 67.5 eps, Loss: 5.342, Avg loss: 5.310, Best loss: 5.306\n",
      "    [batch 2429]: seen 242900 examples : 67.5 eps, Loss: 5.312, Avg loss: 5.310, Best loss: 5.306\n",
      "    [batch 2436]: seen 243600 examples : 67.5 eps, Loss: 5.261, Avg loss: 5.312, Best loss: 5.306\n",
      "    [batch 2443]: seen 244300 examples : 67.5 eps, Loss: 5.358, Avg loss: 5.311, Best loss: 5.306\n",
      "    [batch 2450]: seen 245000 examples : 67.5 eps, Loss: 5.354, Avg loss: 5.310, Best loss: 5.306\n",
      "    [batch 2457]: seen 245700 examples : 67.5 eps, Loss: 5.217, Avg loss: 5.307, Best loss: 5.306\n",
      "    [batch 2464]: seen 246400 examples : 67.5 eps, Loss: 5.382, Avg loss: 5.308, Best loss: 5.306\n",
      "    [batch 2471]: seen 247100 examples : 67.5 eps, Loss: 5.261, Avg loss: 5.306, Best loss: 5.306\n",
      "    [batch 2478]: seen 247800 examples : 67.5 eps, Loss: 5.259, Avg loss: 5.307, Best loss: 5.306\n",
      "    [batch 2485]: seen 248500 examples : 67.5 eps, Loss: 5.214, Avg loss: 5.307, Best loss: 5.306\n",
      "    [batch 2492]: seen 249200 examples : 67.5 eps, Loss: 5.212, Avg loss: 5.307, Best loss: 5.306\n",
      "    [batch 2499]: seen 249900 examples : 67.5 eps, Loss: 5.276, Avg loss: 5.307, Best loss: 5.306\n",
      "    [batch 2506]: seen 250600 examples : 67.5 eps, Loss: 5.879, Avg loss: 5.344, Best loss: 5.306\n",
      "    [batch 2513]: seen 251300 examples : 67.5 eps, Loss: 5.458, Avg loss: 5.382, Best loss: 5.306\n",
      "    [batch 2520]: seen 252000 examples : 67.5 eps, Loss: 5.380, Avg loss: 5.385, Best loss: 5.306\n",
      "    [batch 2527]: seen 252700 examples : 67.5 eps, Loss: 5.394, Avg loss: 5.388, Best loss: 5.306\n",
      "    [batch 2534]: seen 253400 examples : 67.5 eps, Loss: 5.470, Avg loss: 5.391, Best loss: 5.306\n",
      "    [batch 2541]: seen 254100 examples : 67.5 eps, Loss: 5.335, Avg loss: 5.390, Best loss: 5.306\n",
      "    [batch 2548]: seen 254800 examples : 67.5 eps, Loss: 5.489, Avg loss: 5.392, Best loss: 5.306\n",
      "    [batch 2555]: seen 255500 examples : 67.5 eps, Loss: 5.307, Avg loss: 5.391, Best loss: 5.306\n",
      "    [batch 2562]: seen 256200 examples : 67.5 eps, Loss: 5.328, Avg loss: 5.389, Best loss: 5.306\n",
      "    [batch 2569]: seen 256900 examples : 67.5 eps, Loss: 5.331, Avg loss: 5.387, Best loss: 5.306\n",
      "    [batch 2576]: seen 257600 examples : 67.5 eps, Loss: 5.378, Avg loss: 5.385, Best loss: 5.306\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-27815\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-27815\n",
      "    [batch 2582]: seen 258200 examples : 67.5 eps, Loss: 5.282, Avg loss: 5.385, Best loss: 5.306\n",
      "    [batch 2589]: seen 258900 examples : 67.5 eps, Loss: 5.354, Avg loss: 5.383, Best loss: 5.306\n",
      "    [batch 2596]: seen 259600 examples : 67.5 eps, Loss: 5.297, Avg loss: 5.377, Best loss: 5.306\n",
      "    [batch 2603]: seen 260300 examples : 67.5 eps, Loss: 5.462, Avg loss: 5.378, Best loss: 5.306\n",
      "    [batch 2610]: seen 261000 examples : 67.5 eps, Loss: 5.288, Avg loss: 5.374, Best loss: 5.306\n",
      "    [batch 2617]: seen 261700 examples : 67.5 eps, Loss: 5.369, Avg loss: 5.372, Best loss: 5.306\n",
      "    [batch 2624]: seen 262400 examples : 67.5 eps, Loss: 5.419, Avg loss: 5.369, Best loss: 5.306\n",
      "    [batch 2631]: seen 263100 examples : 67.5 eps, Loss: 5.247, Avg loss: 5.367, Best loss: 5.306\n",
      "    [batch 2638]: seen 263800 examples : 67.5 eps, Loss: 5.360, Avg loss: 5.366, Best loss: 5.306\n",
      "    [batch 2645]: seen 264500 examples : 67.5 eps, Loss: 5.143, Avg loss: 5.360, Best loss: 5.306\n",
      "    [batch 2652]: seen 265200 examples : 67.5 eps, Loss: 5.371, Avg loss: 5.359, Best loss: 5.306\n",
      "    [batch 2659]: seen 265900 examples : 67.5 eps, Loss: 5.267, Avg loss: 5.356, Best loss: 5.306\n",
      "    [batch 2666]: seen 266600 examples : 67.5 eps, Loss: 5.302, Avg loss: 5.354, Best loss: 5.306\n",
      "    [batch 2673]: seen 267300 examples : 67.5 eps, Loss: 5.199, Avg loss: 5.351, Best loss: 5.306\n",
      "    [batch 2680]: seen 268000 examples : 67.5 eps, Loss: 5.220, Avg loss: 5.347, Best loss: 5.306\n",
      "    [batch 2687]: seen 268700 examples : 67.5 eps, Loss: 5.284, Avg loss: 5.345, Best loss: 5.306\n",
      "    [batch 2694]: seen 269400 examples : 67.5 eps, Loss: 5.272, Avg loss: 5.344, Best loss: 5.306\n",
      "    [batch 2701]: seen 270100 examples : 67.5 eps, Loss: 5.326, Avg loss: 5.344, Best loss: 5.306\n",
      "    [batch 2708]: seen 270800 examples : 67.5 eps, Loss: 5.306, Avg loss: 5.341, Best loss: 5.306\n",
      "    [batch 2715]: seen 271500 examples : 67.5 eps, Loss: 5.320, Avg loss: 5.339, Best loss: 5.306\n",
      "    [batch 2722]: seen 272200 examples : 67.5 eps, Loss: 5.285, Avg loss: 5.338, Best loss: 5.306\n",
      "    [batch 2729]: seen 272900 examples : 67.5 eps, Loss: 5.270, Avg loss: 5.336, Best loss: 5.306\n",
      "    [batch 2736]: seen 273600 examples : 67.5 eps, Loss: 5.245, Avg loss: 5.332, Best loss: 5.306\n",
      "    [batch 2743]: seen 274300 examples : 67.5 eps, Loss: 5.280, Avg loss: 5.329, Best loss: 5.306\n",
      "    [batch 2750]: seen 275000 examples : 67.5 eps, Loss: 5.357, Avg loss: 5.325, Best loss: 5.306\n",
      "    [batch 2757]: seen 275700 examples : 67.5 eps, Loss: 5.340, Avg loss: 5.321, Best loss: 5.306\n",
      "    [batch 2764]: seen 276400 examples : 67.5 eps, Loss: 5.211, Avg loss: 5.320, Best loss: 5.306\n",
      "    [batch 2771]: seen 277100 examples : 67.5 eps, Loss: 5.348, Avg loss: 5.321, Best loss: 5.306\n",
      "    [batch 2778]: seen 277800 examples : 67.5 eps, Loss: 5.386, Avg loss: 5.318, Best loss: 5.306\n",
      "    [batch 2785]: seen 278500 examples : 67.5 eps, Loss: 5.296, Avg loss: 5.318, Best loss: 5.306\n",
      "    [batch 2792]: seen 279200 examples : 67.5 eps, Loss: 5.313, Avg loss: 5.316, Best loss: 5.306\n",
      "    [batch 2799]: seen 279900 examples : 67.5 eps, Loss: 5.375, Avg loss: 5.316, Best loss: 5.306\n",
      "    [batch 2806]: seen 280600 examples : 67.5 eps, Loss: 5.289, Avg loss: 5.314, Best loss: 5.306\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:20\n",
      "[EPOCH 10] Complete. Avg Loss: 5.315103016905632; Best Loss: 5.3056262025788214\n",
      "[EPOCH 11] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.3 eps, Loss: 5.338, Avg loss: 5.314, Best loss: 5.306\n",
      "    [batch 16]: seen 1600 examples : 78.2 eps, Loss: 5.361, Avg loss: 5.313, Best loss: 5.306\n",
      "    [batch 23]: seen 2300 examples : 75.1 eps, Loss: 5.191, Avg loss: 5.309, Best loss: 5.306\n",
      "    [batch 30]: seen 3000 examples : 73.5 eps, Loss: 5.258, Avg loss: 5.307, Best loss: 5.306\n",
      "    [batch 37]: seen 3700 examples : 72.5 eps, Loss: 5.400, Avg loss: 5.306, Best loss: 5.305\n",
      "    [batch 44]: seen 4400 examples : 71.9 eps, Loss: 5.201, Avg loss: 5.305, Best loss: 5.305\n",
      "    [batch 51]: seen 5100 examples : 71.4 eps, Loss: 5.341, Avg loss: 5.301, Best loss: 5.301\n",
      "    [batch 58]: seen 5800 examples : 71.1 eps, Loss: 5.198, Avg loss: 5.297, Best loss: 5.297\n",
      "    [batch 65]: seen 6500 examples : 70.9 eps, Loss: 5.345, Avg loss: 5.299, Best loss: 5.297\n",
      "    [batch 72]: seen 7200 examples : 70.7 eps, Loss: 5.296, Avg loss: 5.299, Best loss: 5.297\n",
      "    [batch 79]: seen 7900 examples : 70.5 eps, Loss: 5.273, Avg loss: 5.300, Best loss: 5.297\n",
      "    [batch 86]: seen 8600 examples : 70.3 eps, Loss: 5.321, Avg loss: 5.301, Best loss: 5.297\n",
      "    [batch 93]: seen 9300 examples : 70.2 eps, Loss: 5.326, Avg loss: 5.301, Best loss: 5.297\n",
      "    [batch 100]: seen 10000 examples : 70.1 eps, Loss: 5.266, Avg loss: 5.301, Best loss: 5.297\n",
      "    [batch 107]: seen 10700 examples : 70.0 eps, Loss: 5.245, Avg loss: 5.300, Best loss: 5.297\n",
      "    [batch 114]: seen 11400 examples : 69.9 eps, Loss: 5.308, Avg loss: 5.299, Best loss: 5.297\n",
      "    [batch 121]: seen 12100 examples : 69.7 eps, Loss: 5.300, Avg loss: 5.297, Best loss: 5.297\n",
      "    [batch 128]: seen 12800 examples : 69.7 eps, Loss: 5.287, Avg loss: 5.294, Best loss: 5.294\n",
      "    [batch 135]: seen 13500 examples : 69.6 eps, Loss: 5.194, Avg loss: 5.294, Best loss: 5.294\n",
      "    [batch 142]: seen 14200 examples : 69.5 eps, Loss: 5.282, Avg loss: 5.292, Best loss: 5.292\n",
      "    [batch 149]: seen 14900 examples : 69.4 eps, Loss: 5.370, Avg loss: 5.291, Best loss: 5.290\n",
      "    [batch 156]: seen 15600 examples : 69.3 eps, Loss: 5.262, Avg loss: 5.291, Best loss: 5.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 163]: seen 16300 examples : 69.3 eps, Loss: 5.223, Avg loss: 5.289, Best loss: 5.289\n",
      "    [batch 170]: seen 17000 examples : 69.2 eps, Loss: 5.207, Avg loss: 5.286, Best loss: 5.286\n",
      "    [batch 177]: seen 17700 examples : 69.1 eps, Loss: 5.372, Avg loss: 5.288, Best loss: 5.286\n",
      "    [batch 184]: seen 18400 examples : 69.1 eps, Loss: 5.286, Avg loss: 5.287, Best loss: 5.286\n",
      "    [batch 191]: seen 19100 examples : 69.0 eps, Loss: 5.314, Avg loss: 5.285, Best loss: 5.284\n",
      "    [batch 198]: seen 19800 examples : 69.0 eps, Loss: 5.273, Avg loss: 5.284, Best loss: 5.284\n",
      "    [batch 205]: seen 20500 examples : 69.0 eps, Loss: 5.248, Avg loss: 5.284, Best loss: 5.284\n",
      "    [batch 212]: seen 21200 examples : 68.9 eps, Loss: 5.259, Avg loss: 5.282, Best loss: 5.282\n",
      "    [batch 219]: seen 21900 examples : 68.9 eps, Loss: 5.321, Avg loss: 5.282, Best loss: 5.280\n",
      "    [batch 226]: seen 22600 examples : 68.8 eps, Loss: 5.216, Avg loss: 5.282, Best loss: 5.280\n",
      "    [batch 233]: seen 23300 examples : 68.8 eps, Loss: 5.188, Avg loss: 5.280, Best loss: 5.280\n",
      "    [batch 240]: seen 24000 examples : 68.8 eps, Loss: 5.236, Avg loss: 5.277, Best loss: 5.277\n",
      "    [batch 247]: seen 24700 examples : 68.7 eps, Loss: 5.249, Avg loss: 5.276, Best loss: 5.275\n",
      "    [batch 254]: seen 25400 examples : 68.7 eps, Loss: 5.341, Avg loss: 5.275, Best loss: 5.274\n",
      "    [batch 261]: seen 26100 examples : 68.7 eps, Loss: 5.223, Avg loss: 5.274, Best loss: 5.274\n",
      "    [batch 268]: seen 26800 examples : 68.7 eps, Loss: 5.288, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 275]: seen 27500 examples : 68.6 eps, Loss: 5.334, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 282]: seen 28200 examples : 68.6 eps, Loss: 5.242, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 289]: seen 28900 examples : 68.6 eps, Loss: 5.222, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 296]: seen 29600 examples : 68.5 eps, Loss: 5.271, Avg loss: 5.278, Best loss: 5.274\n",
      "    [batch 303]: seen 30300 examples : 68.5 eps, Loss: 5.219, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 310]: seen 31000 examples : 68.5 eps, Loss: 5.304, Avg loss: 5.280, Best loss: 5.274\n",
      "    [batch 317]: seen 31700 examples : 68.5 eps, Loss: 5.174, Avg loss: 5.278, Best loss: 5.274\n",
      "    [batch 324]: seen 32400 examples : 68.5 eps, Loss: 5.397, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 331]: seen 33100 examples : 68.5 eps, Loss: 5.380, Avg loss: 5.281, Best loss: 5.274\n",
      "    [batch 338]: seen 33800 examples : 68.5 eps, Loss: 5.314, Avg loss: 5.281, Best loss: 5.274\n",
      "    [batch 345]: seen 34500 examples : 68.4 eps, Loss: 5.321, Avg loss: 5.283, Best loss: 5.274\n",
      "    [batch 352]: seen 35200 examples : 68.4 eps, Loss: 5.311, Avg loss: 5.281, Best loss: 5.274\n",
      "    [batch 359]: seen 35900 examples : 68.4 eps, Loss: 5.262, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 366]: seen 36600 examples : 68.4 eps, Loss: 5.294, Avg loss: 5.280, Best loss: 5.274\n",
      "    [batch 373]: seen 37300 examples : 68.4 eps, Loss: 5.176, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 380]: seen 38000 examples : 68.3 eps, Loss: 5.356, Avg loss: 5.282, Best loss: 5.274\n",
      "    [batch 387]: seen 38700 examples : 68.3 eps, Loss: 5.288, Avg loss: 5.281, Best loss: 5.274\n",
      "    [batch 394]: seen 39400 examples : 68.3 eps, Loss: 5.359, Avg loss: 5.282, Best loss: 5.274\n",
      "    [batch 401]: seen 40100 examples : 68.3 eps, Loss: 5.337, Avg loss: 5.284, Best loss: 5.274\n",
      "    [batch 408]: seen 40800 examples : 68.3 eps, Loss: 5.246, Avg loss: 5.286, Best loss: 5.274\n",
      "    [batch 415]: seen 41500 examples : 68.3 eps, Loss: 5.270, Avg loss: 5.284, Best loss: 5.274\n",
      "    [batch 422]: seen 42200 examples : 68.3 eps, Loss: 5.245, Avg loss: 5.278, Best loss: 5.274\n",
      "    [batch 429]: seen 42900 examples : 68.3 eps, Loss: 5.285, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 436]: seen 43600 examples : 68.3 eps, Loss: 5.305, Avg loss: 5.280, Best loss: 5.274\n",
      "    [batch 443]: seen 44300 examples : 68.3 eps, Loss: 5.184, Avg loss: 5.278, Best loss: 5.274\n",
      "    [batch 450]: seen 45000 examples : 68.3 eps, Loss: 5.217, Avg loss: 5.275, Best loss: 5.274\n",
      "    [batch 457]: seen 45700 examples : 68.3 eps, Loss: 5.358, Avg loss: 5.275, Best loss: 5.274\n",
      "    [batch 464]: seen 46400 examples : 68.3 eps, Loss: 5.243, Avg loss: 5.278, Best loss: 5.274\n",
      "    [batch 471]: seen 47100 examples : 68.2 eps, Loss: 5.243, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 478]: seen 47800 examples : 68.2 eps, Loss: 5.234, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 485]: seen 48500 examples : 68.2 eps, Loss: 5.259, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 492]: seen 49200 examples : 68.2 eps, Loss: 5.255, Avg loss: 5.279, Best loss: 5.274\n",
      "    [batch 499]: seen 49900 examples : 68.2 eps, Loss: 5.399, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 506]: seen 50600 examples : 68.2 eps, Loss: 5.191, Avg loss: 5.276, Best loss: 5.274\n",
      "    [batch 513]: seen 51300 examples : 68.2 eps, Loss: 5.282, Avg loss: 5.274, Best loss: 5.274\n",
      "    [batch 520]: seen 52000 examples : 68.2 eps, Loss: 5.137, Avg loss: 5.276, Best loss: 5.274\n",
      "    [batch 527]: seen 52700 examples : 68.2 eps, Loss: 5.309, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 534]: seen 53400 examples : 68.2 eps, Loss: 5.287, Avg loss: 5.277, Best loss: 5.274\n",
      "    [batch 541]: seen 54100 examples : 68.2 eps, Loss: 5.255, Avg loss: 5.275, Best loss: 5.274\n",
      "    [batch 548]: seen 54800 examples : 68.2 eps, Loss: 5.180, Avg loss: 5.272, Best loss: 5.272\n",
      "    [batch 555]: seen 55500 examples : 68.2 eps, Loss: 5.371, Avg loss: 5.272, Best loss: 5.270\n",
      "    [batch 562]: seen 56200 examples : 68.1 eps, Loss: 5.358, Avg loss: 5.270, Best loss: 5.269\n",
      "    [batch 569]: seen 56900 examples : 68.1 eps, Loss: 5.265, Avg loss: 5.268, Best loss: 5.268\n",
      "    [batch 576]: seen 57600 examples : 68.1 eps, Loss: 5.362, Avg loss: 5.269, Best loss: 5.268\n",
      "    [batch 583]: seen 58300 examples : 68.1 eps, Loss: 5.239, Avg loss: 5.267, Best loss: 5.267\n",
      "    [batch 590]: seen 59000 examples : 68.1 eps, Loss: 5.263, Avg loss: 5.266, Best loss: 5.266\n",
      "    [batch 597]: seen 59700 examples : 68.1 eps, Loss: 5.330, Avg loss: 5.267, Best loss: 5.266\n",
      "    [batch 604]: seen 60400 examples : 68.1 eps, Loss: 5.308, Avg loss: 5.269, Best loss: 5.266\n",
      "    [batch 611]: seen 61100 examples : 68.1 eps, Loss: 5.331, Avg loss: 5.269, Best loss: 5.266\n",
      "    [batch 618]: seen 61800 examples : 68.1 eps, Loss: 5.236, Avg loss: 5.269, Best loss: 5.266\n",
      "    [batch 625]: seen 62500 examples : 68.1 eps, Loss: 5.310, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 632]: seen 63200 examples : 68.1 eps, Loss: 5.339, Avg loss: 5.271, Best loss: 5.266\n",
      "    [batch 639]: seen 63900 examples : 68.1 eps, Loss: 5.266, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 646]: seen 64600 examples : 68.1 eps, Loss: 5.336, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 653]: seen 65300 examples : 68.1 eps, Loss: 5.215, Avg loss: 5.274, Best loss: 5.266\n",
      "    [batch 660]: seen 66000 examples : 68.0 eps, Loss: 5.195, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 667]: seen 66700 examples : 68.0 eps, Loss: 5.239, Avg loss: 5.273, Best loss: 5.266\n",
      "    [batch 674]: seen 67400 examples : 68.0 eps, Loss: 5.295, Avg loss: 5.274, Best loss: 5.266\n",
      "    [batch 681]: seen 68100 examples : 68.0 eps, Loss: 5.214, Avg loss: 5.271, Best loss: 5.266\n",
      "    [batch 688]: seen 68800 examples : 68.0 eps, Loss: 5.365, Avg loss: 5.271, Best loss: 5.266\n",
      "    [batch 695]: seen 69500 examples : 68.0 eps, Loss: 5.289, Avg loss: 5.271, Best loss: 5.266\n",
      "    [batch 702]: seen 70200 examples : 68.0 eps, Loss: 5.264, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 709]: seen 70900 examples : 68.0 eps, Loss: 5.301, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 716]: seen 71600 examples : 68.0 eps, Loss: 5.249, Avg loss: 5.270, Best loss: 5.266\n",
      "    [batch 723]: seen 72300 examples : 68.0 eps, Loss: 5.360, Avg loss: 5.272, Best loss: 5.266\n",
      "    [batch 730]: seen 73000 examples : 68.0 eps, Loss: 5.086, Avg loss: 5.269, Best loss: 5.266\n",
      "    [batch 737]: seen 73700 examples : 68.0 eps, Loss: 5.339, Avg loss: 5.267, Best loss: 5.266\n",
      "    [batch 744]: seen 74400 examples : 68.0 eps, Loss: 5.261, Avg loss: 5.267, Best loss: 5.266\n",
      "    [batch 751]: seen 75100 examples : 68.0 eps, Loss: 5.303, Avg loss: 5.266, Best loss: 5.266\n",
      "    [batch 758]: seen 75800 examples : 68.0 eps, Loss: 5.342, Avg loss: 5.265, Best loss: 5.265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 765]: seen 76500 examples : 68.0 eps, Loss: 5.261, Avg loss: 5.268, Best loss: 5.265\n",
      "    [batch 772]: seen 77200 examples : 68.0 eps, Loss: 5.317, Avg loss: 5.271, Best loss: 5.265\n",
      "    [batch 779]: seen 77900 examples : 68.0 eps, Loss: 5.174, Avg loss: 5.272, Best loss: 5.265\n",
      "    [batch 786]: seen 78600 examples : 68.0 eps, Loss: 5.273, Avg loss: 5.273, Best loss: 5.265\n",
      "    [batch 793]: seen 79300 examples : 68.0 eps, Loss: 5.265, Avg loss: 5.274, Best loss: 5.265\n",
      "    [batch 800]: seen 80000 examples : 68.0 eps, Loss: 5.303, Avg loss: 5.274, Best loss: 5.265\n",
      "    [batch 807]: seen 80700 examples : 68.0 eps, Loss: 5.332, Avg loss: 5.274, Best loss: 5.265\n",
      "    [batch 814]: seen 81400 examples : 68.0 eps, Loss: 5.232, Avg loss: 5.270, Best loss: 5.265\n",
      "    [batch 821]: seen 82100 examples : 68.0 eps, Loss: 5.269, Avg loss: 5.272, Best loss: 5.265\n",
      "    [batch 828]: seen 82800 examples : 68.0 eps, Loss: 5.188, Avg loss: 5.269, Best loss: 5.265\n",
      "    [batch 835]: seen 83500 examples : 68.0 eps, Loss: 5.234, Avg loss: 5.267, Best loss: 5.265\n",
      "    [batch 842]: seen 84200 examples : 68.0 eps, Loss: 5.241, Avg loss: 5.267, Best loss: 5.265\n",
      "    [batch 849]: seen 84900 examples : 68.0 eps, Loss: 5.295, Avg loss: 5.264, Best loss: 5.263\n",
      "    [batch 856]: seen 85600 examples : 68.0 eps, Loss: 5.307, Avg loss: 5.266, Best loss: 5.263\n",
      "    [batch 863]: seen 86300 examples : 67.9 eps, Loss: 5.294, Avg loss: 5.264, Best loss: 5.263\n",
      "    [batch 870]: seen 87000 examples : 67.9 eps, Loss: 5.265, Avg loss: 5.267, Best loss: 5.263\n",
      "    [batch 877]: seen 87700 examples : 67.9 eps, Loss: 5.277, Avg loss: 5.268, Best loss: 5.263\n",
      "    [batch 884]: seen 88400 examples : 67.9 eps, Loss: 5.279, Avg loss: 5.269, Best loss: 5.263\n",
      "    [batch 891]: seen 89100 examples : 67.9 eps, Loss: 5.295, Avg loss: 5.268, Best loss: 5.263\n",
      "    [batch 898]: seen 89800 examples : 67.9 eps, Loss: 5.260, Avg loss: 5.269, Best loss: 5.263\n",
      "    [batch 905]: seen 90500 examples : 67.9 eps, Loss: 5.239, Avg loss: 5.269, Best loss: 5.263\n",
      "    [batch 912]: seen 91200 examples : 67.9 eps, Loss: 5.269, Avg loss: 5.268, Best loss: 5.263\n",
      "    [batch 919]: seen 91900 examples : 67.9 eps, Loss: 5.248, Avg loss: 5.266, Best loss: 5.263\n",
      "    [batch 926]: seen 92600 examples : 67.9 eps, Loss: 5.306, Avg loss: 5.265, Best loss: 5.263\n",
      "    [batch 933]: seen 93300 examples : 67.9 eps, Loss: 5.296, Avg loss: 5.264, Best loss: 5.263\n",
      "    [batch 940]: seen 94000 examples : 67.9 eps, Loss: 5.287, Avg loss: 5.265, Best loss: 5.263\n",
      "    [batch 947]: seen 94700 examples : 67.9 eps, Loss: 5.248, Avg loss: 5.262, Best loss: 5.262\n",
      "    [batch 954]: seen 95400 examples : 67.9 eps, Loss: 5.268, Avg loss: 5.262, Best loss: 5.261\n",
      "    [batch 961]: seen 96100 examples : 67.9 eps, Loss: 5.349, Avg loss: 5.264, Best loss: 5.261\n",
      "    [batch 968]: seen 96800 examples : 67.9 eps, Loss: 5.275, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 975]: seen 97500 examples : 67.9 eps, Loss: 5.288, Avg loss: 5.264, Best loss: 5.261\n",
      "    [batch 982]: seen 98200 examples : 67.9 eps, Loss: 5.198, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 989]: seen 98900 examples : 67.9 eps, Loss: 5.273, Avg loss: 5.267, Best loss: 5.261\n",
      "    [batch 996]: seen 99600 examples : 67.9 eps, Loss: 5.196, Avg loss: 5.267, Best loss: 5.261\n",
      "    [batch 1003]: seen 100300 examples : 67.9 eps, Loss: 5.205, Avg loss: 5.267, Best loss: 5.261\n",
      "    [batch 1010]: seen 101000 examples : 67.9 eps, Loss: 5.331, Avg loss: 5.270, Best loss: 5.261\n",
      "    [batch 1017]: seen 101700 examples : 67.8 eps, Loss: 5.386, Avg loss: 5.270, Best loss: 5.261\n",
      "    [batch 1024]: seen 102400 examples : 67.8 eps, Loss: 5.299, Avg loss: 5.269, Best loss: 5.261\n",
      "    [batch 1031]: seen 103100 examples : 67.8 eps, Loss: 5.261, Avg loss: 5.266, Best loss: 5.261\n",
      "    [batch 1038]: seen 103800 examples : 67.8 eps, Loss: 5.316, Avg loss: 5.266, Best loss: 5.261\n",
      "    [batch 1045]: seen 104500 examples : 67.8 eps, Loss: 5.241, Avg loss: 5.264, Best loss: 5.261\n",
      "    [batch 1052]: seen 105200 examples : 67.8 eps, Loss: 5.303, Avg loss: 5.263, Best loss: 5.261\n",
      "    [batch 1059]: seen 105900 examples : 67.8 eps, Loss: 5.207, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 1066]: seen 106600 examples : 67.8 eps, Loss: 5.187, Avg loss: 5.264, Best loss: 5.261\n",
      "    [batch 1073]: seen 107300 examples : 67.8 eps, Loss: 5.313, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 1080]: seen 108000 examples : 67.8 eps, Loss: 5.248, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 1087]: seen 108700 examples : 67.8 eps, Loss: 5.267, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 1094]: seen 109400 examples : 67.8 eps, Loss: 5.244, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 1101]: seen 110100 examples : 67.8 eps, Loss: 5.317, Avg loss: 5.265, Best loss: 5.261\n",
      "    [batch 1108]: seen 110800 examples : 67.8 eps, Loss: 5.137, Avg loss: 5.264, Best loss: 5.261\n",
      "    [batch 1115]: seen 111500 examples : 67.8 eps, Loss: 5.294, Avg loss: 5.266, Best loss: 5.261\n",
      "    [batch 1122]: seen 112200 examples : 67.8 eps, Loss: 5.345, Avg loss: 5.267, Best loss: 5.261\n",
      "    [batch 1129]: seen 112900 examples : 67.8 eps, Loss: 5.291, Avg loss: 5.267, Best loss: 5.261\n",
      "    [batch 1136]: seen 113600 examples : 67.8 eps, Loss: 5.239, Avg loss: 5.266, Best loss: 5.261\n",
      "    [batch 1143]: seen 114300 examples : 67.8 eps, Loss: 5.220, Avg loss: 5.266, Best loss: 5.261\n",
      "    [batch 1150]: seen 115000 examples : 67.8 eps, Loss: 5.214, Avg loss: 5.264, Best loss: 5.261\n",
      "    [batch 1157]: seen 115700 examples : 67.8 eps, Loss: 5.320, Avg loss: 5.262, Best loss: 5.261\n",
      "    [batch 1164]: seen 116400 examples : 67.8 eps, Loss: 5.358, Avg loss: 5.263, Best loss: 5.261\n",
      "    [batch 1171]: seen 117100 examples : 67.8 eps, Loss: 5.247, Avg loss: 5.262, Best loss: 5.261\n",
      "    [batch 1178]: seen 117800 examples : 67.8 eps, Loss: 5.176, Avg loss: 5.262, Best loss: 5.261\n",
      "    [batch 1185]: seen 118500 examples : 67.8 eps, Loss: 5.393, Avg loss: 5.263, Best loss: 5.261\n",
      "    [batch 1192]: seen 119200 examples : 67.8 eps, Loss: 5.252, Avg loss: 5.263, Best loss: 5.261\n",
      "    [batch 1199]: seen 119900 examples : 67.8 eps, Loss: 5.173, Avg loss: 5.261, Best loss: 5.260\n",
      "    [batch 1206]: seen 120600 examples : 67.8 eps, Loss: 5.328, Avg loss: 5.261, Best loss: 5.259\n",
      "    [batch 1213]: seen 121300 examples : 67.8 eps, Loss: 5.235, Avg loss: 5.263, Best loss: 5.259\n",
      "    [batch 1220]: seen 122000 examples : 67.8 eps, Loss: 5.220, Avg loss: 5.262, Best loss: 5.259\n",
      "    [batch 1227]: seen 122700 examples : 67.8 eps, Loss: 5.295, Avg loss: 5.261, Best loss: 5.258\n",
      "    [batch 1234]: seen 123400 examples : 67.8 eps, Loss: 5.291, Avg loss: 5.262, Best loss: 5.258\n",
      "    [batch 1241]: seen 124100 examples : 67.8 eps, Loss: 5.199, Avg loss: 5.259, Best loss: 5.258\n",
      "    [batch 1248]: seen 124800 examples : 67.8 eps, Loss: 5.262, Avg loss: 5.257, Best loss: 5.257\n",
      "    [batch 1255]: seen 125500 examples : 67.8 eps, Loss: 5.230, Avg loss: 5.255, Best loss: 5.255\n",
      "    [batch 1262]: seen 126200 examples : 67.8 eps, Loss: 5.257, Avg loss: 5.253, Best loss: 5.253\n",
      "    [batch 1269]: seen 126900 examples : 67.8 eps, Loss: 5.302, Avg loss: 5.253, Best loss: 5.253\n",
      "    [batch 1276]: seen 127600 examples : 67.8 eps, Loss: 5.289, Avg loss: 5.254, Best loss: 5.253\n",
      "    [batch 1283]: seen 128300 examples : 67.8 eps, Loss: 5.233, Avg loss: 5.254, Best loss: 5.253\n",
      "    [batch 1290]: seen 129000 examples : 67.7 eps, Loss: 5.168, Avg loss: 5.253, Best loss: 5.253\n",
      "    [batch 1297]: seen 129700 examples : 67.7 eps, Loss: 5.184, Avg loss: 5.251, Best loss: 5.251\n",
      "    [batch 1304]: seen 130400 examples : 67.7 eps, Loss: 5.163, Avg loss: 5.252, Best loss: 5.251\n",
      "    [batch 1311]: seen 131100 examples : 67.7 eps, Loss: 5.255, Avg loss: 5.252, Best loss: 5.251\n",
      "    [batch 1318]: seen 131800 examples : 67.7 eps, Loss: 5.253, Avg loss: 5.253, Best loss: 5.251\n",
      "    [batch 1325]: seen 132500 examples : 67.7 eps, Loss: 5.132, Avg loss: 5.254, Best loss: 5.251\n",
      "    [batch 1332]: seen 133200 examples : 67.7 eps, Loss: 5.265, Avg loss: 5.253, Best loss: 5.251\n",
      "    [batch 1339]: seen 133900 examples : 67.7 eps, Loss: 5.231, Avg loss: 5.254, Best loss: 5.251\n",
      "    [batch 1346]: seen 134600 examples : 67.7 eps, Loss: 5.179, Avg loss: 5.253, Best loss: 5.251\n",
      "    [batch 1353]: seen 135300 examples : 67.7 eps, Loss: 5.126, Avg loss: 5.251, Best loss: 5.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1360]: seen 136000 examples : 67.7 eps, Loss: 5.252, Avg loss: 5.249, Best loss: 5.249\n",
      "    [batch 1367]: seen 136700 examples : 67.7 eps, Loss: 5.205, Avg loss: 5.250, Best loss: 5.249\n",
      "    [batch 1374]: seen 137400 examples : 67.7 eps, Loss: 5.272, Avg loss: 5.249, Best loss: 5.248\n",
      "    [batch 1381]: seen 138100 examples : 67.7 eps, Loss: 5.212, Avg loss: 5.247, Best loss: 5.247\n",
      "    [batch 1388]: seen 138800 examples : 67.7 eps, Loss: 5.243, Avg loss: 5.248, Best loss: 5.247\n",
      "    [batch 1395]: seen 139500 examples : 67.7 eps, Loss: 5.263, Avg loss: 5.245, Best loss: 5.245\n",
      "    [batch 1402]: seen 140200 examples : 67.7 eps, Loss: 5.207, Avg loss: 5.243, Best loss: 5.243\n",
      "    [batch 1409]: seen 140900 examples : 67.7 eps, Loss: 5.116, Avg loss: 5.243, Best loss: 5.243\n",
      "    [batch 1416]: seen 141600 examples : 67.7 eps, Loss: 5.236, Avg loss: 5.245, Best loss: 5.243\n",
      "    [batch 1423]: seen 142300 examples : 67.7 eps, Loss: 5.207, Avg loss: 5.248, Best loss: 5.243\n",
      "    [batch 1430]: seen 143000 examples : 67.7 eps, Loss: 5.212, Avg loss: 5.246, Best loss: 5.243\n",
      "    [batch 1437]: seen 143700 examples : 67.7 eps, Loss: 5.233, Avg loss: 5.245, Best loss: 5.243\n",
      "    [batch 1444]: seen 144400 examples : 67.7 eps, Loss: 5.231, Avg loss: 5.244, Best loss: 5.243\n",
      "    [batch 1451]: seen 145100 examples : 67.7 eps, Loss: 5.225, Avg loss: 5.245, Best loss: 5.243\n",
      "    [batch 1458]: seen 145800 examples : 67.7 eps, Loss: 5.218, Avg loss: 5.244, Best loss: 5.243\n",
      "    [batch 1465]: seen 146500 examples : 67.7 eps, Loss: 5.230, Avg loss: 5.246, Best loss: 5.243\n",
      "    [batch 1472]: seen 147200 examples : 67.7 eps, Loss: 5.328, Avg loss: 5.248, Best loss: 5.243\n",
      "    [batch 1479]: seen 147900 examples : 67.7 eps, Loss: 5.265, Avg loss: 5.249, Best loss: 5.243\n",
      "    [batch 1486]: seen 148600 examples : 67.7 eps, Loss: 5.309, Avg loss: 5.248, Best loss: 5.243\n",
      "    [batch 1493]: seen 149300 examples : 67.7 eps, Loss: 5.256, Avg loss: 5.245, Best loss: 5.243\n",
      "    [batch 1500]: seen 150000 examples : 67.7 eps, Loss: 5.200, Avg loss: 5.245, Best loss: 5.243\n",
      "    [batch 1507]: seen 150700 examples : 67.7 eps, Loss: 5.185, Avg loss: 5.243, Best loss: 5.243\n",
      "    [batch 1514]: seen 151400 examples : 67.7 eps, Loss: 5.188, Avg loss: 5.243, Best loss: 5.243\n",
      "    [batch 1521]: seen 152100 examples : 67.7 eps, Loss: 5.161, Avg loss: 5.239, Best loss: 5.239\n",
      "    [batch 1528]: seen 152800 examples : 67.7 eps, Loss: 5.303, Avg loss: 5.241, Best loss: 5.238\n",
      "    [batch 1535]: seen 153500 examples : 67.7 eps, Loss: 5.291, Avg loss: 5.243, Best loss: 5.238\n",
      "    [batch 1542]: seen 154200 examples : 67.7 eps, Loss: 5.275, Avg loss: 5.245, Best loss: 5.238\n",
      "    [batch 1549]: seen 154900 examples : 67.6 eps, Loss: 5.326, Avg loss: 5.246, Best loss: 5.238\n",
      "    [batch 1556]: seen 155600 examples : 67.7 eps, Loss: 5.258, Avg loss: 5.246, Best loss: 5.238\n",
      "    [batch 1563]: seen 156300 examples : 67.7 eps, Loss: 5.185, Avg loss: 5.245, Best loss: 5.238\n",
      "    [batch 1570]: seen 157000 examples : 67.7 eps, Loss: 5.313, Avg loss: 5.245, Best loss: 5.238\n",
      "    [batch 1577]: seen 157700 examples : 67.7 eps, Loss: 5.208, Avg loss: 5.245, Best loss: 5.238\n",
      "    [batch 1584]: seen 158400 examples : 67.7 eps, Loss: 5.144, Avg loss: 5.244, Best loss: 5.238\n",
      "    [batch 1591]: seen 159100 examples : 67.7 eps, Loss: 5.180, Avg loss: 5.241, Best loss: 5.238\n",
      "    [batch 1598]: seen 159800 examples : 67.7 eps, Loss: 5.295, Avg loss: 5.240, Best loss: 5.238\n",
      "    [batch 1605]: seen 160500 examples : 67.7 eps, Loss: 5.178, Avg loss: 5.239, Best loss: 5.238\n",
      "    [batch 1612]: seen 161200 examples : 67.6 eps, Loss: 5.267, Avg loss: 5.239, Best loss: 5.238\n",
      "    [batch 1619]: seen 161900 examples : 67.6 eps, Loss: 5.247, Avg loss: 5.239, Best loss: 5.238\n",
      "    [batch 1626]: seen 162600 examples : 67.6 eps, Loss: 5.290, Avg loss: 5.238, Best loss: 5.237\n",
      "    [batch 1633]: seen 163300 examples : 67.6 eps, Loss: 5.294, Avg loss: 5.239, Best loss: 5.237\n",
      "    [batch 1640]: seen 164000 examples : 67.7 eps, Loss: 5.252, Avg loss: 5.240, Best loss: 5.237\n",
      "    [batch 1647]: seen 164700 examples : 67.7 eps, Loss: 5.229, Avg loss: 5.240, Best loss: 5.237\n",
      "    [batch 1654]: seen 165400 examples : 67.6 eps, Loss: 5.219, Avg loss: 5.239, Best loss: 5.237\n",
      "    [batch 1661]: seen 166100 examples : 67.6 eps, Loss: 5.319, Avg loss: 5.239, Best loss: 5.237\n",
      "    [batch 1668]: seen 166800 examples : 67.6 eps, Loss: 5.302, Avg loss: 5.238, Best loss: 5.237\n",
      "    [batch 1675]: seen 167500 examples : 67.6 eps, Loss: 5.290, Avg loss: 5.236, Best loss: 5.235\n",
      "    [batch 1682]: seen 168200 examples : 67.6 eps, Loss: 5.262, Avg loss: 5.235, Best loss: 5.235\n",
      "    [batch 1689]: seen 168900 examples : 67.6 eps, Loss: 5.158, Avg loss: 5.234, Best loss: 5.234\n",
      "    [batch 1696]: seen 169600 examples : 67.6 eps, Loss: 5.257, Avg loss: 5.235, Best loss: 5.234\n",
      "    [batch 1703]: seen 170300 examples : 67.6 eps, Loss: 5.270, Avg loss: 5.235, Best loss: 5.234\n",
      "    [batch 1710]: seen 171000 examples : 67.6 eps, Loss: 5.347, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1717]: seen 171700 examples : 67.7 eps, Loss: 5.211, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1724]: seen 172400 examples : 67.7 eps, Loss: 5.300, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1731]: seen 173100 examples : 67.6 eps, Loss: 5.195, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1738]: seen 173800 examples : 67.7 eps, Loss: 5.244, Avg loss: 5.237, Best loss: 5.234\n",
      "    [batch 1745]: seen 174500 examples : 67.7 eps, Loss: 5.114, Avg loss: 5.236, Best loss: 5.234\n",
      "    [batch 1752]: seen 175200 examples : 67.7 eps, Loss: 5.212, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1759]: seen 175900 examples : 67.7 eps, Loss: 5.121, Avg loss: 5.235, Best loss: 5.234\n",
      "    [batch 1766]: seen 176600 examples : 67.7 eps, Loss: 5.311, Avg loss: 5.236, Best loss: 5.234\n",
      "    [batch 1773]: seen 177300 examples : 67.7 eps, Loss: 5.205, Avg loss: 5.236, Best loss: 5.234\n",
      "    [batch 1780]: seen 178000 examples : 67.7 eps, Loss: 5.191, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1787]: seen 178700 examples : 67.7 eps, Loss: 5.250, Avg loss: 5.240, Best loss: 5.234\n",
      "    [batch 1794]: seen 179400 examples : 67.7 eps, Loss: 5.239, Avg loss: 5.240, Best loss: 5.234\n",
      "    [batch 1801]: seen 180100 examples : 67.7 eps, Loss: 5.332, Avg loss: 5.240, Best loss: 5.234\n",
      "    [batch 1808]: seen 180800 examples : 67.6 eps, Loss: 5.201, Avg loss: 5.240, Best loss: 5.234\n",
      "    [batch 1815]: seen 181500 examples : 67.6 eps, Loss: 5.203, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1822]: seen 182200 examples : 67.7 eps, Loss: 5.204, Avg loss: 5.237, Best loss: 5.234\n",
      "    [batch 1829]: seen 182900 examples : 67.7 eps, Loss: 5.370, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1836]: seen 183600 examples : 67.7 eps, Loss: 5.262, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1843]: seen 184300 examples : 67.7 eps, Loss: 5.234, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1850]: seen 185000 examples : 67.7 eps, Loss: 5.261, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1857]: seen 185700 examples : 67.7 eps, Loss: 5.157, Avg loss: 5.235, Best loss: 5.234\n",
      "    [batch 1864]: seen 186400 examples : 67.7 eps, Loss: 5.225, Avg loss: 5.237, Best loss: 5.234\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-29909\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-29909\n",
      "    [batch 1870]: seen 187000 examples : 67.6 eps, Loss: 5.322, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1877]: seen 187700 examples : 67.6 eps, Loss: 5.201, Avg loss: 5.238, Best loss: 5.234\n",
      "    [batch 1884]: seen 188400 examples : 67.6 eps, Loss: 5.334, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1891]: seen 189100 examples : 67.6 eps, Loss: 5.238, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1898]: seen 189800 examples : 67.6 eps, Loss: 5.189, Avg loss: 5.237, Best loss: 5.234\n",
      "    [batch 1905]: seen 190500 examples : 67.6 eps, Loss: 5.310, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1912]: seen 191200 examples : 67.6 eps, Loss: 5.190, Avg loss: 5.239, Best loss: 5.234\n",
      "    [batch 1919]: seen 191900 examples : 67.6 eps, Loss: 5.137, Avg loss: 5.238, Best loss: 5.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1926]: seen 192600 examples : 67.6 eps, Loss: 5.274, Avg loss: 5.236, Best loss: 5.234\n",
      "    [batch 1933]: seen 193300 examples : 67.6 eps, Loss: 5.148, Avg loss: 5.234, Best loss: 5.234\n",
      "    [batch 1940]: seen 194000 examples : 67.6 eps, Loss: 5.168, Avg loss: 5.233, Best loss: 5.232\n",
      "    [batch 1947]: seen 194700 examples : 67.6 eps, Loss: 5.188, Avg loss: 5.233, Best loss: 5.232\n",
      "    [batch 1954]: seen 195400 examples : 67.6 eps, Loss: 5.192, Avg loss: 5.232, Best loss: 5.232\n",
      "    [batch 1961]: seen 196100 examples : 67.6 eps, Loss: 5.212, Avg loss: 5.230, Best loss: 5.230\n",
      "    [batch 1968]: seen 196800 examples : 67.6 eps, Loss: 5.276, Avg loss: 5.231, Best loss: 5.229\n",
      "    [batch 1975]: seen 197500 examples : 67.6 eps, Loss: 5.265, Avg loss: 5.230, Best loss: 5.228\n",
      "    [batch 1982]: seen 198200 examples : 67.6 eps, Loss: 5.295, Avg loss: 5.229, Best loss: 5.228\n",
      "    [batch 1989]: seen 198900 examples : 67.6 eps, Loss: 5.197, Avg loss: 5.226, Best loss: 5.226\n",
      "    [batch 1996]: seen 199600 examples : 67.6 eps, Loss: 5.261, Avg loss: 5.227, Best loss: 5.226\n",
      "    [batch 2003]: seen 200300 examples : 67.6 eps, Loss: 5.311, Avg loss: 5.229, Best loss: 5.226\n",
      "    [batch 2010]: seen 201000 examples : 67.6 eps, Loss: 5.247, Avg loss: 5.230, Best loss: 5.226\n",
      "    [batch 2017]: seen 201700 examples : 67.6 eps, Loss: 5.238, Avg loss: 5.229, Best loss: 5.226\n",
      "    [batch 2024]: seen 202400 examples : 67.6 eps, Loss: 5.153, Avg loss: 5.229, Best loss: 5.226\n",
      "    [batch 2031]: seen 203100 examples : 67.6 eps, Loss: 5.317, Avg loss: 5.228, Best loss: 5.226\n",
      "    [batch 2038]: seen 203800 examples : 67.6 eps, Loss: 5.234, Avg loss: 5.229, Best loss: 5.226\n",
      "    [batch 2045]: seen 204500 examples : 67.6 eps, Loss: 5.109, Avg loss: 5.227, Best loss: 5.226\n",
      "    [batch 2052]: seen 205200 examples : 67.6 eps, Loss: 5.176, Avg loss: 5.226, Best loss: 5.226\n",
      "    [batch 2059]: seen 205900 examples : 67.6 eps, Loss: 5.167, Avg loss: 5.228, Best loss: 5.225\n",
      "    [batch 2066]: seen 206600 examples : 67.6 eps, Loss: 5.190, Avg loss: 5.228, Best loss: 5.225\n",
      "    [batch 2073]: seen 207300 examples : 67.6 eps, Loss: 5.224, Avg loss: 5.227, Best loss: 5.225\n",
      "    [batch 2080]: seen 208000 examples : 67.6 eps, Loss: 5.152, Avg loss: 5.228, Best loss: 5.225\n",
      "    [batch 2087]: seen 208700 examples : 67.6 eps, Loss: 5.249, Avg loss: 5.229, Best loss: 5.225\n",
      "    [batch 2094]: seen 209400 examples : 67.6 eps, Loss: 5.250, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2101]: seen 210100 examples : 67.6 eps, Loss: 5.247, Avg loss: 5.231, Best loss: 5.225\n",
      "    [batch 2108]: seen 210800 examples : 67.6 eps, Loss: 5.197, Avg loss: 5.229, Best loss: 5.225\n",
      "    [batch 2115]: seen 211500 examples : 67.6 eps, Loss: 5.114, Avg loss: 5.228, Best loss: 5.225\n",
      "    [batch 2122]: seen 212200 examples : 67.6 eps, Loss: 5.259, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2129]: seen 212900 examples : 67.6 eps, Loss: 5.355, Avg loss: 5.233, Best loss: 5.225\n",
      "    [batch 2136]: seen 213600 examples : 67.6 eps, Loss: 5.266, Avg loss: 5.235, Best loss: 5.225\n",
      "    [batch 2143]: seen 214300 examples : 67.6 eps, Loss: 5.322, Avg loss: 5.236, Best loss: 5.225\n",
      "    [batch 2150]: seen 215000 examples : 67.6 eps, Loss: 5.267, Avg loss: 5.234, Best loss: 5.225\n",
      "    [batch 2157]: seen 215700 examples : 67.6 eps, Loss: 5.169, Avg loss: 5.233, Best loss: 5.225\n",
      "    [batch 2164]: seen 216400 examples : 67.6 eps, Loss: 5.242, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2171]: seen 217100 examples : 67.6 eps, Loss: 5.324, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2178]: seen 217800 examples : 67.6 eps, Loss: 5.252, Avg loss: 5.233, Best loss: 5.225\n",
      "    [batch 2185]: seen 218500 examples : 67.6 eps, Loss: 5.253, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2192]: seen 219200 examples : 67.6 eps, Loss: 5.306, Avg loss: 5.233, Best loss: 5.225\n",
      "    [batch 2199]: seen 219900 examples : 67.6 eps, Loss: 5.263, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2206]: seen 220600 examples : 67.6 eps, Loss: 5.256, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2213]: seen 221300 examples : 67.6 eps, Loss: 5.248, Avg loss: 5.233, Best loss: 5.225\n",
      "    [batch 2220]: seen 222000 examples : 67.6 eps, Loss: 5.138, Avg loss: 5.229, Best loss: 5.225\n",
      "    [batch 2227]: seen 222700 examples : 67.6 eps, Loss: 5.188, Avg loss: 5.229, Best loss: 5.225\n",
      "    [batch 2234]: seen 223400 examples : 67.6 eps, Loss: 5.297, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2241]: seen 224100 examples : 67.6 eps, Loss: 5.229, Avg loss: 5.231, Best loss: 5.225\n",
      "    [batch 2248]: seen 224800 examples : 67.6 eps, Loss: 5.234, Avg loss: 5.231, Best loss: 5.225\n",
      "    [batch 2255]: seen 225500 examples : 67.6 eps, Loss: 5.304, Avg loss: 5.229, Best loss: 5.225\n",
      "    [batch 2262]: seen 226200 examples : 67.6 eps, Loss: 5.222, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2269]: seen 226900 examples : 67.6 eps, Loss: 5.295, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2276]: seen 227600 examples : 67.6 eps, Loss: 5.328, Avg loss: 5.231, Best loss: 5.225\n",
      "    [batch 2283]: seen 228300 examples : 67.6 eps, Loss: 5.251, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2290]: seen 229000 examples : 67.6 eps, Loss: 5.239, Avg loss: 5.229, Best loss: 5.225\n",
      "    [batch 2297]: seen 229700 examples : 67.6 eps, Loss: 5.333, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2304]: seen 230400 examples : 67.6 eps, Loss: 5.207, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2311]: seen 231100 examples : 67.6 eps, Loss: 5.205, Avg loss: 5.232, Best loss: 5.225\n",
      "    [batch 2318]: seen 231800 examples : 67.6 eps, Loss: 5.157, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2325]: seen 232500 examples : 67.6 eps, Loss: 5.266, Avg loss: 5.230, Best loss: 5.225\n",
      "    [batch 2332]: seen 233200 examples : 67.6 eps, Loss: 5.337, Avg loss: 5.228, Best loss: 5.225\n",
      "    [batch 2339]: seen 233900 examples : 67.6 eps, Loss: 5.221, Avg loss: 5.228, Best loss: 5.225\n",
      "    [batch 2346]: seen 234600 examples : 67.6 eps, Loss: 5.270, Avg loss: 5.227, Best loss: 5.225\n",
      "    [batch 2353]: seen 235300 examples : 67.6 eps, Loss: 5.141, Avg loss: 5.226, Best loss: 5.225\n",
      "    [batch 2360]: seen 236000 examples : 67.6 eps, Loss: 5.228, Avg loss: 5.224, Best loss: 5.223\n",
      "    [batch 2367]: seen 236700 examples : 67.6 eps, Loss: 5.205, Avg loss: 5.223, Best loss: 5.223\n",
      "    [batch 2374]: seen 237400 examples : 67.6 eps, Loss: 5.136, Avg loss: 5.223, Best loss: 5.223\n",
      "    [batch 2381]: seen 238100 examples : 67.6 eps, Loss: 5.274, Avg loss: 5.223, Best loss: 5.222\n",
      "    [batch 2388]: seen 238800 examples : 67.6 eps, Loss: 5.199, Avg loss: 5.221, Best loss: 5.221\n",
      "    [batch 2395]: seen 239500 examples : 67.6 eps, Loss: 5.221, Avg loss: 5.219, Best loss: 5.219\n",
      "    [batch 2402]: seen 240200 examples : 67.6 eps, Loss: 5.259, Avg loss: 5.220, Best loss: 5.219\n",
      "    [batch 2409]: seen 240900 examples : 67.6 eps, Loss: 5.261, Avg loss: 5.222, Best loss: 5.219\n",
      "    [batch 2416]: seen 241600 examples : 67.6 eps, Loss: 5.246, Avg loss: 5.223, Best loss: 5.219\n",
      "    [batch 2423]: seen 242300 examples : 67.6 eps, Loss: 5.146, Avg loss: 5.226, Best loss: 5.219\n",
      "    [batch 2430]: seen 243000 examples : 67.6 eps, Loss: 5.225, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2437]: seen 243700 examples : 67.6 eps, Loss: 5.285, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2444]: seen 244400 examples : 67.6 eps, Loss: 5.236, Avg loss: 5.229, Best loss: 5.219\n",
      "    [batch 2451]: seen 245100 examples : 67.6 eps, Loss: 5.306, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2458]: seen 245800 examples : 67.6 eps, Loss: 5.276, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2465]: seen 246500 examples : 67.6 eps, Loss: 5.217, Avg loss: 5.230, Best loss: 5.219\n",
      "    [batch 2472]: seen 247200 examples : 67.6 eps, Loss: 5.183, Avg loss: 5.230, Best loss: 5.219\n",
      "    [batch 2479]: seen 247900 examples : 67.6 eps, Loss: 5.195, Avg loss: 5.229, Best loss: 5.219\n",
      "    [batch 2486]: seen 248600 examples : 67.6 eps, Loss: 5.218, Avg loss: 5.229, Best loss: 5.219\n",
      "    [batch 2493]: seen 249300 examples : 67.6 eps, Loss: 5.260, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2500]: seen 250000 examples : 67.6 eps, Loss: 5.213, Avg loss: 5.226, Best loss: 5.219\n",
      "    [batch 2507]: seen 250700 examples : 67.6 eps, Loss: 5.231, Avg loss: 5.226, Best loss: 5.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2514]: seen 251400 examples : 67.6 eps, Loss: 5.222, Avg loss: 5.227, Best loss: 5.219\n",
      "    [batch 2521]: seen 252100 examples : 67.6 eps, Loss: 5.240, Avg loss: 5.225, Best loss: 5.219\n",
      "    [batch 2528]: seen 252800 examples : 67.6 eps, Loss: 5.217, Avg loss: 5.223, Best loss: 5.219\n",
      "    [batch 2535]: seen 253500 examples : 67.6 eps, Loss: 5.196, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2542]: seen 254200 examples : 67.6 eps, Loss: 5.248, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 2549]: seen 254900 examples : 67.6 eps, Loss: 5.248, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 2556]: seen 255600 examples : 67.6 eps, Loss: 5.131, Avg loss: 5.225, Best loss: 5.219\n",
      "    [batch 2563]: seen 256300 examples : 67.6 eps, Loss: 5.162, Avg loss: 5.223, Best loss: 5.219\n",
      "    [batch 2570]: seen 257000 examples : 67.6 eps, Loss: 5.290, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2577]: seen 257700 examples : 67.6 eps, Loss: 5.264, Avg loss: 5.222, Best loss: 5.219\n",
      "    [batch 2584]: seen 258400 examples : 67.6 eps, Loss: 5.266, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2591]: seen 259100 examples : 67.6 eps, Loss: 5.144, Avg loss: 5.222, Best loss: 5.219\n",
      "    [batch 2598]: seen 259800 examples : 67.6 eps, Loss: 5.198, Avg loss: 5.222, Best loss: 5.219\n",
      "    [batch 2605]: seen 260500 examples : 67.6 eps, Loss: 5.232, Avg loss: 5.222, Best loss: 5.219\n",
      "    [batch 2611]: seen 261100 examples : 67.6 eps, Loss: 5.173, Avg loss: 5.219, Best loss: 5.219\n",
      "    [batch 2618]: seen 261800 examples : 67.6 eps, Loss: 5.213, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2625]: seen 262500 examples : 67.6 eps, Loss: 5.240, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2632]: seen 263200 examples : 67.6 eps, Loss: 5.196, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2639]: seen 263900 examples : 67.6 eps, Loss: 5.228, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2646]: seen 264600 examples : 67.6 eps, Loss: 5.157, Avg loss: 5.220, Best loss: 5.219\n",
      "    [batch 2653]: seen 265300 examples : 67.6 eps, Loss: 5.130, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 2660]: seen 266000 examples : 67.6 eps, Loss: 5.302, Avg loss: 5.223, Best loss: 5.219\n",
      "    [batch 2667]: seen 266700 examples : 67.6 eps, Loss: 5.280, Avg loss: 5.222, Best loss: 5.219\n",
      "    [batch 2674]: seen 267400 examples : 67.6 eps, Loss: 5.327, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 2681]: seen 268100 examples : 67.6 eps, Loss: 5.251, Avg loss: 5.225, Best loss: 5.219\n",
      "    [batch 2688]: seen 268800 examples : 67.6 eps, Loss: 5.240, Avg loss: 5.227, Best loss: 5.219\n",
      "    [batch 2695]: seen 269500 examples : 67.6 eps, Loss: 5.338, Avg loss: 5.226, Best loss: 5.219\n",
      "    [batch 2702]: seen 270200 examples : 67.6 eps, Loss: 5.246, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2709]: seen 270900 examples : 67.6 eps, Loss: 5.177, Avg loss: 5.227, Best loss: 5.219\n",
      "    [batch 2716]: seen 271600 examples : 67.5 eps, Loss: 5.290, Avg loss: 5.227, Best loss: 5.219\n",
      "    [batch 2723]: seen 272300 examples : 67.5 eps, Loss: 5.174, Avg loss: 5.227, Best loss: 5.219\n",
      "    [batch 2730]: seen 273000 examples : 67.5 eps, Loss: 5.288, Avg loss: 5.225, Best loss: 5.219\n",
      "    [batch 2737]: seen 273700 examples : 67.5 eps, Loss: 5.226, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 2744]: seen 274400 examples : 67.5 eps, Loss: 5.205, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 2751]: seen 275100 examples : 67.5 eps, Loss: 5.184, Avg loss: 5.226, Best loss: 5.219\n",
      "    [batch 2758]: seen 275800 examples : 67.5 eps, Loss: 5.218, Avg loss: 5.225, Best loss: 5.219\n",
      "    [batch 2765]: seen 276500 examples : 67.5 eps, Loss: 5.188, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 2772]: seen 277200 examples : 67.5 eps, Loss: 5.217, Avg loss: 5.226, Best loss: 5.219\n",
      "    [batch 2779]: seen 277900 examples : 67.5 eps, Loss: 5.221, Avg loss: 5.229, Best loss: 5.219\n",
      "    [batch 2786]: seen 278600 examples : 67.5 eps, Loss: 5.182, Avg loss: 5.229, Best loss: 5.219\n",
      "    [batch 2793]: seen 279300 examples : 67.5 eps, Loss: 5.203, Avg loss: 5.230, Best loss: 5.219\n",
      "    [batch 2800]: seen 280000 examples : 67.5 eps, Loss: 5.252, Avg loss: 5.228, Best loss: 5.219\n",
      "    [batch 2807]: seen 280700 examples : 67.5 eps, Loss: 5.263, Avg loss: 5.226, Best loss: 5.219\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:17\n",
      "[EPOCH 11] Complete. Avg Loss: 5.226025408229978; Best Loss: 5.21851629468438\n",
      "[EPOCH 12] Starting training..\n",
      "    [batch 9]: seen 900 examples : 86.8 eps, Loss: 5.244, Avg loss: 5.224, Best loss: 5.219\n",
      "    [batch 16]: seen 1600 examples : 77.7 eps, Loss: 5.196, Avg loss: 5.221, Best loss: 5.219\n",
      "    [batch 23]: seen 2300 examples : 74.7 eps, Loss: 5.179, Avg loss: 5.218, Best loss: 5.218\n",
      "    [batch 30]: seen 3000 examples : 73.1 eps, Loss: 5.088, Avg loss: 5.216, Best loss: 5.216\n",
      "    [batch 37]: seen 3700 examples : 71.6 eps, Loss: 5.264, Avg loss: 5.214, Best loss: 5.213\n",
      "    [batch 44]: seen 4400 examples : 71.1 eps, Loss: 5.198, Avg loss: 5.212, Best loss: 5.212\n",
      "    [batch 51]: seen 5100 examples : 70.7 eps, Loss: 5.101, Avg loss: 5.209, Best loss: 5.209\n",
      "    [batch 58]: seen 5800 examples : 70.4 eps, Loss: 5.219, Avg loss: 5.206, Best loss: 5.206\n",
      "    [batch 65]: seen 6500 examples : 70.2 eps, Loss: 5.177, Avg loss: 5.205, Best loss: 5.205\n",
      "    [batch 72]: seen 7200 examples : 70.1 eps, Loss: 5.240, Avg loss: 5.206, Best loss: 5.205\n",
      "    [batch 79]: seen 7900 examples : 69.9 eps, Loss: 5.090, Avg loss: 5.202, Best loss: 5.202\n",
      "    [batch 86]: seen 8600 examples : 69.8 eps, Loss: 5.247, Avg loss: 5.200, Best loss: 5.199\n",
      "    [batch 93]: seen 9300 examples : 69.7 eps, Loss: 5.276, Avg loss: 5.202, Best loss: 5.199\n",
      "    [batch 100]: seen 10000 examples : 69.6 eps, Loss: 5.213, Avg loss: 5.200, Best loss: 5.199\n",
      "    [batch 107]: seen 10700 examples : 69.5 eps, Loss: 5.198, Avg loss: 5.200, Best loss: 5.199\n",
      "    [batch 114]: seen 11400 examples : 69.5 eps, Loss: 5.112, Avg loss: 5.198, Best loss: 5.198\n",
      "    [batch 121]: seen 12100 examples : 69.4 eps, Loss: 5.228, Avg loss: 5.196, Best loss: 5.196\n",
      "    [batch 128]: seen 12800 examples : 69.4 eps, Loss: 5.198, Avg loss: 5.196, Best loss: 5.195\n",
      "    [batch 135]: seen 13500 examples : 69.2 eps, Loss: 5.275, Avg loss: 5.199, Best loss: 5.195\n",
      "    [batch 142]: seen 14200 examples : 69.1 eps, Loss: 5.135, Avg loss: 5.196, Best loss: 5.195\n",
      "    [batch 149]: seen 14900 examples : 69.1 eps, Loss: 5.077, Avg loss: 5.193, Best loss: 5.193\n",
      "    [batch 156]: seen 15600 examples : 69.0 eps, Loss: 5.177, Avg loss: 5.190, Best loss: 5.190\n",
      "    [batch 163]: seen 16300 examples : 69.0 eps, Loss: 5.216, Avg loss: 5.191, Best loss: 5.190\n",
      "    [batch 170]: seen 17000 examples : 68.8 eps, Loss: 5.197, Avg loss: 5.191, Best loss: 5.189\n",
      "    [batch 177]: seen 17700 examples : 68.8 eps, Loss: 5.212, Avg loss: 5.191, Best loss: 5.189\n",
      "    [batch 184]: seen 18400 examples : 68.8 eps, Loss: 5.208, Avg loss: 5.190, Best loss: 5.189\n",
      "    [batch 191]: seen 19100 examples : 68.7 eps, Loss: 5.137, Avg loss: 5.189, Best loss: 5.189\n",
      "    [batch 198]: seen 19800 examples : 68.7 eps, Loss: 5.295, Avg loss: 5.190, Best loss: 5.189\n",
      "    [batch 205]: seen 20500 examples : 68.6 eps, Loss: 5.262, Avg loss: 5.191, Best loss: 5.189\n",
      "    [batch 212]: seen 21200 examples : 68.6 eps, Loss: 5.148, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 219]: seen 21900 examples : 68.6 eps, Loss: 5.198, Avg loss: 5.195, Best loss: 5.189\n",
      "    [batch 226]: seen 22600 examples : 68.6 eps, Loss: 5.201, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 233]: seen 23300 examples : 68.5 eps, Loss: 5.192, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 240]: seen 24000 examples : 68.5 eps, Loss: 5.234, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 247]: seen 24700 examples : 68.5 eps, Loss: 5.221, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 254]: seen 25400 examples : 68.5 eps, Loss: 5.231, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 261]: seen 26100 examples : 68.4 eps, Loss: 5.110, Avg loss: 5.197, Best loss: 5.189\n",
      "    [batch 268]: seen 26800 examples : 68.4 eps, Loss: 5.301, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 275]: seen 27500 examples : 68.4 eps, Loss: 5.192, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 282]: seen 28200 examples : 68.4 eps, Loss: 5.156, Avg loss: 5.193, Best loss: 5.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 289]: seen 28900 examples : 68.4 eps, Loss: 5.250, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 296]: seen 29600 examples : 68.4 eps, Loss: 5.120, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 303]: seen 30300 examples : 68.3 eps, Loss: 5.201, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 310]: seen 31000 examples : 68.3 eps, Loss: 5.151, Avg loss: 5.195, Best loss: 5.189\n",
      "    [batch 317]: seen 31700 examples : 68.3 eps, Loss: 5.172, Avg loss: 5.195, Best loss: 5.189\n",
      "    [batch 324]: seen 32400 examples : 68.3 eps, Loss: 5.215, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 331]: seen 33100 examples : 68.3 eps, Loss: 5.047, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 338]: seen 33800 examples : 68.3 eps, Loss: 5.257, Avg loss: 5.195, Best loss: 5.189\n",
      "    [batch 345]: seen 34500 examples : 68.3 eps, Loss: 5.180, Avg loss: 5.195, Best loss: 5.189\n",
      "    [batch 352]: seen 35200 examples : 68.2 eps, Loss: 5.106, Avg loss: 5.193, Best loss: 5.189\n",
      "    [batch 359]: seen 35900 examples : 68.2 eps, Loss: 5.123, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 366]: seen 36600 examples : 68.2 eps, Loss: 5.219, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 373]: seen 37300 examples : 68.2 eps, Loss: 5.247, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 380]: seen 38000 examples : 68.2 eps, Loss: 5.295, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 387]: seen 38700 examples : 68.2 eps, Loss: 5.336, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 394]: seen 39400 examples : 68.2 eps, Loss: 5.199, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 401]: seen 40100 examples : 68.1 eps, Loss: 5.220, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 408]: seen 40800 examples : 68.1 eps, Loss: 5.295, Avg loss: 5.199, Best loss: 5.189\n",
      "    [batch 415]: seen 41500 examples : 68.1 eps, Loss: 5.226, Avg loss: 5.201, Best loss: 5.189\n",
      "    [batch 422]: seen 42200 examples : 68.1 eps, Loss: 5.138, Avg loss: 5.200, Best loss: 5.189\n",
      "    [batch 429]: seen 42900 examples : 68.1 eps, Loss: 5.112, Avg loss: 5.199, Best loss: 5.189\n",
      "    [batch 436]: seen 43600 examples : 68.1 eps, Loss: 5.222, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 443]: seen 44300 examples : 68.1 eps, Loss: 5.100, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 450]: seen 45000 examples : 68.1 eps, Loss: 5.161, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 457]: seen 45700 examples : 68.1 eps, Loss: 5.093, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 464]: seen 46400 examples : 68.1 eps, Loss: 5.167, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 471]: seen 47100 examples : 68.1 eps, Loss: 5.272, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 478]: seen 47800 examples : 68.1 eps, Loss: 5.093, Avg loss: 5.192, Best loss: 5.189\n",
      "    [batch 485]: seen 48500 examples : 68.1 eps, Loss: 5.227, Avg loss: 5.192, Best loss: 5.189\n",
      "    [batch 492]: seen 49200 examples : 68.1 eps, Loss: 5.239, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 499]: seen 49900 examples : 68.1 eps, Loss: 5.144, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 506]: seen 50600 examples : 68.1 eps, Loss: 5.186, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 513]: seen 51300 examples : 68.1 eps, Loss: 5.240, Avg loss: 5.193, Best loss: 5.189\n",
      "    [batch 520]: seen 52000 examples : 68.0 eps, Loss: 5.233, Avg loss: 5.193, Best loss: 5.189\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-31371\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-31371\n",
      "    [batch 526]: seen 52600 examples : 67.9 eps, Loss: 5.153, Avg loss: 5.193, Best loss: 5.189\n",
      "    [batch 533]: seen 53300 examples : 67.9 eps, Loss: 5.202, Avg loss: 5.193, Best loss: 5.189\n",
      "    [batch 540]: seen 54000 examples : 67.9 eps, Loss: 5.302, Avg loss: 5.193, Best loss: 5.189\n",
      "    [batch 547]: seen 54700 examples : 67.9 eps, Loss: 5.106, Avg loss: 5.191, Best loss: 5.189\n",
      "    [batch 554]: seen 55400 examples : 67.9 eps, Loss: 5.185, Avg loss: 5.192, Best loss: 5.189\n",
      "    [batch 561]: seen 56100 examples : 67.9 eps, Loss: 5.116, Avg loss: 5.191, Best loss: 5.189\n",
      "    [batch 568]: seen 56800 examples : 67.9 eps, Loss: 5.094, Avg loss: 5.191, Best loss: 5.189\n",
      "    [batch 575]: seen 57500 examples : 67.9 eps, Loss: 5.320, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 582]: seen 58200 examples : 67.9 eps, Loss: 5.239, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 589]: seen 58900 examples : 67.9 eps, Loss: 5.182, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 596]: seen 59600 examples : 67.9 eps, Loss: 5.061, Avg loss: 5.193, Best loss: 5.189\n",
      "    [batch 603]: seen 60300 examples : 67.9 eps, Loss: 5.276, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 610]: seen 61000 examples : 67.9 eps, Loss: 5.185, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 617]: seen 61700 examples : 67.9 eps, Loss: 5.154, Avg loss: 5.197, Best loss: 5.189\n",
      "    [batch 624]: seen 62400 examples : 67.9 eps, Loss: 5.260, Avg loss: 5.197, Best loss: 5.189\n",
      "    [batch 631]: seen 63100 examples : 67.9 eps, Loss: 5.202, Avg loss: 5.197, Best loss: 5.189\n",
      "    [batch 638]: seen 63800 examples : 67.9 eps, Loss: 5.385, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 645]: seen 64500 examples : 67.9 eps, Loss: 5.187, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 652]: seen 65200 examples : 67.9 eps, Loss: 5.140, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 659]: seen 65900 examples : 67.8 eps, Loss: 5.088, Avg loss: 5.197, Best loss: 5.189\n",
      "    [batch 666]: seen 66600 examples : 67.8 eps, Loss: 5.194, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 673]: seen 67300 examples : 67.8 eps, Loss: 5.124, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 680]: seen 68000 examples : 67.8 eps, Loss: 5.164, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 686]: seen 68600 examples : 67.7 eps, Loss: 5.222, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 693]: seen 69300 examples : 67.8 eps, Loss: 5.240, Avg loss: 5.198, Best loss: 5.189\n",
      "    [batch 700]: seen 70000 examples : 67.8 eps, Loss: 5.207, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 707]: seen 70700 examples : 67.8 eps, Loss: 5.256, Avg loss: 5.196, Best loss: 5.189\n",
      "    [batch 714]: seen 71400 examples : 67.8 eps, Loss: 5.235, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 721]: seen 72100 examples : 67.8 eps, Loss: 5.237, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 728]: seen 72800 examples : 67.8 eps, Loss: 5.209, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 735]: seen 73500 examples : 67.8 eps, Loss: 5.148, Avg loss: 5.194, Best loss: 5.189\n",
      "    [batch 742]: seen 74200 examples : 67.8 eps, Loss: 5.154, Avg loss: 5.192, Best loss: 5.189\n",
      "    [batch 749]: seen 74900 examples : 67.8 eps, Loss: 5.080, Avg loss: 5.189, Best loss: 5.189\n",
      "    [batch 756]: seen 75600 examples : 67.8 eps, Loss: 5.111, Avg loss: 5.188, Best loss: 5.188\n",
      "    [batch 763]: seen 76300 examples : 67.8 eps, Loss: 5.110, Avg loss: 5.187, Best loss: 5.186\n",
      "    [batch 770]: seen 77000 examples : 67.8 eps, Loss: 5.226, Avg loss: 5.187, Best loss: 5.186\n",
      "    [batch 777]: seen 77700 examples : 67.8 eps, Loss: 5.279, Avg loss: 5.187, Best loss: 5.186\n",
      "    [batch 784]: seen 78400 examples : 67.8 eps, Loss: 5.259, Avg loss: 5.185, Best loss: 5.185\n",
      "    [batch 791]: seen 79100 examples : 67.8 eps, Loss: 5.183, Avg loss: 5.186, Best loss: 5.184\n",
      "    [batch 798]: seen 79800 examples : 67.8 eps, Loss: 5.126, Avg loss: 5.187, Best loss: 5.184\n",
      "    [batch 805]: seen 80500 examples : 67.7 eps, Loss: 5.177, Avg loss: 5.186, Best loss: 5.184\n",
      "    [batch 812]: seen 81200 examples : 67.7 eps, Loss: 5.162, Avg loss: 5.187, Best loss: 5.184\n",
      "    [batch 819]: seen 81900 examples : 67.7 eps, Loss: 5.207, Avg loss: 5.189, Best loss: 5.184\n",
      "    [batch 826]: seen 82600 examples : 67.7 eps, Loss: 5.229, Avg loss: 5.191, Best loss: 5.184\n",
      "    [batch 833]: seen 83300 examples : 67.7 eps, Loss: 5.216, Avg loss: 5.192, Best loss: 5.184\n",
      "    [batch 840]: seen 84000 examples : 67.7 eps, Loss: 5.183, Avg loss: 5.190, Best loss: 5.184\n",
      "    [batch 847]: seen 84700 examples : 67.7 eps, Loss: 5.179, Avg loss: 5.190, Best loss: 5.184\n",
      "    [batch 854]: seen 85400 examples : 67.7 eps, Loss: 5.233, Avg loss: 5.190, Best loss: 5.184\n",
      "    [batch 861]: seen 86100 examples : 67.7 eps, Loss: 5.282, Avg loss: 5.190, Best loss: 5.184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 868]: seen 86800 examples : 67.7 eps, Loss: 5.169, Avg loss: 5.189, Best loss: 5.184\n",
      "    [batch 875]: seen 87500 examples : 67.7 eps, Loss: 5.107, Avg loss: 5.186, Best loss: 5.184\n",
      "    [batch 882]: seen 88200 examples : 67.7 eps, Loss: 5.150, Avg loss: 5.185, Best loss: 5.184\n",
      "    [batch 889]: seen 88900 examples : 67.7 eps, Loss: 5.229, Avg loss: 5.183, Best loss: 5.182\n",
      "    [batch 896]: seen 89600 examples : 67.7 eps, Loss: 5.096, Avg loss: 5.181, Best loss: 5.181\n",
      "    [batch 903]: seen 90300 examples : 67.7 eps, Loss: 5.034, Avg loss: 5.179, Best loss: 5.179\n",
      "    [batch 910]: seen 91000 examples : 67.7 eps, Loss: 5.152, Avg loss: 5.176, Best loss: 5.176\n",
      "    [batch 917]: seen 91700 examples : 67.7 eps, Loss: 5.146, Avg loss: 5.179, Best loss: 5.176\n",
      "    [batch 924]: seen 92400 examples : 67.7 eps, Loss: 5.199, Avg loss: 5.178, Best loss: 5.176\n",
      "    [batch 931]: seen 93100 examples : 67.7 eps, Loss: 5.186, Avg loss: 5.176, Best loss: 5.176\n",
      "    [batch 938]: seen 93800 examples : 67.7 eps, Loss: 5.243, Avg loss: 5.176, Best loss: 5.175\n",
      "    [batch 945]: seen 94500 examples : 67.7 eps, Loss: 5.253, Avg loss: 5.177, Best loss: 5.175\n",
      "    [batch 952]: seen 95200 examples : 67.7 eps, Loss: 5.136, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 959]: seen 95900 examples : 67.7 eps, Loss: 5.179, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 966]: seen 96600 examples : 67.7 eps, Loss: 5.106, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 973]: seen 97300 examples : 67.7 eps, Loss: 5.224, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 980]: seen 98000 examples : 67.7 eps, Loss: 5.166, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 987]: seen 98700 examples : 67.7 eps, Loss: 5.216, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 994]: seen 99400 examples : 67.7 eps, Loss: 5.160, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1001]: seen 100100 examples : 67.7 eps, Loss: 5.172, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1008]: seen 100800 examples : 67.7 eps, Loss: 5.155, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1015]: seen 101500 examples : 67.7 eps, Loss: 5.226, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1022]: seen 102200 examples : 67.7 eps, Loss: 5.155, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1029]: seen 102900 examples : 67.7 eps, Loss: 5.224, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1036]: seen 103600 examples : 67.7 eps, Loss: 5.179, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1043]: seen 104300 examples : 67.7 eps, Loss: 5.163, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1050]: seen 105000 examples : 67.7 eps, Loss: 5.156, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1057]: seen 105700 examples : 67.7 eps, Loss: 5.230, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1064]: seen 106400 examples : 67.7 eps, Loss: 5.205, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1071]: seen 107100 examples : 67.7 eps, Loss: 5.182, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1078]: seen 107800 examples : 67.7 eps, Loss: 5.170, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1085]: seen 108500 examples : 67.7 eps, Loss: 5.339, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1092]: seen 109200 examples : 67.7 eps, Loss: 5.140, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1099]: seen 109900 examples : 67.7 eps, Loss: 5.250, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1106]: seen 110600 examples : 67.7 eps, Loss: 5.218, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1113]: seen 111300 examples : 67.7 eps, Loss: 5.114, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1120]: seen 112000 examples : 67.7 eps, Loss: 5.165, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1127]: seen 112700 examples : 67.7 eps, Loss: 5.087, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1134]: seen 113400 examples : 67.7 eps, Loss: 5.195, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1141]: seen 114100 examples : 67.7 eps, Loss: 5.238, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1148]: seen 114800 examples : 67.7 eps, Loss: 5.236, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1155]: seen 115500 examples : 67.7 eps, Loss: 5.174, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1162]: seen 116200 examples : 67.7 eps, Loss: 5.191, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1169]: seen 116900 examples : 67.7 eps, Loss: 5.131, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1176]: seen 117600 examples : 67.7 eps, Loss: 5.180, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1183]: seen 118300 examples : 67.7 eps, Loss: 5.210, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1190]: seen 119000 examples : 67.7 eps, Loss: 5.288, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1197]: seen 119700 examples : 67.7 eps, Loss: 5.106, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1204]: seen 120400 examples : 67.7 eps, Loss: 5.219, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1211]: seen 121100 examples : 67.7 eps, Loss: 5.186, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1218]: seen 121800 examples : 67.7 eps, Loss: 5.200, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1225]: seen 122500 examples : 67.7 eps, Loss: 5.153, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1232]: seen 123200 examples : 67.7 eps, Loss: 5.185, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1239]: seen 123900 examples : 67.7 eps, Loss: 5.211, Avg loss: 5.185, Best loss: 5.175\n",
      "    [batch 1246]: seen 124600 examples : 67.7 eps, Loss: 5.204, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1253]: seen 125300 examples : 67.7 eps, Loss: 5.035, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1260]: seen 126000 examples : 67.7 eps, Loss: 5.158, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1267]: seen 126700 examples : 67.7 eps, Loss: 5.190, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1274]: seen 127400 examples : 67.7 eps, Loss: 5.127, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1281]: seen 128100 examples : 67.7 eps, Loss: 5.120, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1288]: seen 128800 examples : 67.7 eps, Loss: 5.170, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1295]: seen 129500 examples : 67.7 eps, Loss: 5.189, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1302]: seen 130200 examples : 67.7 eps, Loss: 5.229, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1309]: seen 130900 examples : 67.7 eps, Loss: 5.249, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1316]: seen 131600 examples : 67.7 eps, Loss: 5.208, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1323]: seen 132300 examples : 67.7 eps, Loss: 5.181, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1330]: seen 133000 examples : 67.7 eps, Loss: 5.219, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1337]: seen 133700 examples : 67.7 eps, Loss: 5.287, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1344]: seen 134400 examples : 67.7 eps, Loss: 5.230, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1351]: seen 135100 examples : 67.7 eps, Loss: 5.147, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1358]: seen 135800 examples : 67.7 eps, Loss: 5.179, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1365]: seen 136500 examples : 67.7 eps, Loss: 5.245, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1372]: seen 137200 examples : 67.7 eps, Loss: 5.311, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1379]: seen 137900 examples : 67.7 eps, Loss: 5.221, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1386]: seen 138600 examples : 67.7 eps, Loss: 5.178, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1393]: seen 139300 examples : 67.7 eps, Loss: 5.178, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1400]: seen 140000 examples : 67.7 eps, Loss: 5.143, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1407]: seen 140700 examples : 67.7 eps, Loss: 5.093, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1414]: seen 141400 examples : 67.7 eps, Loss: 5.148, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1421]: seen 142100 examples : 67.7 eps, Loss: 5.233, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1428]: seen 142800 examples : 67.7 eps, Loss: 5.161, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1435]: seen 143500 examples : 67.7 eps, Loss: 5.170, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1442]: seen 144200 examples : 67.7 eps, Loss: 5.115, Avg loss: 5.183, Best loss: 5.175\n",
      "    [batch 1449]: seen 144900 examples : 67.7 eps, Loss: 5.159, Avg loss: 5.184, Best loss: 5.175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1456]: seen 145600 examples : 67.7 eps, Loss: 5.265, Avg loss: 5.186, Best loss: 5.175\n",
      "    [batch 1463]: seen 146300 examples : 67.7 eps, Loss: 5.084, Avg loss: 5.184, Best loss: 5.175\n",
      "    [batch 1470]: seen 147000 examples : 67.7 eps, Loss: 5.133, Avg loss: 5.185, Best loss: 5.175\n",
      "    [batch 1477]: seen 147700 examples : 67.7 eps, Loss: 5.221, Avg loss: 5.188, Best loss: 5.175\n",
      "    [batch 1484]: seen 148400 examples : 67.7 eps, Loss: 5.244, Avg loss: 5.185, Best loss: 5.175\n",
      "    [batch 1491]: seen 149100 examples : 67.7 eps, Loss: 5.038, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1498]: seen 149800 examples : 67.7 eps, Loss: 5.185, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1505]: seen 150500 examples : 67.7 eps, Loss: 5.118, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1512]: seen 151200 examples : 67.7 eps, Loss: 5.203, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1519]: seen 151900 examples : 67.7 eps, Loss: 5.219, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1526]: seen 152600 examples : 67.7 eps, Loss: 5.252, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1533]: seen 153300 examples : 67.7 eps, Loss: 5.222, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1540]: seen 154000 examples : 67.7 eps, Loss: 5.124, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1547]: seen 154700 examples : 67.7 eps, Loss: 5.188, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1554]: seen 155400 examples : 67.7 eps, Loss: 5.221, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1561]: seen 156100 examples : 67.7 eps, Loss: 5.171, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1568]: seen 156800 examples : 67.7 eps, Loss: 5.202, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1575]: seen 157500 examples : 67.7 eps, Loss: 5.117, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1582]: seen 158200 examples : 67.7 eps, Loss: 5.180, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1589]: seen 158900 examples : 67.7 eps, Loss: 5.170, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1596]: seen 159600 examples : 67.7 eps, Loss: 5.230, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1603]: seen 160300 examples : 67.7 eps, Loss: 5.183, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1610]: seen 161000 examples : 67.7 eps, Loss: 5.160, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1617]: seen 161700 examples : 67.7 eps, Loss: 5.279, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1624]: seen 162400 examples : 67.7 eps, Loss: 5.186, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1631]: seen 163100 examples : 67.7 eps, Loss: 5.150, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1638]: seen 163800 examples : 67.7 eps, Loss: 5.152, Avg loss: 5.182, Best loss: 5.175\n",
      "    [batch 1645]: seen 164500 examples : 67.7 eps, Loss: 5.109, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1652]: seen 165200 examples : 67.7 eps, Loss: 5.092, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1659]: seen 165900 examples : 67.7 eps, Loss: 5.201, Avg loss: 5.180, Best loss: 5.175\n",
      "    [batch 1666]: seen 166600 examples : 67.7 eps, Loss: 5.089, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1673]: seen 167300 examples : 67.7 eps, Loss: 5.197, Avg loss: 5.177, Best loss: 5.175\n",
      "    [batch 1680]: seen 168000 examples : 67.7 eps, Loss: 5.190, Avg loss: 5.177, Best loss: 5.175\n",
      "    [batch 1687]: seen 168700 examples : 67.7 eps, Loss: 5.303, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1694]: seen 169400 examples : 67.7 eps, Loss: 5.126, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1701]: seen 170100 examples : 67.7 eps, Loss: 5.135, Avg loss: 5.178, Best loss: 5.175\n",
      "    [batch 1708]: seen 170800 examples : 67.7 eps, Loss: 5.170, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1715]: seen 171500 examples : 67.7 eps, Loss: 5.240, Avg loss: 5.181, Best loss: 5.175\n",
      "    [batch 1722]: seen 172200 examples : 67.7 eps, Loss: 5.122, Avg loss: 5.179, Best loss: 5.175\n",
      "    [batch 1729]: seen 172900 examples : 67.7 eps, Loss: 5.153, Avg loss: 5.176, Best loss: 5.175\n",
      "    [batch 1736]: seen 173600 examples : 67.7 eps, Loss: 5.079, Avg loss: 5.177, Best loss: 5.175\n",
      "    [batch 1743]: seen 174300 examples : 67.7 eps, Loss: 5.131, Avg loss: 5.175, Best loss: 5.175\n",
      "    [batch 1750]: seen 175000 examples : 67.7 eps, Loss: 5.186, Avg loss: 5.176, Best loss: 5.175\n",
      "    [batch 1757]: seen 175700 examples : 67.7 eps, Loss: 5.136, Avg loss: 5.175, Best loss: 5.175\n",
      "    [batch 1764]: seen 176400 examples : 67.7 eps, Loss: 5.127, Avg loss: 5.176, Best loss: 5.175\n",
      "    [batch 1771]: seen 177100 examples : 67.7 eps, Loss: 5.067, Avg loss: 5.174, Best loss: 5.174\n",
      "    [batch 1778]: seen 177800 examples : 67.7 eps, Loss: 5.221, Avg loss: 5.172, Best loss: 5.172\n",
      "    [batch 1785]: seen 178500 examples : 67.7 eps, Loss: 5.194, Avg loss: 5.173, Best loss: 5.172\n",
      "    [batch 1792]: seen 179200 examples : 67.7 eps, Loss: 5.132, Avg loss: 5.174, Best loss: 5.172\n",
      "    [batch 1799]: seen 179900 examples : 67.7 eps, Loss: 5.155, Avg loss: 5.176, Best loss: 5.172\n",
      "    [batch 1806]: seen 180600 examples : 67.7 eps, Loss: 5.180, Avg loss: 5.175, Best loss: 5.172\n",
      "    [batch 1813]: seen 181300 examples : 67.7 eps, Loss: 5.192, Avg loss: 5.174, Best loss: 5.172\n",
      "    [batch 1820]: seen 182000 examples : 67.7 eps, Loss: 5.127, Avg loss: 5.175, Best loss: 5.172\n",
      "    [batch 1827]: seen 182700 examples : 67.7 eps, Loss: 5.199, Avg loss: 5.174, Best loss: 5.172\n",
      "    [batch 1834]: seen 183400 examples : 67.7 eps, Loss: 5.233, Avg loss: 5.176, Best loss: 5.172\n",
      "    [batch 1841]: seen 184100 examples : 67.7 eps, Loss: 5.134, Avg loss: 5.179, Best loss: 5.172\n",
      "    [batch 1848]: seen 184800 examples : 67.7 eps, Loss: 5.174, Avg loss: 5.179, Best loss: 5.172\n",
      "    [batch 1855]: seen 185500 examples : 67.7 eps, Loss: 5.122, Avg loss: 5.177, Best loss: 5.172\n",
      "    [batch 1862]: seen 186200 examples : 67.7 eps, Loss: 5.206, Avg loss: 5.176, Best loss: 5.172\n",
      "    [batch 1869]: seen 186900 examples : 67.7 eps, Loss: 5.103, Avg loss: 5.172, Best loss: 5.172\n",
      "    [batch 1876]: seen 187600 examples : 67.7 eps, Loss: 5.132, Avg loss: 5.172, Best loss: 5.172\n",
      "    [batch 1883]: seen 188300 examples : 67.7 eps, Loss: 5.267, Avg loss: 5.170, Best loss: 5.169\n",
      "    [batch 1890]: seen 189000 examples : 67.7 eps, Loss: 5.250, Avg loss: 5.174, Best loss: 5.169\n",
      "    [batch 1897]: seen 189700 examples : 67.7 eps, Loss: 5.027, Avg loss: 5.172, Best loss: 5.169\n",
      "    [batch 1904]: seen 190400 examples : 67.7 eps, Loss: 5.209, Avg loss: 5.174, Best loss: 5.169\n",
      "    [batch 1911]: seen 191100 examples : 67.7 eps, Loss: 5.169, Avg loss: 5.175, Best loss: 5.169\n",
      "    [batch 1918]: seen 191800 examples : 67.7 eps, Loss: 5.177, Avg loss: 5.175, Best loss: 5.169\n",
      "    [batch 1925]: seen 192500 examples : 67.7 eps, Loss: 5.172, Avg loss: 5.173, Best loss: 5.169\n",
      "    [batch 1932]: seen 193200 examples : 67.7 eps, Loss: 5.141, Avg loss: 5.174, Best loss: 5.169\n",
      "    [batch 1939]: seen 193900 examples : 67.7 eps, Loss: 5.099, Avg loss: 5.171, Best loss: 5.169\n",
      "    [batch 1946]: seen 194600 examples : 67.7 eps, Loss: 5.279, Avg loss: 5.174, Best loss: 5.169\n",
      "    [batch 1953]: seen 195300 examples : 67.7 eps, Loss: 5.130, Avg loss: 5.172, Best loss: 5.169\n",
      "    [batch 1960]: seen 196000 examples : 67.7 eps, Loss: 5.133, Avg loss: 5.172, Best loss: 5.169\n",
      "    [batch 1967]: seen 196700 examples : 67.7 eps, Loss: 5.204, Avg loss: 5.173, Best loss: 5.169\n",
      "    [batch 1974]: seen 197400 examples : 67.7 eps, Loss: 5.171, Avg loss: 5.175, Best loss: 5.169\n",
      "    [batch 1981]: seen 198100 examples : 67.7 eps, Loss: 5.233, Avg loss: 5.174, Best loss: 5.169\n",
      "    [batch 1988]: seen 198800 examples : 67.7 eps, Loss: 5.167, Avg loss: 5.175, Best loss: 5.169\n",
      "    [batch 1995]: seen 199500 examples : 67.7 eps, Loss: 5.212, Avg loss: 5.176, Best loss: 5.169\n",
      "    [batch 2002]: seen 200200 examples : 67.7 eps, Loss: 5.318, Avg loss: 5.177, Best loss: 5.169\n",
      "    [batch 2009]: seen 200900 examples : 67.7 eps, Loss: 5.113, Avg loss: 5.174, Best loss: 5.169\n",
      "    [batch 2016]: seen 201600 examples : 67.7 eps, Loss: 5.152, Avg loss: 5.172, Best loss: 5.169\n",
      "    [batch 2023]: seen 202300 examples : 67.7 eps, Loss: 5.115, Avg loss: 5.172, Best loss: 5.169\n",
      "    [batch 2030]: seen 203000 examples : 67.7 eps, Loss: 5.097, Avg loss: 5.169, Best loss: 5.169\n",
      "    [batch 2037]: seen 203700 examples : 67.7 eps, Loss: 5.182, Avg loss: 5.168, Best loss: 5.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2044]: seen 204400 examples : 67.7 eps, Loss: 5.140, Avg loss: 5.167, Best loss: 5.167\n",
      "    [batch 2051]: seen 205100 examples : 67.7 eps, Loss: 5.175, Avg loss: 5.170, Best loss: 5.167\n",
      "    [batch 2058]: seen 205800 examples : 67.7 eps, Loss: 5.167, Avg loss: 5.170, Best loss: 5.167\n",
      "    [batch 2065]: seen 206500 examples : 67.7 eps, Loss: 5.183, Avg loss: 5.169, Best loss: 5.167\n",
      "    [batch 2072]: seen 207200 examples : 67.7 eps, Loss: 5.128, Avg loss: 5.171, Best loss: 5.167\n",
      "    [batch 2079]: seen 207900 examples : 67.7 eps, Loss: 5.172, Avg loss: 5.171, Best loss: 5.167\n",
      "    [batch 2086]: seen 208600 examples : 67.7 eps, Loss: 5.151, Avg loss: 5.168, Best loss: 5.167\n",
      "    [batch 2093]: seen 209300 examples : 67.7 eps, Loss: 5.172, Avg loss: 5.168, Best loss: 5.167\n",
      "    [batch 2100]: seen 210000 examples : 67.7 eps, Loss: 5.069, Avg loss: 5.167, Best loss: 5.167\n",
      "    [batch 2107]: seen 210700 examples : 67.7 eps, Loss: 5.147, Avg loss: 5.170, Best loss: 5.167\n",
      "    [batch 2114]: seen 211400 examples : 67.7 eps, Loss: 5.224, Avg loss: 5.170, Best loss: 5.167\n",
      "    [batch 2121]: seen 212100 examples : 67.7 eps, Loss: 5.055, Avg loss: 5.166, Best loss: 5.166\n",
      "    [batch 2128]: seen 212800 examples : 67.7 eps, Loss: 5.182, Avg loss: 5.167, Best loss: 5.166\n",
      "    [batch 2135]: seen 213500 examples : 67.7 eps, Loss: 5.094, Avg loss: 5.165, Best loss: 5.165\n",
      "    [batch 2142]: seen 214200 examples : 67.7 eps, Loss: 5.166, Avg loss: 5.167, Best loss: 5.165\n",
      "    [batch 2149]: seen 214900 examples : 67.7 eps, Loss: 5.157, Avg loss: 5.169, Best loss: 5.165\n",
      "    [batch 2156]: seen 215600 examples : 67.7 eps, Loss: 5.264, Avg loss: 5.169, Best loss: 5.165\n",
      "    [batch 2163]: seen 216300 examples : 67.7 eps, Loss: 5.160, Avg loss: 5.167, Best loss: 5.165\n",
      "    [batch 2170]: seen 217000 examples : 67.7 eps, Loss: 5.109, Avg loss: 5.163, Best loss: 5.163\n",
      "    [batch 2177]: seen 217700 examples : 67.7 eps, Loss: 5.049, Avg loss: 5.162, Best loss: 5.162\n",
      "    [batch 2184]: seen 218400 examples : 67.7 eps, Loss: 5.235, Avg loss: 5.164, Best loss: 5.162\n",
      "    [batch 2191]: seen 219100 examples : 67.7 eps, Loss: 5.212, Avg loss: 5.164, Best loss: 5.162\n",
      "    [batch 2198]: seen 219800 examples : 67.7 eps, Loss: 5.217, Avg loss: 5.164, Best loss: 5.162\n",
      "    [batch 2205]: seen 220500 examples : 67.6 eps, Loss: 5.145, Avg loss: 5.162, Best loss: 5.162\n",
      "    [batch 2212]: seen 221200 examples : 67.6 eps, Loss: 5.238, Avg loss: 5.161, Best loss: 5.160\n",
      "    [batch 2219]: seen 221900 examples : 67.6 eps, Loss: 5.204, Avg loss: 5.163, Best loss: 5.160\n",
      "    [batch 2226]: seen 222600 examples : 67.6 eps, Loss: 5.145, Avg loss: 5.164, Best loss: 5.160\n",
      "    [batch 2233]: seen 223300 examples : 67.6 eps, Loss: 5.220, Avg loss: 5.164, Best loss: 5.160\n",
      "    [batch 2240]: seen 224000 examples : 67.6 eps, Loss: 5.159, Avg loss: 5.165, Best loss: 5.160\n",
      "    [batch 2247]: seen 224700 examples : 67.6 eps, Loss: 5.210, Avg loss: 5.166, Best loss: 5.160\n",
      "    [batch 2254]: seen 225400 examples : 67.6 eps, Loss: 5.152, Avg loss: 5.164, Best loss: 5.160\n",
      "    [batch 2261]: seen 226100 examples : 67.6 eps, Loss: 5.202, Avg loss: 5.163, Best loss: 5.160\n",
      "    [batch 2268]: seen 226800 examples : 67.6 eps, Loss: 5.263, Avg loss: 5.163, Best loss: 5.160\n",
      "    [batch 2275]: seen 227500 examples : 67.6 eps, Loss: 5.182, Avg loss: 5.164, Best loss: 5.160\n",
      "    [batch 2282]: seen 228200 examples : 67.6 eps, Loss: 5.193, Avg loss: 5.167, Best loss: 5.160\n",
      "    [batch 2289]: seen 228900 examples : 67.6 eps, Loss: 5.177, Avg loss: 5.168, Best loss: 5.160\n",
      "    [batch 2296]: seen 229600 examples : 67.6 eps, Loss: 5.203, Avg loss: 5.169, Best loss: 5.160\n",
      "    [batch 2303]: seen 230300 examples : 67.6 eps, Loss: 5.183, Avg loss: 5.168, Best loss: 5.160\n",
      "    [batch 2310]: seen 231000 examples : 67.6 eps, Loss: 5.089, Avg loss: 5.167, Best loss: 5.160\n",
      "    [batch 2317]: seen 231700 examples : 67.6 eps, Loss: 5.287, Avg loss: 5.166, Best loss: 5.160\n",
      "    [batch 2324]: seen 232400 examples : 67.6 eps, Loss: 5.106, Avg loss: 5.164, Best loss: 5.160\n",
      "    [batch 2331]: seen 233100 examples : 67.6 eps, Loss: 5.168, Avg loss: 5.165, Best loss: 5.160\n",
      "    [batch 2338]: seen 233800 examples : 67.6 eps, Loss: 5.084, Avg loss: 5.161, Best loss: 5.160\n",
      "    [batch 2345]: seen 234500 examples : 67.6 eps, Loss: 5.237, Avg loss: 5.158, Best loss: 5.157\n",
      "    [batch 2352]: seen 235200 examples : 67.6 eps, Loss: 5.157, Avg loss: 5.156, Best loss: 5.156\n",
      "    [batch 2359]: seen 235900 examples : 67.6 eps, Loss: 5.124, Avg loss: 5.158, Best loss: 5.156\n",
      "    [batch 2366]: seen 236600 examples : 67.6 eps, Loss: 5.156, Avg loss: 5.155, Best loss: 5.155\n",
      "    [batch 2373]: seen 237300 examples : 67.6 eps, Loss: 5.223, Avg loss: 5.156, Best loss: 5.154\n",
      "    [batch 2380]: seen 238000 examples : 67.6 eps, Loss: 5.262, Avg loss: 5.157, Best loss: 5.154\n",
      "    [batch 2387]: seen 238700 examples : 67.6 eps, Loss: 5.132, Avg loss: 5.156, Best loss: 5.154\n",
      "    [batch 2394]: seen 239400 examples : 67.6 eps, Loss: 5.161, Avg loss: 5.157, Best loss: 5.154\n",
      "    [batch 2401]: seen 240100 examples : 67.6 eps, Loss: 5.154, Avg loss: 5.157, Best loss: 5.154\n",
      "    [batch 2408]: seen 240800 examples : 67.6 eps, Loss: 5.088, Avg loss: 5.155, Best loss: 5.154\n",
      "    [batch 2415]: seen 241500 examples : 67.6 eps, Loss: 5.121, Avg loss: 5.153, Best loss: 5.153\n",
      "    [batch 2422]: seen 242200 examples : 67.6 eps, Loss: 5.061, Avg loss: 5.153, Best loss: 5.153\n",
      "    [batch 2429]: seen 242900 examples : 67.6 eps, Loss: 5.145, Avg loss: 5.153, Best loss: 5.153\n",
      "    [batch 2436]: seen 243600 examples : 67.6 eps, Loss: 5.053, Avg loss: 5.153, Best loss: 5.153\n",
      "    [batch 2443]: seen 244300 examples : 67.6 eps, Loss: 5.092, Avg loss: 5.153, Best loss: 5.152\n",
      "    [batch 2450]: seen 245000 examples : 67.6 eps, Loss: 5.175, Avg loss: 5.153, Best loss: 5.152\n",
      "    [batch 2457]: seen 245700 examples : 67.6 eps, Loss: 5.044, Avg loss: 5.151, Best loss: 5.151\n",
      "    [batch 2464]: seen 246400 examples : 67.6 eps, Loss: 5.218, Avg loss: 5.155, Best loss: 5.151\n",
      "    [batch 2471]: seen 247100 examples : 67.6 eps, Loss: 5.097, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2478]: seen 247800 examples : 67.6 eps, Loss: 5.232, Avg loss: 5.155, Best loss: 5.151\n",
      "    [batch 2485]: seen 248500 examples : 67.6 eps, Loss: 5.126, Avg loss: 5.151, Best loss: 5.151\n",
      "    [batch 2492]: seen 249200 examples : 67.6 eps, Loss: 5.177, Avg loss: 5.154, Best loss: 5.151\n",
      "    [batch 2499]: seen 249900 examples : 67.6 eps, Loss: 5.006, Avg loss: 5.154, Best loss: 5.151\n",
      "    [batch 2506]: seen 250600 examples : 67.6 eps, Loss: 5.150, Avg loss: 5.154, Best loss: 5.151\n",
      "    [batch 2513]: seen 251300 examples : 67.6 eps, Loss: 5.138, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2520]: seen 252000 examples : 67.6 eps, Loss: 5.249, Avg loss: 5.152, Best loss: 5.151\n",
      "    [batch 2527]: seen 252700 examples : 67.6 eps, Loss: 5.170, Avg loss: 5.152, Best loss: 5.151\n",
      "    [batch 2534]: seen 253400 examples : 67.6 eps, Loss: 5.225, Avg loss: 5.152, Best loss: 5.151\n",
      "    [batch 2541]: seen 254100 examples : 67.6 eps, Loss: 5.193, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2548]: seen 254800 examples : 67.6 eps, Loss: 5.230, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2555]: seen 255500 examples : 67.6 eps, Loss: 5.114, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2562]: seen 256200 examples : 67.6 eps, Loss: 5.177, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2569]: seen 256900 examples : 67.6 eps, Loss: 5.205, Avg loss: 5.154, Best loss: 5.151\n",
      "    [batch 2576]: seen 257600 examples : 67.6 eps, Loss: 5.149, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2583]: seen 258300 examples : 67.6 eps, Loss: 5.076, Avg loss: 5.155, Best loss: 5.151\n",
      "    [batch 2590]: seen 259000 examples : 67.6 eps, Loss: 5.194, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2597]: seen 259700 examples : 67.6 eps, Loss: 5.101, Avg loss: 5.151, Best loss: 5.151\n",
      "    [batch 2604]: seen 260400 examples : 67.6 eps, Loss: 5.262, Avg loss: 5.153, Best loss: 5.151\n",
      "    [batch 2611]: seen 261100 examples : 67.6 eps, Loss: 5.038, Avg loss: 5.151, Best loss: 5.151\n",
      "    [batch 2618]: seen 261800 examples : 67.6 eps, Loss: 5.153, Avg loss: 5.149, Best loss: 5.149\n",
      "    [batch 2625]: seen 262500 examples : 67.6 eps, Loss: 5.245, Avg loss: 5.150, Best loss: 5.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2632]: seen 263200 examples : 67.6 eps, Loss: 5.232, Avg loss: 5.150, Best loss: 5.148\n",
      "    [batch 2639]: seen 263900 examples : 67.6 eps, Loss: 5.127, Avg loss: 5.149, Best loss: 5.147\n",
      "    [batch 2646]: seen 264600 examples : 67.6 eps, Loss: 5.121, Avg loss: 5.149, Best loss: 5.147\n",
      "    [batch 2653]: seen 265300 examples : 67.6 eps, Loss: 5.102, Avg loss: 5.149, Best loss: 5.147\n",
      "    [batch 2660]: seen 266000 examples : 67.6 eps, Loss: 5.115, Avg loss: 5.148, Best loss: 5.147\n",
      "    [batch 2667]: seen 266700 examples : 67.6 eps, Loss: 5.178, Avg loss: 5.148, Best loss: 5.147\n",
      "    [batch 2674]: seen 267400 examples : 67.6 eps, Loss: 5.179, Avg loss: 5.149, Best loss: 5.147\n",
      "    [batch 2681]: seen 268100 examples : 67.6 eps, Loss: 5.191, Avg loss: 5.153, Best loss: 5.147\n",
      "    [batch 2688]: seen 268800 examples : 67.6 eps, Loss: 5.120, Avg loss: 5.153, Best loss: 5.147\n",
      "    [batch 2695]: seen 269500 examples : 67.6 eps, Loss: 5.107, Avg loss: 5.154, Best loss: 5.147\n",
      "    [batch 2702]: seen 270200 examples : 67.6 eps, Loss: 5.241, Avg loss: 5.153, Best loss: 5.147\n",
      "    [batch 2709]: seen 270900 examples : 67.6 eps, Loss: 5.089, Avg loss: 5.153, Best loss: 5.147\n",
      "    [batch 2716]: seen 271600 examples : 67.6 eps, Loss: 5.156, Avg loss: 5.154, Best loss: 5.147\n",
      "    [batch 2723]: seen 272300 examples : 67.6 eps, Loss: 5.132, Avg loss: 5.152, Best loss: 5.147\n",
      "    [batch 2730]: seen 273000 examples : 67.6 eps, Loss: 5.057, Avg loss: 5.150, Best loss: 5.147\n",
      "    [batch 2737]: seen 273700 examples : 67.6 eps, Loss: 5.231, Avg loss: 5.149, Best loss: 5.147\n",
      "    [batch 2744]: seen 274400 examples : 67.6 eps, Loss: 5.140, Avg loss: 5.152, Best loss: 5.147\n",
      "    [batch 2751]: seen 275100 examples : 67.6 eps, Loss: 5.094, Avg loss: 5.151, Best loss: 5.147\n",
      "    [batch 2758]: seen 275800 examples : 67.6 eps, Loss: 5.068, Avg loss: 5.150, Best loss: 5.147\n",
      "    [batch 2765]: seen 276500 examples : 67.6 eps, Loss: 5.273, Avg loss: 5.151, Best loss: 5.147\n",
      "    [batch 2772]: seen 277200 examples : 67.6 eps, Loss: 5.102, Avg loss: 5.149, Best loss: 5.147\n",
      "    [batch 2779]: seen 277900 examples : 67.6 eps, Loss: 5.120, Avg loss: 5.148, Best loss: 5.147\n",
      "    [batch 2786]: seen 278600 examples : 67.6 eps, Loss: 5.183, Avg loss: 5.147, Best loss: 5.147\n",
      "    [batch 2793]: seen 279300 examples : 67.6 eps, Loss: 5.085, Avg loss: 5.150, Best loss: 5.147\n",
      "    [batch 2800]: seen 280000 examples : 67.6 eps, Loss: 5.141, Avg loss: 5.148, Best loss: 5.147\n",
      "    [batch 2807]: seen 280700 examples : 67.6 eps, Loss: 5.223, Avg loss: 5.150, Best loss: 5.147\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:16\n",
      "[EPOCH 12] Complete. Avg Loss: 5.149847961659304; Best Loss: 5.146804621010533\n",
      "[EPOCH 13] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.3 eps, Loss: 5.168, Avg loss: 5.150, Best loss: 5.147\n",
      "    [batch 16]: seen 1600 examples : 78.1 eps, Loss: 5.201, Avg loss: 5.148, Best loss: 5.147\n",
      "    [batch 23]: seen 2300 examples : 75.0 eps, Loss: 5.128, Avg loss: 5.146, Best loss: 5.146\n",
      "    [batch 30]: seen 3000 examples : 73.4 eps, Loss: 5.207, Avg loss: 5.144, Best loss: 5.144\n",
      "    [batch 37]: seen 3700 examples : 72.5 eps, Loss: 5.170, Avg loss: 5.143, Best loss: 5.143\n",
      "    [batch 44]: seen 4400 examples : 71.9 eps, Loss: 5.163, Avg loss: 5.143, Best loss: 5.142\n",
      "    [batch 51]: seen 5100 examples : 71.4 eps, Loss: 5.140, Avg loss: 5.145, Best loss: 5.142\n",
      "    [batch 58]: seen 5800 examples : 71.1 eps, Loss: 5.035, Avg loss: 5.145, Best loss: 5.142\n",
      "    [batch 65]: seen 6500 examples : 70.8 eps, Loss: 5.140, Avg loss: 5.145, Best loss: 5.142\n",
      "    [batch 72]: seen 7200 examples : 70.6 eps, Loss: 5.206, Avg loss: 5.142, Best loss: 5.141\n",
      "    [batch 79]: seen 7900 examples : 70.4 eps, Loss: 5.096, Avg loss: 5.143, Best loss: 5.141\n",
      "    [batch 86]: seen 8600 examples : 70.3 eps, Loss: 5.152, Avg loss: 5.141, Best loss: 5.141\n",
      "    [batch 93]: seen 9300 examples : 69.9 eps, Loss: 5.123, Avg loss: 5.137, Best loss: 5.137\n",
      "    [batch 100]: seen 10000 examples : 69.8 eps, Loss: 5.080, Avg loss: 5.139, Best loss: 5.137\n",
      "    [batch 107]: seen 10700 examples : 69.7 eps, Loss: 5.155, Avg loss: 5.141, Best loss: 5.137\n",
      "    [batch 114]: seen 11400 examples : 69.6 eps, Loss: 5.074, Avg loss: 5.139, Best loss: 5.137\n",
      "    [batch 121]: seen 12100 examples : 69.5 eps, Loss: 5.148, Avg loss: 5.140, Best loss: 5.137\n",
      "    [batch 128]: seen 12800 examples : 69.5 eps, Loss: 5.102, Avg loss: 5.136, Best loss: 5.136\n",
      "    [batch 135]: seen 13500 examples : 69.4 eps, Loss: 5.132, Avg loss: 5.138, Best loss: 5.135\n",
      "    [batch 142]: seen 14200 examples : 69.3 eps, Loss: 4.954, Avg loss: 5.137, Best loss: 5.135\n",
      "    [batch 149]: seen 14900 examples : 69.2 eps, Loss: 5.112, Avg loss: 5.138, Best loss: 5.135\n",
      "    [batch 156]: seen 15600 examples : 69.2 eps, Loss: 5.116, Avg loss: 5.136, Best loss: 5.135\n",
      "    [batch 163]: seen 16300 examples : 69.1 eps, Loss: 5.135, Avg loss: 5.137, Best loss: 5.135\n",
      "    [batch 170]: seen 17000 examples : 69.0 eps, Loss: 5.269, Avg loss: 5.138, Best loss: 5.135\n",
      "    [batch 177]: seen 17700 examples : 69.0 eps, Loss: 5.167, Avg loss: 5.140, Best loss: 5.135\n",
      "    [batch 184]: seen 18400 examples : 68.9 eps, Loss: 5.052, Avg loss: 5.138, Best loss: 5.135\n",
      "    [batch 191]: seen 19100 examples : 68.9 eps, Loss: 5.182, Avg loss: 5.134, Best loss: 5.134\n",
      "    [batch 198]: seen 19800 examples : 68.8 eps, Loss: 5.048, Avg loss: 5.131, Best loss: 5.131\n",
      "    [batch 205]: seen 20500 examples : 68.8 eps, Loss: 5.219, Avg loss: 5.131, Best loss: 5.129\n",
      "    [batch 212]: seen 21200 examples : 68.7 eps, Loss: 5.164, Avg loss: 5.129, Best loss: 5.129\n",
      "    [batch 219]: seen 21900 examples : 68.6 eps, Loss: 5.155, Avg loss: 5.128, Best loss: 5.127\n",
      "    [batch 226]: seen 22600 examples : 68.5 eps, Loss: 5.157, Avg loss: 5.128, Best loss: 5.127\n",
      "    [batch 233]: seen 23300 examples : 68.5 eps, Loss: 5.013, Avg loss: 5.130, Best loss: 5.127\n",
      "    [batch 240]: seen 24000 examples : 68.5 eps, Loss: 5.169, Avg loss: 5.130, Best loss: 5.127\n",
      "    [batch 247]: seen 24700 examples : 68.5 eps, Loss: 5.253, Avg loss: 5.133, Best loss: 5.127\n",
      "    [batch 254]: seen 25400 examples : 68.4 eps, Loss: 5.222, Avg loss: 5.133, Best loss: 5.127\n",
      "    [batch 261]: seen 26100 examples : 68.4 eps, Loss: 5.148, Avg loss: 5.135, Best loss: 5.127\n",
      "    [batch 268]: seen 26800 examples : 68.4 eps, Loss: 5.265, Avg loss: 5.137, Best loss: 5.127\n",
      "    [batch 275]: seen 27500 examples : 68.4 eps, Loss: 5.117, Avg loss: 5.136, Best loss: 5.127\n",
      "    [batch 282]: seen 28200 examples : 68.4 eps, Loss: 5.092, Avg loss: 5.135, Best loss: 5.127\n",
      "    [batch 289]: seen 28900 examples : 68.4 eps, Loss: 5.257, Avg loss: 5.137, Best loss: 5.127\n",
      "    [batch 296]: seen 29600 examples : 68.3 eps, Loss: 5.046, Avg loss: 5.138, Best loss: 5.127\n",
      "    [batch 303]: seen 30300 examples : 68.3 eps, Loss: 5.175, Avg loss: 5.139, Best loss: 5.127\n",
      "    [batch 310]: seen 31000 examples : 68.3 eps, Loss: 5.169, Avg loss: 5.138, Best loss: 5.127\n",
      "    [batch 317]: seen 31700 examples : 68.3 eps, Loss: 5.170, Avg loss: 5.138, Best loss: 5.127\n",
      "    [batch 324]: seen 32400 examples : 68.3 eps, Loss: 5.086, Avg loss: 5.136, Best loss: 5.127\n",
      "    [batch 331]: seen 33100 examples : 68.3 eps, Loss: 5.124, Avg loss: 5.136, Best loss: 5.127\n",
      "    [batch 338]: seen 33800 examples : 68.3 eps, Loss: 5.088, Avg loss: 5.133, Best loss: 5.127\n",
      "    [batch 345]: seen 34500 examples : 68.3 eps, Loss: 5.082, Avg loss: 5.133, Best loss: 5.127\n",
      "    [batch 352]: seen 35200 examples : 68.2 eps, Loss: 5.182, Avg loss: 5.133, Best loss: 5.127\n",
      "    [batch 359]: seen 35900 examples : 68.2 eps, Loss: 5.097, Avg loss: 5.130, Best loss: 5.127\n",
      "    [batch 366]: seen 36600 examples : 68.2 eps, Loss: 5.144, Avg loss: 5.130, Best loss: 5.127\n",
      "    [batch 373]: seen 37300 examples : 68.2 eps, Loss: 5.185, Avg loss: 5.131, Best loss: 5.127\n",
      "    [batch 380]: seen 38000 examples : 68.2 eps, Loss: 5.164, Avg loss: 5.132, Best loss: 5.127\n",
      "    [batch 387]: seen 38700 examples : 68.2 eps, Loss: 5.259, Avg loss: 5.130, Best loss: 5.127\n",
      "    [batch 394]: seen 39400 examples : 68.2 eps, Loss: 5.098, Avg loss: 5.129, Best loss: 5.127\n",
      "    [batch 401]: seen 40100 examples : 68.2 eps, Loss: 5.156, Avg loss: 5.130, Best loss: 5.127\n",
      "    [batch 408]: seen 40800 examples : 68.2 eps, Loss: 5.079, Avg loss: 5.128, Best loss: 5.127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 415]: seen 41500 examples : 68.1 eps, Loss: 5.192, Avg loss: 5.127, Best loss: 5.126\n",
      "    [batch 422]: seen 42200 examples : 68.1 eps, Loss: 5.057, Avg loss: 5.127, Best loss: 5.126\n",
      "    [batch 429]: seen 42900 examples : 68.1 eps, Loss: 5.082, Avg loss: 5.127, Best loss: 5.126\n",
      "    [batch 436]: seen 43600 examples : 68.1 eps, Loss: 5.225, Avg loss: 5.127, Best loss: 5.126\n",
      "    [batch 443]: seen 44300 examples : 68.1 eps, Loss: 5.130, Avg loss: 5.126, Best loss: 5.126\n",
      "    [batch 450]: seen 45000 examples : 68.1 eps, Loss: 5.173, Avg loss: 5.128, Best loss: 5.126\n",
      "    [batch 457]: seen 45700 examples : 68.1 eps, Loss: 5.165, Avg loss: 5.126, Best loss: 5.125\n",
      "    [batch 464]: seen 46400 examples : 68.1 eps, Loss: 5.050, Avg loss: 5.124, Best loss: 5.124\n",
      "    [batch 471]: seen 47100 examples : 68.0 eps, Loss: 5.196, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 478]: seen 47800 examples : 68.0 eps, Loss: 5.127, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 485]: seen 48500 examples : 68.0 eps, Loss: 5.229, Avg loss: 5.132, Best loss: 5.124\n",
      "    [batch 492]: seen 49200 examples : 68.0 eps, Loss: 5.124, Avg loss: 5.132, Best loss: 5.124\n",
      "    [batch 499]: seen 49900 examples : 68.0 eps, Loss: 5.200, Avg loss: 5.130, Best loss: 5.124\n",
      "    [batch 506]: seen 50600 examples : 68.0 eps, Loss: 5.120, Avg loss: 5.130, Best loss: 5.124\n",
      "    [batch 513]: seen 51300 examples : 68.0 eps, Loss: 5.083, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 520]: seen 52000 examples : 68.0 eps, Loss: 5.213, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 527]: seen 52700 examples : 68.0 eps, Loss: 5.180, Avg loss: 5.126, Best loss: 5.124\n",
      "    [batch 534]: seen 53400 examples : 67.9 eps, Loss: 5.051, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 541]: seen 54100 examples : 68.0 eps, Loss: 5.089, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 548]: seen 54800 examples : 68.0 eps, Loss: 5.086, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 555]: seen 55500 examples : 67.9 eps, Loss: 5.103, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 562]: seen 56200 examples : 67.9 eps, Loss: 5.132, Avg loss: 5.129, Best loss: 5.124\n",
      "    [batch 569]: seen 56900 examples : 67.9 eps, Loss: 5.087, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 576]: seen 57600 examples : 67.9 eps, Loss: 5.078, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 583]: seen 58300 examples : 67.9 eps, Loss: 5.242, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 590]: seen 59000 examples : 67.9 eps, Loss: 5.187, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 597]: seen 59700 examples : 67.9 eps, Loss: 5.108, Avg loss: 5.126, Best loss: 5.124\n",
      "    [batch 604]: seen 60400 examples : 67.9 eps, Loss: 5.120, Avg loss: 5.125, Best loss: 5.124\n",
      "    [batch 611]: seen 61100 examples : 67.9 eps, Loss: 5.122, Avg loss: 5.125, Best loss: 5.124\n",
      "    [batch 618]: seen 61800 examples : 67.9 eps, Loss: 5.113, Avg loss: 5.125, Best loss: 5.124\n",
      "    [batch 625]: seen 62500 examples : 67.9 eps, Loss: 5.204, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 632]: seen 63200 examples : 67.9 eps, Loss: 5.077, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 639]: seen 63900 examples : 67.9 eps, Loss: 5.122, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 646]: seen 64600 examples : 67.9 eps, Loss: 5.176, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 653]: seen 65300 examples : 67.9 eps, Loss: 5.110, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 660]: seen 66000 examples : 67.9 eps, Loss: 5.097, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 667]: seen 66700 examples : 67.9 eps, Loss: 5.121, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 674]: seen 67400 examples : 67.9 eps, Loss: 5.132, Avg loss: 5.129, Best loss: 5.124\n",
      "    [batch 681]: seen 68100 examples : 67.9 eps, Loss: 5.137, Avg loss: 5.130, Best loss: 5.124\n",
      "    [batch 688]: seen 68800 examples : 67.9 eps, Loss: 5.187, Avg loss: 5.130, Best loss: 5.124\n",
      "    [batch 695]: seen 69500 examples : 67.9 eps, Loss: 5.111, Avg loss: 5.126, Best loss: 5.124\n",
      "    [batch 702]: seen 70200 examples : 67.9 eps, Loss: 5.094, Avg loss: 5.126, Best loss: 5.124\n",
      "    [batch 709]: seen 70900 examples : 67.9 eps, Loss: 5.213, Avg loss: 5.129, Best loss: 5.124\n",
      "    [batch 716]: seen 71600 examples : 67.9 eps, Loss: 5.106, Avg loss: 5.128, Best loss: 5.124\n",
      "    [batch 723]: seen 72300 examples : 67.9 eps, Loss: 5.109, Avg loss: 5.126, Best loss: 5.124\n",
      "    [batch 730]: seen 73000 examples : 67.9 eps, Loss: 5.206, Avg loss: 5.126, Best loss: 5.124\n",
      "    [batch 737]: seen 73700 examples : 67.9 eps, Loss: 5.131, Avg loss: 5.127, Best loss: 5.124\n",
      "    [batch 744]: seen 74400 examples : 67.9 eps, Loss: 5.161, Avg loss: 5.124, Best loss: 5.123\n",
      "    [batch 751]: seen 75100 examples : 67.9 eps, Loss: 5.120, Avg loss: 5.127, Best loss: 5.123\n",
      "    [batch 758]: seen 75800 examples : 67.9 eps, Loss: 5.175, Avg loss: 5.126, Best loss: 5.123\n",
      "    [batch 765]: seen 76500 examples : 67.9 eps, Loss: 5.221, Avg loss: 5.127, Best loss: 5.123\n",
      "    [batch 772]: seen 77200 examples : 67.9 eps, Loss: 5.053, Avg loss: 5.124, Best loss: 5.123\n",
      "    [batch 779]: seen 77900 examples : 67.9 eps, Loss: 5.116, Avg loss: 5.122, Best loss: 5.122\n",
      "    [batch 786]: seen 78600 examples : 67.9 eps, Loss: 5.156, Avg loss: 5.122, Best loss: 5.120\n",
      "    [batch 793]: seen 79300 examples : 67.9 eps, Loss: 5.013, Avg loss: 5.121, Best loss: 5.120\n",
      "    [batch 800]: seen 80000 examples : 67.9 eps, Loss: 5.144, Avg loss: 5.123, Best loss: 5.120\n",
      "    [batch 807]: seen 80700 examples : 67.9 eps, Loss: 5.163, Avg loss: 5.124, Best loss: 5.120\n",
      "    [batch 814]: seen 81400 examples : 67.9 eps, Loss: 5.136, Avg loss: 5.122, Best loss: 5.120\n",
      "    [batch 821]: seen 82100 examples : 67.9 eps, Loss: 5.156, Avg loss: 5.121, Best loss: 5.120\n",
      "    [batch 828]: seen 82800 examples : 67.9 eps, Loss: 5.221, Avg loss: 5.124, Best loss: 5.120\n",
      "    [batch 835]: seen 83500 examples : 67.9 eps, Loss: 5.169, Avg loss: 5.125, Best loss: 5.120\n",
      "    [batch 842]: seen 84200 examples : 67.9 eps, Loss: 5.111, Avg loss: 5.125, Best loss: 5.120\n",
      "    [batch 849]: seen 84900 examples : 67.9 eps, Loss: 5.095, Avg loss: 5.124, Best loss: 5.120\n",
      "    [batch 856]: seen 85600 examples : 67.9 eps, Loss: 5.124, Avg loss: 5.121, Best loss: 5.120\n",
      "    [batch 863]: seen 86300 examples : 67.9 eps, Loss: 5.183, Avg loss: 5.124, Best loss: 5.120\n",
      "    [batch 870]: seen 87000 examples : 67.8 eps, Loss: 5.008, Avg loss: 5.126, Best loss: 5.120\n",
      "    [batch 877]: seen 87700 examples : 67.9 eps, Loss: 5.068, Avg loss: 5.123, Best loss: 5.120\n",
      "    [batch 884]: seen 88400 examples : 67.9 eps, Loss: 5.091, Avg loss: 5.120, Best loss: 5.120\n",
      "    [batch 891]: seen 89100 examples : 67.9 eps, Loss: 5.165, Avg loss: 5.119, Best loss: 5.118\n",
      "    [batch 898]: seen 89800 examples : 67.9 eps, Loss: 5.076, Avg loss: 5.118, Best loss: 5.117\n",
      "    [batch 902]: seen 90200 examples : 67.6 eps, Loss: 5.166, Avg loss: 5.117, Best loss: 5.116\n",
      "    [batch 909]: seen 90900 examples : 67.6 eps, Loss: 4.970, Avg loss: 5.116, Best loss: 5.116\n",
      "    [batch 916]: seen 91600 examples : 67.6 eps, Loss: 5.086, Avg loss: 5.117, Best loss: 5.116\n",
      "    [batch 923]: seen 92300 examples : 67.6 eps, Loss: 5.125, Avg loss: 5.118, Best loss: 5.116\n",
      "    [batch 927]: seen 92700 examples : 67.4 eps, Loss: 5.231, Avg loss: 5.118, Best loss: 5.116\n",
      "    [batch 934]: seen 93400 examples : 67.4 eps, Loss: 5.188, Avg loss: 5.120, Best loss: 5.116\n",
      "    [batch 941]: seen 94100 examples : 67.5 eps, Loss: 5.097, Avg loss: 5.121, Best loss: 5.116\n",
      "    [batch 948]: seen 94800 examples : 67.5 eps, Loss: 5.169, Avg loss: 5.121, Best loss: 5.116\n",
      "    [batch 952]: seen 95200 examples : 67.3 eps, Loss: 5.166, Avg loss: 5.121, Best loss: 5.116\n",
      "    [batch 959]: seen 95900 examples : 67.3 eps, Loss: 5.143, Avg loss: 5.122, Best loss: 5.116\n",
      "    [batch 966]: seen 96600 examples : 67.3 eps, Loss: 5.052, Avg loss: 5.120, Best loss: 5.116\n",
      "    [batch 973]: seen 97300 examples : 67.3 eps, Loss: 5.086, Avg loss: 5.118, Best loss: 5.116\n",
      "    [batch 977]: seen 97700 examples : 67.1 eps, Loss: 5.154, Avg loss: 5.120, Best loss: 5.116\n",
      "    [batch 984]: seen 98400 examples : 67.1 eps, Loss: 5.080, Avg loss: 5.122, Best loss: 5.116\n",
      "    [batch 991]: seen 99100 examples : 67.1 eps, Loss: 5.091, Avg loss: 5.124, Best loss: 5.116\n",
      "    [batch 998]: seen 99800 examples : 67.1 eps, Loss: 5.048, Avg loss: 5.121, Best loss: 5.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1002]: seen 100200 examples : 66.9 eps, Loss: 5.159, Avg loss: 5.121, Best loss: 5.116\n",
      "    [batch 1009]: seen 100900 examples : 67.0 eps, Loss: 5.212, Avg loss: 5.123, Best loss: 5.116\n",
      "    [batch 1016]: seen 101600 examples : 67.0 eps, Loss: 5.232, Avg loss: 5.125, Best loss: 5.116\n",
      "    [batch 1023]: seen 102300 examples : 67.0 eps, Loss: 5.076, Avg loss: 5.122, Best loss: 5.116\n",
      "    [batch 1027]: seen 102700 examples : 66.8 eps, Loss: 5.124, Avg loss: 5.122, Best loss: 5.116\n",
      "    [batch 1034]: seen 103400 examples : 66.8 eps, Loss: 5.074, Avg loss: 5.122, Best loss: 5.116\n",
      "    [batch 1041]: seen 104100 examples : 66.8 eps, Loss: 5.097, Avg loss: 5.121, Best loss: 5.116\n",
      "    [batch 1048]: seen 104800 examples : 66.8 eps, Loss: 5.209, Avg loss: 5.120, Best loss: 5.116\n",
      "    [batch 1052]: seen 105200 examples : 66.7 eps, Loss: 5.124, Avg loss: 5.119, Best loss: 5.116\n",
      "    [batch 1059]: seen 105900 examples : 66.7 eps, Loss: 5.205, Avg loss: 5.120, Best loss: 5.116\n",
      "    [batch 1066]: seen 106600 examples : 66.7 eps, Loss: 5.105, Avg loss: 5.118, Best loss: 5.116\n",
      "    [batch 1073]: seen 107300 examples : 66.7 eps, Loss: 5.023, Avg loss: 5.115, Best loss: 5.115\n",
      "    [batch 1077]: seen 107700 examples : 66.5 eps, Loss: 5.134, Avg loss: 5.117, Best loss: 5.115\n",
      "    [batch 1084]: seen 108400 examples : 66.6 eps, Loss: 5.001, Avg loss: 5.118, Best loss: 5.115\n",
      "    [batch 1091]: seen 109100 examples : 66.6 eps, Loss: 5.045, Avg loss: 5.117, Best loss: 5.115\n",
      "    [batch 1098]: seen 109800 examples : 66.6 eps, Loss: 5.092, Avg loss: 5.119, Best loss: 5.115\n",
      "    [batch 1102]: seen 110200 examples : 66.4 eps, Loss: 5.079, Avg loss: 5.118, Best loss: 5.115\n",
      "    [batch 1109]: seen 110900 examples : 66.4 eps, Loss: 5.021, Avg loss: 5.116, Best loss: 5.115\n",
      "    [batch 1116]: seen 111600 examples : 66.4 eps, Loss: 5.135, Avg loss: 5.115, Best loss: 5.114\n",
      "    [batch 1123]: seen 112300 examples : 66.4 eps, Loss: 5.108, Avg loss: 5.116, Best loss: 5.114\n",
      "    [batch 1127]: seen 112700 examples : 66.3 eps, Loss: 5.065, Avg loss: 5.115, Best loss: 5.114\n",
      "    [batch 1134]: seen 113400 examples : 66.3 eps, Loss: 5.097, Avg loss: 5.115, Best loss: 5.114\n",
      "    [batch 1141]: seen 114100 examples : 66.3 eps, Loss: 5.131, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1148]: seen 114800 examples : 66.3 eps, Loss: 5.249, Avg loss: 5.119, Best loss: 5.114\n",
      "    [batch 1152]: seen 115200 examples : 66.2 eps, Loss: 5.088, Avg loss: 5.120, Best loss: 5.114\n",
      "    [batch 1159]: seen 115900 examples : 66.2 eps, Loss: 5.205, Avg loss: 5.121, Best loss: 5.114\n",
      "    [batch 1166]: seen 116600 examples : 66.2 eps, Loss: 5.079, Avg loss: 5.117, Best loss: 5.114\n",
      "    [batch 1173]: seen 117300 examples : 66.2 eps, Loss: 5.120, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1177]: seen 117700 examples : 66.1 eps, Loss: 5.122, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1184]: seen 118400 examples : 66.1 eps, Loss: 5.081, Avg loss: 5.117, Best loss: 5.114\n",
      "    [batch 1191]: seen 119100 examples : 66.1 eps, Loss: 5.209, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1198]: seen 119800 examples : 66.1 eps, Loss: 5.157, Avg loss: 5.119, Best loss: 5.114\n",
      "    [batch 1202]: seen 120200 examples : 66.0 eps, Loss: 5.101, Avg loss: 5.117, Best loss: 5.114\n",
      "    [batch 1209]: seen 120900 examples : 66.0 eps, Loss: 5.023, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1216]: seen 121600 examples : 66.0 eps, Loss: 5.159, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1223]: seen 122300 examples : 66.0 eps, Loss: 5.116, Avg loss: 5.118, Best loss: 5.114\n",
      "    [batch 1227]: seen 122700 examples : 65.9 eps, Loss: 5.137, Avg loss: 5.117, Best loss: 5.114\n",
      "    [batch 1234]: seen 123400 examples : 65.9 eps, Loss: 5.081, Avg loss: 5.114, Best loss: 5.114\n",
      "    [batch 1241]: seen 124100 examples : 65.9 eps, Loss: 5.156, Avg loss: 5.114, Best loss: 5.114\n",
      "    [batch 1248]: seen 124800 examples : 65.9 eps, Loss: 5.128, Avg loss: 5.113, Best loss: 5.113\n",
      "    [batch 1252]: seen 125200 examples : 65.8 eps, Loss: 5.063, Avg loss: 5.115, Best loss: 5.113\n",
      "    [EXCEPTION]:  Loss is not finite. ; Restoring model params\n",
      "INFO:tensorflow:Loading checkpoint /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-34908\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/W266/final_0/W266_Final/model_3/saved/train/model-34908\n",
      "    [batch 1258]: seen 125800 examples : 65.7 eps, Loss: 5.113, Avg loss: 5.117, Best loss: 5.113\n",
      "    [batch 1265]: seen 126500 examples : 65.7 eps, Loss: 5.049, Avg loss: 5.114, Best loss: 5.113\n",
      "    [batch 1272]: seen 127200 examples : 65.8 eps, Loss: 5.094, Avg loss: 5.112, Best loss: 5.112\n",
      "    [batch 1279]: seen 127900 examples : 65.8 eps, Loss: 5.035, Avg loss: 5.110, Best loss: 5.110\n",
      "    [batch 1286]: seen 128600 examples : 65.8 eps, Loss: 5.149, Avg loss: 5.112, Best loss: 5.110\n",
      "    [batch 1293]: seen 129300 examples : 65.8 eps, Loss: 5.125, Avg loss: 5.112, Best loss: 5.110\n",
      "    [batch 1300]: seen 130000 examples : 65.8 eps, Loss: 5.055, Avg loss: 5.113, Best loss: 5.110\n",
      "    [batch 1307]: seen 130700 examples : 65.8 eps, Loss: 5.067, Avg loss: 5.112, Best loss: 5.110\n",
      "    [batch 1314]: seen 131400 examples : 65.9 eps, Loss: 5.146, Avg loss: 5.111, Best loss: 5.110\n",
      "    [batch 1321]: seen 132100 examples : 65.9 eps, Loss: 5.022, Avg loss: 5.111, Best loss: 5.110\n",
      "    [batch 1328]: seen 132800 examples : 65.9 eps, Loss: 5.063, Avg loss: 5.108, Best loss: 5.108\n",
      "    [batch 1335]: seen 133500 examples : 65.9 eps, Loss: 5.148, Avg loss: 5.108, Best loss: 5.107\n",
      "    [batch 1342]: seen 134200 examples : 65.9 eps, Loss: 5.128, Avg loss: 5.110, Best loss: 5.107\n",
      "    [batch 1349]: seen 134900 examples : 65.9 eps, Loss: 5.076, Avg loss: 5.107, Best loss: 5.107\n",
      "    [batch 1356]: seen 135600 examples : 65.9 eps, Loss: 5.032, Avg loss: 5.107, Best loss: 5.106\n",
      "    [batch 1363]: seen 136300 examples : 65.9 eps, Loss: 5.185, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1370]: seen 137000 examples : 66.0 eps, Loss: 5.093, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1377]: seen 137700 examples : 66.0 eps, Loss: 5.121, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1384]: seen 138400 examples : 66.0 eps, Loss: 5.056, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1391]: seen 139100 examples : 66.0 eps, Loss: 5.178, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1398]: seen 139800 examples : 66.0 eps, Loss: 5.073, Avg loss: 5.113, Best loss: 5.106\n",
      "    [batch 1405]: seen 140500 examples : 66.0 eps, Loss: 5.150, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1412]: seen 141200 examples : 66.0 eps, Loss: 5.204, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1419]: seen 141900 examples : 66.1 eps, Loss: 5.108, Avg loss: 5.113, Best loss: 5.106\n",
      "    [batch 1426]: seen 142600 examples : 66.1 eps, Loss: 5.054, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1433]: seen 143300 examples : 66.1 eps, Loss: 5.139, Avg loss: 5.109, Best loss: 5.106\n",
      "    [batch 1440]: seen 144000 examples : 66.1 eps, Loss: 5.094, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1447]: seen 144700 examples : 66.1 eps, Loss: 5.064, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1454]: seen 145400 examples : 66.1 eps, Loss: 5.161, Avg loss: 5.115, Best loss: 5.106\n",
      "    [batch 1461]: seen 146100 examples : 66.1 eps, Loss: 5.133, Avg loss: 5.114, Best loss: 5.106\n",
      "    [batch 1468]: seen 146800 examples : 66.1 eps, Loss: 5.035, Avg loss: 5.113, Best loss: 5.106\n",
      "    [batch 1475]: seen 147500 examples : 66.1 eps, Loss: 5.054, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1482]: seen 148200 examples : 66.2 eps, Loss: 5.079, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1489]: seen 148900 examples : 66.2 eps, Loss: 4.999, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1496]: seen 149600 examples : 66.2 eps, Loss: 5.094, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1503]: seen 150300 examples : 66.2 eps, Loss: 5.067, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1510]: seen 151000 examples : 66.2 eps, Loss: 5.048, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1517]: seen 151700 examples : 66.2 eps, Loss: 5.170, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1524]: seen 152400 examples : 66.2 eps, Loss: 5.138, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1531]: seen 153100 examples : 66.2 eps, Loss: 5.067, Avg loss: 5.112, Best loss: 5.106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 1538]: seen 153800 examples : 66.2 eps, Loss: 5.054, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1545]: seen 154500 examples : 66.3 eps, Loss: 5.234, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1552]: seen 155200 examples : 66.3 eps, Loss: 5.118, Avg loss: 5.109, Best loss: 5.106\n",
      "    [batch 1559]: seen 155900 examples : 66.3 eps, Loss: 5.067, Avg loss: 5.108, Best loss: 5.106\n",
      "    [batch 1566]: seen 156600 examples : 66.3 eps, Loss: 5.112, Avg loss: 5.108, Best loss: 5.106\n",
      "    [batch 1573]: seen 157300 examples : 66.3 eps, Loss: 5.076, Avg loss: 5.108, Best loss: 5.106\n",
      "    [batch 1580]: seen 158000 examples : 66.3 eps, Loss: 5.133, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1587]: seen 158700 examples : 66.3 eps, Loss: 5.248, Avg loss: 5.113, Best loss: 5.106\n",
      "    [batch 1594]: seen 159400 examples : 66.3 eps, Loss: 5.068, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1601]: seen 160100 examples : 66.3 eps, Loss: 5.092, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1608]: seen 160800 examples : 66.3 eps, Loss: 5.033, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1615]: seen 161500 examples : 66.4 eps, Loss: 5.045, Avg loss: 5.109, Best loss: 5.106\n",
      "    [batch 1622]: seen 162200 examples : 66.4 eps, Loss: 5.151, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1629]: seen 162900 examples : 66.4 eps, Loss: 5.159, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1636]: seen 163600 examples : 66.4 eps, Loss: 5.099, Avg loss: 5.111, Best loss: 5.106\n",
      "    [batch 1643]: seen 164300 examples : 66.4 eps, Loss: 5.100, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1650]: seen 165000 examples : 66.4 eps, Loss: 5.157, Avg loss: 5.112, Best loss: 5.106\n",
      "    [batch 1657]: seen 165700 examples : 66.4 eps, Loss: 5.087, Avg loss: 5.110, Best loss: 5.106\n",
      "    [batch 1664]: seen 166400 examples : 66.4 eps, Loss: 5.118, Avg loss: 5.107, Best loss: 5.106\n",
      "    [batch 1671]: seen 167100 examples : 66.4 eps, Loss: 5.088, Avg loss: 5.108, Best loss: 5.106\n",
      "    [batch 1678]: seen 167800 examples : 66.4 eps, Loss: 5.099, Avg loss: 5.105, Best loss: 5.105\n",
      "    [batch 1685]: seen 168500 examples : 66.4 eps, Loss: 4.989, Avg loss: 5.105, Best loss: 5.105\n",
      "    [batch 1692]: seen 169200 examples : 66.4 eps, Loss: 5.104, Avg loss: 5.106, Best loss: 5.105\n",
      "    [batch 1699]: seen 169900 examples : 66.4 eps, Loss: 5.189, Avg loss: 5.106, Best loss: 5.104\n",
      "    [batch 1706]: seen 170600 examples : 66.4 eps, Loss: 5.144, Avg loss: 5.107, Best loss: 5.104\n",
      "    [batch 1713]: seen 171300 examples : 66.5 eps, Loss: 5.166, Avg loss: 5.107, Best loss: 5.104\n",
      "    [batch 1720]: seen 172000 examples : 66.5 eps, Loss: 5.098, Avg loss: 5.107, Best loss: 5.104\n",
      "    [batch 1727]: seen 172700 examples : 66.5 eps, Loss: 5.104, Avg loss: 5.106, Best loss: 5.104\n",
      "    [batch 1734]: seen 173400 examples : 66.5 eps, Loss: 5.048, Avg loss: 5.105, Best loss: 5.104\n",
      "    [batch 1741]: seen 174100 examples : 66.5 eps, Loss: 5.038, Avg loss: 5.102, Best loss: 5.102\n",
      "    [batch 1748]: seen 174800 examples : 66.5 eps, Loss: 5.156, Avg loss: 5.103, Best loss: 5.102\n",
      "    [batch 1755]: seen 175500 examples : 66.5 eps, Loss: 5.036, Avg loss: 5.103, Best loss: 5.102\n",
      "    [batch 1762]: seen 176200 examples : 66.5 eps, Loss: 5.136, Avg loss: 5.104, Best loss: 5.102\n",
      "    [batch 1769]: seen 176900 examples : 66.5 eps, Loss: 5.195, Avg loss: 5.105, Best loss: 5.102\n",
      "    [batch 1776]: seen 177600 examples : 66.5 eps, Loss: 5.125, Avg loss: 5.106, Best loss: 5.102\n",
      "    [batch 1783]: seen 178300 examples : 66.5 eps, Loss: 5.138, Avg loss: 5.105, Best loss: 5.102\n",
      "    [batch 1790]: seen 179000 examples : 66.5 eps, Loss: 5.100, Avg loss: 5.109, Best loss: 5.102\n",
      "    [batch 1797]: seen 179700 examples : 66.5 eps, Loss: 5.107, Avg loss: 5.108, Best loss: 5.102\n",
      "    [batch 1804]: seen 180400 examples : 66.5 eps, Loss: 5.184, Avg loss: 5.108, Best loss: 5.102\n",
      "    [batch 1811]: seen 181100 examples : 66.5 eps, Loss: 5.169, Avg loss: 5.108, Best loss: 5.102\n",
      "    [batch 1818]: seen 181800 examples : 66.5 eps, Loss: 5.212, Avg loss: 5.109, Best loss: 5.102\n",
      "    [batch 1825]: seen 182500 examples : 66.5 eps, Loss: 5.087, Avg loss: 5.108, Best loss: 5.102\n",
      "    [batch 1832]: seen 183200 examples : 66.5 eps, Loss: 5.148, Avg loss: 5.109, Best loss: 5.102\n",
      "    [batch 1839]: seen 183900 examples : 66.5 eps, Loss: 5.005, Avg loss: 5.106, Best loss: 5.102\n",
      "    [batch 1846]: seen 184600 examples : 66.6 eps, Loss: 5.015, Avg loss: 5.106, Best loss: 5.102\n",
      "    [batch 1853]: seen 185300 examples : 66.6 eps, Loss: 5.161, Avg loss: 5.108, Best loss: 5.102\n",
      "    [batch 1860]: seen 186000 examples : 66.6 eps, Loss: 5.142, Avg loss: 5.105, Best loss: 5.102\n",
      "    [batch 1867]: seen 186700 examples : 66.6 eps, Loss: 5.064, Avg loss: 5.105, Best loss: 5.102\n",
      "    [batch 1874]: seen 187400 examples : 66.6 eps, Loss: 5.177, Avg loss: 5.103, Best loss: 5.102\n",
      "    [batch 1881]: seen 188100 examples : 66.6 eps, Loss: 5.003, Avg loss: 5.103, Best loss: 5.102\n",
      "    [batch 1888]: seen 188800 examples : 66.6 eps, Loss: 5.099, Avg loss: 5.102, Best loss: 5.102\n",
      "    [batch 1895]: seen 189500 examples : 66.6 eps, Loss: 5.099, Avg loss: 5.103, Best loss: 5.102\n",
      "    [batch 1902]: seen 190200 examples : 66.6 eps, Loss: 5.008, Avg loss: 5.104, Best loss: 5.102\n",
      "    [batch 1909]: seen 190900 examples : 66.6 eps, Loss: 4.997, Avg loss: 5.106, Best loss: 5.102\n",
      "    [batch 1916]: seen 191600 examples : 66.6 eps, Loss: 5.081, Avg loss: 5.103, Best loss: 5.102\n",
      "    [batch 1923]: seen 192300 examples : 66.6 eps, Loss: 5.083, Avg loss: 5.099, Best loss: 5.099\n",
      "    [batch 1930]: seen 193000 examples : 66.6 eps, Loss: 5.106, Avg loss: 5.099, Best loss: 5.098\n",
      "    [batch 1937]: seen 193700 examples : 66.6 eps, Loss: 5.034, Avg loss: 5.098, Best loss: 5.098\n",
      "    [batch 1944]: seen 194400 examples : 66.6 eps, Loss: 5.179, Avg loss: 5.101, Best loss: 5.098\n",
      "    [batch 1951]: seen 195100 examples : 66.6 eps, Loss: 5.131, Avg loss: 5.099, Best loss: 5.098\n",
      "    [batch 1958]: seen 195800 examples : 66.6 eps, Loss: 5.159, Avg loss: 5.100, Best loss: 5.098\n",
      "    [batch 1965]: seen 196500 examples : 66.6 eps, Loss: 5.044, Avg loss: 5.100, Best loss: 5.098\n",
      "    [batch 1972]: seen 197200 examples : 66.6 eps, Loss: 5.110, Avg loss: 5.096, Best loss: 5.096\n",
      "    [batch 1979]: seen 197900 examples : 66.6 eps, Loss: 5.093, Avg loss: 5.097, Best loss: 5.096\n",
      "    [batch 1986]: seen 198600 examples : 66.6 eps, Loss: 5.128, Avg loss: 5.097, Best loss: 5.096\n",
      "    [batch 1993]: seen 199300 examples : 66.6 eps, Loss: 5.101, Avg loss: 5.096, Best loss: 5.095\n",
      "    [batch 2000]: seen 200000 examples : 66.6 eps, Loss: 5.118, Avg loss: 5.096, Best loss: 5.094\n",
      "    [batch 2007]: seen 200700 examples : 66.6 eps, Loss: 5.213, Avg loss: 5.097, Best loss: 5.094\n",
      "    [batch 2014]: seen 201400 examples : 66.7 eps, Loss: 5.026, Avg loss: 5.093, Best loss: 5.093\n",
      "    [batch 2021]: seen 202100 examples : 66.7 eps, Loss: 5.109, Avg loss: 5.095, Best loss: 5.093\n",
      "    [batch 2028]: seen 202800 examples : 66.7 eps, Loss: 5.155, Avg loss: 5.096, Best loss: 5.093\n",
      "    [batch 2035]: seen 203500 examples : 66.7 eps, Loss: 5.130, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2042]: seen 204200 examples : 66.7 eps, Loss: 5.113, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2049]: seen 204900 examples : 66.7 eps, Loss: 5.069, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2056]: seen 205600 examples : 66.7 eps, Loss: 5.015, Avg loss: 5.101, Best loss: 5.093\n",
      "    [batch 2063]: seen 206300 examples : 66.7 eps, Loss: 5.222, Avg loss: 5.102, Best loss: 5.093\n",
      "    [batch 2070]: seen 207000 examples : 66.7 eps, Loss: 5.039, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2077]: seen 207700 examples : 66.7 eps, Loss: 5.180, Avg loss: 5.101, Best loss: 5.093\n",
      "    [batch 2084]: seen 208400 examples : 66.7 eps, Loss: 5.143, Avg loss: 5.100, Best loss: 5.093\n",
      "    [batch 2091]: seen 209100 examples : 66.7 eps, Loss: 5.066, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2098]: seen 209800 examples : 66.7 eps, Loss: 5.021, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2105]: seen 210500 examples : 66.7 eps, Loss: 5.136, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2112]: seen 211200 examples : 66.7 eps, Loss: 5.144, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2119]: seen 211900 examples : 66.7 eps, Loss: 5.036, Avg loss: 5.097, Best loss: 5.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2126]: seen 212600 examples : 66.7 eps, Loss: 5.165, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2133]: seen 213300 examples : 66.7 eps, Loss: 5.039, Avg loss: 5.100, Best loss: 5.093\n",
      "    [batch 2140]: seen 214000 examples : 66.7 eps, Loss: 5.006, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2147]: seen 214700 examples : 66.7 eps, Loss: 5.105, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2154]: seen 215400 examples : 66.7 eps, Loss: 5.092, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2161]: seen 216100 examples : 66.7 eps, Loss: 5.115, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2168]: seen 216800 examples : 66.8 eps, Loss: 5.150, Avg loss: 5.100, Best loss: 5.093\n",
      "    [batch 2175]: seen 217500 examples : 66.8 eps, Loss: 5.071, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2182]: seen 218200 examples : 66.8 eps, Loss: 5.054, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2189]: seen 218900 examples : 66.8 eps, Loss: 5.039, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2196]: seen 219600 examples : 66.8 eps, Loss: 5.154, Avg loss: 5.100, Best loss: 5.093\n",
      "    [batch 2203]: seen 220300 examples : 66.8 eps, Loss: 5.022, Avg loss: 5.100, Best loss: 5.093\n",
      "    [batch 2210]: seen 221000 examples : 66.8 eps, Loss: 5.091, Avg loss: 5.100, Best loss: 5.093\n",
      "    [batch 2217]: seen 221700 examples : 66.8 eps, Loss: 5.173, Avg loss: 5.099, Best loss: 5.093\n",
      "    [batch 2224]: seen 222400 examples : 66.8 eps, Loss: 5.171, Avg loss: 5.098, Best loss: 5.093\n",
      "    [batch 2231]: seen 223100 examples : 66.8 eps, Loss: 5.099, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2238]: seen 223800 examples : 66.8 eps, Loss: 5.136, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2245]: seen 224500 examples : 66.8 eps, Loss: 5.132, Avg loss: 5.096, Best loss: 5.093\n",
      "    [batch 2252]: seen 225200 examples : 66.8 eps, Loss: 5.084, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2259]: seen 225900 examples : 66.8 eps, Loss: 5.131, Avg loss: 5.096, Best loss: 5.093\n",
      "    [batch 2266]: seen 226600 examples : 66.8 eps, Loss: 5.205, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2273]: seen 227300 examples : 66.8 eps, Loss: 5.071, Avg loss: 5.096, Best loss: 5.093\n",
      "    [batch 2280]: seen 228000 examples : 66.8 eps, Loss: 5.067, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2287]: seen 228700 examples : 66.8 eps, Loss: 5.037, Avg loss: 5.096, Best loss: 5.093\n",
      "    [batch 2294]: seen 229400 examples : 66.8 eps, Loss: 5.029, Avg loss: 5.097, Best loss: 5.093\n",
      "    [batch 2301]: seen 230100 examples : 66.8 eps, Loss: 5.101, Avg loss: 5.095, Best loss: 5.093\n",
      "    [batch 2308]: seen 230800 examples : 66.8 eps, Loss: 5.056, Avg loss: 5.093, Best loss: 5.093\n",
      "    [batch 2315]: seen 231500 examples : 66.8 eps, Loss: 5.084, Avg loss: 5.093, Best loss: 5.092\n",
      "    [batch 2322]: seen 232200 examples : 66.8 eps, Loss: 5.010, Avg loss: 5.093, Best loss: 5.092\n",
      "    [batch 2329]: seen 232900 examples : 66.9 eps, Loss: 5.076, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2336]: seen 233600 examples : 66.9 eps, Loss: 5.022, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2343]: seen 234300 examples : 66.9 eps, Loss: 5.116, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2350]: seen 235000 examples : 66.9 eps, Loss: 5.148, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2357]: seen 235700 examples : 66.9 eps, Loss: 5.099, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2364]: seen 236400 examples : 66.9 eps, Loss: 5.084, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2371]: seen 237100 examples : 66.9 eps, Loss: 5.162, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2378]: seen 237800 examples : 66.9 eps, Loss: 5.176, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2385]: seen 238500 examples : 66.9 eps, Loss: 5.196, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2392]: seen 239200 examples : 66.9 eps, Loss: 5.089, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2399]: seen 239900 examples : 66.9 eps, Loss: 5.135, Avg loss: 5.094, Best loss: 5.091\n",
      "    [batch 2406]: seen 240600 examples : 66.9 eps, Loss: 5.068, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2413]: seen 241300 examples : 66.9 eps, Loss: 5.092, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2420]: seen 242000 examples : 66.9 eps, Loss: 4.947, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2427]: seen 242700 examples : 66.9 eps, Loss: 5.125, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2434]: seen 243400 examples : 66.9 eps, Loss: 5.245, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2441]: seen 244100 examples : 66.9 eps, Loss: 5.104, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2448]: seen 244800 examples : 66.9 eps, Loss: 5.127, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2455]: seen 245500 examples : 66.9 eps, Loss: 5.061, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2462]: seen 246200 examples : 66.9 eps, Loss: 4.988, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2469]: seen 246900 examples : 66.9 eps, Loss: 4.964, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2476]: seen 247600 examples : 66.9 eps, Loss: 4.960, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2483]: seen 248300 examples : 66.9 eps, Loss: 5.024, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2490]: seen 249000 examples : 66.9 eps, Loss: 4.971, Avg loss: 5.093, Best loss: 5.091\n",
      "    [batch 2497]: seen 249700 examples : 66.9 eps, Loss: 5.066, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2504]: seen 250400 examples : 66.9 eps, Loss: 5.056, Avg loss: 5.091, Best loss: 5.091\n",
      "    [batch 2511]: seen 251100 examples : 66.9 eps, Loss: 5.236, Avg loss: 5.094, Best loss: 5.091\n",
      "    [batch 2518]: seen 251800 examples : 66.9 eps, Loss: 5.100, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2525]: seen 252500 examples : 66.9 eps, Loss: 5.129, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2532]: seen 253200 examples : 67.0 eps, Loss: 5.145, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2539]: seen 253900 examples : 67.0 eps, Loss: 5.026, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2546]: seen 254600 examples : 67.0 eps, Loss: 4.986, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2553]: seen 255300 examples : 67.0 eps, Loss: 5.097, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2560]: seen 256000 examples : 67.0 eps, Loss: 5.028, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2567]: seen 256700 examples : 67.0 eps, Loss: 5.025, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2574]: seen 257400 examples : 67.0 eps, Loss: 5.126, Avg loss: 5.097, Best loss: 5.091\n",
      "    [batch 2581]: seen 258100 examples : 67.0 eps, Loss: 5.182, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2588]: seen 258800 examples : 67.0 eps, Loss: 5.167, Avg loss: 5.098, Best loss: 5.091\n",
      "    [batch 2595]: seen 259500 examples : 67.0 eps, Loss: 5.043, Avg loss: 5.096, Best loss: 5.091\n",
      "    [batch 2602]: seen 260200 examples : 67.0 eps, Loss: 5.131, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2609]: seen 260900 examples : 67.0 eps, Loss: 5.057, Avg loss: 5.095, Best loss: 5.091\n",
      "    [batch 2616]: seen 261600 examples : 67.0 eps, Loss: 5.085, Avg loss: 5.093, Best loss: 5.091\n",
      "    [batch 2623]: seen 262300 examples : 67.0 eps, Loss: 5.161, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2630]: seen 263000 examples : 67.0 eps, Loss: 5.049, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2637]: seen 263700 examples : 67.0 eps, Loss: 5.082, Avg loss: 5.093, Best loss: 5.091\n",
      "    [batch 2644]: seen 264400 examples : 67.0 eps, Loss: 5.101, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2651]: seen 265100 examples : 67.0 eps, Loss: 5.105, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2658]: seen 265800 examples : 67.0 eps, Loss: 5.183, Avg loss: 5.092, Best loss: 5.091\n",
      "    [batch 2665]: seen 266500 examples : 67.0 eps, Loss: 5.013, Avg loss: 5.091, Best loss: 5.091\n",
      "    [batch 2672]: seen 267200 examples : 67.0 eps, Loss: 5.028, Avg loss: 5.089, Best loss: 5.089\n",
      "    [batch 2679]: seen 267900 examples : 67.0 eps, Loss: 5.062, Avg loss: 5.089, Best loss: 5.088\n",
      "    [batch 2686]: seen 268600 examples : 67.0 eps, Loss: 5.045, Avg loss: 5.090, Best loss: 5.088\n",
      "    [batch 2693]: seen 269300 examples : 67.0 eps, Loss: 5.018, Avg loss: 5.087, Best loss: 5.087\n",
      "    [batch 2700]: seen 270000 examples : 67.0 eps, Loss: 5.105, Avg loss: 5.086, Best loss: 5.085\n",
      "    [batch 2707]: seen 270700 examples : 67.0 eps, Loss: 5.136, Avg loss: 5.085, Best loss: 5.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 2714]: seen 271400 examples : 67.0 eps, Loss: 5.114, Avg loss: 5.085, Best loss: 5.084\n",
      "    [batch 2721]: seen 272100 examples : 67.0 eps, Loss: 5.050, Avg loss: 5.086, Best loss: 5.084\n",
      "    [batch 2728]: seen 272800 examples : 67.0 eps, Loss: 5.188, Avg loss: 5.088, Best loss: 5.084\n",
      "    [batch 2735]: seen 273500 examples : 67.0 eps, Loss: 5.147, Avg loss: 5.088, Best loss: 5.084\n",
      "    [batch 2742]: seen 274200 examples : 67.0 eps, Loss: 5.039, Avg loss: 5.087, Best loss: 5.084\n",
      "    [batch 2749]: seen 274900 examples : 67.0 eps, Loss: 5.049, Avg loss: 5.085, Best loss: 5.084\n",
      "    [batch 2756]: seen 275600 examples : 67.0 eps, Loss: 5.027, Avg loss: 5.084, Best loss: 5.084\n",
      "    [batch 2763]: seen 276300 examples : 67.0 eps, Loss: 5.102, Avg loss: 5.083, Best loss: 5.082\n",
      "    [batch 2770]: seen 277000 examples : 67.0 eps, Loss: 5.082, Avg loss: 5.084, Best loss: 5.082\n",
      "    [batch 2777]: seen 277700 examples : 67.0 eps, Loss: 5.076, Avg loss: 5.083, Best loss: 5.082\n",
      "    [batch 2784]: seen 278400 examples : 67.0 eps, Loss: 5.053, Avg loss: 5.083, Best loss: 5.082\n",
      "    [batch 2791]: seen 279100 examples : 67.0 eps, Loss: 4.965, Avg loss: 5.084, Best loss: 5.082\n",
      "    [batch 2798]: seen 279800 examples : 67.1 eps, Loss: 5.090, Avg loss: 5.084, Best loss: 5.082\n",
      "    [batch 2805]: seen 280500 examples : 67.1 eps, Loss: 5.141, Avg loss: 5.083, Best loss: 5.082\n",
      "    [END] Training complete: Total examples : 280700; Total time: 1:09:47\n",
      "[EPOCH 13] Complete. Avg Loss: 5.084213840207764; Best Loss: 5.082348749943124\n",
      "[EPOCH 14] Starting training..\n",
      "    [batch 9]: seen 900 examples : 87.2 eps, Loss: 4.975, Avg loss: 5.080, Best loss: 5.080\n",
      "    [batch 16]: seen 1600 examples : 77.1 eps, Loss: 5.136, Avg loss: 5.077, Best loss: 5.076\n",
      "    [batch 23]: seen 2300 examples : 74.4 eps, Loss: 5.054, Avg loss: 5.078, Best loss: 5.076\n",
      "    [batch 30]: seen 3000 examples : 73.1 eps, Loss: 4.957, Avg loss: 5.077, Best loss: 5.076\n",
      "    [batch 37]: seen 3700 examples : 72.3 eps, Loss: 5.090, Avg loss: 5.074, Best loss: 5.074\n",
      "    [batch 44]: seen 4400 examples : 71.8 eps, Loss: 5.100, Avg loss: 5.073, Best loss: 5.073\n",
      "    [batch 51]: seen 5100 examples : 71.4 eps, Loss: 5.144, Avg loss: 5.071, Best loss: 5.070\n",
      "    [batch 58]: seen 5800 examples : 71.1 eps, Loss: 4.950, Avg loss: 5.070, Best loss: 5.070\n",
      "    [batch 65]: seen 6500 examples : 70.8 eps, Loss: 5.018, Avg loss: 5.070, Best loss: 5.070\n",
      "    [batch 72]: seen 7200 examples : 70.6 eps, Loss: 5.010, Avg loss: 5.068, Best loss: 5.068\n",
      "    [batch 79]: seen 7900 examples : 70.4 eps, Loss: 5.199, Avg loss: 5.069, Best loss: 5.066\n",
      "    [batch 86]: seen 8600 examples : 70.2 eps, Loss: 5.008, Avg loss: 5.066, Best loss: 5.066\n",
      "    [batch 93]: seen 9300 examples : 70.1 eps, Loss: 5.129, Avg loss: 5.065, Best loss: 5.065\n",
      "    [batch 100]: seen 10000 examples : 69.7 eps, Loss: 4.993, Avg loss: 5.062, Best loss: 5.061\n",
      "    [batch 107]: seen 10700 examples : 69.7 eps, Loss: 5.023, Avg loss: 5.063, Best loss: 5.061\n",
      "    [batch 114]: seen 11400 examples : 69.6 eps, Loss: 5.052, Avg loss: 5.063, Best loss: 5.061\n",
      "    [batch 121]: seen 12100 examples : 69.5 eps, Loss: 5.052, Avg loss: 5.062, Best loss: 5.061\n",
      "    [batch 128]: seen 12800 examples : 69.5 eps, Loss: 5.109, Avg loss: 5.064, Best loss: 5.061\n",
      "    [batch 135]: seen 13500 examples : 69.4 eps, Loss: 5.052, Avg loss: 5.064, Best loss: 5.061\n",
      "    [batch 142]: seen 14200 examples : 69.3 eps, Loss: 5.108, Avg loss: 5.066, Best loss: 5.061\n",
      "    [batch 149]: seen 14900 examples : 69.3 eps, Loss: 5.115, Avg loss: 5.069, Best loss: 5.061\n",
      "    [batch 156]: seen 15600 examples : 69.2 eps, Loss: 5.052, Avg loss: 5.066, Best loss: 5.061\n",
      "    [batch 163]: seen 16300 examples : 69.2 eps, Loss: 5.127, Avg loss: 5.067, Best loss: 5.061\n",
      "    [batch 170]: seen 17000 examples : 69.2 eps, Loss: 5.110, Avg loss: 5.070, Best loss: 5.061\n",
      "    [batch 177]: seen 17700 examples : 69.1 eps, Loss: 5.070, Avg loss: 5.071, Best loss: 5.061\n",
      "    [batch 184]: seen 18400 examples : 69.1 eps, Loss: 5.011, Avg loss: 5.073, Best loss: 5.061\n",
      "    [batch 191]: seen 19100 examples : 69.1 eps, Loss: 5.052, Avg loss: 5.074, Best loss: 5.061\n",
      "    [batch 198]: seen 19800 examples : 69.0 eps, Loss: 5.114, Avg loss: 5.074, Best loss: 5.061\n",
      "    [batch 205]: seen 20500 examples : 68.9 eps, Loss: 5.003, Avg loss: 5.075, Best loss: 5.061\n",
      "    [batch 212]: seen 21200 examples : 68.9 eps, Loss: 5.110, Avg loss: 5.075, Best loss: 5.061\n",
      "    [batch 219]: seen 21900 examples : 68.9 eps, Loss: 5.016, Avg loss: 5.076, Best loss: 5.061\n",
      "    [batch 226]: seen 22600 examples : 68.8 eps, Loss: 5.123, Avg loss: 5.079, Best loss: 5.061\n",
      "    [batch 233]: seen 23300 examples : 68.7 eps, Loss: 4.972, Avg loss: 5.079, Best loss: 5.061\n",
      "    [batch 240]: seen 24000 examples : 68.7 eps, Loss: 5.063, Avg loss: 5.077, Best loss: 5.061\n",
      "    [batch 247]: seen 24700 examples : 68.7 eps, Loss: 5.022, Avg loss: 5.074, Best loss: 5.061\n",
      "    [batch 254]: seen 25400 examples : 68.7 eps, Loss: 5.057, Avg loss: 5.071, Best loss: 5.061\n",
      "    [batch 261]: seen 26100 examples : 68.7 eps, Loss: 5.062, Avg loss: 5.073, Best loss: 5.061\n",
      "    [batch 268]: seen 26800 examples : 68.7 eps, Loss: 5.139, Avg loss: 5.074, Best loss: 5.061\n",
      "    [batch 275]: seen 27500 examples : 68.7 eps, Loss: 5.010, Avg loss: 5.070, Best loss: 5.061\n",
      "    [batch 282]: seen 28200 examples : 68.7 eps, Loss: 5.045, Avg loss: 5.068, Best loss: 5.061\n",
      "    [batch 289]: seen 28900 examples : 68.7 eps, Loss: 5.030, Avg loss: 5.071, Best loss: 5.061\n",
      "    [batch 296]: seen 29600 examples : 68.6 eps, Loss: 4.999, Avg loss: 5.072, Best loss: 5.061\n",
      "    [batch 303]: seen 30300 examples : 68.6 eps, Loss: 5.070, Avg loss: 5.069, Best loss: 5.061\n",
      "    [batch 310]: seen 31000 examples : 68.6 eps, Loss: 5.141, Avg loss: 5.070, Best loss: 5.061\n",
      "    [batch 317]: seen 31700 examples : 68.6 eps, Loss: 5.074, Avg loss: 5.070, Best loss: 5.061\n",
      "    [batch 324]: seen 32400 examples : 68.6 eps, Loss: 4.991, Avg loss: 5.069, Best loss: 5.061\n",
      "    [batch 331]: seen 33100 examples : 68.6 eps, Loss: 5.001, Avg loss: 5.069, Best loss: 5.061\n",
      "    [batch 338]: seen 33800 examples : 68.6 eps, Loss: 5.102, Avg loss: 5.072, Best loss: 5.061\n",
      "    [batch 345]: seen 34500 examples : 68.5 eps, Loss: 5.040, Avg loss: 5.070, Best loss: 5.061\n",
      "    [batch 352]: seen 35200 examples : 68.5 eps, Loss: 5.030, Avg loss: 5.068, Best loss: 5.061\n",
      "    [batch 359]: seen 35900 examples : 68.5 eps, Loss: 5.108, Avg loss: 5.066, Best loss: 5.061\n",
      "    [batch 366]: seen 36600 examples : 68.5 eps, Loss: 5.027, Avg loss: 5.066, Best loss: 5.061\n",
      "    [batch 373]: seen 37300 examples : 68.5 eps, Loss: 5.126, Avg loss: 5.064, Best loss: 5.061\n",
      "    [batch 380]: seen 38000 examples : 68.5 eps, Loss: 5.052, Avg loss: 5.062, Best loss: 5.061\n",
      "    [batch 387]: seen 38700 examples : 68.5 eps, Loss: 5.111, Avg loss: 5.061, Best loss: 5.060\n",
      "    [batch 394]: seen 39400 examples : 68.5 eps, Loss: 5.051, Avg loss: 5.060, Best loss: 5.060\n",
      "    [batch 401]: seen 40100 examples : 68.5 eps, Loss: 5.023, Avg loss: 5.060, Best loss: 5.060\n",
      "    [batch 408]: seen 40800 examples : 68.5 eps, Loss: 5.040, Avg loss: 5.057, Best loss: 5.057\n",
      "    [batch 415]: seen 41500 examples : 68.5 eps, Loss: 5.044, Avg loss: 5.059, Best loss: 5.057\n",
      "    [batch 422]: seen 42200 examples : 68.4 eps, Loss: 4.944, Avg loss: 5.057, Best loss: 5.057\n",
      "    [batch 429]: seen 42900 examples : 68.4 eps, Loss: 5.008, Avg loss: 5.060, Best loss: 5.057\n",
      "    [batch 436]: seen 43600 examples : 68.4 eps, Loss: 5.209, Avg loss: 5.061, Best loss: 5.057\n",
      "    [batch 443]: seen 44300 examples : 68.4 eps, Loss: 4.935, Avg loss: 5.059, Best loss: 5.057\n",
      "    [batch 450]: seen 45000 examples : 68.4 eps, Loss: 5.033, Avg loss: 5.058, Best loss: 5.057\n",
      "    [batch 457]: seen 45700 examples : 68.4 eps, Loss: 5.005, Avg loss: 5.056, Best loss: 5.056\n",
      "    [batch 464]: seen 46400 examples : 68.4 eps, Loss: 5.172, Avg loss: 5.059, Best loss: 5.056\n",
      "    [batch 471]: seen 47100 examples : 68.4 eps, Loss: 4.974, Avg loss: 5.060, Best loss: 5.056\n",
      "    [batch 478]: seen 47800 examples : 68.4 eps, Loss: 5.151, Avg loss: 5.062, Best loss: 5.056\n",
      "    [batch 485]: seen 48500 examples : 68.4 eps, Loss: 5.099, Avg loss: 5.062, Best loss: 5.056\n",
      "    [batch 492]: seen 49200 examples : 68.3 eps, Loss: 4.976, Avg loss: 5.062, Best loss: 5.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [batch 499]: seen 49900 examples : 68.3 eps, Loss: 5.004, Avg loss: 5.062, Best loss: 5.056\n",
      "    [batch 506]: seen 50600 examples : 68.3 eps, Loss: 5.058, Avg loss: 5.060, Best loss: 5.056\n",
      "    [batch 513]: seen 51300 examples : 68.3 eps, Loss: 4.980, Avg loss: 5.056, Best loss: 5.056\n",
      "    [batch 520]: seen 52000 examples : 68.3 eps, Loss: 5.110, Avg loss: 5.057, Best loss: 5.056\n",
      "    [batch 527]: seen 52700 examples : 68.3 eps, Loss: 5.098, Avg loss: 5.057, Best loss: 5.056\n",
      "    [batch 534]: seen 53400 examples : 68.3 eps, Loss: 4.984, Avg loss: 5.056, Best loss: 5.056\n",
      "    [batch 541]: seen 54100 examples : 68.3 eps, Loss: 4.950, Avg loss: 5.054, Best loss: 5.054\n",
      "    [batch 548]: seen 54800 examples : 68.3 eps, Loss: 5.157, Avg loss: 5.057, Best loss: 5.054\n",
      "    [batch 555]: seen 55500 examples : 68.3 eps, Loss: 5.049, Avg loss: 5.060, Best loss: 5.054\n",
      "    [batch 562]: seen 56200 examples : 68.3 eps, Loss: 5.116, Avg loss: 5.061, Best loss: 5.054\n",
      "    [batch 569]: seen 56900 examples : 68.3 eps, Loss: 5.057, Avg loss: 5.063, Best loss: 5.054\n",
      "    [batch 576]: seen 57600 examples : 68.3 eps, Loss: 5.040, Avg loss: 5.061, Best loss: 5.054\n",
      "    [batch 583]: seen 58300 examples : 68.3 eps, Loss: 5.159, Avg loss: 5.059, Best loss: 5.054\n",
      "    [batch 590]: seen 59000 examples : 68.3 eps, Loss: 4.976, Avg loss: 5.058, Best loss: 5.054\n",
      "    [batch 597]: seen 59700 examples : 68.3 eps, Loss: 4.941, Avg loss: 5.057, Best loss: 5.054\n",
      "    [batch 604]: seen 60400 examples : 68.3 eps, Loss: 5.112, Avg loss: 5.059, Best loss: 5.054\n",
      "    [batch 611]: seen 61100 examples : 68.3 eps, Loss: 5.089, Avg loss: 5.058, Best loss: 5.054\n",
      "    [batch 618]: seen 61800 examples : 68.3 eps, Loss: 5.077, Avg loss: 5.058, Best loss: 5.054\n",
      "    [batch 625]: seen 62500 examples : 68.3 eps, Loss: 4.988, Avg loss: 5.056, Best loss: 5.054\n",
      "    [batch 632]: seen 63200 examples : 68.3 eps, Loss: 5.029, Avg loss: 5.056, Best loss: 5.054\n",
      "    [batch 639]: seen 63900 examples : 68.3 eps, Loss: 4.983, Avg loss: 5.055, Best loss: 5.054\n",
      "    [batch 646]: seen 64600 examples : 68.3 eps, Loss: 5.125, Avg loss: 5.056, Best loss: 5.054\n",
      "    [batch 653]: seen 65300 examples : 68.3 eps, Loss: 5.024, Avg loss: 5.054, Best loss: 5.054\n",
      "    [batch 660]: seen 66000 examples : 68.2 eps, Loss: 4.968, Avg loss: 5.053, Best loss: 5.053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8e676984ed07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f4099322d632>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(hps, epochs, train_step, curr_best, best_loss, avg_loss, restore, epoch_start)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                             \u001b[0mhps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                                             \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                                             avg_loss)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcurr_best\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/W266/final_0/W266_Final/model_3/training_util.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(lm, session, batches, summary_writer, train_dir, train_step, saver, hps, best_loss, avg_loss, save_all)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunTrainStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/W266/final_0/W266_Final/model_3/training_util.py\u001b[0m in \u001b[0;36mrunTrainStep\u001b[0;34m(lm, session, batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m     }\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "best_loss = None\n",
    "curr_best = best_loss\n",
    "train_step = 0\n",
    "epochs = 15\n",
    "restore = False\n",
    "epoch_start = 0\n",
    "\n",
    "train(hps,epochs,train_step,curr_best,best_loss,avg_loss,restore,epoch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
